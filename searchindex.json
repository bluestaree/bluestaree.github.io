{"categories":[{"title":"Netty","uri":"https://bluestaree.github.io/categories/netty/"},{"title":"SpringBoot","uri":"https://bluestaree.github.io/categories/springboot/"},{"title":"数据结构与算法","uri":"https://bluestaree.github.io/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"},{"title":"笔记","uri":"https://bluestaree.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"posts":[{"content":"  概述：Redisson是架设在Redis基础上的一个Java驻内存数据网格。简单来说就是Redis分布式锁对于Java语言的实现，其提供的许多分布式服务，本文介绍了如何使用Redisson来实现分布式锁，以及其他几种常用的分布式锁\n 简单实现 1.引入依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;3.12.0\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 2.配置Redisson客户端\n@Configuration\rpublic class MyRedissonConfig {\r@Bean(destroyMethod = \u0026quot;shutdown\u0026quot;)\rpublic RedissonClient redisson() throws IOException {\rConfig config = new Config();\r//config.useClusterServers( )\t//集群配置\r//.addNodeAddress(\u0026quot;127.0.8.1:7004\u0026quot;，\u0026quot;127.0.0.1:6379\u0026quot;);\r//单节点配置 可以用\u0026quot;rediss://\u0026quot;来启用SSL连接\rconfig.useSingleServer().setAddress(\u0026quot;redis://127.0.0.1:6379\u0026quot;);\rreturn Redisson.create(config);\r}\r}\r 3.测试Controller\n@GetMapping(\u0026quot;/hello\u0026quot;)\rpublic String hello(){\r//1、获取一把锁，只要锁的名字一样，就是同一把锁\rRLock lock = redisson.getLock(\u0026quot;my-lock\u0026quot;);\r//2.加锁\rlock.lock(); //阻塞式等待。默认加的锁存活时间为30s。\r//看门狗机制：\r//1)、锁的自动续期，如果业务超长，运行期间会自动给锁续上新的30s。不用担心业务时间长，锁自动过期被删掉\r//2)、加锁的业务只要运行完成，就不会给当前锁续期，即使不手动解锁，锁默认在30s以后自动删除。\rtry {\rSystem.out.println(\u0026quot;加锁成功... \u0026quot; + Thread.currentThread().getId());\rThread.sleep(30000); //模拟执行耗时业务\rreturn \u0026quot;hello\u0026quot;;\r} catch (Exception e) {\r} finally {\r//3、解锁\rSystem.out.println(\u0026quot;释放锁...\u0026quot; + Thread.currentThread().getId());\rlock.unlock();\r}\rreturn \u0026quot;Throw Exception！\u0026quot;;\r}\r 可通过设置虚拟机参数启动多个服务，模拟集群环境下进行测试\n初次访问时，加锁成功，控制台输出内容：\n加锁成功... 60\n等待30s后业务逻辑执行完成，释放锁，控制台输出内容：\n释放锁...60\nRedis中存储的分布式锁信息如下图：\n在浏览器中同时访问多个服务，\n此时控制台输出内容\n加锁成功... 60\n释放锁...60\n加锁成功... 67\n释放锁...67\n这样一个简单的分布式锁就添加成功了，现在每一个进程都需要获取在获取锁后才能进行进一步的业务处理。我们\n就可以根据这一点结合缓存，有效的预防缓存击穿等问题。\nRedisson 看门狗机制 在我们进行测试的时候有一个问题，可以明显的发现，在Redis上存储的分布式锁的有效时间为30s，而且当这个\n值减少到19s时，存活时间又重新刷新为30s。\n这就redisson的看门狗机制。\n让我们先来看看redisson里的Lock方法源码\npublic void lock() {\rtry {\rthis.lock(-1L, (TimeUnit)null, false);\r} catch (InterruptedException var2) {\rthrow new IllegalStateException();\r}\r}\r 接下来会调用另一个带参数的重载方法，我们可以进去直接看其中尝试获取锁的那段源码\nprivate \u0026lt;T\u0026gt; RFuture\u0026lt;Long\u0026gt; tryAcquireAsync(long leaseTime, TimeUnit unit, long threadId) {\rif (leaseTime != -1L) {\rreturn this.tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG);\r} else {\rRFuture\u0026lt;Long\u0026gt; ttlRemainingFuture = this.tryLockInnerAsync(this.commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);\rttlRemainingFuture.onComplete((ttlRemaining, e) -\u0026gt; {\rif (e == null) {\rif (ttlRemaining == null) {\rthis.scheduleExpirationRenewal(threadId);\r}\r}\r});\rreturn ttlRemainingFuture;\r}\r}\r 可以看到，如果我们没有传入指定锁的存活时间，也就是上面的leaseTim变量的值，默认是-1,\n此时走else路线，其中redisson默认将锁的存活时间设置为30s\nthis.lockWatchdogTimeout = 30000L;\r 接下来 ，可以看到一个重要的方法scheduleExpirationRenewal() ,根据名称有一个大概的理解，就是一个到期续\n订的定时任务。\n继续跟踪源码，可以看到最主要的方法renewExpiration()，在这里面就创建了一个定时任务task，\n并且延迟10s执行一次，其中又进行递归调用，相当于每隔10s执行一次，直到我们的业务逻辑执行完毕\nprivate void renewExpiration() {\rRedissonLock.ExpirationEntry ee = (RedissonLock.ExpirationEntry)EXPIRATION_RENEWAL_MAP.get(this.getEntryName());\rif (ee != null) {\rTimeout task = this.commandExecutor.getConnectionManager().newTimeout(new TimerTask() {\rpublic void run(Timeout timeout) throws Exception {\rRedissonLock.ExpirationEntry ent = (RedissonLock.ExpirationEntry)RedissonLock.EXPIRATION_RENEWAL_MAP.get(RedissonLock.this.getEntryName());\rif (ent != null) {\rLong threadId = ent.getFirstThreadId();\rif (threadId != null) {\rRFuture\u0026lt;Boolean\u0026gt; future = RedissonLock.this.renewExpirationAsync(threadId);\rfuture.onComplete((res, e) -\u0026gt; {\rif (e != null) {\rRedissonLock.log.error(\u0026quot;Can't update lock \u0026quot; + RedissonLock.this.getName() + \u0026quot; expiration\u0026quot;, e);\r} else {\rif (res) {\rRedissonLock.this.renewExpiration();\r}\r}\r});\r}\r}\r}\r}, this.internalLockLeaseTime / 3L, TimeUnit.MILLISECONDS);\ree.setTimeout(task);\r}\r}\r 当然我们也可以进入renewExpirationAsync()方法中查看刷新锁存活时间所执行的Lua脚本\nif (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then redis.call('pexpire', KEYS[1], ARGV[1]); return 1; end; return 0;\r 最佳实践，使用时，手动指定过期时间，可以省去整个续期操作\n常见的分布式锁 可重入锁 先看看已下伪代码\na() {\rb();\r}\r 在A方法中调用了B方法，此时A方法需要获取C锁，往下执行，B方法也需要获取C锁，如果C锁为不可重入锁，那\n就需要首先等待A方法释放C锁，而A方法又需要等待B方法执行完成才能释放C锁，这就产生了死锁的问题。如果C\n锁为可重入锁，那么A方法与B方法都同时持有C锁，\n常用的方法\nRlock lock = redisson.getLock(\u0026quot;lock\u0026quot;)\r//加锁\rlock.lock();\r//尝试加锁\rlock.tryLock();\r//释放锁\rlock.unlock();\r 公平锁 顾名思义，所有线程在获取锁时需要顺序的获取，就像日常排队一样。Redisisson默认为非公平锁\n常用的方法\nRlock fireLock = redisson.getFairLock(\u0026quot;fireLock\u0026quot;)\rfireLock.lock();\rfireLock.unlock();\r 读写锁 保证一定能读到最新状态，读锁可以在没有写锁的时候被多个线程同时持有（共享锁），写锁是独占的(排他锁/独\n享锁)。 每次只能有一个写线程，但是可以有多个线程并发地读数据。\n分布式可重入读写锁允许同时有多个读锁和一个写锁处于加锁状态。\n常用的方法\nRReadWriteLock rwlock = redisson.getReadWriteLock(\u0026quot;anyRWLock\u0026quot;);\r//加读锁\rrwlock.readLock().lock();\r//加写锁\rrwlock.writeLock().lock();\r 常见情况分析\n 读+读 ：相当于无锁，并发读，只会在redis中记录好，所有当前的读锁。会同时加锁成功 写+读 ：等待写锁释放 写+写 ：阻塞方式，需等待上一个写锁释放 读+写 ：有读锁，写也需要等待。  总结：只要有写的存在，都必须等待\n信号量 可以限制同时访问共享区域的线程数量，即限流。\n信号量总数存储于Redis的一个key(可自定义)中，每次申请都会将该key对应的value值减去1，直到数量为0，不能\n再次申请。反之，当释放许可时，每次操作都会将其值加上1。\n比喻：相当于一个停车场，来一辆车，可用的车库数就减少一，走一辆，可用的车库数就增加一。\n常用的方法\nRSemaphore semaphore = redisson.getSemaphore(\u0026quot;semaphore\u0026quot;);\r//获取23个信号量，如果无法获取，会一直等待，阻塞方法\rsemaphore.acquire(23);\r//尝试获取1个信号量，无法获取时，返回false\rsemaphore.tryAcquire(); //释放信号量\rsemaphore.release();  闭锁 需要等待其他线程闭锁都执行完成后，才可以开始执行闭锁中的逻辑\n常用的方法\nRCountDownLatch latch = redisson.getCountDownLatch(\u0026quot;anyCountDownLatch\u0026quot;);\r//设置闭锁数量\rlatch.trySetCount(1);\r//等待其他闭锁都执行完成\rlatch.await();\r//在其他线程或其他JVM里\rRCountDownLatch latch = redisson.getCountDownLatch(\u0026quot;anyCountDownLatch\u0026quot;);\r//完成，闭锁数减一\rlatch.countDown();\r ","id":0,"section":"posts","summary":"概述：Redisson是架设在Redis基础上的一个Java驻内存数据网格。简单来说就是Redis分布式锁对于Java语言的实现，其提供的许","tags":["缓存","redisson"],"title":"分布式锁实现-Redisson","uri":"https://bluestaree.github.io/2020/06/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0-redisson/","year":"2020"},{"content":" 缓存穿透 指查询一个一定不存在的数据，由于缓存是不命中，将去查询数据库，但是数据库也无此记录，我们没有将这次查\n询的nulI写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义\n风险:\n他人恶意利用不存在的数据进行攻击，数据库瞬时压力增大，最终导致崩溃\n解决:\n 对于查询不到的结果，可以存为null，并加入短暂过期时间 (可能会导致大量无效key) 使用布隆过滤器，过滤无效请求，拒绝访问（存在误判情况）   缓存雪崩 缓存雪崩是指在我们设置缓存时key采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，\n导致DB瞬时压力过重而崩溃。\n解决:\n原有的失效时间基础上增加一个随机值，不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀，这样\n每一个缓存的过期时间的重复率就会降低，很难引发集体失效的事件。\n 缓存击穿 对于一些设置了过期时间的 key，如果这些 key 可能会在某些时间点被超高并发地访问，是一种非常“热点”的数\n据。如果这个 key 在大量请求同时进来前正好失效，那么所有对这个 key 的数据查询就会直接落到 DB\n解决:\n  加锁。大量并发只让一个去查， 其他人等待，查到以后释放锁，其他人获取到锁，先查缓存，就会有数据，不用去db\n 本地锁 :Synchronized,Lock等  问题：因为Spring容器单例的特点，所以能锁住当前进程资源，即使有百万并发，也只有1个线程访问DB\n但在分布式下，必须使用分布式锁，因为不同服务器进程不同，锁对象也就不同，会存在多余线程请求DB\n的情况\n 分布式锁  使用Redis进行分布式锁的创建(SETNX) 原子加锁\n语法： Set [key] [value] [EX设置过期时间，秒)] [NX] (不存在才设置)\n举个栗子：Set lock uuid EX 300 NX\n每个线程采取自旋的形式周期性尝试获取锁\n注意：在执行业务逻辑后，需要使用Lua脚本进行原子解锁\n\u0026quot;if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\u0026quot;;\r 问题： 需要经过中间件，效率比本地锁要低\nRedis分布式锁的实现方案：Redisson\n  设置热点数据永不过期\n  在 redis、db 中间做一个二级缓存\n  ","id":1,"section":"posts","summary":"缓存穿透 指查询一个一定不存在的数据，由于缓存是不命中，将去查询数据库，但是数据库也无此记录，我们没有将这次查 询的nulI写入缓存，这将导致这","tags":["缓存"],"title":"高并发下的缓存失效问题及解决方案","uri":"https://bluestaree.github.io/2020/06/%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8B%E7%9A%84%E7%BC%93%E5%AD%98%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98/","year":"2020"},{"content":"  由于Spring Cloud Eureka已经宣布停止开源计划，不再继续维护，这怎么行，还能愉快的使用吗。 今天在空闲之余了解了下另外一个功能更加强大的注册中心，那就是SpringCloud Alibaba的Nacos\n SpringCloud Alibaba Spring Cloud Alibaba致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的必需组件,方\n便开发者通过 Spring Cloud编程模型轻松使用这些组件来开发分布式应用服务。\n依托 Spring Cloud Alibaba,您只需要添加一些注解和少量配置,就可以将 Spring Cloud应用接入阿里微服务解决方\n案,通过阿里中间件来迅速搭建分布式应用系统。\nGitHub地址：https://github.com/alibaba/spring-cloud-alibaba\n本文主要介绍Spring Cloud Alibaba项目下的Nacos组件基本使用。\nNacos初体验 使用Nacos作为注册中心 1.首先引入SpringCloud Alibaba依赖 ,但是需要注意版本选择\n 1.5.x 版本适用于 Spring Boot 1.5.x 2.0.x 版本适用于 Spring Boot 2.0.x 2.1.x 版本适用于 Spring Boot 2.1.x 2.2.x 版本适用于 Spring Boot 2.2.x  pom文件配置：\n\u0026lt;dependencyManagement\u0026gt;\r\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-cloud-alibaba-dependencies\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.2.0.RELEASE\u0026lt;/version\u0026gt;\r\u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt;\r\u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r\u0026lt;/dependencyManagement\u0026gt;\r 2.引入Nacos注册中心依赖\npom文件配置：\n \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 配置文件的配置\nserver:\rport: 8080\rspring:\rapplication:\rname: Hello-Nacos\rcloud:\tnacos:\t//这里配置nacos注册中心的地址\rdiscovery:\rserver-addr: 127.0.0.1:8848\r 启动类\n@EnableDiscoveryClient\r@SpringBootApplication\rpublic class WebApplication {\rpublic static void main(String[] args) {\rSpringApplication.run(WebApplication.class, args);\r}\r}\r 获取Nacos的服务端 : https://github.com/alibaba/nacos/releases\n下载后启动服务端，打开浏览器访问http://127.0.0.1:8848/nacos\n默认账号密码均为 : nacos\n启动测试服务后，查看nacos服务管理中心，可以看到该服务已经成功注册\n之后就可以结合spring cloud open-feign进行远程服务调用啦，这里不再演示\n使用Nacos作为配置中心 首先导入nacos配置中心的依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-config\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 新增bootstrap.properties配置文件,添加已下配置信息\nspring.application.name=hello-nacos\t//项目名\rspring.cloud.nacos.config.server-addr=127.0.0.1:8848\t//nacos配置中心地址\r 在配置中心中新建配置文件,nacos配置中心默认会加载项目名.properties文件\nController相关代码\n@RestController\rpublic class WebController {\r@Value(\u0026quot;${mycustomer.name}\u0026quot;)\rpublic String name;\r@Value(\u0026quot;${mycustomer.age}\u0026quot;)\rpublic int age;\r@GetMapping\rprivate Map test() {\rHashMap hashMap = new HashMap();\rhashMap.put(\u0026quot;name\u0026quot;, name);\rhashMap.put(\u0026quot;age\u0026quot;, age);\rreturn hashMap;\r}\r}\r 结果\n成功读取配置中心里配置信息\n这里还可以配合使用**@RefreshScope**注解实现动态配置刷新\n注意：如果配置中心和当前应用的配置文件中都配置了相同的项，会优先使用配置中心里的配置\n 实现多配置文件加载(如开发，生产，测试等环境\u0026hellip;) nacos配置中心的一些概念\n  命名空间,默认：public(保留空间)，默认新增的所有配置都存在public空间,\n要使用特定的命名空间，需要在bootstrap.properties配置文件中指定命名空间ID\nspring.cloud.nacos.config.namespace=23902197-c354-4216-94cf-8e5cb8537e26\r 通过这一点，我们可以为每一个微服务创建一个命名空间，形成基于微服务间的隔离\n  配置集：所有配置文件的集合\n  配置集ID：相当于文件名\n  配置分组：默认所有配置集都属于DEFAULT_GROUP，我们可以在创建配置文件时，使用配置分组来区分不同的环境\n在bootstrap.properties配置文件 中指定分组\nspring.cloud.nacos.config.group=dev\t//指定配置分组\r   bootstrap.properties配置文件中指定多配置文件加载\n#多配置文件加载\rspring.cloud.nacos.config.ext-config[0].data-id=datasource.yml\t//配置ID\rspring.cloud.nacos.config.ext-config[0].group=dev\t//配置分组\rspring.cloud.nacos.config.ext-config[0].refresh=true\t//自动刷新\rspring.cloud.nacos.config.ext-config[1].data-id=hello-nacos.properties\rspring.cloud.nacos.config.ext-config[1].group=dev\rspring.cloud.nacos.config.ext-config[1].refresh=true\r ","id":2,"section":"posts","summary":"由于Spring Cloud Eureka已经宣布停止开源计划，不再继续维护，这怎么行，还能愉快的使用吗。 今天在空闲之余了解了下另外一个功能更加强大的注","tags":["SpringCloud","Nacos"],"title":"SpringCloud Alibaba-Nacos 注册与配置中心","uri":"https://bluestaree.github.io/2020/05/springcloud-alibaba-nacos-%E6%B3%A8%E5%86%8C%E4%B8%8E%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/","year":"2020"},{"content":"  前言：TCP是面向连接的，面向流的，提供高可靠性服务。收发两端(客户端和服务器端)都要有一一成对的socket，因此发送端为了将多个发给接收端的包，更有效的发给对方，使用了优化方法(Nagle算法)，将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包。这样做虽然提高了效率，但是接收端就难于分辨出完整的数据包了，因为面向流的通信是无消息保护边界的。\n 由于TCP无消息保护边界,需要在接收端处理消息边界问题，也就是我们所说的粘句、拆包问题，看一张图\n假设客户端分别发送了两个数据包D1和D2给服务端，由于服务端一次读取到字节数是不确定的，故可能存在以下四种情况:\n  服务端分两次读取到了两个独立的数据包，分别是D1和D2，没有粘包和拆包\n  服务端一次接受到了两个数据包，D1和D2粘合在一起，称之为TCP粘包\n  服务端分两次读取到了数据包，第一次读取到了完整的D1包和D2包的部分内容，第二次读取到了D2包的剩余内容，这称之为TCP拆包\n  服务端分两次读取到了数据包，第一次读取到了D1包的部分内容D1_1，第二次读取到了D1包的剩余部分内容D1_ 2和完整的D2包。\n  解决方案\n  使用自定义协议(一个自定义对象)+编解码器来解决\n  关键就是要解决服务器端每次读取数据长度的问题,这个问题解决，就不会出现服务器多读或少读数据的问题，从而避免的TCP粘包、拆包。\n  举个栗子\n自定义传输协议对象\npublic class MessageProtocol {\rprivate int len;\rprivate byte[] content;\r// set,get方法\r//....\r}\r 编码器\npublic class MyMessageEncoder extends MessageToByteEncoder\u0026lt;MessageProtocol\u0026gt; {\r@Override\rprotected void encode( ChannelHandlerContext ctx, MessageProtocol msg,ByteBuf out) throws Exception {\rout.writeInt(msg.getLen());\rout.writeBytes(msg.getContent());\r}\r}\r 解码器\npublic class MyMessageDecoder extends ReplayingDecoder\u0026lt;Void\u0026gt; {\r@Override\rprotected void decode(ChannelHandlerContext ctx, ByteBuf in, List\u0026lt;object\u0026gt; out) throws Exception {\r//将得到的二进制字节码转换为MessageProtocol 自定义协议包(对象)\rint length = in.readInt();\rbyte[] content = new byte[length] ;\rin.readBytes(content);\r//封装成MessageProtocol对象，放入out,传递给下一个handler处理\rMessageProtocol messageProtocol = new MessageProtocol();\rmessageProtocol.setLen(length);\rmessageProtocol.setContent( content);\rout.add(messageProtocol);\r}\r}\r ","id":3,"section":"posts","summary":"前言：TCP是面向连接的，面向流的，提供高可靠性服务。收发两端(客户端和服务器端)都要有一一成对的socket，因此发送端为了将多个发给接收","tags":null,"title":"TCP粘包和拆包问题","uri":"https://bluestaree.github.io/2020/05/tcp%E7%B2%98%E5%8C%85%E5%92%8C%E6%8B%86%E5%8C%85%E9%97%AE%E9%A2%98/","year":"2020"},{"content":" Netty的编解码器 当Netty发送或者接受一个消息的时候，就将会发生一次数据转换。入站消息会被解码：从字节转换为另一种格式(比如java对象)；如果是出站消息，它会被编码成字节。\nNetty提供一系列实用的编解码器，他们都实现了ChannelInboundHadnler或者ChannelOutboundHandler接口。在这些类中，channelRead方法已经被重写了。以入站为例，对于每个从入站Channel读取的消息，这个方法会被调用。随后，它将调用由解码器所提供的decode()方法进行解码，并将已经解码的字节转发给ChannelPipeline中的下一个ChannellnboundHandler.\n举个栗子\n关于一个ByteToMessageDecoder(入站解码器)实例分析\npublic class ToIntegerDecoder extends ByteToMessageDecoder {\r@Override\rprotected void decode(ChannelHandlerContext ctx, ByteBuf in, List\u0026lt;Object\u0026gt; out) throws Exception\r//按照每4字节，即一个int类型进行解码，将读取的数据放入out数组中\r//并将其传入下一个Handler处理器\r//该方法将根据消息内容大小被调用多次\rif (in.readableBytes()\u0026gt;=4){ //判断缓存区(ByteBuf)的数据是否足够，防止拆包和粘包问题\rout.add(in.readInt());\r}\r}\r 说明\n decode 解码器会根据接收的数据，被调用多次，直到确定没有新的元素被添加到list，或者是ByteBuf 没有更多的可读字节为止 如果list不为空，就会将list的内容传递给下一个Handler处理，该处理器的方法也会被调用多次，比如一个8字节的数据，经过上述解码器解码，会调用两次decode方法， 并执行两次解码器之后的Handler的业务处理方法，(简单来说就是客户端发送一个8字节数据，服务端将会应答2次) 编写encode编码器时，需要注意指定编码数据的类型，在发送数据时，其底层会判断当前发送的数据类型是否与之匹配，如果不符合，会直接将数据写出，不会进行相关编码操作  结论\n  不论解码器handler还是编码器handler即接收的消息类型必须与待处理的消息类型一致，否则handler不会被执行\n  在解码器进行数据解码时，需要判断缓存区(ByteBuf)的数据是否足够，否则接收到的结果会期望结果可能不一致\n  ReplayingDecoder ReplayingDecoder扩展了Byte\u0026rsquo;ToMessageDecoder类，使用这个类，我们不必调用readableBytes()方法。参数S指定了用户状态管理的类型，其中Void代表不需要状态管理\npublic class MyByteToLongDecoder extends ReplayingDecoder\u0026lt;Void\u0026gt; {\r@Override\rprotected void decode(ChannelHandlerContext ctx, ByteBuf in, List\u0026lt;object\u0026gt; out) throws Exception {\r//在ReplayingDecoder不需要判断数据是否足够读取，内部会进行处理判断\rout.add( in.readLong());\r}\r ReplayingDecoder使用方便， 但它也有一些局限性:\n1.并不是所有的ByteBuf操作都被支持如果调用了一个不被支持的方法，将会抛出一个UnsupportedOperationException。\n2.ReplayingDecoder在某些情况下可能稍慢于ByteToMessageDecoder，例如网络缓慢并且消息格式复杂时，消\n息会被拆成了多个碎片，速度变慢\n其它解码器\n LineBasedFrameDecoder: 这个类在Netty内部也有使用，它使用行尾控制字符(\\n或者\\r\\n)作为分隔符来解析  数据。\n DelimiterBasedFrameDecoder: 使用自定义的特殊字符作为消息的分隔符进行解码。\n  HttpObjectDecoder: 一个HTTP数据的解码器\n  LengthFieldBasedFrameDecoder: 通过指定长度来标识整包消息，这样就可以自动的处理黏包和半包消息。\n  其他编码器\n  ObjectEncoder : 简单地说就是把对象序列化后，转为ChannelBuffer并返回\n  Base64Encoder : base64编码器\n  StringEncoder : 消息转成String编码器\n  ZlibEncoder ：压缩数据\n  ","id":4,"section":"posts","summary":"Netty的编解码器 当Netty发送或者接受一个消息的时候，就将会发生一次数据转换。入站消息会被解码：从字节转换为另一种格式(比如java对","tags":["Netty"],"title":"Netty编解码器","uri":"https://bluestaree.github.io/2020/05/netty%E7%9A%84%E7%BC%96%E8%A7%A3%E7%A0%81%E5%99%A8/","year":"2020"},{"content":"  前言：Netty中ChannelHandler 的作用就是处理IO事件或拦截IO事件，并将其处理结果转发给下一个Handler，那么Handler链的调用机制又是怎样的呢\n 出站和入站机制 ChannelHandler充当了处理入站和出站数据的应用程序逻辑的容器。例如，实现ChannelInboundHandler接口\n(或ChannelInboundHandlerAdapter)，你就可以接收入站事件和数据，这些数据会被业务逻辑处理。当要给客户\n端发送响应时，也可以从ChannelInboundHandler冲刷数据。业务逻辑通常写在一个或者多个\nChannelInboundHandler中。ChannelOutboundHandler原理一 样，只不过它是用来处理出站数据的\n ChannelPipeline提供了ChannelHandler链的容器。出站和入站方向是相对的，以客户端应用程序为例。如果事\n件的运动方向是从客户端到服务端的，那么我们称这些事件为出站的，即客户端发送给服务端的数据会通过\npipeline中的一系列ChannelOutboundHandler，并被这些Handler处理，反之则称为入站的\n官方图解\n一般来说\n出站要编码，入站要解码\n出站对应写，入站对应读\n","id":5,"section":"posts","summary":"前言：Netty中ChannelHandler 的作用就是处理IO事件或拦截IO事件，并将其处理结果转发给下一个Handler，那么Handl","tags":["Netty"],"title":"Handler链的调用机制","uri":"https://bluestaree.github.io/2020/05/handler%E9%93%BE%E7%9A%84%E8%B0%83%E7%94%A8%E6%9C%BA%E5%88%B6/","year":"2020"},{"content":" 总览  Bootstrap or ServerBootstrap EventLoop or EventLoopGroup ChannelInitializer ChannelHandler ChannelPipeline ChannelHandlerContext Future or ChannelFuture  Bootstrap or ServerBootstrap 都是用来启动一个Netty应用的配置类，它主要作用是配置整个Netty程序，串联起各个组件。\nEventLoop or EventLoopGroup   EventLoopGroup 是一组EventLoop的抽象，Netty 为了更好的利用多核CPU资源，一般会有多个EventLoop同时工作，每个EventLoop维护着一个Selector实例。\n  EventLoopGroup 提供next接口，可以从组里面按照一定规则获取其中一个EventLoop来处理任务。在Netty服务器端编程中，我们一般都需要提供两个EventLoopGroup，例如: BossEventLoopGroup 和WorkerEventLoopGroup。\n  客户端连接处理流程如下图\nChannelInitializer channel的初始化容器，我们就是在这里面设置自定义的处理器\n相关API\nbootstrap.group(bossGroup, workerGroup) .handler(new NettyBossHandler()) // 给bossGroup的EventLoop对应的管道设置处理器\r.childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() {\r//给pipeline设置处理器\r@Override\rprotected void initChannel(SocketChannel ch) throws Exception {\r//获取当前通道对应的管道,在末尾添加一个自定义的处理器\rch.pipeline().addLast(new NettyWorkerHandler()); }\r}); // 给workerGroup的EventLoop对应的管道设置处理器\r ChannelHandler ChannelHandler 的作用就是处理IO事件或拦截IO事件，并将其转发给下一个处理程序ChannelHandler。Handler处理事件是分入站和出站的，两个方向的操作都是不同的，因此，Netty 定义了两个子接口继承ChannelHandler\n ChannelInboundHandler 处理入站事件接口   ChannelOutboundHandler 处理出站事件接口  此外，ChannelDuplexHandler 类能够同时处理出站和入站事件\n每个客户端Channel 都独享自己的 Handle\nChannelPipeline 在Netty中每个Channel都有且仅有一个ChannelPipeline与之对应，pipeline和channel是相互包含关系 即双方都可以获取对方的实例。它们的组成关系如下图所示\n一个Channel包含了一个ChannelPipeline，而ChannelPipeline 中又维护了一个由ChannelHandlerContext组成的双向链表，并且每个ChannelHandlerContext中又关联着一个ChannelHandler\n入站事件和出站事件在一个双向链表中，入站事件会从链表head往后传递到最后一个入站的handler,出站事件会从链表tail往前传递到最前一个出站的handler,两种类型的handler互不干扰\nChannelHandlerContext 多个ChannelHandlerContext组成了一个双向链表，Context只是对Handler的封装。\n  保存了Channel相关的所有上下文信息，同时关联一个ChannelHandler 对象\n  即ChannelHandlerContext中包含一个具体的事件处理器ChannelHandler,同时也绑定了对应的pipeline和Channel的信息，方便对ChannelHandler进行调用.\n  常用方法\n   ChanelFuture close(), 关闭通道 ChannelOutboundInvoker flush()，刷新 ChannelFuture writeAndFlush(Object msg)， 将数据写到ChannelPipeline中当前ChannelHandler 的下一个ChannelHandler开始处理(出站)  Future or ChannelFuture Netty异步模型\n基本介绍\n 异步的概念和同步相对。当一个异步过程调用发出后,调用者不能立刻得到结果。实际处理这个调用的组件在完  成后,通过状态、通知和回调来通知调用者。\n Nett中的I/0操作是异步的,包括Bind、 Write、 Connect等操作会简单的返回一个ChannelFuture。\n  调用者并不能立刻获得结果,而是通过 Future-Listener机制,用户可以方便的主动获取或者通过通知机制获得IO\n  操作结果\nNetty的异步模型是建立在 future和 callback的之上的。 callback就是回调。重点说Future,它的核心思想是:假  设一个方法fun,计算过程可能非常耗时,等待fun返回显然不合适。那么可以在调用fun的时候,立马返回一个 Future,\n后续可以通过Future去监控方法fun的处理过程(即: Future-Listener机制)\n 当 Future对象刚刚创建时,处于非完成状态,调用者可以通过返回的 ChannelFuture来获取操作执行的状态,注册监听函数来执行完成后的操作\n常见有如下操作\n1.通过 isDone 方法来判断当前操作是否完成;\n2.通过 isSuccess 方法来判断已完成的当前操作是否成功;\n3.通过 getCause 方法来获取已完成的当前操作失败的原因;\n4.通过 isCancelled 方法来判断已完成的当前操作是否被取消;\n5.通过 addlistener 方法来注册监听器,当操作已完成( isDone方法返回完成),将会通知指定的监听器;如果 Future对象已完成,则通知指定的监听器;\n举个栗子\n//启动服务器(并绑定端口)\rChannelFuture cf = bootstrap.bind(6668).sync();\r//给cf 注册监听器，监控我们关心的事件\rcf.addListener(new ChannelFutureListener() {\r@Override\rpublic void operationComplete(ChannelFuture future) throws Exception {\rif (cf.isSuccess()) {\rSystem.out.println(\u0026quot;监听端口 6668 成功\u0026quot;);\r} else {\rSystem.out.println(\u0026quot;监听端口 6668 失败\u0026quot;);\r}\r}\r});\r ","id":6,"section":"posts","summary":"总览 Bootstrap or ServerBootstrap EventLoop or EventLoopGroup ChannelInitializer ChannelHandler ChannelPipeline ChannelHandlerContext Future or ChannelFuture Bootstrap or ServerBootstrap 都是用来启动一个Netty应用的配置类，它主要作用是配置整个Netty程序，串联起各个组件。 EventLoop or EventLoopGroup EventLoopGroup 是一","tags":["Netty"],"title":"Netty基础组件","uri":"https://bluestaree.github.io/2020/05/netty%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D/","year":"2020"},{"content":"  前言：通过Netty完成一个简单的多客户端与单服务端交互的demo\n Netty初体验 服务端\npublic class NettyServer {\rpublic static void main(String[] args) throws Exception {\r//1. 创建两个线程组 bossGroup 和 workerGroup\r//2. bossGroup 只是处理连接请求 , 真正的和客户端业务处理，会交给 workerGroup完成\r//3. 两个都是无限循环\r//4. bossGroup 和 workerGroup 含有的子线程(NioEventLoop)的个数可以在参数中指定\r// 默认数量为实际 cpu核数 * 2\rEventLoopGroup bossGroup = new NioEventLoopGroup(1);//通常bossGroup只需要1个\rEventLoopGroup workerGroup = new NioEventLoopGroup(); try {\r//创建服务器端的启动引导类对象，可以配置服务器参数\rServerBootstrap bootstrap = new ServerBootstrap();\r//使用链式编程来进行设置\rbootstrap.group(bossGroup, workerGroup) //设置两个线程组\r//使用NioSocketChannel 作为服务器的通道实现\r.channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 128) // 设置线程队列得到连接个数\r.childOption(ChannelOption.SO_KEEPALIVE, true) //设置保持活动连接状态\r// .handler(null) // 该 handler对应 bossGroup设置 , childHandler 对应 workerGroup\r.childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() {//创建一个通道初始化对象(匿名对象)\r//给pipeline 设置处理器\r@Override\rprotected void initChannel(SocketChannel ch) throws Exception {\r//这里的SocketChannel 是客户端通道实例\r//获取当前通道对应的管道,在末尾添加一个自定义的处理器\rch.pipeline().addLast(new NettyServerHandler()); }\r}); // 给我们的workerGroup 的 EventLoop 对应的管道设置处理器\r//绑定一个端口，同步执行(阻塞当前线程), 返回一个 ChannelFuture 对象(netty的异步模型)，\r//可通过此对象获取方法执行结果\r//启动服务器(并绑定端口)\rChannelFuture cf = bootstrap.bind(6668).sync();\r//服务端管道关闭的监听器,并同步阻塞,直到channel关闭,线程才会往下执行,进入finally关闭通道结束进程\rcf.channel().closeFuture().sync();\r}finally {\r//优r雅的关闭\rbossGroup.shutdownGracefully();\rworkerGroup.shutdownGracefully();\r}\r}\r}\r 自定义服务端Handler\npublic class NettyServerHandler extends SimpleChannelInboundHandler\u0026lt;String\u0026gt; {\r//通道一旦链接，此方法第一个执行\r@Override\rpublic void handlerAdded(ChannelHandlerContext ctx) throws Exception {\r//通过上线文获取通道信息\rChannel channel = ctx.channel();\r//业务处理\r}\r//断开链接\r@Override\rpublic void handlerRemoved(ChannelHandlerContext ctx) throws Exception {\r}\r//通道处于活跃状态\r@Override\rpublic void channelActive(ChannelHandlerContext ctx) throws Exception {\r}\r//非活跃状态\r@Override\rpublic void channelInactive(ChannelHandlerContext ctx) throws Exception {\r}\r//异常处理,一般是需要关闭通道\r@Override\rpublic void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\rctx.close();\r}\r//通道有数据可读，第二个参数是消息内容\r@Override\rprotected void channelRead0(ChannelHandlerContext channelHandlerContext, String s) throws Exception {\r//writeAndFlush 是 write + flush\r//将数据写入到缓存，并刷新\r//一般，我们会对这个发送的数据进行编码\rctx.writeAndFlush(Unpooled.copiedBuffer(\u0026quot;hello, 客户端~\u0026quot;, CharsetUtil.UTF_8));\r}\r}\r 客户端\npublic class NettyClient {\rpublic static void main(String[] args) throws Exception {\r//客户端需要一个事件循环组\rEventLoopGroup group = new NioEventLoopGroup();\rtry {\r//创建客户端启动对象\r//注意客户端使用的不是 ServerBootstrap 而是 Bootstrap\rBootstrap bootstrap = new Bootstrap();\r//设置相关参数\rbootstrap.group(group) //设置线程组\r.channel(NioSocketChannel.class) // 设置客户端通道的实现类\r.handler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() {\r@Override\rprotected void initChannel(SocketChannel ch) throws Exception {\r//这里可以加入自己的处理器\rch.pipeline().addLast(new NettyClientHandler()); }\r});\r//启动客户端去连接服务器端\rChannelFuture channelFuture = bootstrap.connect(\u0026quot;127.0.0.1\u0026quot;, 6668).sync();\r//给关闭通道进行监听\rchannelFuture.channel().closeFuture().sync();\r}finally {\rgroup.shutdownGracefully();\r}\r}\r}\r 自定义客户端Handler\npublic class NettyClientHandler extends ChannelInboundHandlerAdapter {\r//当通道就绪就会触发该方法\r@Override\rpublic void channelActive(ChannelHandlerContext ctx) throws Exception {\rSystem.out.println(\u0026quot;client \u0026quot; + ctx);\rctx.writeAndFlush(Unpooled.copiedBuffer(\u0026quot;hello, server\u0026quot;, CharsetUtil.UTF_8));\r}\r//当通道有读取事件时，会触发\r@Override\rpublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\rByteBuf buf = (ByteBuf) msg;\rSystem.out.println(\u0026quot;服务器回复的消息:\u0026quot; + buf.toString(CharsetUtil.UTF_8));\rSystem.out.println(\u0026quot;服务器的地址： \u0026quot;+ ctx.channel().remoteAddress());\r}\r@Override\rpublic void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\rcause.printStackTrace();\rctx.close();\r}\r}\r 关于Channel类型设置\n不同协议、不同的阻塞类型的连接都有不同的 Channel类型与之对应,常用的Channel类型:\n NioSocketChannel,异步的客户端 TCP Socket连接 NioServerSocketChannel,异步的服务器端 TCP Socket连接。 NioDatagramChannel,异步的UDP连接。 NioSctpChannel,异步的客户端Sctp连接。 NioSctpServerChannel,异步的Sctp服务器端连接,这些通道涵盖了UDP和TCP网络IO以及文件IO。  关于ChannelOption参数设置\n参数如下\nChannelOption.SO_BACKLOG\n对应TCP/IP协议listen函数中的backlog参数，用来初始化服务器可连接队列大小。服务端处理客户端连接请求是顺序处理的，所以同一时间只能处理一个客户端连接。 多个客户端来的时候，服务端将不能处理的客户端连接请求放在队列中等待处理，backlog 参数指定了队列的大小。\nChannelOption.SO_KEEPALIVE\n一直保持连接活动状态\n相关代码API\nbootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 128) //给bossGroup通道设置参数\r.childOption(ChannelOption.SO_KEEPALIVE, true) //给workerGroup通道设置参数\r ","id":7,"section":"posts","summary":"前言：通过Netty完成一个简单的多客户端与单服务端交互的demo Netty初体验 服务端 public class NettyServer { public static void main(String[] args) throws Exception { //1. 创建两个线程组 bossGroup 和 workerGroup //2. bossGroup 只","tags":["Netty"],"title":"Netty初体验","uri":"https://bluestaree.github.io/2020/05/netty%E5%88%9D%E4%BD%93%E9%AA%8C/","year":"2020"},{"content":"  转载 · 原文链接：https://www.jianshu.com/p/275602182f39\n 前言 零拷贝这三个字，一直是服务器网络编程的关键字，任何性能优化都离不开。在 Java 程序员的世界，常用的零拷贝有 mmap 和 sendFile。那么，他们在 OS 里，到底是怎么样的一个的设计？本文将简单聊聊 mmap 和 sendFile 这两个零拷贝。\n传统数据读写的劣势 初学 Java 时，我们在学习 IO 和 网络编程时，会使用以下代码：\nFile file = new File(\u0026quot;index.html\u0026quot;);\rRandomAccessFile raf = new RandomAccessFile(file, \u0026quot;rw\u0026quot;);\rbyte[] arr = new byte[(int) file.length()];\rraf.read(arr);\rSocket socket = new ServerSocket(8080).accept();\rsocket.getOutputStream().write(arr);\r 我们会调用 read 方法读取 index.html 的内容—— 变成字节数组，然后调用 write 方法，将 index.html 字节流写到 socket 中，那么，我们调用这两个方法，在 OS 底层发生了什么呢？我这里借鉴了一张其他文字的图片，尝试解释这个过程。\n传统 IO 操作\n上图中，上半部分表示用户态和内核态的上下文切换。下半部分表示数据复制操作。下面说说他们的步骤：\n read 调用导致用户态到内核态的一次变化，同时，第一次复制开始：DMA（Direct Memory Access，直接内存存取，即不使用 CPU 拷贝数据到内存，而是 DMA 引擎传输数据到内存，用于解放 CPU） 引擎从磁盘读取 index.html 文件，并将数据放入到内核缓冲区。 发生第二次数据拷贝，即：将内核缓冲区的数据拷贝到用户缓冲区，同时，发生了一次用内核态到用户态的上下文切换。 发生第三次数据拷贝，我们调用 write 方法，系统将用户缓冲区的数据拷贝到 Socket 缓冲区。此时，又发生了一次用户态到内核态的上下文切换。 第四次拷贝，数据异步的从 Socket 缓冲区，使用 DMA 引擎拷贝到网络协议引擎。这一段，不需要进行上下文切换。 write 方法返回，再次从内核态切换到用户态。  如你所见，复制拷贝操作太多了。如何优化这些流程？\nmmap 优化 mmap 通过内存映射，将文件映射到内核缓冲区，同时，用户空间可以共享内核空间的数据。这样，在进行网络传输时，就可以减少内核空间到用户控件的拷贝次数。如下图：\nmmap 流程\n如上图，user buffer 和 kernel buffer 共享 index.html。如果你想把硬盘的 index.html 传输到网络中，再也不用拷贝到用户空间，再从用户空间拷贝到 Socket 缓冲区。\n现在，你只需要从内核缓冲区拷贝到 Socket 缓冲区即可，这将减少一次内存拷贝（从 4 次变成了 3 次），但不减少上下文切换次数。\nsendFile 那么，我们还能继续优化吗？ Linux 2.1 版本 提供了 sendFile 函数，其基本原理如下：数据根本不经过用户态，直接从内核缓冲区进入到 Socket Buffer，同时，由于和用户态完全无关，就减少了一次上下文切换。\nsnedFile 2.1 版本\n如上图，我们进行 sendFile 系统调用时，数据被 DMA 引擎从文件复制到内核缓冲区，然后调用，然后掉一共 write 方法时，从内核缓冲区进入到 Socket，这时，是没有上下文切换的，因为在一个用户空间。\n最后，数据从 Socket 缓冲区进入到协议栈。\n此时，数据经过了 3 次拷贝，3 次上下文切换。\n那么，还能不能再继续优化呢？ 例如直接从内核缓冲区拷贝到网络协议栈？\n实际上，Linux 在 2.4 版本中，做了一些修改，避免了从内核缓冲区拷贝到 Socket buffer 的操作，直接拷贝到协议栈，从而再一次减少了数据拷贝。具体如下图：\nsendFile 在 2.4 版本的再一次优化\n现在，index.html 要从文件进入到网络协议栈，只需 2 次拷贝：第一次使用 DMA 引擎从文件拷贝到内核缓冲区，第二次从内核缓冲区将数据拷贝到网络协议栈；内核缓存区只会拷贝一些 offset 和 length 信息到 SocketBuffer，基本无消耗。\n等一下，不是说零拷贝吗？为什么还是要 2 次拷贝？\n答：首先我们说零拷贝，是从操作系统的角度来说的。因为内核缓冲区之间，没有数据是重复的（只有 kernel buffer 有一份数据，sendFile 2.1 版本实际上有 2 份数据，算不上零拷贝）。例如我们刚开始的例子，内核缓存区和 Socket 缓冲区的数据就是重复的。\n而零拷贝不仅仅带来更少的数据复制，还能带来其他的性能优势，例如更少的上下文切换，更少的 CPU 缓存伪共享以及无 CPU 校验和计算。\n再稍微讲讲 mmap 和 sendFile 的区别。\n mmap 适合小数据量读写，sendFile 适合大文件传输。 mmap 需要 4 次上下文切换，3 次数据拷贝；sendFile 需要 3 次上下文切换，最少 2 次数据拷贝。 sendFile 可以利用 DMA 方式，减少 CPU 拷贝，mmap 则不能（必须从内核拷贝到 Socket 缓冲区）。  在这个选择上：rocketMQ 在消费消息时，使用了 mmap。kafka 使用了 sendFile。\nJava 世界的例子 kafka 在客户端和 broker 进行数据传输时，会使用 transferTo 和 transferFrom 方法，即对应 Linux 的 sendFile。\ntomcat 内部在进行文件拷贝的时候，也会使用 transferto 方法。\ntomcat 在处理一下心跳保活时，也会调用该 sendFile 方法。\n在 pulsar 项目中，下载文件时，也会使用 sendFile。如下图：\n所以，如果你需要优化网络传输的性能，或者文件读写的速度，请尽量使用零拷贝。他不仅能较少复制拷贝次数，还能较少上下文切换，缓存行污染。\n作者：莫那一鲁道 来源：简书\n ","id":8,"section":"posts","summary":"转载 · 原文链接：https://www.jianshu.com/p/275602182f39 前言 零拷贝这三个字，一直是服务器网络编程的关键字","tags":null,"title":"零拷贝","uri":"https://bluestaree.github.io/2020/05/%E9%9B%B6%E6%8B%B7%E8%B4%9D/","year":"2020"},{"content":" 前言  IO模型：就是用什么样的通道进行数据的发送和接收,很大程度上决定了程序通信的性能\n而netty是一款基于NIO(Nonblocking I/O,非阻塞IO)所开发的网络通信框架。\n 下面介绍三种I/O模型。\nBIO，传统同步阻塞 ： 服务器实现模式为一个连接一个线程,即客户端有连接请求时服务器端就需要启动一个线程\n进行处理,如果这个连接不做任何事情会造成不必要的线程开销\nNIO，同步非阻塞：服务器实现模式为一个线程处理多个请求(连接),即客户端发送的连接请求都会注册到多路复用\n器上,多路复用器轮询到连接有IO请求就进行处理\nAIO，异步非阻塞：AIO引入异步通道的概念,采用了 Proactor模式,简化了程序编写,有效的请求才启动线程,它的特\n点是先由操作系统完成后才通知服务端程序启动线程去处理,一般适用于连接数较多且连接时间较长的应用\nBIO、NIO、AIO适用场景分析  BIO方式适用于连接数目比较小且固定的架构,这种方式对服务器资源要求比较高并发局限于应用中,JDK1.4以前  的唯一选择,但程序简单易理解。\n NIO方式适用于连接数目多且连接比较短(轻操作)的架构,比如聊天服务器,弹幕系统,服务器间通讯等。编程比较复杂,JDK1.4开始支持\n  AIO方式使用于连接数目多且连接比较长(重操作)的架构,比如相册服务器,充分调用OS参与并发操作,编程比较复\n  杂,JDK7开始支持\nNIO的三大核心组件 \u0026ndash; Channel , Selector , Buffer 缓冲区( Buffer ) 缓冲区本质上是一个可以读写数据的内存块,可以理解成是一个容器对象(含数组),该对象提供了一组方法,可以更轻\n松地使用内存块，缓冲区对象内置了一些机制,，能够跟踪和记录缓冲区的状态变化情况。 Channel提供从文件、\n网络读取数据的渠道，但是读取或写入的数据都必须经由 Buffer，常用的Buffer缓冲区：ByteBuffer\n除了Boolean，java中的其他原生数据类型都有与之对应的Buffer\nBuffer的分散和聚集 NIO还支持通过多个Buffer(即Buffer数组)完成读写操作，即Scattering和Gathering\n Scattering：将数据写入到buffer时，可以采用buffer数组的形式，依次写入【分散】 Gathering：从buffer读取数据时，可以采用buffer数组，依次读  通道( Channel ) NIO的通道类似于流,但有些区别如下\n 通道可以同时进行读写,而流只能读或者只能写 通道可以实现异步读写数据 通道可以从缓冲读数据,也可以写数据到缓冲:  常用的通道：FileChannel(文件读写)、DatagramChannel(对UDP数据读写)、ServerSocketChannel(TCP数据读写)、SocketChannel(TCP数据读写)\nChannel 可从原生IO中获取\n// 创建一个输出流- \u0026gt;channel\rFileOutputStream fileOutputStream = new FileOutputStream(\u0026quot;d:\\\\file01.txt\u0026quot;);\r//通过fileOutputStream获取对应的FileChannel\r//这个fileChannel真实类型是FileChannelImpl\rFileChannel fileChannel = fileOutputStream.getChannel();\r NIO还提供了 MappedByteBuffer，可以让文件直接在内存(堆外的内存)中进行修改，而如何同步到文件由NIO来完成.\nRandomAccessFile randomAccessFile = new RandomAccessFile(\u0026quot;1.txt\u0026quot;,\u0026quot;rw\u0026quot;);\r//获取对应的通道\rFileChannel channel = randomAccessFile.getChannel();\r/**\r*参数1: FileChannel.MapMode.READ_WRITE使用的读写模式\r*参数2: 0:可以直接修改的起始位置\r*参数3: 5:是映射到内存的大小, 即将1.txt的多少个字节映射到内存\r*可以直接修改的范围就是 0-5\r*/\rMappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, 5);\rmappedByteBuffer.put(0,(byte)'H');\rmappedByteBuffer.put(3,(byte)'9');\r 选择器( Selector )   Java的NIO，用非阻塞的IO方式。可以用一个线程，处理多个的客户端连接，就会使用到 Selector(选择器)\n  Selector能够检测多个注册的通道上是否有事件发生(注意:多个 Channel以事件的方式可以注册到同一个\n  Selector)，如果有事件发生，便获取事件然后针对每个事件进行相应的处理。这样就可以只用一个单线程去管理\n多个通道，也就是管理多个连接和请求。\n 只有在连接真正有读写事件发生时，才会进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程\n  避免了多线程之间的上下文切换导致的开销\n  NIO初体验 使用NIO实现简单多人聊天功能\n服务端\nimport java.io.IOException;\rimport java.net.InetSocketAddress;\rimport java.nio.ByteBuffer;\rimport java.nio.channels.*;\rimport java.util.Iterator;\rimport java.util.Set;\r//实现简单多人聊天功能\r//服务端\rpublic class NioService {\rpublic ServerSocketChannel serverSocketChannel;\rpublic Selector selector;\rpublic static final int PORT = 8888;\r//初始化参数\rpublic NioService() throws IOException {\r//初始化serverSocketChannel\rserverSocketChannel = ServerSocketChannel.open();\r//初始化selector\rselector = Selector.open();\r//绑定监听端口\rserverSocketChannel.socket().bind(new InetSocketAddress(PORT));\r//设置非阻塞\rserverSocketChannel.configureBlocking(false);\r//注册至selector\rserverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\rSystem.out.println(\u0026quot;服务器初始化完成 = \u0026quot;);\r}\r//监听\rpublic void listen() {\rtry {\rwhile (true) {\rint i = selector.select();\rif (i \u0026gt; 0) { // 有事件发生\r//获取触发事件的所有SelectionKey\rIterator\u0026lt;SelectionKey\u0026gt; iterator = selector.selectedKeys().iterator();\r//遍历,\rwhile (iterator.hasNext()) {\rSelectionKey key = iterator.next();\r//连接事件\rif (key.isAcceptable()) {\r//获取客户端链接通道\rSocketChannel socketChannel = serverSocketChannel.accept();\r//设置非阻塞\rsocketChannel.configureBlocking(false);\r//注册至selector\rsocketChannel.register(selector, SelectionKey.OP_READ);\r//提示\rSystem.out.println(socketChannel.getRemoteAddress() + \u0026quot; 上线\u0026quot; );\r}\rif (key.isReadable()) {\r//读数据\rreceiverMessage(key);\r}\riterator.remove();\r}\r}\r}\r} catch (IOException e) {\re.printStackTrace();\r}\r}\r//接收数据\rpublic void receiverMessage(SelectionKey key) {\rif (key == null) {\rreturn;\r}\rSocketChannel socketChannel = (SocketChannel) key.channel();\rByteBuffer byteBuffer = ByteBuffer.allocate(1024);\rtry {\rsocketChannel.read(byteBuffer);\r//\rString msg = new String(byteBuffer.array());\rSystem.out.println(\u0026quot;转发 \u0026quot; + socketChannel.getRemoteAddress() + \u0026quot; :的信息\u0026quot; + msg);\r//转发信息\rsendMessage(msg,socketChannel);\r} catch (IOException e) {\re.printStackTrace();\rtry {\rSystem.out.println(socketChannel.getRemoteAddress() + \u0026quot; 离线了\u0026quot;);\rkey.channel();\rsocketChannel.close();\r} catch (IOException ex) {\rex.printStackTrace();\r}\r}\r}\r//转发信息\rpublic void sendMessage(String msg, SocketChannel self) throws IOException {\rSystem.out.println(\u0026quot;服务器转发消息中\u0026quot;);\r//获取所有已注册的通道(除去自己)\rSet\u0026lt;SelectionKey\u0026gt; keys = selector.keys();\rfor (SelectionKey key : keys) {\rChannel channel = key.channel();\rif (channel instanceof SocketChannel \u0026amp;\u0026amp; channel != self) {\rByteBuffer byteBuffer = ByteBuffer.wrap(msg.getBytes());\r((SocketChannel) channel).write(byteBuffer);\r}\r}\r}\rpublic static void main(String[] args) throws IOException {\rNioService nioService = new NioService();\rnioService.listen();\r}\r}\r 客户端\nimport java.io.IOException;\rimport java.net.InetSocketAddress;\rimport java.nio.ByteBuffer;\rimport java.nio.channels.SelectionKey;\rimport java.nio.channels.Selector;\rimport java.nio.channels.SocketChannel;\rimport java.util.Iterator;\rimport java.util.Scanner;\r//客户端\rpublic class NioClient {\rprivate SocketChannel socketChannel;\rprivate Selector selector;\rprivate static final String ADDRESS = \u0026quot;127.0.0.1\u0026quot;;\rprivate static final int PORT = 8888;\rprivate String username;\rpublic NioClient() throws IOException {\rsocketChannel = SocketChannel.open(new InetSocketAddress(ADDRESS, PORT));\rselector = Selector.open();\rsocketChannel.configureBlocking(false);\rsocketChannel.register(selector, SelectionKey.OP_READ);\rusername = socketChannel.getLocalAddress().toString().substring(1);\rSystem.out.println(username + \u0026quot;is ok...\u0026quot; );\r}\rpublic void sendMessage(String msg) throws IOException {\rmsg = username + \u0026quot; 说:\u0026quot; + msg;\rByteBuffer byteBuffer = ByteBuffer.wrap(msg.getBytes());\rsocketChannel.write(byteBuffer);\r}\rpublic void listen() throws IOException {\rint select = selector.select();\rif (select \u0026gt; 0) {\rIterator\u0026lt;SelectionKey\u0026gt; iterator = selector.selectedKeys().iterator();\rwhile (iterator.hasNext()) {\rSelectionKey key = iterator.next();\rif (key.isReadable()) {\rByteBuffer byteBuffer = ByteBuffer.allocate(1024);\rsocketChannel.read(byteBuffer);\rSystem.out.println(new String(byteBuffer.array()));\r}\r}\riterator.remove();\r}\r}\rpublic static void main(String[] args) throws Exception {\rNioClient nioClient = new NioClient();\r//开启一条线程监听消息\rnew Thread(){\r@Override\rpublic void run() {\rwhile(true) {\rtry {\rnioClient.listen();\rThread.currentThread().sleep(3000);\r} catch (Exception e) {\re.printStackTrace();\r}\r}\r}\r}.start();\r//主线程发送消息\rScanner scanner = new Scanner(System.in);\rwhile (scanner.hasNextLine()) {\rnioClient.sendMessage(scanner.next());\r}\r}\r}\r ","id":9,"section":"posts","summary":"前言 IO模型：就是用什么样的通道进行数据的发送和接收,很大程度上决定了程序通信的性能 而netty是一款基于NIO(Nonblocking I/","tags":["Netty"],"title":"Netty的IO模型","uri":"https://bluestaree.github.io/2020/05/io%E6%A8%A1%E5%9E%8B/","year":"2020"},{"content":" 前言  不同的线程模型，对程序的性能有很大的影响，Netty线程模型主要基于主从Reactor多线程模型做了一定的改进\n 目前存在的线程模型有：\n传统I/O服务模型 模型特点\n 1)采用阻塞I0模式获取输入的数据 2)每个连接都需要独立的线程完成数据的输入，业务处理，数据返回等操作  Reactor模式 针对传统阻塞I/0服务模型的2个缺点，解决方案:\n 基于I/O 复用模型:多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象等待，无需阻塞等待所有连接。当某个连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理 基于线程池复用线程资源:不必再为每个连接创建线程，将连接完成后的业务处理任务分配给线程进行处理，一个线程可以处理多个连接的业务。  I/0复用结合线程池，就是Reactor模式基本设计思想，\n根据Reactor的数量和处理资源池线程的数量不同，有3种典型的实现：\n  单Reactor单线程 流程说明\n  Select 是前面I/0复用模型介绍的标准网络编程API， 可以实现应用程序通过一个阻塞对象监听多路连接请求\n  Reactor 对象通过Select监控客户端请求事件，收到事件后通过Dispatch进行分发\n  如果是建立连接请求事件，则由Acceptor通过accept处理连接请求，然后创建一 个Handler对象处理连接完成后的后续业务处理\n  如果不是建立连接事件，则Reactor会分发调用连接对应的Handler来响应\n  Handler 会完成Read \u0026gt;业务处理\u0026gt;Send 的完整业务流程\n  模型分析\n  优点:模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成\n  缺点:性能问题，只有一个线程，无法完全发挥多核CPU的性能。Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈\n  缺点:可靠性问题，线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障\n    单Reactor多线程 流程说明\n  Reactor 对象通过select监控客户端请求事件，收到事件后，通过dispatch进行分发\n  如果建立连接请求，则右Acceptor通过accept处理连接请求，然后创建一个Handler对象处理完成连接后的各种事件\n  如果不是连接请求，则由reactor分发调用连接对应的handler来处理\n  handler只负责响应事件，不做具体的业务处理，通过read读取数据后，会分发给后面的worker线程池的某个线程处理业务\n  worker线程池会分配独立线程完成真正的业务，并将结果返回给handler\n  handler收到响应后 ，通过send 将结果返回给client\n  模型分析\n  优点:可以充分的利用多核cpu的处理能力。\n  缺点:多线程数据共享和访问比较复杂，reactor 处理所有的事件的监听和响应，在单线程运行，在高并发场景容易出现性能瓶颈。\n    主从Reactor多线程 流程说明\n  Reactor主线程MainReactor对象通过select监听连接事件，收到事件后，通过Acceptor处理连接事件\n  当Acceptor处理连接事件后，MainReactor将连接分配给SubReactor\n  subreactor将连接加入到连接队列进行监听,并创建handler进行各种事件处理\n  当有新事件发生时，subreactor 就会调用对应的handler处理\n  handler通过read读取数据，分发给后面的worker线程处理\n  worker线程池分配独立的worker线程进行业务处理，并返回结果\n  handler收到响应的结果后，再通过send将结果返回给client\n  注：Reactor主线程可以对应多个Reactor子线程，即MainRecator可以关联多个SubReactor\n模型分析\n  优点:父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。\n  优点:父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。\n  缺点:编程复杂度较高\n    Netty线程模式 主要基于主从Reactor多线程模型做了一定的改进，其中主从Reactor多线程模型中有多个Reactor\n流程说明\n  Netty抽象出两组线程池BossGroup专门负责接收客户端的连接，WorkerGroup专门负责网络读写\n  BossGroup和WorkerGroup类型都是NioEventLoopGroup\n  NioEventLoopGroup相当于一个事件循环组，这个组中含有多个事件循环，每一个事件循环是NioEventLoop\n  NioEventLoop 表示一个不断循环的执行处理任务的线程，每个NioEventLoop都有一个selector ,用于监听绑定在其上的socket的网络通讯\n  NioEventLoopGroup 可以有多个线程，即可以含有多个NioEventLoop\n  每个BossNioEventLoop循环执行的步骤有3步\n   ​\t轮询accept事件 ​\t处理accept事件,与client建立连接，生成NioSocketChannel ,并将其注册到某个worker NIOEventLoop上的selector，分配机制是看哪个线程空闲就分配，否则进入等待 ​\t处理任务队列的任务 ，即runAllTasks  每个Worker NIOEventLoop循环执行的步骤   ​\t轮询read, write事件 ​\t处理i/o事件，即read , write事件，在对应NioSocketChannel处理 ​\t处理任务队列的任务，即runAllTasks  处理过程中会使用到pipeline，其中包含了channel ，通过pipeline可以获取到对应通道，且其中维护了很多处理器，可以自定义处理器\n 总结：Boss Group只是处理连按请求,真正的和客户端业务处理,会交给Worker Group完成\nNioEventLoopGroup下包含多个NioEventLoop\n 每个 NioEventLoop中包含有一个 Selector,一个 taskQueue 每个 NioEventLoop的 Selector上可以注册监听多个 NioChannel 每个 Niochannel只会绑定在唯一的 NioEventLoop上 每个 NioChannel都绑定有一个自己的 ChannelPipeline  ","id":10,"section":"posts","summary":"前言 不同的线程模型，对程序的性能有很大的影响，Netty线程模型主要基于主从Reactor多线程模型做了一定的改进 目前存在的线程模型有： 传统","tags":["Netty"],"title":"Netty线程模型","uri":"https://bluestaree.github.io/2020/05/netty%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/","year":"2020"},{"content":" 所谓的正向与反向，都是对于我们自己的电脑来说\n正向代理：帮助客户端访问外部资源的，\n举个例子：如科学上网。如果我们需要访问谷歌，就需要代理服务器帮助我们访问获得数据，再由代理服务器返回\n给客户端，也就是帮助客户端进行访问连接的，这就是正向代理，\n正向代理作用：\n 访问原来无法访问的资源， 隐藏客户端信息  如何隐藏客户端的信息？因为客户端是将请求转发给代理服务器，此时对于谷歌而言，真正访问的是代理服务器，\n所能看到的地址也只是代理服务器的IP地址\n 反向代理：主要负责接收客户端的请求，并将其转发到内网服务器集群中。\n通常一些真正处理请求的服务器都是部署在内网中，并不会对外暴露真正的IP地址，这主要是为了防止网络攻击。\n那么我们要如何访问位于内网中的服务呢。这时候就需要使用反向代理服务器，如Nginx，对外暴露公网IP地址，\n将所接收到的请求转发到内网中，并将获得的结果返回给客户端。\n反向代理的作用：\n 负载均衡 保护内网安全  ","id":11,"section":"posts","summary":"所谓的正向与反向，都是对于我们自己的电脑来说 正向代理：帮助客户端访问外部资源的， 举个例子：如科学上网。如果我们需要访问谷歌，就需要代理服务器","tags":null,"title":"正向代理与方向代理","uri":"https://bluestaree.github.io/2020/05/%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86%E4%B8%8E%E6%96%B9%E5%90%91%E4%BB%A3%E7%90%86/","year":"2020"},{"content":" 1.PO(Persistant Object) 持久对象\nPO就是对应数据库中某个表中的一条记录,多个记录可以用PO的集合。PO中应该不包含任何对数据库的操作。\n 2.DO(Domain object) 领域对象\n就是从现实世界中抽象出来的有形或无形的业务实体\n 3.TO(Transfer Object) 数据传输对象\n不同的应用程序(服务)之间传输的对象\n 4.DTO(Data Transfer Object) 数据传输对象\n这个概念来源于J2EE的设计模式,原来的目的是为了EJB的分布式应用提供粗粒度的数据实体,以减少分布式调用的次\n数,从而提高分布式调用的性能和降低网络负载,但在这里,泛指用于展示层与服务层之间的数据传输对象。\n 5.VO(Value Object) 值对象\n通常用于业务层之间的数据传递,和PO一样也是仅仅包含数据而已。但应是抽象出的业务对象,可以和表对应,也可\n以不,这根据业务的需要。用new关键字创建,由GC回收的。\n也可以理解为 (View Object) 视图对象\n 接收页面传递过来的数据，封装成一个对象 经过业务处理完成后，封装成页面要用的数据   6.BO(Business Object) 业务对象\n从业务模型的角度看,见UML元件领域模型中的领域对象。封装业务逻辑的java对象,通过调用DAO方法，结合\nPO,VO进行业务操作。\nbusiness object:业务对象主要作用是把业务逻辑封装为一个对象。这个对象可以包括一个或多个其它的对象。比\n如一个简历,有教育经历、工作经历、社会关系等等。我们可以把教育经历对应一个PO,工作经历对应一个PO,社会\n关系对应一个PO。建立一个对应简历的Bo对象处理简历,每个BO包含这些PO。这样处理业务逻辑时,我们就可以针\n对BO去处理。\n 7.POJO(Plain Ordinary Java Object) 简单无规则的java对象\n传统意义的java对象。就是说在一些 Object/Relation Mapping工具中,能够做到维护数据库表记录的 persisent\nobject完全是一个符合 Java Bean规范的纯Java对象，没有增加别的属性和方法。\n我的理解就是最基本的 Java Bean,只有属性字段及 setter和 getter方法!\nPOJO是 DO / DTO / BO / VO 的统称。\n 8.DAO(Data Access Object) 数据访问对象\n是一个sun的一个标准j2ee设计模式，这个模式中有个接囗就是DAO，它负持久层的操作。为业务层提供接口。此\n对象用于访问数据库。通常和PO结合使用，DAO中包含了各种数据库的操作方法。通过它的方法，结合PO对数据\n库进行相关的操作。夹在业务逻辑与数据库资源中间。配合VO，提供数据库的CRUD操作。\n","id":12,"section":"posts","summary":"1.PO(Persistant Object) 持久对象 PO就是对应数据库中某个表中的一条记录,多个记录可以用PO的集合。PO中应该不包含任何对数据库的操作。 2.DO(Domain object) 领域对象 就是从现实世界","tags":null,"title":"Object划分","uri":"https://bluestaree.github.io/2020/05/object%E5%88%92%E5%88%86/","year":"2020"},{"content":" 前言  现在的项目大多都是前后端分离的项目，那么对于一些重要数据的校验，单单使用前端控制是不行的，我们可以使用一些http请求工具如 Postman ，就可以轻松的跳过前端验证直接请求后台服务。因此服务端的数据验证也是必不可少，本文介绍了对于JSR303校验标准的简单使用\n 使用步骤 1.对需要校验的Bean对应字段加上校验注解，并定义错误消息提示\n所支持的校验注解类型可以在 **javax.validation.constraints ** 包下查看\n2.开启校验\n使用**@Valid**开启校验\n这样就能够完成校验功能了，是不是很简单，当然也允许使用自定义规则的校验注解，这里不再进行演示。\n异常信息处理 对于校验不通过的异常数据，通常需要我们自己来处理，如果我们没有进行异常处理，默认返回的结果就像这样一\n长串的错误信息，用户体验就不是很好了\n这样的数据肯定不是我们所希望的，\n处理方法 我们可以在校验方法上，添加 BindingResult 方法参数，就可以接收到异常信息，获取到校验的结果，并进行相应的逻辑处理\n当然这样也不是最好的解决方案，如果有很多服务都需要校验异常，那就太麻烦了，我们可以使用SprngMVC所提\n供控制器增强功能，进行全局异常捕获处理，针对MethodArgumentNotValidException异常进行捕获，并统\n一返回自定义的结果\n分组校验 分组校验适合多场景校验的情况，举个栗子，比如对于商品评论ID，规定在新增时不需要携带ID信息，使用自增\n长主键，而在修改时必须要携带ID信息。\n这样一来就需要在Bean中的ID字段添加多个校验注解,这时就需要用到分组校验\n注意，分组的标识必须为接口类型 ，可以自定义一个标记接口\n在校验的时候使用 @Validated 指定校验组即可\n需要注意的是如果存在没有指定分组的校验注解，在指定分组校验的情况下不会生效\n","id":13,"section":"posts","summary":"前言 现在的项目大多都是前后端分离的项目，那么对于一些重要数据的校验，单单使用前端控制是不行的，我们可以使用一些http请求工具如 Postman ，就可以轻","tags":null,"title":"使用JSR303规范标准进行数据校验","uri":"https://bluestaree.github.io/2020/04/%E4%BD%BF%E7%94%A8jsr303%E8%A7%84%E8%8C%83%E6%A0%87%E5%87%86%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E6%A0%A1%E9%AA%8C/","year":"2020"},{"content":"  转载 · 原文链接：https://blog.csdn.net/wu1317581750/java/article/details/81662929\n hibernate运行原理： hibernate里面提供了3个核心接口 Configuration、SessionFactory、Session\nhibernate启动的时候利用Configuration读取xml配置文件\n通过配置文件创建SessionFactory对象，初始化hibernate基本信息\n获取session然后调用CRUD方法进行数据操作，hibernate会把我们的数据进行三种状态的划分，然后根据状态进行管理我们的数据，对应的发送SQL进行数据操作\n关闭session，如果有事务的情况下，需要手动获取事务并开启，然后事务结束后提交事务。\n在提交事务的时候，去验证我们的快照里面的数据和缓存数据是否一致，如果不一致，发送SQL进行修改，\nhibernate的get方法和load方法的区别 get和load都是利用主键策略查询数据，\nget默认不使用懒加载机制，load默认要使用懒加载机制，所谓的懒加载就是我们这个数据如果不使用，hibernate就不发送SQL到数据库查询数据。\n当查询数据库不存在的数据的时候，get方法返回null，load方法抛出空指针异常，\n原因是因为，load方法采用的动态代理的方式实现的，我们使用load方法的时候，hibernate会创建一个该实体的代理对象，该代理只保存了该对象的ID，当我们访问该实体对象其他属性，hibernate就发送SQL查询数据封装到代理对象，然后在利用代理对象返回给我们实际的数据，\nhibernate的数据三种状态 hibernate把他所管理的数据划分为三种状态\n瞬时的（刚new出来的数据–内存有，数据库没有）\n持久的 （从数据查询的，或者刚保存到数据库，session没关闭的， 数据库有，内存也有）\n游离的 、脱管的（数据库有，内存没有）\n实际上hibernate对数据划分三种状态，主要是为了管理我们持久的数据，在事务提交的时候，hibernate去对比处于持久状态的数据是否发生改变，(快照区、一级缓存区)，当我们会话结束前，对持久状态数据进行了修改的话，快照区的数据会跟着改变。当session提交事务的时候，如果发现快照区和一级缓存的数据不一致，就会发送SQL进行修改。\n简述hibernate的缓存机制 hibernate分为2级缓存\n一级缓存又叫session缓存，又叫事务级缓存，生命周期从事务开始到事务结束，一级缓存是hibernate自带的，暴力使用，当我们一创建session就已有这个缓存了。数据库就会自动往缓存存放，\n二级缓存是hibernate提供的一组开放的接口方式实现的，都是通过整合第三方的缓存框架来实现的，二级缓存又叫sessionFactory的缓存，可以跨session访问。常用的EHcache、OScache，这个需要一些配置。\n当我们每次 查询数据的时候，首先是到一级缓存查看是否存在该对象，如果有直接返回，如果没有就去二级缓存进行查看，如果有直接返回，如果没有在发送SQL到数据库查询数据，\n当SQL发送查询回该数据的时候，hibernate会把该对象以主键为标记的形式存储到二级缓存和一级缓存，如果返回的是集合，会把集合打散然后以主键的形式存储到缓存。一级缓存和二级缓存只针对以ID查询的方式生效，get、load方法。\n简述hibernate中getCurrentSession和openSession区别 getCurrentSession和openSession都是通过H的工厂去获取数据库的会话对象，\n1、getCurrentSession会绑定当前线程，而openSession不会，因为我们把hibernate交给我们的spring来管理之后，我们是有事务配置，这个有事务的线程就会绑定当前的工厂里面的每一个session，而openSession是创建一个新session。\n2、getCurrentSession事务是有spring来控制的，而openSession需要我们手动开启和手动提交事务，\n3、getCurrentSession是不需要我们手动关闭的，因为工厂会自己管理，而openSession需要我们手动关闭。\n4、而getCurrentSession需要我们手动设置 绑定事务的机制，有三种设置方式，jdbc本地的Thread、JTA、第三种是spring提供的事务管理机制org.springframework.orm.hibernate4.SpringSessionContext，而且srping默认使用该种事务管理机制，\n————————————————\n","id":14,"section":"posts","summary":"转载 · 原文链接：https://blog.csdn.net/wu1317581750/java/article/details/816629","tags":["hibernate"],"title":"Hibernate常见问题","uri":"https://bluestaree.github.io/2020/04/hibernate%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","year":"2020"},{"content":"  转载 · 原文链接：https://www.jianshu.com/p/dc1e5091a0d8\n 在大型互联网应用当中如果你的应用引入了缓存机制，那么有一个大前提就是你的业务场景上必须得接受数据的新鲜度上有可能会有一定时间的延迟。删除缓存失败是一个极小概率事件，且在不能保证所有操作100%成功的几率下，采用JOB补偿的机制是目前比较成熟的解决方案。大并发量写请求的应用，不可能去实时写DB，基本都采用队列+消息异步写DB的机制，不然会有大量的并发问题。\n缓存机制介绍 如今利用缓存机制来提高查询效率已被广泛用在各大生产环境，查询数据的一般流程如下所示\n\n在没有更新数据的情况下，数据库和缓存的数据是保持一致的，当时当要执行数据库的更新操作时，数据库和缓存就会出现不一致的情况。\n首先需要明确的是，既然系统引入缓存机制，就必须接受系统会出现数据不一致的情况发生，我们不可能完全避免，只能尽量减少不一致的时间，达到最终一致性。常见的有以下几种方案：\n 先删缓存，再更新数据库 先更新数据库，再删缓存 缓存延时双删，即先删除一次缓存，再更新数据库，延时一小段时间后再次删除缓存 监听MySQL binlog进行缓存更新  之所以缓存不采取更新操作而是直接删除，是因为高并发环境下，无论是先操作数据库还是后操作数据库，如果加上缓存更新，那就更容易导致数据库与缓存的不一致（删除缓存直接且简单得多）\n先删除缓存，再更新数据库 1、线程A删除了缓存\n2、线程B读不到缓存，然后去DB中读取了旧数据\n3、线程B将旧数据写入缓存\n4、线程A更新DB\n这样一来，DB中是新的数据，缓存中是旧的数据，造成了不一致问题。\n先更新数据库，再删除缓存 1、缓存已失效时，线程A从DB中读取到旧值\n2、线程B更新数据库，并删除了缓存\n3、线程A将旧值写入缓存\n这样一来，DB中是新的数据，缓存中是旧的数据，造成了不一致问题。\n延时双删 为解决先删除缓存，再更新数据库可能出现的问题，出现了该方案\n1、线程A删除了缓存\n2、线程B读不到缓存，然后去DB中读取了旧数据\n3、线程B将旧数据写入缓存\n4、线程A更新DB\n5、延时异步再删除缓存 上面已经分析了，如果没有第5步，会出现DB是新值，缓存是旧值的情况。加上第五步之后，4-5之间的这段时间，还是会出现数据不一致，但是一旦执行了第5步，数据又将达成最终一致性。\n","id":15,"section":"posts","summary":"转载 · 原文链接：https://www.jianshu.com/p/dc1e5091a0d8 在大型互联网应用当中如果你的应用引入了缓存机制，","tags":["缓存"],"title":"缓存与数据库双写一致性问题及最佳解决方案","uri":"https://bluestaree.github.io/2020/04/%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E5%8F%8A%E6%9C%80%E4%BD%B3%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","year":"2020"},{"content":" 记录一个坑，我现在所用的MySQL数据库的版本是8.019，在尝试使用Navicat连接数据库时，出现1251错误\n解决方法： 进入docker容器修改MySQL的root用户加密规则\n ALTER USER \u0026lsquo;root\u0026rsquo;@\u0026lsquo;localhost\u0026rsquo; IDENTIFIED WITH mysql_native_password BY \u0026lsquo;password\u0026rsquo;; #修改加密规则 ALTER USER \u0026lsquo;root\u0026rsquo;@\u0026lsquo;localhost\u0026rsquo; IDENTIFIED BY \u0026lsquo;password\u0026rsquo; PASSWORD EXPIRE NEVER; #更新一下用户的密码 FLUSH PRIVILEGES; #刷新权限  \u0026lsquo;root\u0026rsquo; 为你自己定义的用户名\n\u0026lsquo;localhost\u0026rsquo; 指的是用户开放的IP，可以是\u0026rsquo;localhost\u0026rsquo;(仅本机访问，相当于127.0.0.1)，可以是具体的\u0026rsquo;...'(具体某一IP)，也可以是 \u0026lsquo;%\u0026rsquo; (所有IP均可访问)\n\u0026lsquo;password\u0026rsquo; 是你想使用的用户密码\n","id":16,"section":"posts","summary":"记录一个坑，我现在所用的MySQL数据库的版本是8.019，在尝试使用Navicat连接数据库时，出现1251错误 解决方法： 进入docker","tags":null,"title":"Navicat连接MySQL出现1251错误","uri":"https://bluestaree.github.io/2020/04/navicat-1251%E9%94%99%E8%AF%AF/","year":"2020"},{"content":"  转载 · 原文链接：https://blog.csdn.net/CSDN_Ty/article/details/98877883\n 本文的内容主要想解决一下几个问题：\n equals() 和 == 的作用是什么？ equals() 和 == 的区别是什么？ hashCode()的作用是什么？ hashCode()与equals()之间有什么联系？  equals() 和 == 的作用  == 是用来判断两个对象是否为同一个对象，通过判断两个对象的内存地址来区分它们是否相等。 equals() 是用来判断两个对象是否相等，equals()定义在Object类中，所有类都继承了该方法。  从源码可以看出，默认情况下，equals与==没有区别，equals就是调用的==来进行判断。\npublic boolean equals(Object obj) {\rreturn (this == obj);\r}\r 所以，通常我们都会重写equals方法：两对象内容相等，则返回true，否则返回false。举例：\n①没有重写equals()方法时：\npublic class Test {\r@AllArgsConstructor\r@Setter\r@Getter\rpublic static class Student {\rprivate String name;\rprivate int age;\r}\rpublic static void main(String[] args) {\rStudent stu1 = new Student(\u0026quot;ye17186\u0026quot;, 18);\rStudent stu2 = new Student(\u0026quot;ye17186\u0026quot;, 18);\rSystem.out.println(\u0026quot;stu1.equals(stu2): \u0026quot; + stu1.equals(stu2));\r}\r}\r 输出结果：\n\n解析：\n由于stu1、stu2都是直接new出来的对象，它们指向两块不同的内存地址，在未重写equals方法的情况下，调用equals()方法其实就是调用==，比较的是他们的内存地址是否相同，所以这里打印的结果的false。\n②重写equals()方法时：\npublic class Test {\r@AllArgsConstructor\r@Setter\r@Getter\rpublic static class Student {\rprivate String name;\rprivate int age;\r@Override\rpublic boolean equals(Object o) {\rif (this == o) {\rreturn true;\r}\rif (o == null || getClass() != o.getClass()) {\rreturn false;\r}\rStudent student = (Student) o;\rreturn name.equals(student.getName()) \u0026amp;\u0026amp; age == student.age;\r}\r}\rpublic static void main(String[] args) {\rStudent stu1 = new Student(\u0026quot;ye17186\u0026quot;, 18);\rStudent stu2 = new Student(\u0026quot;ye17186\u0026quot;, 18);\rSystem.out.println(\u0026quot;stu1.equals(stu2): \u0026quot; + stu1.equals(stu2));\r}\r}\r 输出结果：\n\n解析：\n重写equals方法后，就会使用equals方法内的逻辑来判断是否相等，例子中直接比较了name和age是否相等，stu1和stu2两个对象，他们的name都是ye17186，age都是18，所以这里输出的结果是true。\nequals()与==的区别 上面已经解析过了，从设计上说==是用来判断是否为同一个对象，equals()用来判断两个对象是否相等。如果我们没有重写equals()方法，那么二者其实是等价的。但一般我们会重写equals()方法，这样会按照我们重写的逻辑来判断两个对象是否相等。\nhashCode的作用  hashCode()的作用是获取哈希码，也成为了散列码，它实际上返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。 hashCode()定义在java.lang.Object中，这意味着JAVA中任何类都有这个函数。 虽然每个JAVA类都有hashCode函数，但是仅仅当创建某个“类的散列表”时，该类的hashCode()才有用（作用是确定该类的每一个对象在散列表中的位置），其他情况下（例如：创建类的单个对象，或者创建类的对象数组等），类的hashCode()没有作用。 上面的散列表，指的是JAVA集合中本质是散列表的类，如HashMap、HashTable、HashSet。 也就是说，hashCode()在散列表中有用，在其他情况下没用。在散列表中hashCode()用于获取对象的散列码，从而确定该对象在散列表中的位置。 如果两个对象相等，他们的散列码一定相等；但是如果散列码相等，它们不一定相等  hashCode()与equals之间的联系 在非”本质是散列表的类”中，两者没有任何关系。而在”本质是散列表的类”中，在HashSet中，如果两个对象的hashCode相同，即使equals不等，它们在集合中也只会存储一个。\n","id":17,"section":"posts","summary":"转载 · 原文链接：https://blog.csdn.net/CSDN_Ty/article/details/98877883 本文的内容主要想","tags":["hashCode","equals"],"title":"hashCode和equals的相关问题","uri":"https://bluestaree.github.io/2020/04/hashcode%E5%92%8Cequals%E7%9A%84%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/","year":"2020"},{"content":" Feign调用流程  构造请求对象，将对象转为json 发送执行请求(执行成功会解码响应得数据) 获取结果  从代码中可以看出，如何请求出现异常，就会执行**retryer.continueOrPropagate(e)**方法进行重试，直到重试次数到指定的值，或者重试成功为止\n","id":18,"section":"posts","summary":"Feign调用流程 构造请求对象，将对象转为json 发送执行请求(执行成功会解码响应得数据) 获取结果 从代码中可以看出，如何请求出现异常，就会执","tags":null,"title":"Feign重试机制","uri":"https://bluestaree.github.io/2020/04/feign%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6/","year":"2020"},{"content":"  Spring Security 是spring项目之中的一个安全模块，可以非常方便与spring项目无缝集成。特别是在spring boot项目中加入spring security更是十分简单。本篇主要记录spring security的验证与授权流程，以及spring security在web应用中的相关配置。\n 认证流程 Spring Security的认证流程如下:\n授权流程 Spring Security使用标准Filter建立了对web请求的拦截,最终实现对资源的授权访问。\nSpring Security的授权流程如下:\n会话控制 我们可以通过以下选项准确控制会话何时创建以及Spring Security如何与之交互:\n   机制 描述     always 如果没有session存在就创建一个   ifRequired 如果需要就创建一个Session (默认) 登录时   never SpringSecurity将不会创建Session ,但是如果应用中其他地方创建了Session ,那么SpringSecurity将会使用它。   stateless SpringSecurity将绝对不会创建Session，也不使用Session    通过以下配置方式对该选项进行配置:\n@Override\rprotected void configure (HttpSecurity http) throws Exception {\rhttp.sessionManagement()\r.sessionCreationPolicy(SessionCreationPolicy.IFREQUIRED);\r}\r ​\t默认情况下, Spring Security会为每个登录成功的用户会新建一个Session ,就是ifRequired。\n​\t若选用never ,则指示Spring Security对登录成功的用户不创建Session了,但若你的应用程序在某地方新建了session ,那么Spring Security会用它的。\n​\t若使用stateless ,则说明Spring Security对登录成功的用户不会创建Session了,你的应用程序也不会允许新建session。并且它会暗示不使用cookie ,所以每个请求都需要重新进行身份验证。这种无状态架构适用于REST API及其无状态认证机制。\n安全拦截配置-HttpSecurity spring security提供了用户名密码登录、退出、会话管理等认证功能,只需要配置即可使用。\nHttpSecurity配置列表:\n   方法 说明     openidLogin() 用于基于Openld的验证   headers() 将安全标头添加到响应   cors() 配置跨域资源共享( CORS )   sessionManagement() 允许配置会话管理   portMapper() 允许配置一个PortMapper(HttpSecurity#(getSharedObject(lass))) ,其他提供SecurityConfigurer的对象使用PortMapper从HTTP重定向到HTTPS或者从HTTPS重定向到HTTP.默认情况下, Spring Security使用一个PortMapperlmp映射HTTP端口8080到HTTPS端口8443 , HTTP端口80到HTTPS端口443   jee() 配置基于容器的预认证。在这种情况下 ,认证由Servlet容器管理   x509() 配置基于x509的认证   rememberMe 允许配置\u0026quot;记住我\u0026quot;的验证   authorizeRequests() 允许基于使用HttpServletRequest限制访问   requestCache() 允许配置请求缓存   exceptionHandling() 允许配置错误处理   securityContext() 在HttpServletRequests之间的SecurityContextHolder上设置SecurityContext的管理。当使用WebSecurityConfigurerAdapter时 ，这将自动应用   servletApi() 将HttpServletRequest方法与在其上找到的值集成到SecurityContext中。当使用WebSecurityConfigurerAdapter时,这将自动应用   csrf() 添加CSRF支持,使用WebSecurityConfigurerAdapter时,默认启用   logout() 添加退出登录支持。当使用WebSecurityConfigurerAdapter时 ,这将自动应用。默认情况是,访问URL\u0026rdquo;/ logout\u0026rdquo; ,使HTTP Session无效来清除用户,清除已配置的任何#rememberMe()身份验证,清除SecurityContextHolder ,然后重定向到\u0026rdquo;/login?success\u0026rdquo;   anonymous() 允许配置匿名用户的表示方法。 当与WebSecurityConfigurerAdapter结合使用时,这将自动应用。默认情况下,匿名用户将使用org.springframework.security.authentication.AnonymousAuthenticationToker表示，并包含角色\u0026quot;ROLE ANONYMOUS\u0026rdquo;   formLogin() 指定支持基于表单的身份验证。如果未指定FormLoginConfigurer#loginPage(String) ,则将生成默认登录页面   oauth2Login() 根据外部OAuth 2.0或OpenID Connect 1.0提供程序配置身份验证   requiresChannel() 配置通道安全。为了使该配置有用,必须提供至少一个到所需信道的映射   httpBasic() 配置Http Basic验证   addFilterAt() 在指定的Filter类的位置添加过滤器    web授权 如何能够对访问路径进行灵活的控制呢？我们可以通过给**http. authorizeRequests()**添加多个子节点来定制需求到我们的URL ,如下代码\n@Override\rprotected void configure(HttpSecurity http) throws Exception {\rhttp\r.authorizeRequests()\r.antMatchers(\u0026quot;/r/r1\u0026quot;).hasAuthority(\u0026quot;p1\u0026quot;)\r.antMaychers(\u0026quot;/r/r2\u0026quot;).hasAuthority(\u0026quot;p2\u0026quot;)\r.antMatchers(\u0026quot;/r/r3\u0026quot;).access(\u0026quot;hasAuthority('p1') and hasAuthority('p2')\u0026quot;)\r.antMatchers(\u0026quot;/r/**\u0026quot;).authenticated()\r.anyRequest().permitAll();\r//...\r}\r 保护URL常用的方法有:\nauthenticated() 保护URL ,需要用户登录\npermitAll() 指定URL无需保护, 一般应用与静态资源文件\nhasRole(String role) 限制单个角色访问,角色将被增加\u0026quot;ROLE_”.所以\u0026quot;ADMIN\u0026quot;将和\u0026quot;ROLE ADMIN\u0026quot;进行比较\nhasAuthority(String authority) 限制单个权限访问\nhasAnyRole(String\u0026hellip; roles) 允许多个角色访问.\nhasAnyAuthority(String\u0026hellip; authorities) 允许多个权限访问\naccess(String attribute) 该方法使用SpEL表达式,所以可以创建复杂的限制.\nhaslpAddress(String ipaddressExpression) 限制IP地址或子网\n这里需要注意的是:\n规则的顺序是重要的,更具体的规则应该先写,现在以/admin开始的所有内容都需要具有ADMIN角色的身份验证用户,即使是/admin/login路径(因为/admin/login已经被/admin/**规则匹配,因此第二个规则被忽略).\n.antMatchers(\u0026quot;/admin/**\u0026quot;).hasRole(\u0026quot;ADMIN\u0026quot;)\r.antMatchers(\u0026quot;/admin/login\u0026quot;).permitAll()\r 因此,登录页面的具体规则应该在/admin/**规则之前.例如.\n.antMatchers(\u0026quot;/admin/login\u0026quot;).permitAll()\r.antMatchers(\u0026quot;/admin/**\u0026quot;).hasRole(\u0026quot;ADMIN\u0026quot;)\r 方法授权 除了对web路径进行访问授权外，我们还可以对方法进行访问限制，主要依赖于3个注解:@PreAuthorize,@PostAuthorize,@Secured实现\n使用如下代码可启用@prePost注解的支持\n@EnableGlobalMethodSecurity(prePostEnabled = true)\rpublic class MethodSecurityConfig {\r//...\r}\r 相对应java代码如下：\npublic interface BankService {\r@PreAuthorize(\u0026quot;isAnonymous()\u0026quot;)\rpublic Account readAccount(Long id);\r@PreAuthorize(\u0026quot;isAnonymous()\u0026quot;)\rpublic Account[] findAccounts();\r@PreAuthorize(\u0026quot;hasAuthority('p_transfer') and hasAuthority('p_read_account')\u0026quot;)\rpublic Account post(Account account, double amount);\r}\r 以上配置标明readAccount. findAccounts方法可匿名访问 , post方法需要同时拥有p_transfer和 p_read. account权限才能访问,底层使用WebExpressionVoter投票器,可从AffirmativeBased第23行代码跟踪\n","id":19,"section":"posts","summary":"Spring Security 是spring项目之中的一个安全模块，可以非常方便与spring项目无缝集成。特别是在spring boot项目中加入spring secu","tags":["SpringSecurity"],"title":"SpringSecurity流程与配置","uri":"https://bluestaree.github.io/2020/04/spring-security%E6%B5%81%E7%A8%8B%E4%B8%8E%E9%85%8D%E7%BD%AE/","year":"2020"},{"content":" 最近在学习中遇到了新的包管理工具 - Gradle 。\n上网查询了下Gradle 的依赖方式，方便与Maven区分对比 。\n 转载 · 原文链接：https://blog.csdn.net/zyt_524744325/article/details/86535463\n 依赖配置-Gradle 目前Gradle版本支持的依赖配置有：implementation、api、compileOnly、runtimeOnly和annotationProcessor，已经废弃的配置有：compile、provided、apk、providedCompile。此外依赖配置还可以加一些配置项，例如AndroidTestImplementation、debugApi等等。\n implementation  与compile对应，会添加依赖到编译路径，并且会将依赖打包到输出（aar或apk），但是在编译时不会将依赖的实现暴露给其他module，也就是只有在运行时其他module才能访问这个依赖中的实现。使用这个配置，可以显著提升构建时间，因为它可以减少重新编译的module的数量。建议，尽量使用这个依赖配置。\n api  与compile对应，功能完全一样，会添加依赖到编译路径，并且会将依赖打包到输出（aar或apk），与implementation不同，这个依赖可以传递，其他module无论在编译时和运行时都可以访问这个依赖的实现，也就是会泄漏一些不应该不使用的实现。举个例子，A依赖B，B依赖C，如果都是使用api配置的话，A可以直接使用C中的类（编译时和运行时），而如果是使用implementation配置的话，在编译时，A是无法访问C中的类的。\n compileOnly  与provided对应，Gradle把依赖加到编译路径，编译时使用，不会打包到输出（aar或apk）。这可以减少输出的体积，在只在编译时需要，在运行时可选的情况，很有用。\n runtimeOnly  与apk对应，gradle添加依赖只打包到APK，运行时使用，但不会添加到编译路径。这个没有使用过。\n annotationProcessor  与compile对应，用于注解处理器的依赖配置，这个没用过。\n 依赖配置-Maven  compile  默认scope为compile，表示为当前依赖参与项目的编译、测试和运行阶段，属于强依赖。打包之时，会达到包里去。\n test  该依赖仅仅参与测试相关的内容，包括测试用例的编译和执行，比如定性的Junit。\n runtime  依赖仅参与运行周期中的使用。一般这种类库都是接口与实现相分离的类库，比如JDBC类库，在编译之时仅依赖相关的接口，在具体的运行之时，才需要具体的mysql、oracle等等数据的驱动程序。\n此类的驱动都是为runtime的类库。\n provided  该依赖在打包过程中，不需要打进去，这个由运行的环境来提供，比如tomcat或者基础类库等等，事实上，该依赖可以参与编译、测试和运行等周期，与compile等同。区别在于打包阶段进行了exclude操作。\n system  使用上与provided相同，不同之处在于该依赖不从maven仓库中提取，而是从本地文件系统中提取，其会参照systemPath的属性进行提取依赖。\n import  这个是maven2.0.9版本后出的属性，import只能在dependencyManagement的中使用，能解决maven单继承问题，import依赖关系实际上并不参与限制依赖关系的传递性。\n","id":20,"section":"posts","summary":"最近在学习中遇到了新的包管理工具 - Gradle 。 上网查询了下Gradle 的依赖方式，方便与Maven区分对比 。 转载 · 原文链接：https://blog","tags":["Maven","Gradle"],"title":"Maven,Gradle依赖","uri":"https://bluestaree.github.io/2020/04/mavengradle%E4%BE%9D%E8%B5%96/","year":"2020"},{"content":"  转载 · 原文链接：https://blog.csdn.net/qw463800202/article/details/103221651\n 一、动态sql使用 1.1、在项目中涉及多个动态查询条件，一般我们是通过 where 1 = 1，这样可以处理where后面对应条件全空的情况，我们可以使用标签，该标签可以自动处理,主要是当我们的sql查询条件以AND和OR结尾时，会自动去除，如\n\u0026lt;where\u0026gt; \u0026lt;if test=\u0026quot;keyword != null\u0026quot;\u0026gt; and title like concat('%',trim(#{keyword}),'%') \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt;\r\u0026lt;where\u0026gt; \u0026lt;if test=\u0026quot;name != null\u0026quot;\u0026gt; or name=#{name} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026quot;keyword != null\u0026quot;\u0026gt; or title like concat('%',trim(#{keyword}),'%') \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt;\r 1.2、在项目中涉及多个动态update条件时，传统的项目需要我们去除最后一个条件的逗号，但是在mybatis中我们可以使用标签，如\nUPDATE user\r\u0026lt;set\u0026gt;\r\u0026lt;if test ='null != name'\u0026gt;name = #{name},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != email'\u0026gt;email = #{email},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != headUrl'\u0026gt;head_url = #{headUrl},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != linkData'\u0026gt;link_data = #{linkData},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != createTime'\u0026gt;create_time = #{createTime},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != updateTime'\u0026gt;update_time = #{updateTime}\u0026lt;/if\u0026gt;\r\u0026lt;/set\u0026gt;\r ​ 1.3、动态if else语句，在mybatis中使用choose、when、otherwise来处理，如下代码\nmybatis 中 SQL 写在mapper.xml文件中，而xml解析 \u0026lt; 、\u0026gt;、\u0026lt;=、\u0026gt;= 时会出错，这时应该使用转义写法，如下\n   \u0026lt; \u0026lt;= \u0026gt; \u0026gt;= \u0026amp; ' \u0026quot;     \u0026amp;lt; \u0026amp;lt;= \u0026amp;gt; \u0026amp;gt;= \u0026amp;amp; \u0026amp;apos; \u0026amp;quot;    三、mybatis循环标签 3.1、循环查询in语句，代码如下\n \u0026lt;select id=\u0026quot;findBy\u0026quot; resultMap=\u0026quot;BaseResultMap\u0026quot;\u0026gt;\rselect * from user where user_id in\r\u0026lt;foreach item=\u0026quot;item\u0026quot; index=\u0026quot;index\u0026quot; collection=\u0026quot;list\u0026quot; open=\u0026quot;(\u0026quot; separator=\u0026quot;,\u0026quot; close=\u0026quot;)\u0026quot;\u0026gt;\r#{item}\r\u0026lt;/foreach\u0026gt;\r\u0026lt;/select\u0026gt;\r 3.2、批量插入使用循环,代码如下\n\u0026lt;insert id=\u0026quot;insertList\u0026quot; parameterType=\u0026quot;java.util.List\u0026quot;\u0026gt;\rinsert into user\r( name,sex,email,remark)\rvalues\r\u0026lt;foreach collection=\u0026quot;list\u0026quot; item=\u0026quot;item\u0026quot; index=\u0026quot;index\u0026quot; separator=\u0026quot;,\u0026quot;\u0026gt;\r(\r#{item.name},\r#{item.sex},\r#{item.email},\r#{item.remark}\r)\r\u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt;  四、重复的sql片段整合在一起使用include标签 定义：\r\u0026lt;sql id=\u0026quot;Base_Column_List\u0026quot; \u0026gt; id, name, url, priority, logo, img \u0026lt;/sql\u0026gt; 引用：\r\u0026lt;include refid=\u0026quot;Base_Column_List\u0026quot; /\u0026gt;  ————————————————\n","id":21,"section":"posts","summary":"转载 · 原文链接：https://blog.csdn.net/qw463800202/article/details/103221651 一、动","tags":["Mybatis"],"title":"Mybatis常用语法汇总","uri":"https://bluestaree.github.io/2020/03/mybatis%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%E6%B1%87%E6%80%BB/","year":"2020"},{"content":"  转载 · 原文链接：https://www.runoob.com/java/java8-new-features.html\n java 8 新特性 Java8 新增了非常多的特性，我们主要讨论以下几个：\n Lambda 表达式 − Lambda 允许把函数作为一个方法的参数（函数作为参数传递到方法中）。 方法引用 − 方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。 默认方法 − 默认方法就是一个在接口里面有了一个实现的方法。 新工具 − 新的编译工具，如：Nashorn引擎 jjs、 类依赖分析器jdeps。 Stream API −新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。 Date Time API − 加强对日期与时间的处理。 Optional 类 − Optional 类已经成为 Java 8 类库的一部分，用来解决空指针异常。 Nashorn, JavaScript 引擎 − Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用  先来看看排序方式的对比把\n// 使用 java 7 排序\rprivate void sortUsingJava7(List\u0026lt;String\u0026gt; names){ Collections.sort(names, new Comparator\u0026lt;String\u0026gt;() {\r@Override\rpublic int compare(String s1, String s2) {\rreturn s1.compareTo(s2);\r}\r});\r}\r// 使用 java 8 排序\rprivate void sortUsingJava8(List\u0026lt;String\u0026gt; names){\rCollections.sort(names, (s1, s2) -\u0026gt; s1.compareTo(s2));\r}\r 怎么样，是不是感觉代码简化了不少，让我们继续深入学习java8的那些新特性\nLambda 表达式实例 Lambda 表达式的简单例子:\n// 1. 不需要参数,返回值为 5 () -\u0026gt; 5 // 2. 接收一个参数(数字类型),返回其2倍的值 x -\u0026gt; 2 * x // 3. 接受2个参数(数字),并返回他们的差值 (x, y) -\u0026gt; x – y // 4. 接收2个int型整数,返回他们的和 (int x, int y) -\u0026gt; x + y // 5. 接受一个 string 对象,并在控制台打印,不返回任何值(看起来像是返回void) (String s) -\u0026gt; System.out.print(s)\r 使用 Lambda 表达式需要注意以下两点：\n Lambda 表达式主要用来定义行内执行的方法类型接口，例如，一个简单方法接口。在上面例子中，我们使用各种类型的Lambda表达式来定义MathOperation接口的方法。然后我们定义了sayMessage的执行。 Lambda 表达式免去了使用匿名方法的麻烦，并且给予Java简单但是强大的函数化的编程能力。  Java 8 方法引用 方法引用通过方法的名字来指向一个方法。\n方法引用可以使语言的构造更紧凑简洁，减少冗余代码。\n方法引用使用一对冒号 :: 。\n **构造器引用：**它的语法是Class::new，或者更一般的Class\u0026lt; T \u0026gt;::new实例如下：  final Car car = Car.create( Car::new );\rfinal List\u0026lt; Car \u0026gt; cars = Arrays.asList( car );\r  **静态方法引用：**它的语法是Class::static_method，实例如下：  cars.forEach( Car::collide );\r  **特定类的任意对象的方法引用：**它的语法是Class::method实例如下：  cars.forEach( Car::repair );\r  **特定对象的方法引用：**它的语法是instance::method实例如下：  final Car police = Car.create( Car::new );\rcars.forEach( police::follow );\r Java 8 Stream Java 8 API添加了一个新的抽象称为流Stream，可以让你以一种声明的方式处理数据。\nStream 使用一种类似用 SQL 语句从数据库查询数据的直观方式来提供一种对 Java 集合运算和表达的高阶抽象。\nStream API可以极大提高Java程序员的生产力，让程序员写出高效率、干净、简洁的代码。\n这种风格将要处理的元素集合看作一种流， 流在管道中传输， 并且可以在管道的节点上进行处理， 比如筛选， 排序，聚合等。\n元素流在管道中经过中间操作（intermediate operation）的处理，最后由最终操作(terminal operation)得到前面处理的结果。\n生成流\n在 Java 8 中, 集合接口有两个方法来生成流：\n stream() − 为集合创建串行流。 parallelStream() − 为集合创建并行流。  List\u0026lt;String\u0026gt; strings = Arrays.asList(\u0026quot;abc\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;bc\u0026quot;, \u0026quot;efg\u0026quot;, \u0026quot;abcd\u0026quot;,\u0026quot;\u0026quot;, \u0026quot;jkl\u0026quot;);\rList\u0026lt;String\u0026gt; filtered = strings.stream().filter(string -\u0026gt; !string.isEmpty()).collect(Collectors.toList());\r  forEach\nStream 提供了新的方法 \u0026lsquo;forEach\u0026rsquo; 来迭代流中的每个数据。以下代码片段使用 forEach 输出了10个随机数：\nRandom random = new Random();\rrandom.ints().limit(10).forEach(System.out::println);\r  map\nmap 方法用于映射每个元素到对应的结果，以下代码片段使用 map 输出了元素对应的平方数：\nList\u0026lt;Integer\u0026gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\r// 获取对应的平方数\rList\u0026lt;Integer\u0026gt; squaresList = numbers.stream().map( i -\u0026gt; i*i).distinct().collect(Collectors.toList());\r  filter\nfilter 方法用于通过设置的条件过滤出元素。以下代码片段使用 filter 方法过滤出空字符串：\nList\u0026lt;String\u0026gt;strings = Arrays.asList(\u0026quot;abc\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;bc\u0026quot;, \u0026quot;efg\u0026quot;, \u0026quot;abcd\u0026quot;,\u0026quot;\u0026quot;, \u0026quot;jkl\u0026quot;);\r// 获取空字符串的数量\rlong count = strings.stream().filter(string -\u0026gt; string.isEmpty()).count();\r  limit\nlimit 方法用于获取指定数量的流。 以下代码片段使用 limit 方法打印出 10 条数据：\nRandom random = new Random();\rrandom.ints().limit(10).forEach(System.out::println);\r  sorted\nsorted 方法用于对流进行排序。以下代码片段使用 sorted 方法对输出的 10 个随机数进行排序：\nRandom random = new Random();\rrandom.ints().limit(10).sorted().forEach(System.out::println);\r  并行（parallel）程序\nparallelStream 是流并行处理程序的代替方法。以下实例我们使用 parallelStream 来输出空字符串的数量：\nList\u0026lt;String\u0026gt; strings = Arrays.asList(\u0026quot;abc\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;bc\u0026quot;, \u0026quot;efg\u0026quot;, \u0026quot;abcd\u0026quot;,\u0026quot;\u0026quot;, \u0026quot;jkl\u0026quot;);\r// 获取空字符串的数量\rint count = strings.parallelStream().filter(string -\u0026gt; string.isEmpty()).count();\r 我们可以很容易的在顺序运行和并行直接切换。\n Collectors\nCollectors 类实现了很多归约操作，例如将流转换成集合和聚合元素。Collectors 可用于返回列表或字符串：\nList\u0026lt;String\u0026gt; strings = Arrays.asList(\u0026quot;abc\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;bc\u0026quot;, \u0026quot;efg\u0026quot;, \u0026quot;abcd\u0026quot;,\u0026quot;\u0026quot;, \u0026quot;jkl\u0026quot;);\rList\u0026lt;String\u0026gt; filtered = strings.stream().filter(string -\u0026gt; !string.isEmpty()).collect(Collectors.toList());\rSystem.out.println(\u0026quot;筛选列表: \u0026quot; + filtered);\rString mergedString = strings.stream().filter(string -\u0026gt; !string.isEmpty()).collect(Collectors.joining(\u0026quot;, \u0026quot;));\rSystem.out.println(\u0026quot;合并字符串: \u0026quot; + mergedString);\r  统计\n另外，一些产生统计结果的收集器也非常有用。它们主要用于int、double、long等基本类型上，它们可以用来产生类似如下的统计结果。\nList\u0026lt;Integer\u0026gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\rIntSummaryStatistics stats = numbers.stream().mapToInt((x) -\u0026gt; x).summaryStatistics();\rSystem.out.println(\u0026quot;列表中最大的数 : \u0026quot; + stats.getMax());\rSystem.out.println(\u0026quot;列表中最小的数 : \u0026quot; + stats.getMin());\rSystem.out.println(\u0026quot;所有数之和 : \u0026quot; + stats.getSum());\rSystem.out.println(\u0026quot;平均数 : \u0026quot; + stats.getAverage());\r 默认方法 Java 8 新增了接口的默认方法。\n简单说，默认方法就是接口可以有实现方法，而且不需要实现类去实现其方法。\n我们只需在方法名前面加个 default 关键字即可实现默认方法。\n语法\n默认方法语法格式如下：\npublic interface Vehicle {\rdefault void print(){\rSystem.out.println(\u0026quot;我是一辆车!\u0026quot;);\r}\r}\r Java 8 函数式接口 函数式接口(Functional Interface)就是一个有且仅有一个抽象方法，但是可以有多个非抽象方法的接口。\n函数式接口可以被隐式转换为 lambda 表达式。\nLambda 表达式和方法引用（实际上也可认为是Lambda表达式）上。\n如定义了一个函数式接口如下：\n@FunctionalInterface\rinterface GreetingService {\rvoid sayMessage(String message);\r}\r 那么就可以使用Lambda表达式来表示该接口的一个实现(注：JAVA 8 之前一般是用匿名类实现的)：\nGreetingService greetService1 = message -\u0026gt; System.out.println(\u0026quot;Hello \u0026quot; + message);\r Java 8 Optional 类 Optional 类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。\nOptional 是个容器：它可以保存类型T的值，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测。\nOptional 类的引入很好的解决空指针异常。\n类方法    序号 方法 \u0026amp; 描述     1 static Optional empty() 返回空的 Optional 实例。   2 boolean equals(Object obj) 判断其他对象是否等于 Optional。   3 Optional filter(Predicate predicate) 如果值存在，并且这个值匹配给定的 predicate，返回一个Optional用以描述这个值，否则返回一个空的Optional。   4 Optional flatMap(Function\u0026gt; mapper) 如果值存在，返回基于Optional包含的映射方法的值，否则返回一个空的Optional   5 T get() 如果在这个Optional中包含这个值，返回值，否则抛出异常：NoSuchElementException   6 int hashCode() 返回存在值的哈希码，如果值不存在 返回 0。   7 void ifPresent(Consumer consumer) 如果值存在则使用该值调用 consumer , 否则不做任何事情。   8 boolean isPresent() 如果值存在则方法会返回true，否则返回 false。   9 Optional map(Function mapper) 如果有值，则对其执行调用映射函数得到返回值。如果返回值不为 null，则创建包含映射返回值的Optional作为map方法返回值，否则返回空Optional。   10 static Optional of(T value) 返回一个指定非null值的Optional。   11 static Optional ofNullable(T value) 如果为非空，返回 Optional 描述的指定值，否则返回空的 Optional。   12 T orElse(T other) 如果存在该值，返回值， 否则返回 other。   13 T orElseGet(Supplier other) 如果存在该值，返回值， 否则触发 other，并返回 other 调用的结果。   14 T orElseThrow(Supplier exceptionSupplier) 如果存在该值，返回包含的值，否则抛出由 Supplier 继承的异常   15 String toString() 返回一个Optional的非空字符串，用来调试    注意： 这些方法是从 java.lang.Object 类继承来的。\nJava 8 日期时间 API Java 8通过发布新的Date-Time API (JSR 310)来进一步加强对日期与时间的处理。\n在旧版的 Java 中，日期时间 API 存在诸多问题，其中有：\n 非线程安全 − java.util.Date 是非线程安全的，所有的日期类都是可变的，这是Java日期类最大的问题之一。 设计很差 − Java的日期/时间类的定义并不一致，在java.util和java.sql的包中都有日期类，此外用于格式化和解析的类在java.text包中定义。java.util.Date同时包含日期和时间，而java.sql.Date仅包含日期，将其纳入java.sql包并不合理。另外这两个类都有相同的名字，这本身就是一个非常糟糕的设计。 时区处理麻烦 − 日期类并不提供国际化，没有时区支持，因此Java引入了java.util.Calendar和java.util.TimeZone类，但他们同样存在上述所有的问题。  Java 8 在 java.time 包下提供了很多新的 API。以下为两个比较重要的 API：\n Local(本地) − 简化了日期时间的处理，没有时区的问题。 Zoned(时区) − 通过制定的时区处理日期时间。  新的java.time包涵盖了所有处理日期，时间，日期/时间，时区，时刻（instants），过程（during）与时钟（clock）的操作。\n本地化日期时间 API\nLocalDate/LocalTime 和 LocalDateTime 类可以在处理时区不是必须的情况。代码如下：\nJava8Tester.java 文件\nimport java.time.LocalDate;\rimport java.time.LocalTime;\rimport java.time.LocalDateTime;\rimport java.time.Month;\rpublic class Java8Tester {\rpublic static void main(String args[]){\rJava8Tester java8tester = new Java8Tester();\rjava8tester.testLocalDateTime();\r}\rpublic void testLocalDateTime(){\r// 获取当前的日期时间\rLocalDateTime currentTime = LocalDateTime.now();\rSystem.out.println(\u0026quot;当前时间: \u0026quot; + currentTime);\rLocalDate date1 = currentTime.toLocalDate();\rSystem.out.println(\u0026quot;date1: \u0026quot; + date1);\rMonth month = currentTime.getMonth();\rint day = currentTime.getDayOfMonth();\rint seconds = currentTime.getSecond();\rSystem.out.println(\u0026quot;月: \u0026quot; + month +\u0026quot;, 日: \u0026quot; + day +\u0026quot;, 秒: \u0026quot; + seconds);\rLocalDateTime date2 = currentTime.withDayOfMonth(10).withYear(2012);\rSystem.out.println(\u0026quot;date2: \u0026quot; + date2);\r// 12 december 2014\rLocalDate date3 = LocalDate.of(2014, Month.DECEMBER, 12);\rSystem.out.println(\u0026quot;date3: \u0026quot; + date3);\r// 22 小时 15 分钟\rLocalTime date4 = LocalTime.of(22, 15);\rSystem.out.println(\u0026quot;date4: \u0026quot; + date4);\r// 解析字符串\rLocalTime date5 = LocalTime.parse(\u0026quot;20:15:30\u0026quot;);\rSystem.out.println(\u0026quot;date5: \u0026quot; + date5);\r}\r}\r 执行以上脚本，输出结果为：\n$ javac Java8Tester.java $ java Java8Tester\r当前时间: 2016-04-15T16:55:48.668\rdate1: 2016-04-15\r月: APRIL, 日: 15, 秒: 48\rdate2: 2012-04-10T16:55:48.668\rdate3: 2014-12-12\rdate4: 22:15\rdate5: 20:15:30\r ","id":22,"section":"posts","summary":"转载 · 原文链接：https://www.runoob.com/java/java8-new-features.html java 8 新特性 Java8 新增了非常","tags":["jdk8"],"title":"JDK 8 的那些新特性","uri":"https://bluestaree.github.io/2020/03/jdk-8%E7%9A%84%E9%82%A3%E4%BA%9B%E6%96%B0%E7%89%B9%E6%80%A7/","year":"2020"},{"content":" 原反补的相互转换 今天在学习算法时遇到了这个问题，然后大脑就突然宕机。什么情况w(ﾟДﾟ)w！\n在此上网查询资料后记录下，\n 转载 · 原文链接：https://blog.csdn.net/chaochaoaiyuer/article/details/82868761\n 原码转反码\n 符号位不变，数值位按位取反  反码转原码\n 符号位不变，数值位按位取反  原码转补码\n  正数：正数的补码就是其本身。\n  负数：在原码的基础上，符号位不变，其余的各个位取反，最后+1.（反码+1）\n  补码转原码\n 符号位不变，数值位按位取反，末位再加１．即补码的补码等于原码，  已知补码，求原码的负数的补码\n 符号位和数值位都按位取反，末位再加１   总结：  计算机在进行减法时，都是在做加法运算。 正数原码、反码、补码是一样。 负数的反码，在原码的基础上，符号位不变，其余的各个位取反（1变0，0变1）。 负数的补码，就是反码+1.   ","id":23,"section":"posts","summary":"原反补的相互转换 今天在学习算法时遇到了这个问题，然后大脑就突然宕机。什么情况w(ﾟДﾟ)w！ 在此上网查询资料后记录下， 转载 · 原文链接：htt","tags":null,"title":"原码、反码和补码","uri":"https://bluestaree.github.io/2020/03/%E5%8E%9F%E7%A0%81%E5%8F%8D%E7%A0%81%E8%A1%A5%E7%A0%81/","year":"2020"},{"content":" 排序分类   内部排序：将所有需要处理的数据加载到内部存储器中进行排序 (使用内存)\n  插入排序\n 直接插入排 希尔排序    选择排序\n 简单选择排序 堆排序    交换排序\n 冒泡排序 快速排序    归并排序\n  基数排序\n    外部排序：数据量过大时，需要借助外部存储进行排序 (内存和外存相结合)\n   算法效率 = 时间复杂度 + 空间复杂度  时间复杂度：无论多少行代码，代码所执行的次数  常见的有: 常数阶O(1) ,对数阶O(og2N) ,线性阶O(n),线性对数阶O(n *log2n),平方阶O(n^2)\n 空间复杂度：该算法所耗费的存储空间  常见算法对比\n看情况选择合适的算法(数据规模：n的大小)，\n 常见排序算法 冒泡排序  时间复杂度O(n^2)  对数组中的数据两两比较，将较大的数向后移动，共需要排序array.legth -1次(第一次确定最大的数，第二次确定倒数第二大的数，以此类推)\n优化: 如果在某次排序中，没有发送一次交换，可以提前结束。\n选择排序  时间复杂度O(n^2)  第一次，假定第一个数的值最小 ， 依次与后面的数比较，并记录其更小数的索引和值，最后交换位置(确定最小)，第二次从数组的第二个索引位置开始依次对比，依旧找出最小的与之交换，以此类推,共需要排序array.legth -1次\n因为交换次数少，效率会比冒泡高，\n选择排序思路分析图：\n直接插入排序 第一次排序时，将待排序的数组的第一个元素看成一个有序表，其他元素为无序表。第二次排序时，将无序表的一个元素取出放入有序表中，并比较放入适当的位置，以此类推\n插入排序思路分析图：\n希尔排序  (缩小增量排序) 插入排序的优化版本  分为交换法(类似冒泡排序，速度很慢) 和 移位法(结合插入排序，速度很快)\n利用将整体拆分为多组排序的，最后整合的思想，\n首先，根据数据的长度/2 = n，分n组但元素量较小的数组进行排序。此后依次按照上一次分组的结果n/2 进行新的分组排序，每次增量(步长)都会减小，但每组元素数量增加，直到最后一次,增量(步长)为1，相当于对整个数据进行排序(此时由于之前已经对将整个数组根据增量拆分为多组并分别排序，已经有了一定的顺序，无限接近有序)，因此最后一次只需要进行善后处理，)\n希尔排序示意图：\n快速排序 是对冒泡排序的一种改进 ，使用递归完成\n首先，找一个数作为基准，将整个数组分割为两个数组，\n以从小到大排序为例，其中第一个数组的值都要比第二个数组值小同时也是小于或等于基准值，继续在这两组元素中找一个基准值，继续分割，依次类推，使用递归处理，直到分割的每一个数组只剩一个元素，将每一个元素和基准数按照顺序组合在一起就是一个有序数组\n快速排序示意图：\n归并排序 经典分治策略\n使用递归完成排序 ，排序次数 length-1 次\n首先，将一个数组按照中间索引等量拆分为两数组，再对这两个数组的中间索引进行拆分，知道每组元素只剩1个。\n通过递归调用，开始合并拆分的数组，并在合并时进行排序，将结果存储在一个临时数组中,每次排序后将结果都复制到原来数组覆盖，最后的结果就是一个有序的数组。 根据递归调用的原理，首先会将处于栈顶的只含单元素的数组进行合并排序，依次类推，直到最后一次合并，形成完整的数组进行最后的排序\n基数排序 - (桶排序) 空间换时间，占用内存大 稳定性排序\n稳定性排序\u0026mdash;-如果排序的数组中有多个相同的数，那么在排序后，这些相同的数也会按照原来的先后位置排列（相对位置不变），。 如 r[i]=r[j] 且原数组 r[i]在r[j]之前，那么排序后，r[i]的位置仍在r[j]之前\n每一次排序，将数组中的每个数，取出其的个位的数，放入十个桶中(序号0-9表示指定位数的值)， 然后按桶的序号，依次取出，并赋给原数组。完成第一次后， 取出百位，继续上述步骤(取决于数据中最大值的位数)，\n排序次数，该数组中数据最大值的位数\n堆排序 堆排序是利用堆这种数据结构而设计的一种排序算法，堆排序是一种选择排序,\n堆是具有以下性质的完全二叉树:每个结点的值都大于或等于其左右孩子结点的值，称为大顶堆,注意:没有要求结点的左孩子的值和右孩子的值的大小关系。\n大顶堆特点: arr[i] \u0026gt;= arr[2xi+1] \u0026amp;\u0026amp; arr[i] \u0026gt;=arr[2xi+2] // i对应第几个节点，i从0始编号\n小顶堆特点:\narr[i] \u0026lt;= arr[2xi+1] \u0026amp;\u0026amp; arr[i] \u0026lt;= arr[2xi+2] // i对应第几个节点，i从0开始编号，\n堆排序的基本思想是:\n 将待排序序列构造成一个大顶堆 此时，整个序列的最大值就是堆顶的根节点。 将其与末尾元素进行交换，此时末尾就为最大值。 然后把未尾的最大值剔除，将剩余 n-1个元素重新构造成一个堆， 这样会得到n个元素中的次小值。如此反复执行，便能得到一个有序序列了。 可以看到在构建大顶堆的过程中，大顶堆元素的个数逐渐减少，最后就得到-一个有序序列了.  ","id":24,"section":"posts","summary":"排序分类 内部排序：将所有需要处理的数据加载到内部存储器中进行排序 (使用内存) 插入排序 直接插入排 希尔排序 选择排序 简单选择排序 堆排序 交换排序 冒泡","tags":["算法"],"title":"排序算法","uri":"https://bluestaree.github.io/2020/03/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","year":"2020"},{"content":" 常用的查找算法： 1）顺序(线性)查找 - 有序与无序数组均可。逐一比对，发现相同值，就返回\n 2）二分查找/折半查找 前提：必须为有序数组\n二分查找的思路分析\n1.首先确定该数组的中间的下标\n​\tmid= (left + right)/ 2\n2.然后让需要查找的数findVal和arr[mid]比较\n findVal\u0026gt;arr[mid],说明你要查找的数在mid的右边，因此需要递归的向右查找 findVal\u0026lt; arr[mid],说明你要查找的数在mid的左边，因此需要递归的向左查找 findVal== arr[mid]说明找到，就返回  什么时候我们需要结束递归.\n  找到就结束递归\n  递归完整个数组，仍然没有找到findVal，也需要结束递归 当left\u0026gt; right就需要退出\n   3）插值查找 前提：必须为有序数组\n  插值查找算法类似于二分查找，不同的是插值查找每次从自适应mid处开始查找。\n  下面是折半查找中的求mid索引的公式,其中low表示左边索引left,high表示右边索引right.key就是前面我们讲的\n  findVal\n求中值公式\nint mid = low + (high - low) * (key - arr[low])/ (arr[high] - arr[low]) ;\n 4）斐波那契查找 (黄金分割法) 前提：必须为有序数组\n斐波那契查找原理与前两种相似，仅仅改变了中间结点 (mid) 的位置，mid不再是中间或插值得到，而是位于黄金\n分割点附近，即mid=low+F(k-1)-1(F代表斐波那契数列)，如下图所示\n对F(k-1)-1的理解:\n 由斐波那契数列F[k]=F[k-1]+F[k-2]的性质，可以得到 (F[k]-1) = (F[k-1]-1) + (F[k-2]-1) +1。该式说明:只要顺序  表的长度为F[k]-1,则可以将该表分成长度为F[k-1]-1和F[k-2]-1的两段，即如上图所示。从而中间位置为\nmid=low+F(k-1)-1\n 类似的， 每一子段也可以用相同的方式分割\n  需要注意的是需要排序的顺序表长度n,不一定刚好等于F[k]-1, 所以需要将原来的顺序表长度n增加至F[k]-1后,才\n  能使用斐波那契查找算法。这里的k值只要能使得F[k]-1恰好大于或等于n即可。\n","id":25,"section":"posts","summary":"常用的查找算法： 1）顺序(线性)查找 - 有序与无序数组均可。逐一比对，发现相同值，就返回 2）二分查找/折半查找 前提：必须为有序数组 二分查找的思","tags":["算法"],"title":"查找算法","uri":"https://bluestaree.github.io/2020/03/%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95/","year":"2020"},{"content":" 图的遍历方式 ：\n  深度优先(DFS) 广度优先(BFS)   代码实现\n首先创建一个自定义的Graph对象，其中包含一个二维数组表示图结构\n//创建图对象\rGraph graph = new Graph(n);\r//循环的添加顶点\rfor(String vertex: Vertexs) {\rgraph.insertVertex(vertex);\r}\r//添加边\r//A-B A-C B-C B-D B-E graph.insertEdge(0, 1, 1); // A-B\rgraph.insertEdge(0, 2, 1); // A-C\rgraph.insertEdge(1, 2, 1); // B-C\rgraph.insertEdge(1, 3, 1); // B-D\rgraph.insertEdge(1, 4, 1); // B-E\r //添加边\r/**\r* * @param v1 表示点的下标即使第几个顶点 \u0026quot;A\u0026quot;-\u0026quot;B\u0026quot; \u0026quot;A\u0026quot;-\u0026gt;0 \u0026quot;B\u0026quot;-\u0026gt;1\r* @param v2 第二个顶点对应的下标\r* @param weight 表示权值\r*/\rpublic void insertEdge(int v1, int v2, int weight) {\redges[v1][v2] = weight;\redges[v2][v1] = weight;\rnumOfEdges++;\r}\r 获取下一个相邻的节点，以及次相邻的节点 方法\n//得到第一个邻接结点的下标 w /**\r* * @param index * @return 如果存在就返回对应的下标，否则返回-1\r*/\rpublic int getFirstNeighbor(int index) {\rfor(int j = 0; j \u0026lt; vertexList.size(); j++) {\rif(edges[index][j] \u0026gt; 0) {\rreturn j;\r}\r}\rreturn -1;\r}\r//根据前一个邻接结点的下标来获取下一个邻接结点\rpublic int getNextNeighbor(int v1, int v2) {\rfor(int j = v2 + 1; j \u0026lt; vertexList.size(); j++) {\rif(edges[v1][j] \u0026gt; 0) {\rreturn j;\r}\r}\rreturn -1;\r}\r //深度优先遍历算法\r//i 第一次就是 0\rprivate void dfs(boolean[] isVisited, int i) {\r//首先我们访问该结点,输出\rSystem.out.print(getValueByIndex(i) + \u0026quot;-\u0026gt;\u0026quot;);\r//将结点设置为已经访问\risVisited[i] = true;\r//查找结点i的第一个邻接结点w\rint w = getFirstNeighbor(i);\rwhile(w != -1) {//说明有\rif(!isVisited[w]) {\rdfs(isVisited, w);\r}\r//如果w结点已经被访问过\rw = getNextNeighbor(i, w);\r}\r}\r //广度优先遍历算法\rprivate void bfs(boolean[] isVisited, int i) {\rint u ; // 表示队列的头结点对应下标\rint w ; // 邻接结点w\r//队列，记录结点访问的顺序\rLinkedList queue = new LinkedList();\r//访问结点，输出结点信息\rSystem.out.print(getValueByIndex(i) + \u0026quot;=\u0026gt;\u0026quot;);\r//标记为已访问\risVisited[i] = true;\r//将结点加入队列\rqueue.addLast(i);\rwhile( !queue.isEmpty()) {\r//取出队列的头结点下标\ru = (Integer)queue.removeFirst();\r//得到第一个邻接结点的下标 w w = getFirstNeighbor(u);\rwhile(w != -1) {//找到\r//是否访问过\rif(!isVisited[w]) {\r//访问该结点\rSystem.out.print(getValueByIndex(w) + \u0026quot;=\u0026gt;\u0026quot;);\r//标记已经访问\risVisited[w] = true;\r//入队\rqueue.addLast(w);\r}\r//以u为前驱点，找w后面的下一个邻结点\rw = getNextNeighbor(u, w); }\r}\r}   结果展示\n如下图所示，插入以下坐标\n结果\n1)深度优先遍历顺序为: 1-\u0026gt;2-\u0026gt;4-\u0026gt;8-\u0026gt;5-\u0026gt;3-\u0026gt;6-\u0026gt;7\n2)广度优先算法的遍历顺序为: 1-\u0026gt;2-\u0026gt;3-\u0026gt;4-\u0026gt;5-\u0026gt;6-\u0026gt;7-\u0026gt;8\n","id":26,"section":"posts","summary":"图的遍历方式 ： 深度优先(DFS) 广度优先(BFS) 代码实现 首先创建一个自定义的Graph对象，其中包含一个二维数组表示图结构 //创建图对象 Graph","tags":["数据结构"],"title":"图的遍历方式","uri":"https://bluestaree.github.io/2020/03/%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86%E6%96%B9%E5%BC%8F/","year":"2020"},{"content":" 前言   数据结构是计算机存储、组织数据的方式 数据结构包括，线性结构和非线性结构 线性结构：特点是数据元素之间存在一对一的线性关系，如数据a[0]与a[1]各表示一个数据  存储方式，分为顺序存储结构(数组,在内存中存储的地址是连续的) ，和链式存储结构(链表)。常见的线性结构有：数组，队列，链表和栈\n 非线性结构:包括二维数组，多维数组，广义表，树结构，图结构   稀疏数组 当一个数组中大部分元素为0，或者为同一个值时，可以使用稀疏数组来保存该数组，既将数组中没有意义的数值进行压缩，方便保存。\n方法;1.记录数组一共有几行几列，有多少个不同的值\n2.把具有不同值的元素的行列及值记录在一个小规模的数组中，从而缩小存储的规模\n哈希表 散列函数(Hash table ,也称哈希表) 通过关键码值 映射到表中的一个位置来访问记录，可用作缓存\n树结构 为何需要树结构存储数据？\n数组增删慢(需要整体移动)，查询快(索引定位)\n链表增删快，查询慢\n  二叉树   二叉树是每个结点最多有两个子树的树结构。通常子树被称作“左子树”和“右子树”。\n如图所示\n二叉树的遍历方式\n//前序遍历\rpublic void preOrder() {\rSystem.out.print1n(this);\rif(this.leftNode != null) {\rthis.leftNode.preOrder();\r}\rif(this.rightNode != null) {\rthis.rightNode.preOrder();\r}\r}\r //中序遍历\rpublic void preOrder() {\rif(this.leftNode != null) {\rthis.leftNode.preOrder();\r}\rSystem.out.print1n(this);\rif(this.rightNode != null) {\rthis.rightNode.preOrder();\r}\r}\r //后序遍历\rpublic void preOrder() {\rif(this.leftNode != null) {\rthis.leftNode.preOrder();\r}\rif(this.rightNode != null) {\rthis.rightNode.preOrder();\r}\rSystem.out.print1n(this);\r}\r 小结:看输出父节点的顺序，就确定是前序，中序还是后序\n 顺序存储二叉树   将一个有序的数组，通过特定的索引值，实现树结构\n顺序存储二叉树的特点:\n  顺序二叉树通常只考虑完全二叉树\n  第n个元素的左子节点为2*n+ 1\n  第n个元素的右子节点为2*n+2\n  第n个元素的父节点为(n-1)/ 2\n  n:表示二叉树中的第几个元素(按0开始编号如图所示)\n  顺序二叉树对应的数组结构\n 线索化二叉树   有效利用所有节点的左右指针\n说明:当线索化二叉树后，Node节点的属性left和right,有如下情况:\n left 指向的是左子树，也可能是指向的前驱节点比如①节点left指向的左子树，而⑩节点的left指向的就是前驱节  点.\nright指向的是右子树， 也可能是指向后继节点，比如①节点right指向的是右子树，而⑩节点的right指向的是后  继节点.\n 二叉排序数   二叉排序树: BST: (Binary Sort(Search) Tree),对于二叉排序树的任何一个非叶子节点，要求左子节点的值比当前节\n点的值小，右子节点的值比当前节点的值大。\n特别说明: 如果有相同的值，可以将该节点放在左子节点或右子节点比如针对前面的数据(7,3,10,12,5,1,9)，对应\n的二叉排序树为:\n 平衡二叉树     平衡二叉树也叫平衡二叉搜索树(Self-balancing binary search tree)又被称为AVL树，可以保证查询效率较高。\n  具有以下特点:它是一棵空树或它的左右两个子树的高度差的绝对值不超过1,并且左右两个子树都是一棵平衡二叉树。平衡二叉树的常用实现方法有红黑树、AVL、替罪羊树、Treap、 伸展树等。\n  当我们要在平衡二叉树中添加一个新的值时，就很难保证是平衡二叉树了，我们可以进行旋转处理\n左旋转\n右旋转\n 多叉树   23树，234树等都属于多叉树\n将数列{16, 24, 12, 32, 14, 26, 34, 10, 8, 28, 38, 20}构建成2-3树，\n插入规则:\n  2-3树的所有叶子节点都在同一层.(只要是B树都满足这个条件)\n  有两个子节点的节点叫二节点，二节点要么没有子节点，要么有两个子节点.\n  有三个子节点的节点叫三节点，三节点要么没有子节点，要么有三个子节点.\n  当按照规则插入一个数到某个节点时，不能满足上面三个要求，就需要拆，先向上拆，如果上层满，则拆本层，拆后仍然需要满足上面3个条件。\n  对于三节点的子树的值大小仍然遵守(BST二叉排序树)的规则\n  除了23树，还有234树等，概念和23树类似，也是一种B树。如图:\n B树、B+树和B*树   前面已经介绍了2-3树和2-3-4树，他们就是B树(英语: B-tree 也写成B-树)，这里再做一个说明，我们在学习Mysql\n时，经常听到说某种类型的索引是基于B树或者B+树的，如图:\nB树 B树的说明:\n  B树的阶: 节点的最多子节点个数。比如2-3树的阶是3，2-3-4树的阶是4\n  B树的搜索，从根结点开始，对结点内的关键字(有序)序列进行二分查找，如果命中则结束，否则进入查询关键\n  字所属范围的儿子结点; 重复，直到所对应的儿子指针为空，或已经是叶子结点\n 关键字集合分布在整颗树中，即叶子节点和非叶子节点都存放数据.\n  搜索有可能在非叶子结点结束\n  其搜索性能等价于在关键字全集内做一次分查找\n  B+树 B+树是B树的变体，也是一种多路搜索树。\nB+树的说明:\n B+树的搜索 与B树也基本相同，区别是B+树只有达到叶子结点才命中(B树可以在非叶子结点命中)，其性能也等  价于在关键字全集做一次二分查找\n 所有关键字都出现在叶子结点的链表中(即数据只能在叶子节点[也叫稠密索引] )，且链表中的关键字(数据)恰好是有序的。\n  不可能在非叶子结点命中\n  非叶子结点相当于是叶子结点的索引(稀疏索引)，叶子结点相当于是存储(关键字)数据的数据层\n  更适合文件索引系统\n  B树和B+树各有自己的应用场景，不能说B+树完全比B树好，反之亦然.\n  B*树 B*树是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针。\nB树的说明:\n B*树定义了非叶子结点关键字个数至少为 (2/3) * M ， 即块的最低使用率为 2/3，而B+树的块的最低使用率为  B+树的1/2。\n从第1个特点我们可以看出，B*树分配新结点的概率比B+树要低，空间使用率更高   图   图是一种数据结构，其中结点可以具有零个或多个相邻元素。两个结点之间的连接称为边。结点也可以称为顶\n点。如图:\n有向图\n项点之间的连接有方向，比如A-B,只能是A-\u0026gt; B不能是B-\u0026gt;A.\n带权图\n这种边带权值的图也叫网\n","id":27,"section":"posts","summary":"前言 数据结构是计算机存储、组织数据的方式 数据结构包括，线性结构和非线性结构 线性结构：特点是数据元素之间存在一对一的线性关系，如数据a[0]与","tags":["数据结构"],"title":"数据结构","uri":"https://bluestaree.github.io/2020/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","year":"2020"},{"content":"  转载 · 原文链接：https://www.codesheep.cn/2018/09/04/springboot-startup-process/\n 结合 SpringBoot 2.0的源码，来看看SpringBoot应用程序的启动流程！\n概述 说到接触 SpringBoot 伊始，给我第一映像最深的是有两个关键元素：\n对照上面的典型代码，这个两个元素分别是：\n @SpringBootApplication SpringApplication 以及 run() 方法  那么本文我们就来看看这个 SpringApplication 以及 run() 方法 到底是个什么鬼，它背后又隐藏了哪些奥秘呢？\n SpringApplication 惊鸿一瞥 SpringApplication 这个类应该算是 SpringBoot 框架 的“创新”产物了，原始的 Spring中并没有这个类，SpringApplication 里面封装了一套 Spring 应用的启动流程，然而这对用户完全透明，因此我们上手 SpringBoot 时感觉简洁、轻量。\n一般来说默认的 SpringApplication 执行流程已经可以满足大部分需求，但是 若用户想干预这个过程，则可以通过 SpringApplication 在流程某些地方开启的 扩展点 来完成对流程的扩展，典型的扩展方案那就是使用 set 方法。\n我们来举一个栗子，把我们天天司空见惯的 SpringBoot 应用的启动类来拆解一下写出来：\n@SpringBootApplication\rpublic class CodeSheepApplication {\rpublic static void main( String[] args ) {\r// SpringApplication.run( CodeSheepApplication.class args ); // 这是传统SpringBoot应用的启动，一行代码搞定，内部默认做了很多事\rSpringApplication app = new SpringApplication( CodeSheepApplication.class );\rapp.setXXX( ... ); // 用户自定的扩展在此 ！！！\rapp.run( args );\r}\r}\r 这样一拆解后我们发现，我们也需要先构造 SpringApplication 类对象，然后调用该对象的 run() 方法。那么接下来就讲讲 SpringApplication 的构造过程 以及其 run() 方法的流程，搞清楚了这个，那么也就搞清楚了SpringBoot应用是如何运行起来的！\n SpringApplication 实例的初始化 我们对照代码来看：\n四个关键的步骤已标注在图中，分别解释如下：\n ① 推断应用的类型：创建的是 REACTIVE应用、SERVLET应用、NONE 三种中的某一种   ② 使用 SpringFactoriesLoader查找并加载 classpath下 META-INF/spring.factories文件中所有可用的 ApplicationContextInitializer   ③ 使用 SpringFactoriesLoader查找并加载 classpath下 META-INF/spring.factories文件中的所有可用的 ApplicationListener   ④ 推断并设置 main方法的定义类    SpringApplication 的run()方法探秘 先看看代码长啥样子：\n各个主要步骤我已经标注在上图之中了，除此之外，我也按照自己的理解画了一个流程图如下所示，可以对照数字标示看一下：\n我们将各步骤总结精炼如下：\n 通过 SpringFactoriesLoader 加载 META-INF/spring.factories 文件，获取并创建 SpringApplicationRunListener 对象 然后由 SpringApplicationRunListener 来发出 starting 消息 创建参数，并配置当前 SpringBoot 应用将要使用的 Environment 完成之后，依然由 SpringApplicationRunListener 来发出 environmentPrepared 消息 创建 ApplicationContext 初始化 ApplicationContext，并设置 Environment，加载相关配置等 由 SpringApplicationRunListener 来发出 contextPrepared 消息，告知SpringBoot 应用使用的 ApplicationContext 已准备OK 将各种 beans 装载入 ApplicationContext，继续由 SpringApplicationRunListener 来发出 contextLoaded 消息，告知 SpringBoot 应用使用的 ApplicationContext 已装填OK refresh ApplicationContext，完成IoC容器可用的最后一步 由 SpringApplicationRunListener 来发出 started 消息 完成最终的程序的启动 由 SpringApplicationRunListener 来发出 running 消息，告知程序已运行起来了  至此，全流程结束！\n","id":28,"section":"posts","summary":"转载 · 原文链接：https://www.codesheep.cn/2018/09/04/springboot-startup-process","tags":["SpringBoot"],"title":"SpringBoot应用程序启动过程","uri":"https://bluestaree.github.io/2020/03/springboot%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/","year":"2020"},{"content":"  转载 · 原文链接：https://www.codesheep.cn/2018/07/30/at-SpringBootApplication-zhujie/\n 概 述 我们在开发基于 SpringBoot 的应用时，用到了一些新的注解和类，正式由于其存在，才让JavaEE的开发如鱼得水。这其中我们用的最多的注解之一，当属 SpringBoot 应用启动类上的 @SpringBootApplication 注解了\n本文就来看看它到底是个啥！\n@SpringBootApplication 背后到底是什么？ @SpringBootApplication注解实际上是SpringBoot提供的一个复合注解，我们来看一看其源码：\n@Target(ElementType.TYPE)\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\r@Inherited\r@SpringBootConfiguration\r@EnableAutoConfiguration\r@ComponentScan(excludeFilters = {\r@Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),\r@Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })\rpublic @interface SpringBootApplication {\r...\r}\r 看得很清楚，其是一个合成体，但其中最重要的三个注解分别是：\n @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan  我们不妨称其为 “ 三体结构 ” 吧！\n如果我们不怕麻烦，在 SpringBoot 应用的启动类上用这个三个注解代替@SpringBootApplication 注解发现也是没问题的：\n@SpringBootConfiguration\r@EnableAutoConfiguration\r@ComponentScan\rpublic class TestSpringBootApplication {\r...\r}\r 下面分别剖析一下这三个注解的功效！\n  @SpringBootConfiguration 看代码吧，代码里是这样写的：\n@Target(ElementType.TYPE)\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\r@Configuration\rpublic @interface SpringBootConfiguration {\r}\r 这说明 @SpringBootConfiguration 也是来源于 @Configuration，二者功能都是将当前类标注为配置类，并将当前类里以 @Bean 注解标记的方法的实例注入到srping容器中，实例名即为方法名。\n至于@Configuration，我想在非SpringBoot时代大家应该不陌生吧，作用是配置Spring容器，也即 JavaConfig 形式的 Spring IoC 容器的配置类所使用。\n到目前来看，好像还没有什么新东西！！！\n  @EnableAutoConfiguration 再继续看代码，代码是这样的：\n@Target(ElementType.TYPE)\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\r@Inherited\r@AutoConfigurationPackage\r@Import(AutoConfigurationImportSelector.class)\rpublic @interface EnableAutoConfiguration {\r...\r}\r @EnableAutoConfiguration 注解启用自动配置，其可以帮助 SpringBoot 应用将所有符合条件的 @Configuration 配置都加载到当前 IoC 容器之中，可以简要用图形示意如下：\n@EnableAutoConfiguration 幕后的组件调用关系\n接下来我们对照源码，来解释一下这个流程：\n @EnableAutoConfiguration 借助 AutoConfigurationImportSelector 的帮助，而后者通过实现 selectImports() 方法来导出 Configuration  selectImports()\n AutoConfigurationImportSelector 类的 selectImports() 方法里面通过调用Spring Core 包里 SpringFactoriesLoader 类的 **loadFactoryNames()**方法  SpringFactoriesLoader.loadFactoryNames()\n 最终通过 SpringFactoriesLoader.loadFactoryNames() 读取了 ClassPath 下面的 META-INF/spring.factories 文件来获取所有导出类。  而spring.factories 文件里关于 EnableAutoConfiguration 的配置其实就是一个键值对结构，样子大概长下面这样：\nspring.factories\n说了这么多，如果从稍微宏观一点的角度 概括总结 上述这一过程那就是：\n从 ClassPath下扫描所有的 META-INF/spring.factories 配置文件，并将spring.factories 文件中的 EnableAutoConfiguration 对应的配置项通过反射机制实例化为对应标注了 @Configuration 的形式的IoC容器配置类，然后注入IoC容器。\n@ComponentScan\n@ComponentScan 对应于XML配置形式中的 context:component-scan，用于将一些标注了特定注解的bean定义批量采集注册到Spring的IoC容器之中，这些特定的注解大致包括：\n @Controller @Entity @Component @Service @Repository  等等\n对于该注解，还可以通过 basePackages 属性来更细粒度的控制该注解的自动扫描范围，比如：\n@ComponentScan(basePackages = {\u0026quot;cn.codesheep.controller\u0026quot;,\u0026quot;cn.codesheep.entity\u0026quot;})\r 可见 这个注解也并不是什么新东西！\n","id":29,"section":"posts","summary":"转载 · 原文链接：https://www.codesheep.cn/2018/07/30/at-SpringBootApplication-z","tags":["SpringBoot"],"title":"@SpringBootApplication注解","uri":"https://bluestaree.github.io/2020/03/springbootapplication%E6%B3%A8%E8%A7%A3/","year":"2020"},{"content":" 查看当前所有镜像\ndocker images\n查看所有容器\ndocker ps -a\n根据一个镜像创建一个容器并运行 (windows环境)\ndocker run -d \u0026ndash;name mysql_3308 -e MYSQL_ROOT_HOST=% -e MYSQL_ROOT_PASSWORD=tdt123 -p 3307:3306 -v //f/docker/mysql_3308:/var/lib/mysql mysql:5.5\n \u0026ndash;name mysql_3308 \u0026hellip; mysql:5.5 设置容器名，及选用镜像（如果没有tag即5.5，则会自动下载最新版的mysql） -e MYSQL_ROOT_HOST=% 允许远程登录 -e MYSQL_ROOT_PASSWORD=123456 root登录密码 -p 3308:3306 端口映射至宿主机3308 -d 后台运行容器，并返回容器ID； -v //f/docker/mysql_3308:/var/lib/mysql 绑定镜像位置到宿主机上 \u0026ndash;lower_case_table_names=1 不区分大小写   其他栗子\ndocker run \u0026ndash;name mysql -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -v //e/docker/share/mysql_3306:/var/lib/mysql mysql\ndocker create \u0026ndash;name tracker \u0026ndash;net host -v //e/docker/data/tracker:/var/fdfs delron/fastdfs tracker\ndocker create \u0026ndash;name es -p 9200:9200 -p 9300:9300 -e \u0026ldquo;discovery.type=single-node\u0026rdquo; -v //e/docker/es/data/:/usr/share/elasticsearch/data elasticsearch:6.5.4\ndocker create \u0026ndash;name kibana -p 5601:5601 -v //e/docker/es/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml kibana:6.5.4\ndocker create \u0026ndash;name redis -p 6379:6379 -v //e/docker/redis/data:/data redis:5.0.2\n复制当前目录文件至指定容器位置\ndocker cp elasticsearch-analysis-ik-6.5.4.zip es:/usr/share/elasticsearch/plugins/\n启动容器并显示启动日志\ndocker start rabbitmq \u0026amp;\u0026amp; docker logs -f rabbitmq\n进入容器\ndocker exec -it 775c7c9ee1e1 /bin/bash (进入容器控制台)\n 775c7c9ee1e1 为容器ID  查看容器信息\ndokcer inspect 容器名\n查找文件\nfind / -name tracker.conf\n保存镜像文件\ndocker save\ndocker save -o python_3.tar python:3\n加载镜像文件\ndocker load\ndocker load -i python_3.tar\n-\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\n","id":30,"section":"posts","summary":"查看当前所有镜像 docker images 查看所有容器 docker ps -a 根据一个镜像创建一个容器并运行 (windows环境) docker run -d \u0026ndash;name mysql_3308 -e MYSQL_ROOT_HOST=% -e MYSQL_ROOT_PASSWORD=tdt123 -p 3307:3306 -v //f/docker/mysql_3308:/var/lib/mysql mysql:5.5 \u0026ndash;name mysql_3308 \u0026hellip; mysql:5.5 设置容器名，及","tags":["docker"],"title":"Docker常用命令","uri":"https://bluestaree.github.io/2020/03/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","year":"2020"},{"content":"  转载 · 原文链接：https://www.codesheep.cn/2018/06/05/SpringBoot%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2%E4%BA%8E%E5%A4%96%E7%BD%AETomcat%E5%AE%B9%E5%99%A8/\n 0x01. 概述 SpringBoot平时我们用的爽歪歪，爽到它自己连Tomcat都自集成了，我们可以直接编写SBT启动类，然后一键开启内置的Tomcat容器服务，确实是很好上手。但考虑到实际的情形中，我们的Tomcat服务器一般是另外部署好了的，有专门的维护方式。此时我们需要剥离掉SBT应用内置的Tomcat服务器，进而将应用发布并部署到外置的Tomcat容器之中，本文就实践一下这个。\n0x02. 修改打包方式 修改项目的pom.xml配置，我们修改其打包方式为war方式，如：\n\u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;demo\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt;\r\u0026lt;packaging\u0026gt;war\u0026lt;/packaging\u0026gt;\r  0x03. 移除SBT自带的嵌入式Tomcat 修改pom.xml，从maven的pom中移除springboot自带的的嵌入式tomcat插件\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt;\r\u0026lt;!-- 移除嵌入式tomcat插件 --\u0026gt;\r\u0026lt;exclusions\u0026gt;\r\u0026lt;exclusion\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-tomcat\u0026lt;/artifactId\u0026gt;\r\u0026lt;/exclusion\u0026gt;\r\u0026lt;/exclusions\u0026gt;\r\u0026lt;/dependency\u0026gt;\r  0x04. 添加servlet-api依赖 修改pom.xml，在maven的pom中添加servlet-api的依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;javax.servlet-api\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r  0x05. 修改启动类，并重写初始化方法 在SpringBoot中我们平常用main方法启动的方式，都有一个SpringBootApplication的启动类，类似代码如下：\n@SpringBootApplication\rpublic class Application {\rpublic static void main(String[] args) {\rSpringApplication.run(Application.class, args);\r}\r}\r 而我们现在需要类似于web.xml的配置方式来启动spring应用，为此，我们在Application类的同级添加一个SpringBootStartApplication类，其代码如下:\n// 修改启动类，继承 SpringBootServletInitializer 并重写 configure 方法\rpublic class SpringBootStartApplication extends SpringBootServletInitializer {\r@Override\rprotected SpringApplicationBuilder configure(SpringApplicationBuilder builder) {\r// 注意这里一定要指向原先用main方法执行的Application启动类\rreturn builder.sources(Application.class);\r}\r}\r  0x06. 部署到外部的Tomcat容器并验证  在项目根目录下（即包含pom.xml的目录）记性maven打包操作：  mvn clean package\r 等待打包完成，出现 [INFO] BUILD SUCCESS 即为打包成功\n 然后我们把target目录下生成的war包放到tomcat的webapps目录下，启动tomcat，即可自动解压部署。  最后在浏览器中验证:\nhttp://YOUR_IP:[端口号]/[打包项目名]\r ","id":31,"section":"posts","summary":"转载 · 原文链接：https://www.codesheep.cn/2018/06/05/SpringBoot%E5%BA%94%E7%94%","tags":["SpringBoot"],"title":"SpringBoot应用部署于外置Tomcat容器","uri":"https://bluestaree.github.io/2020/03/springboot%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2%E4%BA%8E%E5%A4%96%E7%BD%AEtomcat%E5%AE%B9%E5%99%A8/","year":"2020"}],"tags":[{"title":"docker","uri":"https://bluestaree.github.io/tags/docker/"},{"title":"equals","uri":"https://bluestaree.github.io/tags/equals/"},{"title":"Gradle","uri":"https://bluestaree.github.io/tags/gradle/"},{"title":"hashCode","uri":"https://bluestaree.github.io/tags/hashcode/"},{"title":"hibernate","uri":"https://bluestaree.github.io/tags/hibernate/"},{"title":"jdk8","uri":"https://bluestaree.github.io/tags/jdk8/"},{"title":"Maven","uri":"https://bluestaree.github.io/tags/maven/"},{"title":"Mybatis","uri":"https://bluestaree.github.io/tags/mybatis/"},{"title":"Nacos","uri":"https://bluestaree.github.io/tags/nacos/"},{"title":"Netty","uri":"https://bluestaree.github.io/tags/netty/"},{"title":"redisson","uri":"https://bluestaree.github.io/tags/redisson/"},{"title":"SpringBoot","uri":"https://bluestaree.github.io/tags/springboot/"},{"title":"SpringCloud","uri":"https://bluestaree.github.io/tags/springcloud/"},{"title":"SpringSecurity","uri":"https://bluestaree.github.io/tags/springsecurity/"},{"title":"数据结构","uri":"https://bluestaree.github.io/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"title":"算法","uri":"https://bluestaree.github.io/tags/%E7%AE%97%E6%B3%95/"},{"title":"缓存","uri":"https://bluestaree.github.io/tags/%E7%BC%93%E5%AD%98/"}]}