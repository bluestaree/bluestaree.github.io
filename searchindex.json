{"categories":[{"title":"Netty","uri":"https://bluestaree.github.io/categories/netty/"},{"title":"Spring Boot","uri":"https://bluestaree.github.io/categories/spring-boot/"},{"title":"Spring Cloud Alibaba","uri":"https://bluestaree.github.io/categories/spring-cloud-alibaba/"},{"title":"笔记","uri":"https://bluestaree.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"posts":[{"content":"  转载 · 原文链接：https://blog.csdn.net/weixin_43906974/article/details/107515953\n 场景：前端下拉框展示数据，老项目没有数据字典，在尽量不改动的情况下，可以使用以下方法\npackage com.example.demo.Enum;\rimport java.util.ArrayList;\rimport java.util.HashMap;\rimport java.util.List;\rimport java.util.Map;\r/**\r* XXXX枚举\r*/\rpublic enum TimeKeepingEnum {\rFIRST(1,\u0026quot;20钻石/分钟\u0026quot;),\rSECOND(2,\u0026quot;30钻石/分钟\u0026quot;),\rTHIRD(3,\u0026quot;40钻石/分钟\u0026quot;);\rprivate int value;\rprivate String desc;\rprivate TimeKeepingEnum(int value, String desc) {\rthis.value = value;\rthis.desc = desc;\r}\rpublic int getValue() {\rreturn value;\r}\rpublic void setValue(int value) {\rthis.value = value;\r}\rpublic String getDesc() {\rreturn desc;\r}\rpublic void setDesc(String desc) {\rthis.desc = desc;\r}\r/**\r* 请求返回的Enum集合数据\r* @return\r*/\rpublic static List\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; getTimeKeepingEnumList() {\rList\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; list = new ArrayList\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt;();\rfor (TimeKeepingEnum timeKeepingEnum: TimeKeepingEnum.values()) {\rMap item= new HashMap\u0026lt;String, Object\u0026gt;();\ritem.put(\u0026quot;value\u0026quot;,timeKeepingEnum.value);\ritem.put(\u0026quot;desc\u0026quot;,timeKeepingEnum.desc);\rlist.add(item);\r}\rreturn list;\r}\rpublic static void main(String[] args) {\rSystem.out.println(TimeKeepingEnum.getTimeKeepingEnumList());\r}\r}\r ","id":0,"section":"posts","summary":"转载 · 原文链接：https://blog.csdn.net/weixin_43906974/article/details/10751595","tags":null,"title":"枚举类转为集合数据","uri":"https://bluestaree.github.io/2020/09/%E6%9E%9A%E4%B8%BE%E7%B1%BB%E8%BD%AC%E4%B8%BA%E9%9B%86%E5%90%88%E6%95%B0%E6%8D%AE/","year":"2020"},{"content":" 最近在项目开发中遇到了个bug，排查后发现Long类型主键字段作为参数返回后，前端接收时出现精度丢失问题\n 原因：前端js对Long类型支持的精度不够，导致后端使用的Long传到前端丢失精度，比如现在分布式id生成算法“雪花算法”在使用中就会出现问题。\n 解决方式： 1、后端的Long类型的id转用String存储，不推荐，失去了其Long类型本身的意义。\n2、在Long类型字段上使用注解标明序列化方式，代码量不大的情况可以考虑\n3、实现WebMvcConfigurer接口，重写configureMessageConverters方法\n@Override\rpublic void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) {\rMappingJackson2HttpMessageConverter jackson2HttpMessageConverter = new MappingJackson2HttpMessageConverter();\rObjectMapper objectMapper = new ObjectMapper();\rSimpleModule simpleModule = new SimpleModule();\rsimpleModule.addSerializer(BigInteger.class, ToStringSerializer.instance);\rsimpleModule.addSerializer(Long.class, ToStringSerializer.instance);\rsimpleModule.addSerializer(Long.TYPE, ToStringSerializer.instance);\robjectMapper.registerModule(simpleModule);\rjackson2HttpMessageConverter.setObjectMapper(objectMapper);\rconverters.add(jackson2HttpMessageConverter);\rconverters.add(new StringHttpMessageConverter(StandardCharsets.UTF_8));\r}\r 但是这种方式需要开启@EnableWebMvc注解。\n开启这个注解意味着springboot的mvc等自动配置失效，所以这个方式实际上也是不可取的。\n类似的还有继承WebMvcConfigurationSupport类，也会导致一些配置失效\n可参考 https://www.cnblogs.com/asker009/p/12752716.html\n类似不可取的还有重写HttpMessageConverters，这会覆盖其他的类型转换。\n@Configuration\rpublic class LongToJsonConfig {\rpublic LongToJsonConfig() {\r}\r@Bean\rpublic HttpMessageConverters customConverters() {\rMappingJackson2HttpMessageConverter jackson2HttpMessageConverter = new MappingJackson2HttpMessageConverter();\rObjectMapper objectMapper = new ObjectMapper();\rSimpleModule simpleModule = new SimpleModule();\rsimpleModule.addSerializer(Long.class, ToStringSerializer.instance);\rsimpleModule.addSerializer(Long.TYPE, ToStringSerializer.instance);\robjectMapper.registerModule(simpleModule);\rjackson2HttpMessageConverter.setObjectMapper(objectMapper);\rreturn new HttpMessageConverters(new HttpMessageConverter[]{jackson2HttpMessageConverter});\r}\r}\r 以上方式基本都不可取。\n4、重新注册ObjectMapper的Long类型序列化方式，推荐使用，暂时没发现问题。\n@Configuration\rpublic class LongClassMessageConverter implements InitializingBean {\r@Resource\rObjectMapper objectMapper;\rprivate SimpleModule getSimpleModule() {\rSimpleModule simpleModule = new SimpleModule();\rsimpleModule.addSerializer(BigInteger.class, ToStringSerializer.instance);\rsimpleModule.addSerializer(Long.class, ToStringSerializer.instance); // 暂时放弃对小long的转换，约定与前端交互数据时，大Long全部转换成字符串 // simpleModule.addSerializer(Long.TYPE, ToStringSerializer.instance);\robjectMapper.registerModule(simpleModule);\rreturn simpleModule;\r}\r@Override\rpublic void afterPropertiesSet() {\rSimpleModule simpleModule = getSimpleModule();\robjectMapper.registerModule(simpleModule);\r}\r}\r 5、重新构建Jackson序列化方式，与第四点类似的解决方式，推荐使用。\n@Configuration\rpublic class JacksonConfig {\r/**\r* Jackson全局转化long类型为String，解决jackson序列化时传入前端Long类型缺失精度问题\r*/\r@Bean\rpublic Jackson2ObjectMapperBuilderCustomizer jackson2ObjectMapperBuilderCustomizer() {\rJackson2ObjectMapperBuilderCustomizer cunstomizer = new Jackson2ObjectMapperBuilderCustomizer() {\r@Override\rpublic void customize(Jackson2ObjectMapperBuilder jacksonObjectMapperBuilder) {\rjacksonObjectMapperBuilder.serializerByType(BigInteger.class, ToStringSerializer.instance);\rjacksonObjectMapperBuilder.serializerByType(Long.class, ToStringSerializer.instance);\r// jacksonObjectMapperBuilder.serializerByType(Long.TYPE, ToStringSerializer.instance); }\r};\rreturn cunstomizer;\r}\r}\r 6、以上方式针对springboot默认的Jackson序列化，fastjson等其他json组件类似处理。\n7、如果前端自身涉及到Long类型的计算，那么需要前端自己实现Long类型支持，参考： https://github.com/dcodeIO/long.js)//github.com/dcodeIO/long.js\n","id":1,"section":"posts","summary":"最近在项目开发中遇到了个bug，排查后发现Long类型主键字段作为参数返回后，前端接收时出现精度丢失问题 原因：前端js对Long类型支持的精","tags":null,"title":"后端Long类型传到前端精度丢失的正确解决方式","uri":"https://bluestaree.github.io/2020/09/long%E7%B1%BB%E5%9E%8B%E7%B2%BE%E5%BA%A6%E4%B8%A2%E5%A4%B1/","year":"2020"},{"content":"  转载:https://www.jianshu.com/p/157279e6efdb\n 1. volatile简介 在上一篇文章中我们深入理解了java关键字synchronized，我们知道在java中还有一大神器就是关键volatile，可以说是和synchronized各领风骚，其中奥妙，我们来共同探讨下。\n通过上一篇的文章我们了解到synchronized是阻塞式同步，在线程竞争激烈的情况下会升级为重量级锁。而volatile就可以说是java虚拟机提供的最轻量级的同步机制。但它同时不容易被正确理解，也至于在并发编程中很多程序员遇到线程安全的问题就会使用synchronized。Java内存模型告诉我们，各个线程会将共享变量从主内存中拷贝到工作内存，然后执行引擎会基于工作内存中的数据进行操作处理。线程在工作内存进行操作后何时会写到主内存中？这个时机对普通变量是没有规定的，而针对volatile修饰的变量给java虚拟机特殊的约定，线程对volatile变量的修改会立刻被其他线程所感知，即不会出现数据脏读的现象，从而保证数据的“可见性”。\n现在我们有了一个大概的印象就是：被volatile修饰的变量能够保证每个线程能够获取该变量的最新值，从而避免出现数据脏读的现象。\n2. volatile实现原理 volatile是怎样实现了？比如一个很简单的Java代码：\n instance = new Instancce() //instance是volatile变量\n 在生成汇编代码时会在volatile修饰的共享变量进行写操作的时候会多出Lock前缀的指令（具体的大家可以使用一些工具去看一下，这里我就只把结果说出来）。我们想这个Lock指令肯定有神奇的地方，那么Lock前缀的指令在多核处理器下会发现什么事情了？主要有这两个方面的影响：\n 将当前处理器缓存行的数据写回系统内存； 这个写回内存的操作会使得其他CPU里缓存了该内存地址的数据无效  为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2或其他）后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。因此，经过分析我们可以得出如下结论：\n Lock前缀的指令会引起处理器缓存写回内存； 一个处理器的缓存回写到内存会导致其他处理器的缓存失效； 当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值。  这样针对volatile变量通过这样的机制就使得每个线程都能获得该变量的最新值。\n3. volatile的happens-before关系 经过上面的分析，我们已经知道了volatile变量可以通过缓存一致性协议保证每个线程都能获得最新值，即满足数据的“可见性”。我们继续延续上一篇分析问题的方式（我一直认为思考问题的方式是属于自己，也才是最重要的，也在不断培养这方面的能力），我一直将并发分析的切入点分为两个核心，三大性质。两大核心：JMM内存模型（主内存和工作内存）以及happens-before；三条性质：原子性，可见性，有序性（关于三大性质的总结在以后得文章会和大家共同探讨）。废话不多说，先来看两个核心之一：volatile的happens-before关系。\n在六条happens-before规则中有一条是：**volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。**下面我们结合具体的代码，我们利用这条规则推导下：\npublic class VolatileExample {\rprivate int a = 0;\rprivate volatile boolean flag = false;\rpublic void writer(){\ra = 1; //1\rflag = true; //2\r}\rpublic void reader(){\rif(flag){ //3\rint i = a; //4\r}\r}\r}\r 上面的实例代码对应的happens-before关系如下图所示：\nVolatileExample的happens-before关系推导\n加锁线程A先执行writer方法，然后线程B执行reader方法图中每一个箭头两个节点就代码一个happens-before关系，黑色的代表根据程序顺序规则推导出来，红色的是根据volatile变量的写happens-before 于任意后续对volatile变量的读，而蓝色的就是根据传递性规则推导出来的。这里的2 happen-before 3，同样根据happens-before规则定义：如果A happens-before B,则A的执行结果对B可见，并且A的执行顺序先于B的执行顺序，我们可以知道操作2执行结果对操作3来说是可见的，也就是说当线程A将volatile变量 flag更改为true后线程B就能够迅速感知。\n4. volatile的内存语义 还是按照两个核心的分析方式，分析完happens-before关系后我们现在就来进一步分析volatile的内存语义（按照这种方式去学习，会不会让大家对知识能够把握的更深，而不至于不知所措，如果大家认同我的这种方式，不妨给个赞，小弟在此谢过，对我是个鼓励）。还是以上面的代码为例，假设线程A先执行writer方法，线程B随后执行reader方法，初始时线程的本地内存中flag和a都是初始状态，下图是线程A执行volatile写后的状态图。\n线程A执行volatile写后的内存状态图\n当volatile变量写后，线程中本地内存中共享变量就会置为失效的状态，因此线程B再需要读取从主内存中去读取该变量的最新值。下图就展示了线程B读取同一个volatile变量的内存变化示意图。\n线程B读volatile后的内存状态图\n从横向来看，线程A和线程B之间进行了一次通信，线程A在写volatile变量时，实际上就像是给B发送了一个消息告诉线程B你现在的值都是旧的了，然后线程B读这个volatile变量时就像是接收了线程A刚刚发送的消息。既然是旧的了，那线程B该怎么办了？自然而然就只能去主内存去取啦。\n好的，我们现在两个核心：happens-before以及内存语义现在已经都了解清楚了。是不是还不过瘾，突然发现原来自己会这么爱学习（微笑脸），那我们下面就再来一点干货\u0026mdash;-volatile内存语义的实现。\n4.1 volatile的内存语义实现 我们都知道，为了性能优化，JMM在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序，那如果想阻止重排序要怎么办了？答案是可以添加内存屏障。\n 内存屏障\n JMM内存屏障分为四类见下图，\n内存屏障分类表\njava编译器会在生成指令系列时在适当的位置会插入内存屏障指令来禁止特定类型的处理器重排序。为了实现volatile的内存语义，JMM会限制特定类型的编译器和处理器重排序，JMM会针对编译器制定volatile重排序规则表：\nvolatile重排序规则表\n\u0026ldquo;NO\u0026quot;表示禁止重排序。为了实现volatile内存语义时，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎是不可能的，为此，JMM采取了保守策略：\n 在每个volatile写操作的前面插入一个StoreStore屏障； 在每个volatile写操作的后面插入一个StoreLoad屏障； 在每个volatile读操作的后面插入一个LoadLoad屏障； 在每个volatile读操作的后面插入一个LoadStore屏障。  需要注意的是：volatile写是在前面和后面分别插入内存屏障，而volatile读操作是在后面插入两个内存屏障\nStoreStore屏障：禁止上面的普通写和下面的volatile写重排序；\nStoreLoad屏障：防止上面的volatile写与下面可能有的volatile读/写重排序\nLoadLoad屏障：禁止下面所有的普通读操作和上面的volatile读重排序\nLoadStore屏障：禁止下面所有的普通写操作和上面的volatile读重排序\n下面以两个示意图进行理解，图片摘自相当好的一本书《java并发编程的艺术》。\nvolatile写插入内存屏障示意图\nvolatile读插入内存屏障示意图\n5. 一个示例 我们现在已经理解volatile的精华了，文章开头的那个问题我想现在我们都能给出答案了。更正后的代码为：\npublic class VolatileDemo {\rprivate static volatile boolean isOver = false;\rpublic static void main(String[] args) {\rThread thread = new Thread(new Runnable() {\r@Override\rpublic void run() {\rwhile (!isOver) ;\r}\r});\rthread.start();\rtry {\rThread.sleep(500);\r} catch (InterruptedException e) {\re.printStackTrace();\r}\risOver = true;\r}\r}\r 注意不同点，现在已经将isOver设置成了volatile变量，这样在main线程中将isOver改为了true后，thread的工作内存该变量值就会失效，从而需要再次从主内存中读取该值，现在能够读出isOver最新值为true从而能够结束在thread里的死循环，从而能够顺利停止掉thread线程。现在问题也解决了，知识也学到了：）。\n","id":2,"section":"posts","summary":"转载:https://www.jianshu.com/p/157279e6efdb 1. volatile简介 在上一篇文章中我们深入理解了java","tags":null,"title":"Java中Volatile关键字","uri":"https://bluestaree.github.io/2020/08/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8Bvolatile%E5%85%B3%E9%94%AE%E5%AD%97%E8%A7%A3%E6%9E%90/","year":"2020"},{"content":"  简介：Sentinel-哨兵，是Spring Cloud Alibaba 的开源项目，是面向微服务的轻量级流量控制框架，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。\n官方文档\n 服务熔断 A服务调用B服务的某个功能，由于网络不稳定问题，或者B服务卡机，导致功能时间超长。如果这样子的次数太多。我们就可以直接将B断路了(A不再请求B接口)，凡是调用B的直接返回降级数据，不必等待B的超长执行。这样 B的故障问题，就不会级联影响到A。\n服务降级 整个网站处于流量高峰期，服务器压力剧增,根据当前业务情况及流量，对一些服务和页面进行有策略的降级，停止服务，所有的调用直接返回降级数据 (服务器繁忙，请稍后再试) 。以此缓解服务器资源的的压力，以保证核心业务的正常运行，同时也保持了客户和大部分客户的得到正确的相应。\n异同: 相同点:\n 为了保证集群大部分服务的可用性和可靠性，防止崩溃，牺牲小我 用户最终都是体验到某个功能不可用  不同点:\n 熔断是被调用方故障，触发的系统主动规则 降级是基于全局考虑，停止一些正常服务，释放资源  限流 对打入服务的请求流量进行控制，使服务能够承担不超过自己能力的流量压力\nSentinel基本概念 资源 资源是 Sentinel 的关键概念。它可以是Java 应用程序中的任何内容，例如，由应用程序提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。\n只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。\n规则 围绕资源的实时状态设定的规则，可以包括流量控制规则、熔断降级规则以及系统保护规则。所有规则可以动态实时调整。\nSentinel简单使用 1.导入依赖 \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-sentinel\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.0.2.RELEASE\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 2.sentinel 控制台 sentinel 控制台提供了一个可视化界面，通过它我们可以很轻松的对各个规则进行添加、查询和修改，也可以查看到实时监控，机器列表等信息。 github地址\n 注：优先选择对应版本的控制台，版本的不同可能会出现数据无法传输等问题\n 启动控制台\nsentinel 控制台是一个Spring boot 项目打成的jar包 ，我们可以直接在使用命令行启动这个jar包\njava -jar .\\sentinel-dashboard-1.7.1.jar\n 注：如果端口被占用，可以添加启动参数，修改默认运行端口\n默认用户密码：sentinel\n 初始化界面\n3.启动服务 配置文件\napplication.yml\nspring:\rcloud:\rsentinel:\rtransport:\rport: 8719 #本项目与sentinel控制台数据传输端口，\rdashboard: localhost:8080 #控制台端口\r 默认 sentinel 与spring cloud整合，会将所有请求都标识为受保护的资源\n在服务启动后，我们先访问一个测试请求，之后就可以在sentinel的控制台中查看到本次请求情况\n可以看到，在控制台中，我们能很方便的给指定请求设置一些规则\n这里我们尝试先添加一个流量控制规则 ， sentinel 流量规则定义\n这里设置 QPS = 1 (每秒只允许一个请求进行访问)，其他请求会被限制\n 注意：默认所有的规则设置保存在服务内存中，这些配置会在服务重启后失效\n 效果测试\n超过规则限制，sentinel 默认的返回数据\nsentinel 实时监控 Spring Boot Actuator 可以帮助你监控和管理Spring Boot应用，比如健康检查、审计、统计和HTTP追踪等。所有的这些特性可以通过JMX或者HTTP endpoints来获得。\nSentinel 可以通过获取 Actuator 的信息来达到对服务各项数据的实时监控\n集成Actuator 导入依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 配置文件\nmanagement.endpoints.web.exposure.include:*\r 对外暴露Actuator统计的审计端点信息，让Sentinel能够获取到这些信息\n重新启动服务后，\n结合上面 QPS = 1 的流控设置测试，可以直观的看到 Sentinel 控制台中显示的实时监控数据：\n每秒只允许1个请求访问，其它多余请求都被限制了\n自定义统一处理 设置url请求统一处理:WebCallbackManager\n导入依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.csp\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;sentinel-web-servlet\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 配置类\n@Configuration\rpublic class MySentinelConfig {\r@PostConstruct\rpublic void init() {\rWebCallbackManager.setUrlBlockHandler(new UrlBlockHandler() {\r@Override\rpublic void blocked(HttpServletRequest httpServletRequest, HttpServletResponse response, BlockException e) throws IOException {\rresponse.setCharacterEncoding(\u0026quot;utf-8\u0026quot;);\rresponse.setContentType(\u0026quot;application/json\u0026quot;);\rresponse.getWriter().write(\u0026quot;服务器繁忙，亲稍后再试\u0026quot;);\r}\r}\r);\r}\r}\r 也可以单独实现 UrlBlockHandler 接口实现类，根据异常信息执行相对应的业务，之后再注册到 WebCallbackManager 中\n 注：对于一些特殊业务，可以单独进行配置\n 自定义受保护的资源 常用的几种 sentinel 定义资源方式使用\n1.抛出异常 测试方法\npublic String getProductById(Integer id) {\r//自定义搜保护的资源\rtry (Entry entry = SphU.entry(\u0026quot;getproduct\u0026quot;)) {\rreturn \u0026quot;ok, get product : \u0026quot; + id;\r} catch ( BlockException e) {\r//资源访问受限，相应的处理操作\rlog.info(\u0026quot;请求getproduct资源过多，\u0026quot;,e.getMessage());\r//return \u0026quot;亲，你点的太快了~\u0026quot;;\r}\rreturn \u0026quot;error\u0026quot;;\r}\r 对自定义受保护资源添加流控规则，同上设置QPS=1，方便测试\n多次访问该请求，控制台输出内容\n2.基于注解 //定义资源，以及访问受限时调用的方法\r@SentinelResource(value = \u0026quot;getProductById\u0026quot;,blockHandler = \u0026quot;blockHandlerForGetProduct\u0026quot;)\rpublic String getProductById(Integer id) {\rreturn \u0026quot;ok, get product : \u0026quot; + id;\r}\rpublic String blockHandlerForGetProduct(BlockException e) {\rreturn \u0026quot;亲，你点的太快了~\u0026quot;;\r}\r  其他资源定义方式：Sentinel 定义资源\n 使用Sentinel来保护feign远程调用 以往我们在使用feign进行远程服务调用时，如果忘记启动远程服务了，那么肯定会出现服务不可用500异常。Sentinel能够整合feign对远程服务添加默认熔断处理，来处理这种问题\n1.配置文件\n添加 Sentinel 对 Feign 的支持\nfeign:\rsentinel:\renabled: true\r 2.定义Feign远程测试接口\n@FeignClient(name = \u0026quot;test-sentinel-product\u0026quot;,fallback = ProductFeignClientFallback.class)\rpublic interface ProductFeignClient {\r@GetMapping(\u0026quot;/product/get\u0026quot;)\rpublic String getProductById(@RequestParam(\u0026quot;pid\u0026quot;) Integer pid);\r}\r 3.定义sentinel熔断回调方法\n@Component\rpublic class ProductFeignClientFallback implements ProductFeignClient {\r@Override\rpublic String getProductById(Integer pid) {\rreturn \u0026quot;亲，你点的太快了~\u0026quot;;\r}\r}\r 4.关闭远程服务（模拟宕机情况）\n5.请求资源\ncontroller\n@GetMapping(\u0026quot;/relation/product/{pid}\u0026quot;)\rpublic String buildOrder(@PathVariable(\u0026quot;pid\u0026quot;) Integer pid) {\rreturn productFeignClient.getProductById(pid);\r}\r 响应结果\n虽然我们没有启动远程服务，但是由于我们配置了 sentinel 熔断处理，没有出现服务异常，返回了默认数据。\n对feign添加熔断保护，就相当于加了一个保险。如果远程服务宕机，我们还能够响应默认数据给客户端，而不会因为feign远程调用失败，而导致服务不可用。\n 当然，我们也可以对远程服务添加降级规则，当feign请求超过规则限制，同样会触发我们刚刚设置的熔断回调方法\n对远程服务设置降级规则\n远程服务\n这里为了测试效果，我们可以让线程小睡一会\npublic String getProductById(Integer id) {\rtry {\rThread.sleep(300);\r} catch (InterruptedException e) {\rreturn \u0026quot;error\u0026quot;;\r}\rreturn \u0026quot;ok, get product : \u0026quot; + id;\r}\r 正常启动远程服务\n测试时，远程服务启动，访问相同资源是可以得到正常数据的。但如果你刷新的足够快，触发了服务降级，调用方就会执行我们设置的默认方法，将默认数据返回\n","id":3,"section":"posts","summary":"简介：Sentinel-哨兵，是Spring Cloud Alibaba 的开源项目，是面向微服务的轻量级流量控制框架，从流量控制、熔断降级、系统负载保护等多个维度保","tags":["Sentinel"],"title":"高并发下保证服务稳定性-Sentinel","uri":"https://bluestaree.github.io/2020/08/springcloud-alibaba-sentinel/","year":"2020"},{"content":" 概述 接口幂等性\n接口幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的， 不会因为多次点击而产生了副作用;比如说支付场景，用户购买了商品支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额返发现多扣钱了，流水记录也变成了两条. . .，这就没有保证接口的幂等性。\n哪些情况需要防止  用户多次点击按钮 用户页面回退再次提交 微服务互相调用，由于网络问题，导致请求失败。feign 触发重试机制 其他业务情况  什么情况下需要幂等 以SQL为例，有些操作是天然幂等的。\n SELECT * FROM table WHER id=? , 无论执行多少次都不会改变状态，是天然的幂等。 UPDATE tab1 SET col1=1 WHERE col2=2 ,无论执行成功多少次状态都是一致的，也是幂等操作。 delete from user where userid=1 ,多次操作，结果样，具备幂等性 insert into user(userid,name) values(1,\u0026lsquo;a\u0026rsquo;) 如userid为唯一主键， 即重复操作上面的业务，只会插入一条用户数据，具备幂等性。    UPDATE tab1 SET col1=col1+1 WHERE col2=2 ,每次执行的结果都会发生变化，不是幂等的。 insert into user(userid,name) values(1,\u0026lsquo;a\u0026rsquo;) 如userid.不是主键，可以重复，那上面业务多次操作，数据都会新增多条，不具备幂等性。  幂等解决方案 Token机制   服务端提供了发送token的接口。我们在分析业务的时候，哪些业务是存在幂等问题的，就必须在执行业务前，先去获取token,服务器会把token保存到redis中。\n  然后调用业务接口请求时，把token携带过去，一般放在请求头部。\n  服务器判断token是否存在redis中，存在表示第一次请求，然后删除token,继续执行业务。\n  如果判断token不存在redis中，就表示是重复操作，直接返回重复标记给client,这样就保证了业务代码，不被重复执行。\n  危险性:\n1、先删除token还是后删除token;\n(1)先删除可能导致，业务确实没有执行，重试还带上之前token,由于防重设计导致，请求还是不能执行。\n(2)后删除可能导致，业务处理成功，但是服务闪断，出现超时，没有删除token,别人继续重试，导致业务被执行两遍\n(3)我们最好设计为先删除token,如果业务调用失败，就重新获取token再次请求。\n2、Token获取、比较和删除必须是原子性\n(1) redis.get(token) 、token.equals 、redis.del(token)如果这两个操作不是原子， 可能导致，高并发下，都get到同样的数据，判断都成功，继续业务并发执行\n(2)可以在redis使用lua脚本完成这个操作\nif redis.call('get',KEYS[1]) == ARGV[1] then return redis.cal('del', KEYS[1]) else return 0 end\r 各种锁机制 1、数据库悲观锁\nselect * from xxxx where id= 1 for update;\n悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，需要根据实际情况选用。另外要注意的是，id字段一定是主键或者唯一索引，这样只会锁住索引或者主键对应的行。普通字段加上for update会造成锁表的结果，处理起来会非常麻烦。\n2、数据库乐观锁\n这种方法适合在更新的场景中，\nupdate t_goods set count = count -1, version = version+ 1 where good_ id=2 and version= 1\n根据version版本，也就是在操作库存前先获取当前商品的version版本号，然后操作的时候带上此version号。我们梳理下，我们第一次操作库存时，得到version为1,调用库存服务version变成了2;但返回给订单服务出现了问题，订单服务又一次发起调用库存服务，当订单服务传如的version还是1，再执行上面的s语句时，就不会执行;因为version已经变为2了，where 条件就不成立。这样就保证了不管调用几次，只会真正的处理次。乐观锁主要使用于处理读多写少的问题\n3、业务层分布式锁\n如果多个机器可能在同一时间同时处理相同的数据，比如多台机器定时任务都拿到了相同数据处理，我们就可以加分布式锁，锁定此数据，处理完成后释放锁。获取到锁的必须先判断这个数据是否被处理过。\n各种唯一约束 1、数据库唯一约束\n插入数据，应该按照唯一索引进行插入， 比如订单号，相同的订单就不可能有两条记录插入。我们在数据库层面防止重复。\n这个机制是利用了数据库的主键唯一约束的特性，解决了在insert场景时幂等问题。但主键的要求不是自增的主键，这样就需要业务生成全局唯一的主键。如果是分库分表场景下，路由规则要保证相同请求下，落地在同一个数据库和同一表中，要不然数据库主键约束就不起效果了，因为是不同的数据库和表主键不相关。\n2、redis set防重\n很多数据需要处理，只能被处理一次，比如我们可以计算数据的MD5将其放入redis的set，每次处理数据，先看这个MD5是否已经存在，存在就不处理。\n防重表 使用订单号orderNo做为去重表的唯一索引， 把唯一索引插入去重表， 再进行业务操作，且他们在同一个事务中。这个保证了重复请求时，因为去重表有唯一约束， 导致请求失败，避免了幂等问题。这里要注意的是，去重表和业务表应该在同一库中，这样就保证了在同一个事务，即使业务操作失败了，也会把去重表的数据回滚。这个很好的保证了数据一致性。之前说的redis防重也算\n全局请求唯一id 调用接口时，生成一个唯一id, redis将数据保存到集合中(去重)，存在即处理过。\n可以使用nginx设置每一个请求的唯一id;\nproxy_set_header X-Request-Id $request_id;\n","id":4,"section":"posts","summary":"概述 接口幂等性 接口幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的， 不会因为多次点击而产生了副作用;比如说支付场景，用户购","tags":null,"title":"接口幂等性问题与解决方案","uri":"https://bluestaree.github.io/2020/08/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E6%80%A7/","year":"2020"},{"content":"  简介：Seata是一款阿里巴巴开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了AT、TCC、SAGA 和XA事务模式,为用户打造一站式的分布式解决方案。\n 使用Seata AT(Auto Transaction) 模式控制分布式事务 整体机制 两阶段提交协议的演变：\n 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源。 二阶段：  提交异步化，非常快速地完成。 回滚通过一阶段的回滚日志进行反向补偿。    案例演示 用户下订单的部分业务逻辑，由2个微服务组成\n订单服务：创建订单\n库存服务：从订单商品信息中，锁定相应库存\n环境搭建 数据库\n订单表\nCREATE TABLE `orders` (\r`order_number` varchar(32) NOT NULL COMMENT '订单号',\r`initial_price` float(8,2) DEFAULT NULL COMMENT '定价',\r`price` float(8,2) DEFAULT NULL COMMENT '交易价',\r`start_time` datetime NOT NULL COMMENT '起始时间',\r`end_time` datetime NOT NULL COMMENT '结束时间',\r`status` varchar(32) DEFAULT NULL COMMENT '交易状态',\r`user_id` varchar(32) DEFAULT NULL COMMENT '用户id',\r`details` varchar(1000) DEFAULT NULL COMMENT '订单明细',\rPRIMARY KEY (`order_number`)\r) ENGINE=InnoDB DEFAULT CHARSET=utf8;\r 库存表\nCREATE TABLE `ware` (\r`id` bigint(20) NOT NULL COMMENT '库存id',\r`sku_id` bigint(20) DEFAULT NULL COMMENT 'sku_id',\r`ware_id` bigint(20) DEFAULT NULL COMMENT '仓库id',\r`stock` int DEFAULT NULL COMMENT '库存数量',\r`sku_name` varchar(255) DEFAULT NULL COMMENT 'sku名称',\r`stock_locked` int DEFAULT NULL COMMENT '锁定库存量',\rPRIMARY KEY (`id`)\r) ENGINE=InnoDB DEFAULT CHARSET=utf8;\r 主要业务逻辑 订单服务\n@Transactional\rpublic void submitOrder() {\r//生成订单\rOrders orders = new Orders();\rorders.setOrderNumber(UUID.randomUUID().toString().replace(\u0026quot;-\u0026quot;, \u0026quot;\u0026quot;));\rorders.setDetails(\u0026quot;测试订单\u0026quot;);\rorders.setStartTime(new Date());\rorders.setEndTime(new Date());\rordersRepository.save(orders);\r//远程减库存\rwareClient.updateWareStockLockedBySkuId(16,10);\r//TODO 其他微服务业务调用\r//模拟异常发生\r//int num = 1/0;\r}\r 测试 无异常情况\n订单表\n库存表\n两个事务动能正常提交，没有问题。\n接下来演示失败情况，手动操作数据库，将订单表的记录和锁定的库存数量重置\n异常情况\n打开异常代码注释\n可以看到，订单表事务正常回滚，而库存表事务却未回滚，因为spring 控制的是本地事务，无法对远程事务进行控制，造成了数据不一致的情况\n引入Seata进行分布式事务控制 1. 为每一个需要控制事务的数据库都创捷一个 UNDO_LOG 表 -- 注意此处0.3.0+ 增加唯一索引 ux_undo_log\rCREATE TABLE `undo_log` (\r`id` bigint(20) NOT NULL AUTO_INCREMENT,\r`branch_id` bigint(20) NOT NULL,\r`xid` varchar(100) NOT NULL,\r`context` varchar(128) NOT NULL,\r`rollback_info` longblob NOT NULL,\r`log_status` int(11) NOT NULL,\r`log_created` datetime NOT NULL,\r`log_modified` datetime NOT NULL,\r`ext` varchar(100) DEFAULT NULL,\rPRIMARY KEY (`id`),\rUNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)\r) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;\r 当事务需要回滚时，Seata 会根据此表的记录，魔改数据库，将改变的数据再次复原\n2.下载Seata-Service软件包，就是全局事务协调器。 https://github.com/seata/seata/releases\n配置Seata-Service\n下载完Seata-Service软件包后，解压次压缩包。配置文件就位于conf文件夹下\n主要修改已下配置文件设置\nregistry.conf\nregistry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = \u0026quot;eureka\u0026quot; #指定Seata-Service注册中心\r#各个服务器的配置，指定地址\rnacos {\rserverAddr = \u0026quot;localhost\u0026quot;\rnamespace = \u0026quot;public\u0026quot;\rcluster = \u0026quot;default\u0026quot;\r}\reureka {\rserviceUrl = \u0026quot;http://localhost:60101/eureka\u0026quot;\rapplication = \u0026quot;seata-server\u0026quot;\t#应用名称\rweight = \u0026quot;1\u0026quot;\r}\rredis {\rserverAddr = \u0026quot;localhost:6379\u0026quot;\rdb = \u0026quot;0\u0026quot;\r}\rzk {\rcluster = \u0026quot;default\u0026quot;\rserverAddr = \u0026quot;127.0.0.1:2181\u0026quot;\rsession.timeout = 6000\rconnect.timeout = 2000\r}\rconsul {\rcluster = \u0026quot;default\u0026quot;\rserverAddr = \u0026quot;127.0.0.1:8500\u0026quot;\r}\retcd3 {\rcluster = \u0026quot;default\u0026quot;\rserverAddr = \u0026quot;http://localhost:2379\u0026quot;\r}\rsofa {\rserverAddr = \u0026quot;127.0.0.1:9603\u0026quot;\rapplication = \u0026quot;default\u0026quot;\rregion = \u0026quot;DEFAULT_ZONE\u0026quot;\rdatacenter = \u0026quot;DefaultDataCenter\u0026quot;\rcluster = \u0026quot;default\u0026quot;\rgroup = \u0026quot;SEATA_GROUP\u0026quot;\raddressWaitTime = \u0026quot;3000\u0026quot;\r}\rfile {\rname = \u0026quot;file.conf\u0026quot;\r}\r}\rconfig {\r# file、nacos 、apollo、zk、consul、etcd3\rtype = \u0026quot;file\u0026quot; #设置seata配置的存储位置 ,默认为当前目录下的file.conf\rnacos {\rserverAddr = \u0026quot;localhost\u0026quot;\rnamespace = \u0026quot;public\u0026quot;\rcluster = \u0026quot;default\u0026quot;\r}\rconsul {\rserverAddr = \u0026quot;127.0.0.1:8500\u0026quot;\r}\rapollo {\rapp.id = \u0026quot;seata-server\u0026quot;\rapollo.meta = \u0026quot;http://192.168.1.204:8801\u0026quot;\r}\rzk {\rserverAddr = \u0026quot;127.0.0.1:2181\u0026quot;\rsession.timeout = 6000\rconnect.timeout = 2000\r}\retcd3 {\rserverAddr = \u0026quot;http://localhost:2379\u0026quot;\r}\rfile {\rname = \u0026quot;file.conf\u0026quot;\r}\r}\r 在bin目录下，根据操作系统启动Seata-Service\n可以看到在eurek中Seata-Service已经注册成功\n3.导入Seata依赖 \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-cloud-alibaba-seata\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.0.0.RELEASE\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 4.添加@GlobalTransactional 注解 在分布式大事务方法上添加@GlobalTransactional 注解 ，其他远程分支事务保持@Transactional注解即可\n5.使用seata DataSourceProxy代理自己的数据源 所有需要使用seata控制事务的微服务都需要进行配置\n@Configuration\rpublic class MySeataConfig {\r@Autowired\rDataSourceProperties dataSourceProperties;\r@Bean\rpublic DataSource dataSource(DataSourceProperties dataSourceProperties) {\rHikariDataSource dataSource = dataSourceProperties.initializeDataSourceBuilder().type(HikariDataSource.class).build();\rif (StringUtils.hasText(dataSourceProperties.getName())) {\rdataSource.setPoolName(dataSourceProperties.getName());\r}\rreturn new DataSourceProxy(dataSource);\r}\r}\r 6.导入registry.conf和file.conf文件 每一个服务，都必须导入Seata-Service的conf目录下的registry.conf和file.conf\n其中file.conf的service.vgroup_ mapping配置必须和spring. application.name一致。否则会提示no available server to connect错误\n格式\nvgroup_mapping.{application.name}-fescar-service-group = \u0026quot;default\u0026quot;\n7.启动测试 测试之前，为了方便查看结果，记得把数据库中的数据手动重置下\n先看正常情况\n异常情况\n在加入Seata控制事务后\n两个事务都能够进行回滚。成功解决了分布式事务控制问题\n 注意：AT模式并不适合超高并发的情况。在控制事务的过程中，会使用各种锁机制来进行事务控制，在高并发情况下，就会变成串行化。\n在高并发下可以采用消息队列 + 最终一致性的方案\n ","id":5,"section":"posts","summary":"简介：Seata是一款阿里巴巴开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了AT、TCC、S","tags":["Seata"],"title":"分布式解决方案-Seata","uri":"https://bluestaree.github.io/2020/08/springcloud-alibaba-seata/","year":"2020"},{"content":" 本地事务 事务的基本性质 数据库事务的几个特性:原子性(Atomicity)、一致性( Consistency )、隔离性或独立性( Isolation )和持久性( Durabilily )，简称就是ACID：\n   ACID 说明     原子性 一系列的操作整体不可拆分，要么同时成功，要么同时失败。   一致性 数据在事务的前后，业务整体一致。例 A:1000; B:1000; 转200 事务成功 -\u0026gt; A:800 B:1200   隔离性 事务之间互相隔离。   持久性 一旦事务成功，数据-定会落盘在数据库。    在以往的单体应用中，我们多个业务操作使用同一条连接操作不同的数据表，一旦有异常，我们可以很容易的整体回滚;\n事务的隔离级别   READ UNCOMMITED (读未提交) 该隔离级别的事务会读到其它未提交事务的数据，此现象也称之为脏读。\n  READ COMMITTED (读已提交)\n一个事务可以读取另一个已提交的事务，多次读取会造成不一样的结果，此现象称为不可重复读问题，Oracle 和SQL Server的默认隔离级别。\n  REPEATABLE READ (可重复读) 该隔离级别是 MySQL 默认的隔离级别，在同一个事务里，select 的结果是事务开始时时间点的状态，因此，同样的 select 操作读到的结果会是一致的， 但是，会有幻读现象。MySQL 的 InnoDB 引擎可以通过 next-key locks 机制来避免幻读。\n  SERIALIZABLE (序列化) 在该隔离级别下事务都是串行顺序执行的，MySQL 数据库的 InnoDB 引擎会给读操作隐式加一把读共享锁，从而避免了脏读、不可重读复读和幻读问题。\n  在spring事务控制中，指定隔离级别\n@Transactional(isolation = Isolation.READ_COMMITTED)\rpublic void submit(Order order) {\r//TODO ....\r}\r 事务的传播行为    传播行为 说明     PROPAGATION_REQUIRED 如果当前没有事务，就创建一个新事务， 如果当前存在事务，就加入该事务，该设置是最常用的设置。   PROPAGATION _SUPPORTS 支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。   PROPAGATION_MANDATORY 支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。   PROPAGATION_REQUIRES_NEW 创建新事务，无论当前存不存在事务，都创建新事务   PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。   PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。   PROPAGATION_NESTED 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED 类似的操作。    举个栗子： 先看下面的伪代码。\n@Transactional(timeout = 30)\rpublic void a(){\rb();//使用a事务\rc();//新开一个事务,(后续如果出现异常，不回滚)\r//模拟异常情况\rint num = 2/0; }\r//默认为PROPAGATION_REQUIRED\r@Transactional(propagation = Propagation.REQUIRED，timeout = 10) public void b(){\r}\r@Transactional(propagation = Propagation.REQUIRES_NEW)\rpublic void c(){\r}\r  假定存在a、b、c三个事务方法，其中a调用了b、c方法。（可以理解为一个大事务中包含了其他小事务）\nb事务所设置的是默认传播行为，表示需要一个事务即可，这里会与a方法共用一个事务,并且a事务的所有设置都会传播给和他公用一个事务的方法，（上面的情况，b事务的 timeout = 10会失效）\nc事务的传播行为，表示无论是否存在事务，都会创建一个新事务.\n 如果a方法能够顺利执行，中途没有任何异常情况，那么所有事务都会正常提交，无事发生。\n如果b和c方法都顺利执行，但在a方法最后出现了异常，这时只有a和b会进行回滚(同一个事务控制)，而c由于是另外一个事务控制，不会回滚。\n我们可以更改事务的传播行为来控制多事务嵌套的情况\nSpringBoot事务控制的一个坑\n在同一个类里面，编写两个方法，内部调用的时候，会导致事务设置失效。原因是没有用到代理对象的缘故。\n在上面的伪代码中，如果a、b、c三个方法都是在同一个类中定义的，那么在SpringBoot事务控制下，这些事务设置都不会生效\n原因： 事务是使用代理对象来控制的，在同一个对象内进行方法相互调用，就相当于直接将b、c方法中的代码复制到a中，\n解决： 通过aspectJ 获取当前类的代理对象，或者将方法抽取出来。\n 引入aop-starter，主要为了使用aspectj  \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r  使用 @EnableAspectJAutoProxy(exposeProxy = true) 注解;开启aspectj动态代理功能。以后所有的动态代理都是aspectj创建的(即使没有接口也可以创建动态代理)，默认使用的是jdk动态代理,必须要有接口，设置exposeProxy = true，对外暴露代理对象\n  使用 AopContext.currentProxy(); 获取当前对象的代理对象.\n@Transactional\rpublic void a(){\rTsService tsService = (TsService) AopContext.currentProxy() ;\rtsService.b();\rtsService.c();\rint num = 2/0; }\r   分布式事务 分布式系统经常出现的异常机器宕机、网络异常、消息丢失、消息乱序、数据错误、不可靠的TCP、存储数据丢失等问题\u0026hellip;导致服务器之前无法及时感知对方的状态。\n因此要协调多个系统之间来控制整体事务就非常困难。\nCAP定理与BASE理论 CAP定理    CAP定理 说明     一致性 (Consistency) 在分布式系统中的所有数据备份，在同一时刻是否同样的值。(等同于所有节点访问同一份最新的数据副本)   可用性(Availability) 在集群中一部分节点故障后， 集群整体是否还能响应客户端的读写请求。(对数据更新具备高可用性)   分区容错性 (Partition tolerance) 大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区(partition)。分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。    CAP原则指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。\n一般来说，分区容错无法避免，因此可以认为CAP的P总是成立。CAP定理告诉我们，剩下的C和A无法同时做到。\nCA其实就是本地项目（无网络情况），CP就需要通过一些算法raft,paxos等来保证数据一致性\nRaft算法动画演示地址\n核心：领导选取，日志复制。通过这些操作来保证数据的一致性\n 对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到99.9999% (N个9)，即保证p和A,舍弃C。\nBASE理论 是对CAP理论的延伸，思想是即使无法做到强一致性(CAP的一致性就是强一致性)，但可以采用适当的采取弱一致性，即最终一致性。\n   BASE理论 说明     基本可用 (Basically Available) 基本可用是指分布式系统在 出现故障的时候,允许损失部分可用性(例如响应时间、功能上的可用性)，允许损失部分可用性。需要注意的是，基本可用绝不等价于系统不可用。   软状态 (Soft State) 软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据会有多个副本，允许不同副本同步的延时就是软状态的体现。mysql replication的异步复制也是一种体现。   最终一致性 ( Eventual Consistency) 最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。    从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了不同的一致性。对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。如果能容忍后续的部分或者全部访问不到，则是弱一致性。如果经过一段时间后要求能访问到更新后的数据，则是最终一致性\n分布式事务的几种解决方案 2PC模式 数据库支持的2PC [2 phase commit 二阶提交]，又叫做XA Transactions。 MySQL从5.5版本开始支持，SQL Server 2005开始支持，Oracle7 开始支持。 其中，XA 是一个两阶段提交协议，该协议分为以下两个阶段:\n 第一阶段: 事务协调器要求每个涉及到事务的数据库预提交 (precommit) 此操作，并反映是否可以提交. 第二阶段: 事务协调器要求每个数据库提交数据。  其中，如果有任何一个数据库否决此次提交，那么所有数据库都会被要求回滚它们在此事务中的那部分信息。\n也有3PC,引入了超时机制(无论协调者还是参与者，在向对方发送请求后，若长时间未收到回应则做出相应处理)\n柔性事务 - TCC事务补偿 刚性事务: 遵循ACID原则，强一致性。\n柔性事务: 遵循BASE理论，最终一致性;\n与刚性事务不同，柔性事务允许一定时间内， 不同节点的数据不一致，但要求最终一致。\n一阶段 prepare 行为: 调用自定义的try逻辑。\n二阶段 commit 行为: 调用自定义的commit逻辑。\n三阶段 rollback 行为: 调用自定义的rollback逻辑。\n所谓TCC 模式，是指支持把自定义的分支事务纳入到全局事务的管理中。\n柔性事务 - 最大努力通知型方案 按规律进行通知，不保证数据一定能通知成功， 但会提供可查询操作接口进行核对。这种方案主要用在与第三方系统通讯时，\n比如: 调用微信或支付宝支付后的支付结果通知。这种方案也是结合MQ进行实现，例如: 通过MQ发送http请求，设置最大通知次数。达到通知次数后即不再通知。\n案例: 银行通知、商户通知等(各大交易业务平台间的商户通知: 多次通知、查询校对、对账文件)，支付宝的支付成功异步回调\n柔性事务 - 可靠消息 + 最终一致性方案 (异步确保型) 实现: 业务处理服务在业务事务提交之前，向实时消息服务请求发送消息，实时消息服务只记录消息数据，而不是真正的发送。业务处理服务在业务事务提交之后，向实时消息服务确认发送。只有在得到确认发送指令后，实时消息服务才会真正发送。\n方案问题和解决： 1.保证消息可靠性 - 消息丢失   消息发送出去，由于网络问题没有抵达服务器\n 做好容错方法(try-catch) ，发送消息可能会网络失败，失败后要有重试机制，可记录到数据库，采用定期扫描重发的方式  表结构示例：\nCREATE TABLE 'mq_ message' (\r'message_id' CHAR(32) NOT NULL COMMENT '消息id',\r'content' TEXT COMMENT '消息内容，json数据',\r'to_exchane' VARCHAR(255) COMMENT '目标交换机',\r'routing_key' VARCHAR(255) DEFAULT NULL COMMENT '路由key',\r'class_type' VARCHAR(255) DEFAULT NULL COMMENT '消息类型',\r'message_status' INT(1) DEFAULT '0' COMMENT '状态 0-新建 1-已发送 2-错误抵达 3-已抵达',\r'create_time' DATETIME DEFAULT NULL,\r'update_time' DATETIME DEFAULT NULL,\rPRIMARY KEY ('message_id')\r) ENGINE=INNODB DEFAULT CHARSET=utf8mb4\r  做好日志记录，每个消息状态是否都被服务器收到都应该记录 做好定期重发，如果消息没有发送成功，定期去数据库扫描未成功的消息进行重发    消息抵达Broker, Broker要将消息写入磁盘(持久化)才算成功。此时Broker尚未持久化完成，宕机。\n  publisher也必须加入确认回调机制(returnCallback)，确认消息成功进入目标队列后，修改数据库消息状态。\n  自动ACK的状态下。消费者收到消息，但没来得及消息然后宕机\n 开启手动ACK，消费成功才移除，失败或者没来得及处理就noAck并重新入队    2.保证消息可靠性 - 消息重复   消息消费成功，事务已经提交，ack时，机器宕机。导致没有ack成功，Broker的消息重新由unack变为ready，并发送给其他消费者\n  消息消费失败，由于重试机制，自动又将消息发送出去\n  成功消费，ack时宕机，消息由unack变为ready，Broker又重新发送\n  消费者的业务消费接口应该设计为幂等性的。比如扣库存有工作单的状态标志\n  使用防重表(redis/mysql)，发送消息每一个都有业务的唯一标识，处理过就不用处理，类似上述方法\n  rabbitMQ的每一个消息都有redelivered字段, 可以获取是否是被重新投递过来的，而不是第一次投递过来的\n  Boolean redelivered = message.getMessageProperties().getRedelivered();\n 注意：也可能是因为上一个业务没有处理成功，将消息重新入队，而被标识已接收\n   3.保证消息可靠性 - 消息积压   消费者宕机积压\n  消费者消费能力不足积压\n  发送者发送流量太大\n  上线更多的消费者，进行正常消费\n  上线专门的队列消费服务，将消息先批量取出来，记录数据库，离线慢慢处理\n    ","id":6,"section":"posts","summary":"本地事务 事务的基本性质 数据库事务的几个特性:原子性(Atomicity)、一致性( Consistency )、隔离性或独立性( Isolation )和持久性( Durabilily )，简称就是ACID","tags":null,"title":"本地事务与分布式事务","uri":"https://bluestaree.github.io/2020/08/%E6%9C%AC%E5%9C%B0%E4%BA%8B%E5%8A%A1%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","year":"2020"},{"content":"  概述：在一些应用场景下，服务端也需要返回完整的页面信息给客户端，比如有利于SEO的主页，搜索页面等，都需要服务端渲染。当然使用Nuxt或Next也可以完美解决此问题，本文使用了Spring Session技术，结合Redis来解决原生Session使用中的一些问题。\n HeepSession 原生HeepSession，是在服务器内存中开辟了一个存储空间，底层使用的是Map结构，用于存储此次会话数据，由SessionManager进行统一管理.\n工作原理： 在第一次使用session时，服务器会创建一个带 JSESSIONID 的cookie，默认以当前服务器域名为该cookie的作用域，以后浏览器只要在对应的作用域下进行请求，服务器就能获取cookie中的JSESSIONID对应的Session数据.\n问题：\n 不能跨域名共享，可以看到该cookie中指定了可生效的域名 分布式情况下，多个服务器下，一个用户的session无法共享  解决方法 Session共享问题解决-session复制 多服务器集群之间进行session的复制，无论负载均衡到哪一个服务器都能找到数据\n优点\n web-server (Tomcat) 原生支持，只需要修改配置文件  缺点\n session同步需要数据传输， 占用大量网络带宽，降低了服务器群的业务处理能力 任意一台web-server保存的数据都是所有web-server的session总和，受到内存限制无法水平扩展更多的web-server 大型分布式集群情况下，由于所有web-server都全量保存数据，所以此方案不可取。  Session共享问题解决-客户端存储 将所有信息都通过cookie存储到客户端中\n优点\n 服务器不需存储session, 用户保存自己的session信息到cookie中。节省服务端资源  缺点\n 每次http请求， 携带用户在cookie中的完整信息，浪费网络带宽 session数据放在cookie中，cookie有长度限制4K,不能保存大量信息 session数据放在cookie中，存在泄漏、篡改、窃取等安全隐患  Session共享问题解决-hash一致性 通过负载均衡，保证同一个IP的多次请求，都落在一个服务器上\n优点:\n 只需要改nginx配置，不需要修改应用代码 负载均衡，只要hash属性的值分布是均匀的，多台web-server的负载是均衡的 可以支持web-server水平扩 展(session同步法是不行的，受内存限制)  缺点:\n session还是存在web server中的， 所以web-server重启可能导致部分session丢失，影响业务，如部分用户需要重新登录 如果web-serven水平扩 展，rehash后session重新分布，也会有一部分用户路由不到正确的session 但是以上缺点问题也不是很大，因为session本来都是有有效期的。所以这两种反向代理的方式可以使用  Session共享问题解决-统一存储 不存在服务器内存中，转为由数据库，或Redis等其他中间件进行存储\n优点:\n 没有安全隐患 可以水平扩展， 数据库/缓存水平切分即可 web-server重启或者扩 容都不会有session丢失  缺点:\n 增加了一次网络调用，并且需要修改应用代码;如将所有的getSession方法替换为从Redis查数据的方式。redis获取数据比内存慢很多  Session共享问题解决-不同服务，子域session共享 子域session无法共享问题主要原因是：默认的cookie有效域仅为当前域名。\n我们可以整合Spring Session修改这个作用域，扩大它的作用范围，如jd.com，这样在其他子域名(pro.jd.com)就\n可以携带此cookie ,实现跨域session共享。\n简单接入Spring Session Spring Session提供了一套API，用于完成管理用户Session的功能\nSpring Session与Redis整合 1. pom文件配置\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.session\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-session-data-redis\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 配置文件\n#Redis连接信息\rspring.redis.host=127.0.0.1\rspring.redis.port=6379\rspring.session.store-type=redis #指定session存储类型\rserver.servlet.session.timeout=30m #session超时时间\r 2. Config配置类\n//配置JSON序列化，默认为JDK序列化方式\r@Bean\rpublic RedisSerializer\u0026lt;Object\u0026gt; springSessionDefaultRedisSerializer() {\rreturn new GenericJackson2JsonRedisSerializer();\r}\r//配置自定义cookie信息\r@Bean\rpublic CookieSerializer cookieSerializer() {\rDefaultCookieSerializer serializer = new DefaultCookieSerializer();\rserializer.setCookieName(\u0026quot;JSESSIONID\u0026quot;); serializer.setCookiePath(\u0026quot;/\u0026quot;); serializer.setDomainName(\u0026quot;bookstore.com\u0026quot;); return serializer;\r}\r 3. Controller\n在Session中添加数据\n@GetMapping(\u0026quot;/session\u0026quot;)\rprivate String session(HttpSession session) {\rUserInfo userInfo = new UserInfo();\ruserInfo.setName(\u0026quot;Jack\u0026quot;);\ruserInfo.setAge(25);\rsession.setAttribute(\u0026quot;userInfo\u0026quot;, userInfo);\rreturn \u0026quot;redirect:http://www.bookstore.com\u0026quot;;\r}\r 4. 启动类\n启动类中添加如下注解\n//整合redis作为session存储\r@EnableRedisHttpSession\r@SpringBootApplication\rpublic class WebApplication {\rpublic static void main(String[] args) {\rSpringApplication.run(WebApplication.class, args);\r}\r}  Redis存储结构 页面cookie信息 这样一来，我们就将Session存储的位置转移到了Redis，并且修改了Cookie默认信息，只要携带有效的Cookie访问服务器，Spring Session就能从Redis中获取到对应的Session数据，在页面中进行渲染。\n","id":7,"section":"posts","summary":"概述：在一些应用场景下，服务端也需要返回完整的页面信息给客户端，比如有利于SEO的主页，搜索页面等，都需要服务端渲染。当然使用Nuxt或Ne","tags":null,"title":"Spring Session与Redis整合","uri":"https://bluestaree.github.io/2020/07/spring-session%E4%B8%8Eredis%E6%95%B4%E5%90%88/","year":"2020"},{"content":"  前言：在一些业务复杂的场景中，往往会涉及多个业务之间的相互调用，通过线程池性能稳定，也可以获取执行结果，并捕获异常。但是，在业务复杂情况下，一个异步调用可能会依赖于另一个异步调用的执行结果。为了解决这个问题，我们可以使用JDK1.8版本新引入的类CompletableFuture来实现异步编排，控制多线程的执行顺序。\n 初始化线程的4种方式  继承Thread  Thread01 thread = new Thread01();\rthread.start();//启动线程\r 实现Runnable接口 ，然后交由Thread处理  Runable01 runable01 = new Runable01();\rnew Thread(runable01).start();\r 实现Callable接口+ FutureTask ( 可以拿到返回结果，处理异常)  FutureTask\u0026lt;Integer\u0026gt; futureTask = new FutureTask\u0026lt;\u0026gt;(new Callable01()); new Thread(futureTask).start();\r//等待整个线程执行完成，获取返回结果 (阻塞等待)\rInteger num = futureTask.get();\r 线程池  方式1和方式2：主进程无法获取线程的运算结果。\n方式3：主进程可以获取线程的运算结果，但是不利于控制服务器中的线程资源。可能导致服务器资源耗尽。\n方式4：通过如下两种方式初始化线程池\n//1.使用Executors工具类（底层使用的是ThreadPoolExecutor）\rExecutors.newFiexedThreadPool(3);\r//2.通过ThreadPoolExecutor 创建线程池。\rnew ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAlieTime, TimeUnit unit,workQueue, threadFactory, handler);\r ThreadPoolExecutor ThreadPoolExecutor 7 个最重要的参数\n corePoolSize ：核心线程数;一直存在除非 设置了(allowCoreThreadTimeOut)参数。线程池创建好以后就准备就绪的线程数量，等待来接受异步任务去执行 maximumPoolSize：最大线程数量，控制资源 keepAliveTime：线程存活时间。如果当前线程数量大于corePoolSize 超过该事件，就会释放空闲的线程（maximumPoolSize - corePoolSize ） unit ：keepAliveTime 参数的时间单位。 workQueue：队列。如果任务很多，就会将多的任务放入队列中，只要有空闲的线程，就会去队列中取出新的任务执行 threadFactory：创建线程Thread的工厂，使用默认即可 handler：如果队列满了，按照所指定的\t拒绝策略，拒绝执行任务  ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(10, 30,\r300, TimeUnit.SECONDS, new ArrayBlockingQueue\u0026lt;Runnable\u0026gt;(100),\rExecutors.defaultThreadFactory(), new ThreadPoolExecutor.CallerRunsPolicy());\r 关于拒绝策略\n可选参数：\n DiscardOldestPolicy : 丢弃队列中最老的任务 CallerRunsPolicy : 直接调用run方法，也就是使用主线程main执行，（同步调用） AbortPolicy : 直接丢弃新的任务，抛异常 DiscardPolicy : 丢弃新的任务，不抛异常  运行流程:\n1、线程池创建，准备好core数量的核心线程，准备接受任务\n2、新的任务进来，用core准备好的空闲线程执行。\n  core满了，就将再进来的任务放入阻塞队列中。空闲的core就会自己去阻塞队列获取任务执行\n  阻塞队列满了，就直接开新线程执行，最大只能开到max指定的数量\n  max都执行好了。Max-core数量空闲的线程会在keepAliveTime指定的时间后自动销毁。最终保持到core大小\n  如果线程数开到了max的数量，还有新任务进来，就会使用reject 指定的拒绝策略进行处理\n  3、所有的线程创建都是由指定的factory创建的。\n 举个栗子:\n一个线程池core=7;max=20,queue=50, 当100并发进来怎么分配的;\n先有7个能直接得到执行，接下来50个进入队列排队，在多开13个继续执行。现在70个被安排上了。剩下30个默认拒绝策略。\n 常见的4种线程池 使用Exectors线程池工具类创建方法\nnewCachedThreadPool\n创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。\nnewFixedThreadPool\n创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。\nnewScheduledThreadPool\n创建一个定长线程池，支持定时及周期性任务执行。\nnewSingleThreadExecutor\n创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，从队列中获取任务，挨个执行\n为什么使用线程池   降低资源的消耗\n通过重复利用已经创建好的线程降低线程的创建和销毁带来的损耗\n  提高响应速度\n因为线程池中的线程数没有超过线程池的最大上限时，有的线程处于等待分配任务的状态，当任务来时无需创建新的线程就能执行\n  提高线程的可管理性\n线程池会根据当前系统特点对池内的线程进行优化处理,减少创建和销毁线程带来的系统开销。无限的创建和销毁线程不仅消耗系统资源，还降低系统的稳定性，使用线程池进行统一分配\n  CompletableFuture 这个completableFuture是JDK1.8版本新引入的类。\n业务场景:\n查询商品详情页的逻辑比较复杂，有些数据还需要远程调用，必然需要花费更多的时间。\n // 1.获取sku的基本信息 0.5s\n// 2.获取sku的图片信息0.5s\n// 3.获取sku的促销信息1s\n// 4.获取spu的所有销售属性 1s\n// 5.获取规格参数组及组下的规格参数1.5s\n// 6. spu详情1s\n 假如商品详情页的每个查询，需要如下标注的时间才能完成\n那么，用户需要5.5s后才能看到商品详情页的内容。很显然是不能接受的。\n如果有多个线程同时完成这6步操作，也许只需要1.5s即可完成响应。\n但是，可以看到上述1，2，3步骤可以异步进行，互不影响，但是4，5，6则需要1的结果才能进行查询，关系还是比较复杂的\n在这种场景下，我们就可以使用CompletableFuture来处理\nCompletableFuture实现了Future接口，Future可以获取到异步结果，可以理解为vue中的promise，\n1. 创建一个异步对象 CompletableFuture提供了四个静态方法来创建一一个异步操作。\npublic static CompletableFuture\u0026lt;Void\u0026gt; runAsync(Runnable runnable)\rpublic static CompletableFuture\u0026lt;Void\u0026gt; runAsync (Runnable runnable, Executor executor )\rpublic static \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; supplyAsync (Supplier\u0026lt;U\u0026gt; supplier)\rpublic static \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; supplyAsync (Supplier\u0026lt;U\u0026gt; supplier, Executor executor)\r 说明：\n runXxxx都是没有返回结果的，supplyXx都是可以获取返回结果的 可以传入自定义的线程池executor ，否则就用默认的线程池;  2.计算完成时的回调方法 public CompletableFuture\u0026lt;T\u0026gt; whenComplete(BiConsumer\u0026lt;? super T,? super Throwable\u0026gt; action);\rpublic CompletableFuture\u0026lt;T\u0026gt; whenCompleteAsync(BiConsumer\u0026lt;? super T,? super Throwable\u0026gt; action);\rpublic CompletableFuture\u0026lt;T\u0026gt; whenCompleteAsync(BiConsumer\u0026lt;? super T,? super Throwable\u0026gt; action,Executor executor);\rpublic CompletableFuture\u0026lt;T\u0026gt; exceptionally(Function\u0026lt;Throwable,? extends T\u0026gt; fn);\r 说明：\n1.whenComplete可以处理正常和异常的计算结果，exceptionally 处理异常情祝。\n2.whenComplete和whenCompleteAsync 的区别:\n whenComplete:是执行当前任务的线程执行继续执行whenComplete的任务。 whenCompleteAsync:是执行把whenCompleteAsync这个任务继续提交给线程池来进行执行。  方法不以Async结尾，意味着Action使用相同的线程执行，而Async可能会使用其他线程执行(如果是使用相同的线程池，也可能会被同一个线程选中执行\npublic static void main(String[] args) throws ExecutionException,InterruptedException {\rCompletableFuture\u0026lt;Integer\u0026gt; future = CompletableFuture.supplyAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;当前线程:\u0026quot;+ Thread.currentThread().getId());\rint i = 10/0;\rSystem.out.println(\u0026quot;运行结果:\u0026quot;+ i);\rreturn i;\r},executor).whenComplete((res, excption)-\u0026gt;{\r//虽然能得到异常信息，但是没法修改返回数据。\rSystem.out.println( \u0026quot;异步任务成功完成了.. .结果是: \u0026quot;+res+\u0026quot; ;异常是:\u0026quot;+excption);\r}).exceptionally(throwable -\u0026gt; {\r//可以感知异常，同时返回默认值\rreturn 10;\r});\r//使用handle,在方法执行完成后可以进行后续处理\r/*CompletableFuture\u0026lt;Integer\u0026gt; future = CompletableFuture.supplyAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;当前线程:”+ Thread.currentThread().getId());\rint i = 10/4;\rSystem.out.println(\u0026quot;运行结果:“+ i);\rreturn i;\r},executor).handle((res,thr)-\u0026gt;{\rif(res!=nu11){\rreturn res*2;\r}\rif(thr!=nu11){\rreturn 0;\r}\rreturn 0;\r});*/\r//阻塞等待，直到任务结束，获取结果值\rInteger integer = future.get();\rSystem.out.println(\u0026quot;main.... end....\u0026quot;+integer);\r}\r}\r 3.handle 方法 public \u0026lt;U\u0026gt; Completionstage\u0026lt;U\u0026gt; handle(BiFunction\u0026lt;? super T,Throwable, ? extends U\u0026gt; fn) ;\rpublic \u0026lt;U\u0026gt; Completionstage\u0026lt;U\u0026gt; handleAsync(BiFunction\u0026lt;? super T,Throwable, ? extends U\u0026gt; fn);\rpublic \u0026lt;U\u0026gt; CompletionStage\u0026lt;U\u0026gt; handleAsync(BiFunction\u0026lt;? super T,Throwable, ? extends U\u0026gt; fn,Executor executor);\r 说明：\n和complete一样，可对结果做最后的处理(可处理异常)，可改变返回值。\n4.线程串行化方法 //获取上一个任务的执行结果，并返回当前执行的结果\rpublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenApply(Function\u0026lt;? super T,? extends U\u0026gt; fn)\rpublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenApplyAsync(Function\u0026lt;? super T,? extends U\u0026gt; fn)\rpublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenApplyAsync(Function\u0026lt;? super T,? extends U\u0026gt; fn, Executor executor )\r//可以获取到上一个线程执行结果\rpublic Completionstage\u0026lt;Void\u0026gt; thenAccept (Consumer\u0026lt;? super T\u0026gt; action) :\rpublic CompletionStage\u0026lt;Void\u0026gt; thenAcceptAsync(Consumer\u0026lt;? super T\u0026gt; action);\rpublic CompletionStage\u0026lt;Void\u0026gt; thenAcceptAsync (Consumer\u0026lt;? super T\u0026gt; ; action, Executor executor );\r//获取不到上一个线程执行的结果\rpublic CompletionStage\u0026lt;Void\u0026gt; thenRun(Runnable action);\rpublic CompletionStage\u0026lt;Void\u0026gt; thenRunAsync (Runnable action);\rpublic Completionstage\u0026lt;Void\u0026gt; thenRunAsync (Runnable action, Executor executor);\r 说明：\n thenApply方法:当一个线程依赖另一个线程时，获取上一个任务返回的结果，并返回当前任务的返回值。 thenAccept方法:消费处理结果。接收任务的处理结果，并消费处理，无返回结果。 thenRun方法:只要上面的任务执行完成，就开始执行thenRun,只是处理完任务后，执行thenRun的后续操作 带有Async默认是异步执行的。同之前。  以上都要前置任务成功完成。\n/**\r*线程串行化\r* 1)、thenRun:不能获取到上一步的执行结果，无返回值\r*/\rCompletableFuture\u0026lt;Void\u0026gt; future = CompletableFuture.supplyAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;当前线程:\u0026quot; + Thread.currentThread().getId());\rint i = 10 / 4;\rSystem.out.println(\u0026quot;运行结果:\u0026quot; + i);\rreturn i;\r}, executor).thenRunAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;任务2启动了...\u0026quot;);\r}, executor);\r/**\r* 2)、thenAcceptAsync:能接受上一步结果，但是无返回值\r*/\rCompletableFuture.supplyAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;当前线程:\u0026quot; + Thread.currentThread().getId());\rint i = 10 / 4;\rSystem.out.println(\u0026quot;运行结果:\u0026quot; + i);\rreturn i;\r}, executor).thenAcceptAsync(res -\u0026gt; {\rSystem.out.println(\u0026quot;任务2启动了...\u0026quot; + res);\r}, executor);\r/**\r*3)、thenApplyAsync:能接受上一步结果，有返回值\r*/\rCompletableFuture\u0026lt;String\u0026gt; future = CompletableFuture.supplyAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;当前线程:\u0026quot; + Thread.currentThread().getId());\rint i = 10 / 4;\rSystem.out.println(\u0026quot;运行结果:\u0026quot; + i);\rreturn i;\r}, executor).thenApplyAsync(res -\u0026gt; {\rSystem.out.println(\u0026quot;任务2启动了...\u0026quot; + res);\rreturn \u0026quot;Hello\u0026quot; + res;\r}, executor);\rSystem.out.println(\u0026quot;main....end....\u0026quot; + future.get());\r}\r 5.两任务组合-都要完成 public \u0026lt;U,V\u0026gt; CompletableFuture\u0026lt;V\u0026gt; thenCombine(CompletionStage\u0026lt;? extends U\u0026gt; other,BiFunction\u0026lt;? super T,? super U,? extends V\u0026gt; fn);\rpublic \u0026lt;U,V\u0026gt; CompletableFuture\u0026lt;V\u0026gt; thenCombineAsync(CompletionStage\u0026lt;? extends U\u0026gt; other , BiFunction\u0026lt;? super T,? super U,? extends V\u0026gt; fn);\rpublic \u0026lt;U,V\u0026gt; CompletableFuture\u0026lt;V\u0026gt; thenCombineAsync(Completionstage\u0026lt;? extends U\u0026gt; other, BiFunction\u0026lt;? super T,? super U,? extends V\u0026gt; fn,Executor executor);\rpublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;Void\u0026gt; thenAcceptBoth(Completionstage\u0026lt;? extends U\u0026gt; other,BiConsumer\u0026lt;? super T, ? super U\u0026gt; action);\rpublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;Void\u0026gt; thenacceptBothasync(CompletionStage\u0026lt;? extends U\u0026gt; other,BiConsumer\u0026lt;? super T, ? super U\u0026gt; action); public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;Void\u0026gt; thenAcceptBothAsync(CompletionStage\u0026lt;? extends U\u0026gt; other,BiConsumer\u0026lt;? super T,? super U\u0026gt; action, Executor executor);\rpublic CompletableFuture\u0026lt;Void\u0026gt; runAfterBoth(CompletionStage\u0026lt;?\u0026gt; other ,Runnable action);\rpublic CompletableFuture\u0026lt;Void\u0026gt; runAfterBothAsync(CompletionStage\u0026lt;?\u0026gt; other,Runnable action);\rpublic CompletableFuture\u0026lt;Void\u0026gt; runAfterBothAsync (Completionstage\u0026lt;?\u0026gt; other,Runnable action,Executor executor);\r 说明：\n两个任务必须都完成，触发该任务。\n thenCombine:组合两个future,获取两个future的返回结果，并返回当前任务的返回值。 thenAcceptBoth:组合两个future,获取两个future任务的返回结果，然后处理任务，没有返回值。 runAfterBoth:组合两个future,不需要获取future的结果，只需两个future处理完任务后，处理该任务。  CompletableFuture\u0026lt;Object\u0026gt; future01 = CompletableFuture.supplyAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;任务1线程: \u0026quot; + Thread.currentThread().getId());\rint i = 10 / 4;\rSystem.out.println(\u0026quot;任务1结束:”);\rreturn i;\r}, executor);\rCompletableFuture\u0026lt;Object\u0026gt; future02 = CompletableFuture.supplyAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;任务2线程:\u0026quot; + Thread.currentThread().getId());\rSystem.out.println(\u0026quot;任务2结束:\u0026quot;);\rreturn \u0026quot;Hello\u0026quot;;\r}, executor);\r/*//在1，2任务执行完后执行3，不能获取之前任务的结果\rfuture01.runAfterBothAsync(future02,()-\u0026gt;{\rSystem.out.println(\u0026quot;任务3开始...\u0026quot;);\r}, executor);*/\r/*//在1，2任务执行完后执行3，可以获取上一次执行的结果\rfuture01.thenAcceptBothAsync(future02,(f1,f2)-\u0026gt;{\rSystem.out.println(\u0026quot;任务3开始...之前的结果: \u0026quot;+f1+\u0026quot;--》 \u0026quot;+f2);\r},executor);*/\r//在1，2任务执行完后执行3，获取上一次处理的结果，并返回当前结果\rCompletableFuture\u0026lt;String\u0026gt; future = future01.thenCombineAsync(future02, (f1, f2) -\u0026gt; {\rreturnf1 + \u0026quot;:\u0026quot; + f2 + \u0026quot;-\u0026gt;Haha\u0026quot;;\r}, executor);\rSystem.out.println(\u0026quot;main... .end....\u0026quot; + future.get());\r 6.两任务组合-一个完成 public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; applyToEither(CompletionStage\u0026lt;? extends T\u0026gt; other, Function\u0026lt;? super T, U\u0026gt; fn);\rpublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; applyToEitherAsync(CompletionStage\u0026lt;? extends T\u0026gt; other, Function\u0026lt;? super T, U\u0026gt; fn);\rpublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; applyToEitherAsync(Complet ionstage\u0026lt;? extends T\u0026gt; other, Function\u0026lt;? super T, U\u0026gt; fn,Executor executor);\rpublic CompletableFuture\u0026lt;Void\u0026gt; acceptEither(CompletionStage\u0026lt;? extends T\u0026gt; other, Consumer\u0026lt;? super T\u0026gt; action);\rpublic CompletableFuture\u0026lt;Void\u0026gt; acceptEitherAsync(CompletionStage\u0026lt;? extends T\u0026gt; other, Consumer\u0026lt;? super T\u0026gt; action) ;\rpublic CompletableFuture\u0026lt;Void\u0026gt; acceptEitherAsync(CompletionStage\u0026lt;? extends T\u0026gt; other, Consumer\u0026lt;? super T\u0026gt; action,Executor executor);\rpublic CompletableFuture\u0026lt;Void\u0026gt; runAfterEither(CompletionStage\u0026lt;?\u0026gt; other ,Runnable action);\rpublic CompletableFuture\u0026lt;Void\u0026gt; runAfterEitherAsync (CompletionStage\u0026lt;?\u0026gt; other ,Runnable action);\rpublic CompletableFuture\u0026lt;Void\u0026gt; runAfterEitherAsync (CompletionStage\u0026lt;?\u0026gt; other ,Runnable action,Executor executor);\r 说明：\n当两个任务中，任意一个future任务完成的时候，执行任务。\n applyToEither : 两个任务有一个执行完成，获取它的返回值，处理任务并有新的返回值。 acceptEither : 两个任务有一个执行完成，获取它的返回值，处理任务，没有新的返回值。 runAfterEither : 两个任务有个执行完成，不需要获取future的结果，处理任务，也没有返回值。  //runAfterEitherAsync ，不获取上一次执行的结果，也没有返回值\rfuture01.runAfterEitherAsync(future02,()-\u0026gt;{\rSystem.out.println(\u0026quot;任务3开始...之前的结果: \u0026quot;);\r},executor);\r//acceptEitherAsync可获取上一次执行的结果，没有返回值\rfuture01.acceptEitherAsync(future02, (res)-\u0026gt;{\rSystem.out.println(\u0026quot;任务3开始...之前的结果: \u0026quot; + res);\r},executor);\r//获取上一次执行的结果，并且有返回值\rCompletableFuture\u0026lt;String\u0026gt; future = future01.applyToEitherAsync(future02, (res)-\u0026gt;{\rSystem.out.println(\u0026quot;任务3开始...之前的结果: \u0026quot; + res);\rreturn res.toString()+\u0026quot;- \u0026gt;哈哈\u0026quot;;\r} ,executor);\rSystem.out.println(\u0026quot;main... .end....\u0026quot;+future.get()) ;\r 7.等待多任务完成 要等待所有异步任务完成，获取前面线程所执行的结果可以使用CompletableFuture.allOf(task1,task2,....)方法\n此方法可以将各个future实例添加到allOf方法中，然后通过future的get()方法获取future的状态。如果allOf里面的所有线程尚未执行完毕，主线程会阻塞，直到allOf里面的所有线程都执行，线程才会被唤醒。\nCompletableFuture.allOf(future01,future02).get()\n","id":8,"section":"posts","summary":"前言：在一些业务复杂的场景中，往往会涉及多个业务之间的相互调用，通过线程池性能稳定，也可以获取执行结果，并捕获异常。但是，在业务复杂情况下，","tags":null,"title":"CompletableFuture-异步编排","uri":"https://bluestaree.github.io/2020/07/completablefuture-%E5%BC%82%E6%AD%A5%E7%BC%96%E6%8E%92/","year":"2020"},{"content":"  转载 · 原文链接：https://www.jianshu.com/p/6db623355e11\n 一、概述 SpringCache本身是一个缓存体系的抽象实现，并没有具体的缓存能力，要使用SpringCache还需要配合具体的缓存实现来完成。\n虽然如此，但是SpringCache是所有Spring支持的缓存结构的基础，而且所有的缓存的使用最后都要归结于SpringCache，那么一来，要想使用SpringCache，还是要仔细研究一下的。\n二、缓存注解 SpringCache缓存功能的实现是依靠下面的这几个注解完成的。\n @EnableCaching：开启缓存功能 @Cacheable：定义缓存，用于触发缓存 @CachePut：定义更新缓存，触发缓存更新 @CacheEvict：定义清除缓存，触发缓存清除 @Caching：组合定义多种缓存功能 @CacheConfig：定义公共设置，位于class之上  2.1 @EnableCaching 该注解主要用于开启基于注解的缓存功能,使用方式为：\n@EnableCaching\r@Configuration\rpublic class CacheConfig {\r@Bean\rpublic CacheManager cacheManager() {\rSimpleCacheManager cacheManager = new SimpleCacheManager();\rcacheManager.setCaches(Arrays.asList(new ConcurrentMapCache(\u0026quot;default\u0026quot;)));\rreturn cacheManager;\r}\r}\r  注意：在SpringBoot中使用SpringCache可以由自动配置功能来完成CacheManager的注册，SpringBoot会自动发现项目中拥有的缓存系统，而注册对应的缓存管理器，当然我们也可以手动指定。\n 使用该注解和如下XML配置具有一样的效果：\n\u0026lt;beans\u0026gt;\r\u0026lt;cache:annotation-driven/\u0026gt;\r\u0026lt;bean id=\u0026quot;cacheManager\u0026quot; class=\u0026quot;org.springframework.cache.support.SimpleCacheManager\u0026gt;\r\u0026lt;property name=\u0026quot;caches\u0026quot;\u0026gt;\r\u0026lt;set\u0026gt;\r\u0026lt;bean class=\u0026quot;org.springframework.cache.concurrent.ConcurrentMapCacheFactoryBean\u0026gt;\r\u0026lt;property name=\u0026quot;name\u0026quot; value=\u0026quot;default\u0026quot;/\u0026gt;\r\u0026lt;/bean\u0026gt;\r\u0026lt;/set\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;/bean\u0026gt;\r\u0026lt;/beans\u0026gt;\r 下面来看看@EnableCaching的源码：\n@Target(ElementType.TYPE)\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\r@Import(CachingConfigurationSelector.class)\rpublic @interface EnableCaching {\r// 用于设置使用哪种代理方式，默认为基于接口的JDK动态代理（false），\r// 设置为true，则使用基于继承的CGLIB动态代理\rboolean proxyTargetClass() default false;\r// 用于设置切面织入方式(设置面向切面编程的实现方式)，\r// 默认为使用动态代理的方式织入，当然也可以设置为ASPECTJ的方式来实现AOP\rAdviceMode mode() default AdviceMode.PROXY;\r// 用于设置在一个切点存在多个通知的时候各个通知的执行顺序，默认为最低优先级，\r// 其中数字却大优先级越低，这里默认为最低优先级，int LOWEST_PRECEDENCE =\r// Integer.MAX_VALUE;，却是整数的最大值\rint order() default Ordered.LOWEST_PRECEDENCE;\r}\rpublic enum AdviceMode {\rPROXY,\rASPECTJ\r}\rpublic interface Ordered {\rint HIGHEST_PRECEDENCE = Integer.MIN_VALUE;\rint LOWEST_PRECEDENCE = Integer.MAX_VALUE;\rint getOrder();\r}\r 由上面的源码可以看出，缓存功能是依靠AOP来实现的。\n2.2 @Cacheable 该注解用于标注于方法之上用于标识该方法的返回结果需要被缓存起来，标注于类之上标识该类中所有方法均需要将结果缓存起来。\n该注解标注的方法每次被调用前都会触发缓存校验，校验指定参数的缓存是否已存在（已发生过相同参数的调用），若存在，直接返回缓存结果，否则执行方法内容，最后将方法执行结果保存到缓存中。\n2.2.1 使用 @Service\r@Log4j2\rpublic class AnimalService {\r@Autowired\rprivate AnimalRepository animalRepository;\r//...\r// @Cacheable(\u0026quot;animalById\u0026quot;)\r@Cacheable(value = \u0026quot;animalById\u0026quot;, key = \u0026quot;#id\u0026quot;)\rpublic ResponseEntity\u0026lt;Animal\u0026gt; getAnimalById(final int id){\rreturn ResponseEntity.ok(animalRepository.selectById(id));\r}\r//...\r}\r 上面的实例中两个@Cacheable配置效果其实是一样的，其中value指定的缓存的名称，它和另一个方法cacheName效果一样，一般来说这个缓存名称必须要有，因为这个是区别于其他方法的缓存的唯一方法。\n这里我们介绍一下缓存的简单结构，在缓存中，每个这样的缓存名称的名下都会存在着多个缓存条目，这些缓存条目对应在使用不同的参数调用当前方法时生成的缓存，所有一个缓存名称并不是一个缓存，而是一系列缓存。\n另一个key用于指定当前方法的缓存保存时的键的组合方式，默认的情况下使用所有的参数组合而成，这样可以有效区分不同参数的缓存。当然我们也可以手动指定，指定的方法是使用SPEL表达式。\n这里我么来简单看看其源码，了解下其他几个方法的作用：\n@Target({ElementType.METHOD, ElementType.TYPE})\r@Retention(RetentionPolicy.RUNTIME)\r@Inherited\r@Documented\rpublic @interface Cacheable {\r// 用于指定缓存名称，与cacheNames()方法效果一致\r@AliasFor(\u0026quot;cacheNames\u0026quot;)\rString[] value() default {};\r// 用于指定缓存名称，与value()方法效果一致\r@AliasFor(\u0026quot;value\u0026quot;)\rString[] cacheNames() default {};\r// 用于使用SPEL手动指定缓存键的组合方式，默认情况使用所有的参数来组合成键，除非自定义了keyGenerator。\r// 使用SPEL表达式可以根据上下文环境来获取到指定的数据：\r// #root.method：用于获取当前方法的Method实例\r// #root.target：用于获取当前方法的target实例\r// #root.caches：用于获取当前方法关联的缓存\r// #root.methodName：用于获取当前方法的名称\r// #root.targetClass：用于获取目标类类型\r// #root.args[1]：获取当前方法的第二个参数，等同于：#p1和#a1和#argumentName\rString key() default \u0026quot;\u0026quot;;\r// 自定义键生成器，定义了该方法之后，上面的key方法自动失效，这个键生成器是：\r// org.springframework.cache.interceptor.KeyGenerator，这是一个函数式接口，\r// 只有一个generate方法，我们可以通过自定义的逻辑来实现自定义的key生成策略。\rString keyGenerator() default \u0026quot;\u0026quot;;\r// 用于设置自定义的cacheManager(缓存管理器),可以自动生成一个cacheResolver\r// （缓存解析器），这一下面的cacheResolver()方法设置互斥\rString cacheManager() default \u0026quot;\u0026quot;;\r// 用于设置一个自定义的缓存解析器\rString cacheResolver() default \u0026quot;\u0026quot;;\r// 用于设置执行缓存的条件，如果条件不满足，方法返回的结果就不会被缓存，默认无条件全部缓存。\r// 同样使用SPEL来定义条件，可以使用的获取方式同key方法。\rString condition() default \u0026quot;\u0026quot;;\r// 这个用于禁止缓存功能，如果设置的条件满足，就不执行缓存结果，与上面的condition不同之处在于，\r// 该方法执行在当前方法调用结束，结果出来之后，因此，它除了可以使用上面condition所能使用的SPEL\r// 表达式之外，还可以使用#result来获取方法的执行结果，亦即可以根据结果的不同来决定是否缓存。\rString unless() default \u0026quot;\u0026quot;;\r// 设置是否对多个针对同一key执行缓存加载的操作的线程进行同步，默认不同步。这个功能需要明确确定所\r// 使用的缓存工具支持该功能，否则不要滥用。\rboolean sync() default false;\r}\r 如何自定义一个KeyGenerator呢？\npublic class AnimalKeyGenerator implements KeyGenerator {\r@Override\rpublic Object generate(Object target, Method method, Object... params) {\rStringBuilder sb = new StringBuilder(\u0026quot;animal-\u0026quot;);\rsb.append(target.getClass().getSimpleName()).append(\u0026quot;-\u0026quot;).append(method.getName()).append(\u0026quot;-\u0026quot;);\rfor (Object o : params) {\rString s = o.toString();\rsb.append(s).append(\u0026quot;-\u0026quot;);\r}\rreturn sb.deleteCharAt(sb.lastIndexOf(\u0026quot;-\u0026quot;)).toString();\r}\r}\r 2.3 @CachePut 该注解用于更新缓存，无论结果是否已经缓存，都会在方法执行结束插入缓存，相当于更新缓存。一般用于更新方法之上。\n@Service\r@Log4j2\rpublic class AnimalService {\r@Autowired\rprivate AnimalRepository animalRepository;\r//...\r@CachePut(value = \u0026quot;animalById\u0026quot;, key = \u0026quot;#animal.id\u0026quot;)\rpublic ResponseEntity\u0026lt;Animal\u0026gt; updateAnimal(final Animal animal){\rWrapper\u0026lt;Animal\u0026gt; animalWrapper = new UpdateWrapper\u0026lt;\u0026gt;();\r((UpdateWrapper\u0026lt;Animal\u0026gt;) animalWrapper).eq(\u0026quot;id\u0026quot;,animal.getId());\ranimalRepository.update(animal, animalWrapper);\rreturn ResponseEntity.ok(this.getAnimalById(animal.getId()));\r}\r//...\r}\r 这里指定更新缓存，value同样还是缓存名称，这里更新的是上面查询操作的同一缓存，而且key设置为id也与上面的key设置对应。\n如此设置之后，每次执行update方法时都会直接执行方法内容，然后将返回的结果保存到缓存中，如果存在相同的key,直接替换缓存内容执行缓存更新。\n下面来看看源码：\n@Target({ElementType.METHOD, ElementType.TYPE})\r@Retention(RetentionPolicy.RUNTIME)\r@Inherited\r@Documented\rpublic @interface CachePut {\r// 同上\r@AliasFor(\u0026quot;cacheNames\u0026quot;)\rString[] value() default {};\r// 同上\r@AliasFor(\u0026quot;value\u0026quot;)\rString[] cacheNames() default {};\r// 同上\rString key() default \u0026quot;\u0026quot;;\r// 同上\rString keyGenerator() default \u0026quot;\u0026quot;;\r// 同上\rString cacheManager() default \u0026quot;\u0026quot;;\r// 同上\rString cacheResolver() default \u0026quot;\u0026quot;;\r// 同上\rString condition() default \u0026quot;\u0026quot;;\r// 同上\rString unless() default \u0026quot;\u0026quot;;\r}\r 只有一点要注意：这里的设置一定要和执行缓存保存的方法的@Cacheable的设置一致，否则无法准确更新。\n2.4 @CacheEvict 该注解主要用于删除缓存操作。\n@Service\r@Log4j2\rpublic class AnimalService {\r@Autowired\rprivate AnimalRepository animalRepository;\r//...\r@CacheEvict(value = \u0026quot;animalById\u0026quot;, key = \u0026quot;#id\u0026quot;)\rpublic ResponseEntity\u0026lt;Integer\u0026gt; deleteAnimalById(final int id){\rreturn ResponseEntity.ok(animalRepository.deleteById(id));\r}\r//...\r}\r 简单明了，看看源码：\n@Target({ElementType.METHOD, ElementType.TYPE})\r@Retention(RetentionPolicy.RUNTIME)\r@Inherited\r@Documented\rpublic @interface CacheEvict {\r// 同上\r@AliasFor(\u0026quot;cacheNames\u0026quot;)\rString[] value() default {};\r// 同上\r@AliasFor(\u0026quot;value\u0026quot;)\rString[] cacheNames() default {};\r// 同上\rString key() default \u0026quot;\u0026quot;;\r// 同上\rString keyGenerator() default \u0026quot;\u0026quot;;\r// 同上\rString cacheManager() default \u0026quot;\u0026quot;;\r// 同上\rString cacheResolver() default \u0026quot;\u0026quot;;\r// 同上\rString condition() default \u0026quot;\u0026quot;;\r// 这个设置用于指定当前缓存名称名下的所有缓存是否全部删除，默认false。\rboolean allEntries() default false;\r// 这个用于指定删除缓存的操作是否在方法调用之前完成，默认为false，表示先调用方法，在执行缓存删除。\rboolean beforeInvocation() default false;\r}\r 2.5 @Caching 这个注解用于组个多个缓存操作，包括针对不用缓存名称的相同操作等，源码：\n@Target({ElementType.METHOD, ElementType.TYPE})\r@Retention(RetentionPolicy.RUNTIME)\r@Inherited\r@Documented\rpublic @interface Caching {\r// 用于指定多个缓存设置操作\rCacheable[] cacheable() default {};\r// 用于指定多个缓存更新操作\rCachePut[] put() default {};\r// 用于指定多个缓存失效操作\rCacheEvict[] evict() default {};\r}\r 简单用法：\n@Service\r@Log4j2\rpublic class AnimalService {\r@Autowired\rprivate AnimalRepository animalRepository;\r//...\r@Caching(\revict = {\r@CacheEvict(value = \u0026quot;animalById\u0026quot;, key = \u0026quot;#id\u0026quot;),\r@CacheEvict(value = \u0026quot;animals\u0026quot;, allEntries = true, beforeInvocation = true)\r}\r)\rpublic ResponseEntity\u0026lt;Integer\u0026gt; deleteAnimalById(final int id){\rreturn ResponseEntity.ok(animalRepository.deleteById(id));\r}\r@Cacheable(\u0026quot;animals\u0026quot;)\rpublic ResponseEntity\u0026lt;Page\u0026lt;Animal\u0026gt;\u0026gt; getAnimalPage(final Animal animal, final int pageId, final int pageSize){\rPage\u0026lt;Animal\u0026gt; page = new Page\u0026lt;\u0026gt;();\rpage.setCurrent(pageId);\rpage.setSize(pageSize);\rreturn ResponseEntity.ok((Page\u0026lt;Animal\u0026gt;) animalRepository.selectPage(page,packWrapper(animal, WrapperType.QUERY)));\r}\r//...\r}\r 2.6 @CacheConfig 该注解标注于类之上，用于进行一些公共的缓存相关配置。源码为：\n@Target(ElementType.TYPE)\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\rpublic @interface CacheConfig {\r// 设置统一的缓存名，适用于整个类中的方法全部是针对同一缓存名操作的情况\rString[] cacheNames() default {};\r// 设置统一个键生成器，免去了每个缓存设置中单独设置\rString keyGenerator() default \u0026quot;\u0026quot;;\r// 设置统一个自定义缓存管理器\rString cacheManager() default \u0026quot;\u0026quot;;\r// 设置统一个自定义缓存解析器\rString cacheResolver() default \u0026quot;\u0026quot;;\r}\r ","id":9,"section":"posts","summary":"转载 · 原文链接：https://www.jianshu.com/p/6db623355e11 一、概述 SpringCache本身是一个缓存体系","tags":["Spring Cache"],"title":"Spring Cache使用","uri":"https://bluestaree.github.io/2020/07/springcache%E4%BD%BF%E7%94%A8/","year":"2020"},{"content":"  前言：现在互联网高并发的背景下，为了有效的提高服务应用的响应速度，相信大家都会想到采用缓存技术。然而如果你的应用引入了缓存机制，那么有一个问题是必须要考虑的：如何在数据库更新数据时，保证缓存是最新的数据？这也是缓存在写模式下所存在的问题\n 缓存机制介绍  参考文章：https://www.jianshu.com/p/dc1e5091a0d8\n 如今利用缓存机制来提高查询效率已被广泛用在各大生产环境，查询数据的一般流程如下所示\n在没有更新数据的情况下，数据库和缓存的数据是保持一致的，当时当要执行数据库的更新操作时，数据库和缓存就会出现不一致的情况。\n首先需要明确的是，既然系统引入缓存机制，就必须接受系统会出现数据不一致的情况发生，我们不可能完全避免，只能尽量减少不一致的时间，达到最终一致性。\n那么如何将缓存中的数据与数据库保持一致呢，比较常见的两个模式是：\n 双写模式 失效模式  缓存数据一致性-双写模式 思路：首先更改数据库，然后再更新缓存\n可能存在的问题，如图所示，假设存在两个请求，且其执行顺序如下：\n 请求A更新数据-1 请求B更新数据-2 请求B更新缓存-2 请求A更新缓存-1  出现了缓存与数据不一致的情况。\n这是暂时性的脏数据问题，因为在数据稳定，缓存过期以后，又能得到最新的正确数据。\n解决： 添加读写锁，如果有线程需要更新数据，其他线程必须等待其执行完成。\n注：如果业务允许暂时性的数据不一致问题，可以忽略此问题，但要注意设置合适的缓存过期时间。保证最终数据的一致性。\n缓存数据一致性-失效模式 思路：首先更改数据库，然后删除缓存，等待下次一主动查询进行更新\n可能存在的问题，如图所示，假设存在三个请求，且其执行顺序如下:\n 请求A更新数据-1 请求A删除缓存 请求B更新数据-2 请求C获取数据，此时缓存已经被删除 请求C读取数据-1 请求B删除缓存 请求C更新缓存  此问题依旧导致的是脏数据问题，主要在于线程之间写和读的问题，也可以通过加锁的方式进行解决，不过会增加系统负重性，降低效率。\n缓存数据一致性-解决方案 无论是双写模式还是失效模式，都会导致缓存的不一致问题。即多个实例同时更新会出事。怎么办?\n 对于一些实时性要求靠的数据，如：用户数据，订单数据等，缓存数据加上过期时间，每隔一段时间触发读的主动更新即可 如果是菜单，商品介绍等基础数据，也可以去使用canal订阅binlog的方式。 缓存数据+过期时间也足够解决大部分业务对于缓存的要求。 通过加锁保证并发读写，写写的时候按顺序排好队。读读无所谓。所以适合使用读写锁。 (业务不关心脏数据，允许临时脏数据可忽略) ;  总结:  放入缓存的数据本就不应该是实时性、一致性要求超高的。所以缓存数据的时候加上过期时间，保证每天拿到当前最新数据即可。 不应该过度设计，增加系统的复杂性 遇到实时性、一致性要求高的数据，就应该查数据库，即使慢点。  解决方案之Canal简单介绍 Canal是阿里巴巴旗下的一款开源项目。其定位是基于数据库增量日志解析，提供增量数据订阅\u0026amp;消费。\n使用Canal更新缓存\nCanal可以模拟为Mysql的一个从服务器，只要Mysql数据发生更改，Canal就能够同步到变化的内容（binlog）。\n利用这个特性，我们就可以编写逻辑一些业务，在数据库更改的同时修改redis缓存信息。这样一来，在编码期\n间，我们只需要关注修改数据库的逻辑即可\n优点：屏蔽了对缓存的操作，简化代码\n缺点：添加新的中间件，需要额外开发自定义功能\n 使用Canal解决数据异构\nCanal也可以在大数据情况下解决数据异构问题，举个栗子：\n一些电商网站都会根据用户浏览喜好，显示相关的推荐商品，引导客户点击购买。Canal就可以高效的完成并计算\n分析出用户可能感兴趣的商品。\nCanal通过订阅用户浏览记录表，商品信息表，购物车表等数据的更新。结合这些数据，Canal可以智能的分析计算出用户的喜好商品，并生成一张新的表： 用户推荐表，这样我们就无需自己进行大量计算。\n","id":10,"section":"posts","summary":"前言：现在互联网高并发的背景下，为了有效的提高服务应用的响应速度，相信大家都会想到采用缓存技术。然而如果你的应用引入了缓存机制，那么有一个问","tags":["缓存"],"title":"缓存与数据库一致性问题及最佳解决方案","uri":"https://bluestaree.github.io/2020/07/%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E5%8F%8A%E6%9C%80%E4%BD%B3%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","year":"2020"},{"content":"  概述：Redisson是架设在Redis基础上的一个Java驻内存数据网格。简单来说就是Redis分布式锁对于Java语言的实现，其提供的许多分布式服务，本文介绍了如何使用Redisson来实现分布式锁，以及其他几种常用的分布式锁\n 简单实现 1.引入依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;3.12.0\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 2.配置Redisson客户端\n@Configuration\rpublic class MyRedissonConfig {\r@Bean(destroyMethod = \u0026quot;shutdown\u0026quot;)\rpublic RedissonClient redisson() throws IOException {\rConfig config = new Config();\r//config.useClusterServers( )\t//集群配置\r//.addNodeAddress(\u0026quot;127.0.8.1:7004\u0026quot;，\u0026quot;127.0.0.1:6379\u0026quot;);\r//单节点配置 可以用\u0026quot;rediss://\u0026quot;来启用SSL连接\rconfig.useSingleServer().setAddress(\u0026quot;redis://127.0.0.1:6379\u0026quot;);\rreturn Redisson.create(config);\r}\r}\r 3.测试Controller\n@GetMapping(\u0026quot;/hello\u0026quot;)\rpublic String hello(){\r//1、获取一把锁，只要锁的名字一样，就是同一把锁\rRLock lock = redisson.getLock(\u0026quot;my-lock\u0026quot;);\r//2.加锁\rlock.lock(); //阻塞式等待。默认加的锁存活时间为30s。\r//看门狗机制：\r//1)、锁的自动续期，如果业务超长，运行期间会自动给锁续上新的30s。不用担心业务时间长，锁自动过期被删掉\r//2)、加锁的业务只要运行完成，就不会给当前锁续期，即使不手动解锁，锁默认在30s以后自动删除。\rtry {\rSystem.out.println(\u0026quot;加锁成功... \u0026quot; + Thread.currentThread().getId());\rThread.sleep(30000); //模拟执行耗时业务\rreturn \u0026quot;hello\u0026quot;;\r} catch (Exception e) {\r} finally {\r//3、解锁\rSystem.out.println(\u0026quot;释放锁...\u0026quot; + Thread.currentThread().getId());\rlock.unlock();\r}\rreturn \u0026quot;Throw Exception！\u0026quot;;\r}\r 可通过设置虚拟机参数启动多个服务，模拟集群环境下进行测试\n初次访问时，加锁成功，控制台输出内容：\n加锁成功... 60\n等待30s后业务逻辑执行完成，释放锁，控制台输出内容：\n释放锁...60\nRedis中存储的分布式锁信息如下图：\n在浏览器中同时访问多个服务，\n此时控制台输出内容\n加锁成功... 60\n释放锁...60\n加锁成功... 67\n释放锁...67\n这样一个简单的分布式锁就添加成功了，现在每一个进程都需要获取在获取锁后才能进行进一步的业务处理。我们\n就可以根据这一点=有效的预防缓存击穿、接口幂等性等问题。\nRedisson 看门狗机制 在我们进行测试的时候有一个问题，可以明显的发现，在Redis上存储的分布式锁的有效时间为30s，而且当这个\n值减少到19s时，存活时间又重新刷新为30s。\n这就redisson的看门狗机制。\n让我们先来看看redisson里的 Lock 方法源码\npublic void lock() {\rtry {\rthis.lock(-1L, (TimeUnit)null, false);\r} catch (InterruptedException var2) {\rthrow new IllegalStateException();\r}\r}\r 接下来会调用另一个带参数的重载方法，我们可以进去直接看其中尝试获取锁的那段源码\nprivate \u0026lt;T\u0026gt; RFuture\u0026lt;Long\u0026gt; tryAcquireAsync(long leaseTime, TimeUnit unit, long threadId) {\rif (leaseTime != -1L) {\rreturn this.tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG);\r} else {\rRFuture\u0026lt;Long\u0026gt; ttlRemainingFuture = this.tryLockInnerAsync(this.commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);\rttlRemainingFuture.onComplete((ttlRemaining, e) -\u0026gt; {\rif (e == null) {\rif (ttlRemaining == null) {\rthis.scheduleExpirationRenewal(threadId);\r}\r}\r});\rreturn ttlRemainingFuture;\r}\r}\r 可以看到，如果我们没有传入指定锁的存活时间，也就是上面的 leaseTim 变量的值，默认是-1,\n此时走else路线，其中redisson默认将锁的存活时间设置为30s\nthis.lockWatchdogTimeout = 30000L;\r 接下来 ，可以看到一个重要的方法 scheduleExpirationRenewal() ,根据名称有一个大概的理解，就是一个到期续\n订的定时任务。\n继续跟踪源码，可以看到最主要的方法 renewExpiration()，在这里面就创建了一个定时任务task，\n并且延迟10s执行一次，其中又进行递归调用，相当于每隔10s执行一次，直到我们的业务逻辑执行完毕\nprivate void renewExpiration() {\rRedissonLock.ExpirationEntry ee = (RedissonLock.ExpirationEntry)EXPIRATION_RENEWAL_MAP.get(this.getEntryName());\rif (ee != null) {\rTimeout task = this.commandExecutor.getConnectionManager().newTimeout(new TimerTask() {\rpublic void run(Timeout timeout) throws Exception {\rRedissonLock.ExpirationEntry ent = (RedissonLock.ExpirationEntry)RedissonLock.EXPIRATION_RENEWAL_MAP.get(RedissonLock.this.getEntryName());\rif (ent != null) {\rLong threadId = ent.getFirstThreadId();\rif (threadId != null) {\rRFuture\u0026lt;Boolean\u0026gt; future = RedissonLock.this.renewExpirationAsync(threadId);\rfuture.onComplete((res, e) -\u0026gt; {\rif (e != null) {\rRedissonLock.log.error(\u0026quot;Can't update lock \u0026quot; + RedissonLock.this.getName() + \u0026quot; expiration\u0026quot;, e);\r} else {\rif (res) {\rRedissonLock.this.renewExpiration();\r}\r}\r});\r}\r}\r}\r}, this.internalLockLeaseTime / 3L, TimeUnit.MILLISECONDS);\ree.setTimeout(task);\r}\r}\r 当然我们也可以进入renewExpirationAsync()方法中查看刷新锁存活时间所执行的Lua脚本\nif (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then redis.call('pexpire', KEYS[1], ARGV[1]); return 1; end; return 0;\r 最佳实践，使用时，手动指定过期时间，可以省去整个续期操作\n常见的分布式锁 可重入锁 先看看已下伪代码\na() {\rb();\r}\r 在A方法中调用了B方法，此时A方法需要获取C锁，往下执行，B方法也需要获取C锁，如果C锁为不可重入锁，那\n就需要首先等待A方法释放C锁，而A方法又需要等待B方法执行完成才能释放C锁，这就产生了死锁的问题。如果C\n锁为可重入锁，那么A方法与B方法都同时持有C锁，\n常用的方法\nRlock lock = redisson.getLock(\u0026quot;lock\u0026quot;)\r//加锁\rlock.lock();\r//尝试加锁\rlock.tryLock();\r//释放锁\rlock.unlock();\r 公平锁 顾名思义，所有线程在获取锁时需要顺序的获取，就像日常排队一样。Redisisson默认为非公平锁\n常用的方法\nRlock fireLock = redisson.getFairLock(\u0026quot;fireLock\u0026quot;)\rfireLock.lock();\rfireLock.unlock();\r 读写锁 保证一定能读到最新状态，读锁可以在没有写锁的时候被多个线程同时持有（共享锁），写锁是独占的(排他锁/独\n享锁)。 每次只能有一个写线程，但是可以有多个线程并发地读数据。\n分布式可重入读写锁允许同时有多个读锁和一个写锁处于加锁状态。\n常用的方法\nRReadWriteLock rwlock = redisson.getReadWriteLock(\u0026quot;anyRWLock\u0026quot;);\r//加读锁\rrwlock.readLock().lock();\r//加写锁\rrwlock.writeLock().lock();\r 常见情况分析\n 读+读 ：相当于无锁，并发读，只会在redis中记录好，所有当前的读锁。会同时加锁成功 写+读 ：等待写锁释放 写+写 ：阻塞方式，需等待上一个写锁释放 读+写 ：有读锁，写也需要等待。  总结：只要有写的存在，都必须等待\n信号量 可以限制同时访问共享区域的线程数量，即限流。\n信号量总数存储于Redis的一个key(可自定义)中，每次申请都会将该key对应的value值减去1，直到数量为0，不能\n再次申请。反之，当释放许可时，每次操作都会将其值加上1。\n比喻：相当于一个停车场，来一辆车，可用的车库数就减少一，走一辆，可用的车库数就增加一。\n常用的方法\nRSemaphore semaphore = redisson.getSemaphore(\u0026quot;semaphore\u0026quot;);\r//获取23个信号量，如果无法获取，会一直等待，阻塞方法\rsemaphore.acquire(23);\r//尝试获取1个信号量，无法获取时，返回false\rsemaphore.tryAcquire(); //释放信号量\rsemaphore.release();  闭锁 需要等待其他线程闭锁都执行完成后，才可以开始执行闭锁中的逻辑\n常用的方法\nRCountDownLatch latch = redisson.getCountDownLatch(\u0026quot;anyCountDownLatch\u0026quot;);\r//设置闭锁数量\rlatch.trySetCount(1);\r//等待其他闭锁都执行完成\rlatch.await();\r//在其他线程或其他JVM里\rRCountDownLatch latch = redisson.getCountDownLatch(\u0026quot;anyCountDownLatch\u0026quot;);\r//完成，闭锁数减一\rlatch.countDown();\r ","id":11,"section":"posts","summary":"概述：Redisson是架设在Redis基础上的一个Java驻内存数据网格。简单来说就是Redis分布式锁对于Java语言的实现，其提供的许","tags":["缓存","redisson"],"title":"分布式锁实现-Redisson","uri":"https://bluestaree.github.io/2020/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0-redisson/","year":"2020"},{"content":"  概览：在高并发场景下，缓存在读模式下所存在的问题\n 缓存穿透 缓存雪崩 缓存击穿   缓存穿透 指查询一个一定不存在的数据，由于缓存是不命中，将去查询数据库，但是数据库也无此记录，我们没有将这次查\n询的nulI写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义\n风险:\n他人恶意利用不存在的数据进行攻击，数据库瞬时压力增大，最终导致崩溃\n解决:\n 对于查询不到的结果，可以存为null，并加入短暂过期时间 (可能会导致大量无效key) 使用布隆过滤器，过滤无效请求，拒绝访问（存在误判情况）   缓存雪崩 缓存雪崩是指在我们设置缓存时key采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，\n导致DB瞬时压力过重而崩溃。\n解决:\n原有的失效时间基础上增加一个随机值，不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀，这样\n每一个缓存的过期时间的重复率就会降低，很难引发集体失效的事件。\n 缓存击穿 对于一些设置了过期时间的 key，如果这些 key 可能会在某些时间点被超高并发地访问，是一种非常“热点”的数\n据。如果这个 key 在大量请求同时进来前正好失效，那么所有对这个 key 的数据查询就会直接落到 DB\n解决:\n  加锁。大量并发只让一个去查， 其他人等待，查到以后释放锁，其他人获取到锁，先查缓存，就会有数据，不用去db\n 本地锁 :Synchronized,Lock等  问题：因为Spring容器单例的特点，所以能锁住当前进程资源，即使有百万并发，也只有1个线程访问DB。但在分布式下，必须使用分布式锁，因为不同服务器进程不同，锁对象也就不同，会存在多余线程请求DB的情况\n 分布式锁  使用Redis进行分布式锁的创建(SETNX) 原子加锁\n语法： Set [key] [value] [EX设置过期时间，秒)] [NX] (不存在才设置)\n 举个栗子：Set lock uuid EX 300 NX\n spring data-redis : API\nredisTemplate.opsForValue().setIfAbsent(key,value )\r 每个线程采取自旋的形式周期性尝试获取锁\n注意：在执行业务逻辑后，需要使用Lua脚本进行原子解锁\n\u0026quot;if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\u0026quot;;\r 问题： 需要经过中间件，效率比本地锁要低\nRedis分布式锁的实现方案：Redisson\n  设置热点数据永不过期\n  在 redis、db 中间做一个二级缓存\n  ","id":12,"section":"posts","summary":"概览：在高并发场景下，缓存在读模式下所存在的问题 缓存穿透 缓存雪崩 缓存击穿 缓存穿透 指查询一个一定不存在的数据，由于缓存是不命中，将去查询数据库","tags":["缓存"],"title":"高并发下的缓存失效问题及解决方案","uri":"https://bluestaree.github.io/2020/07/%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8B%E7%9A%84%E7%BC%93%E5%AD%98%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98/","year":"2020"},{"content":"  由于Spring Cloud Eureka已经宣布停止开源计划，不再继续维护，这怎么行，还能愉快的使用吗。 今天在空闲之余了解了下另外一个功能更加强大的注册中心，那就是SpringCloud Alibaba的Nacos\n SpringCloud Alibaba Spring Cloud Alibaba致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的必需组件,方\n便开发者通过 Spring Cloud编程模型轻松使用这些组件来开发分布式应用服务。\n依托 Spring Cloud Alibaba,您只需要添加一些注解和少量配置,就可以将 Spring Cloud应用接入阿里微服务解决方\n案,通过阿里中间件来迅速搭建分布式应用系统。GitHub地址\n本文主要介绍Spring Cloud Alibaba项目下的Nacos组件基本使用。\nNacos初体验 使用Nacos作为注册中心 1.首先引入SpringCloud Alibaba依赖\n 注意：选择合适的版本\n 1.5.x 版本适用于 Spring Boot 1.5.x 2.0.x 版本适用于 Spring Boot 2.0.x 2.1.x 版本适用于 Spring Boot 2.1.x 2.2.x 版本适用于 Spring Boot 2.2.x   pom文件配置：\n\u0026lt;dependencyManagement\u0026gt;\r\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-cloud-alibaba-dependencies\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.2.0.RELEASE\u0026lt;/version\u0026gt;\r\u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt;\r\u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r\u0026lt;/dependencyManagement\u0026gt;\r 2.引入Nacos注册中心依赖\npom文件配置：\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 配置文件的配置\nserver:\rport: 8080\rspring:\rapplication:\rname: Hello-Nacos\rcloud:\tnacos:\t//这里配置nacos注册中心的地址\rdiscovery:\rserver-addr: 127.0.0.1:8848\r 启动类\n@EnableDiscoveryClient\r@SpringBootApplication\rpublic class WebApplication {\rpublic static void main(String[] args) {\rSpringApplication.run(WebApplication.class, args);\r}\r}\r 3.获取Nacos的服务端 : https://github.com/alibaba/nacos/releases\n下载后启动服务端，打开浏览器访问http://127.0.0.1:8848/nacos\n 默认账号密码均为 : nacos\n 4.启动服务\n启动测试服务后，查看nacos服务管理中心，可以看到该服务已经成功注册\n之后就可以结合spring cloud open-feign进行远程服务调用啦，这里不再演示\n使用Nacos作为配置中心 1.首先导入nacos配置中心的依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-config\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 2.新增bootstrap.properties配置文件,添加已下配置信息\nspring.application.name=hello-nacos\t#项目名\rspring.cloud.nacos.config.server-addr=127.0.0.1:8848\t#nacos配置中心地址\r 3.在配置中心中新建配置文件,nacos配置中心默认会加载项目名.properties文件\nController相关代码\n@RestController\rpublic class WebController {\r@Value(\u0026quot;${mycustomer.name}\u0026quot;)\rpublic String name;\r@Value(\u0026quot;${mycustomer.age}\u0026quot;)\rpublic int age;\r@GetMapping\rprivate Map test() {\rHashMap hashMap = new HashMap();\rhashMap.put(\u0026quot;name\u0026quot;, name);\rhashMap.put(\u0026quot;age\u0026quot;, age);\rreturn hashMap;\r}\r}\r 测试结果\n成功读取配置中心里配置信息\n这里还可以配合使用 @RefreshScope 注解实现动态配置刷新\n 注意：如果配置中心和当前应用的配置文件中都配置了相同的项，会优先使用配置中心里的配置\n  实现多配置文件加载(如开发，生产，测试等环境\u0026hellip;) nacos配置中心的一些概念\n  命名空间 ,默认：public(保留空间)，默认新增的所有配置都存在public空间,\n要使用特定的命名空间，需要在bootstrap.properties配置文件中指定命名空间ID\nspring.cloud.nacos.config.namespace=23902197-c354-4216-94cf-8e5cb8537e26\r 通过这一点，我们可以为每一个微服务创建一个命名空间，形成基于微服务间的隔离\n  配置集 ：所有配置文件的集合\n  配置集ID ：相当于文件名\n  配置分组 ：默认所有配置集都属于DEFAULT_GROUP，我们可以在创建配置文件时，使用配置分组来区分不同的环境\n在bootstrap.properties配置文件 中指定分组\nspring.cloud.nacos.config.group=dev\t#指定配置分组\r   bootstrap.properties配置文件中指定多配置文件加载\n#多配置文件加载\rspring.cloud.nacos.config.ext-config[0].data-id=datasource.yml\t#配置ID\rspring.cloud.nacos.config.ext-config[0].group=dev\t#配置分组\rspring.cloud.nacos.config.ext-config[0].refresh=true\t#自动刷新\rspring.cloud.nacos.config.ext-config[1].data-id=hello-nacos.properties\rspring.cloud.nacos.config.ext-config[1].group=dev\rspring.cloud.nacos.config.ext-config[1].refresh=true\r ","id":13,"section":"posts","summary":"由于Spring Cloud Eureka已经宣布停止开源计划，不再继续维护，这怎么行，还能愉快的使用吗。 今天在空闲之余了解了下另外一个功能更加强大的注","tags":["Nacos"],"title":"Spring Cloud Alibaba-Nacos 注册与配置中心","uri":"https://bluestaree.github.io/2020/07/springcloud-alibaba-nacos-%E6%B3%A8%E5%86%8C%E4%B8%8E%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/","year":"2020"},{"content":"  前言：TCP是面向连接的，面向流的，提供高可靠性服务。收发两端(客户端和服务器端)都要有一一成对的socket，因此发送端为了将多个发给接收端的包，更有效的发给对方，使用了优化方法(Nagle算法)，将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包。这样做虽然提高了效率，但是接收端就难于分辨出完整的数据包了，因为面向流的通信是无消息保护边界的。\n 由于TCP无消息保护边界,需要在接收端处理消息边界问题，也就是我们所说的粘句、拆包问题，看一张图\n假设客户端分别发送了两个数据包D1和D2给服务端，由于服务端一次读取到字节数是不确定的，故可能存在以下四种情况:\n  服务端分两次读取到了两个独立的数据包，分别是D1和D2，没有粘包和拆包\n  服务端一次接受到了两个数据包，D1和D2粘合在一起，称之为TCP粘包\n  服务端分两次读取到了数据包，第一次读取到了完整的D1包和D2包的部分内容，第二次读取到了D2包的剩余内容，这称之为TCP拆包\n  服务端分两次读取到了数据包，第一次读取到了D1包的部分内容D1_1，第二次读取到了D1包的剩余部分内容D1_ 2和完整的D2包。\n  解决方案\n  使用自定义协议(一个自定义对象)+编解码器来解决\n  关键就是要解决服务器端每次读取数据长度的问题,这个问题解决，就不会出现服务器多读或少读数据的问题，从而避免的TCP粘包、拆包。\n  举个栗子\n自定义传输协议对象\npublic class MessageProtocol {\rprivate int len;\rprivate byte[] content;\r// set,get方法\r//....\r}\r 编码器\npublic class MyMessageEncoder extends MessageToByteEncoder\u0026lt;MessageProtocol\u0026gt; {\r@Override\rprotected void encode( ChannelHandlerContext ctx, MessageProtocol msg,ByteBuf out) throws Exception {\rout.writeInt(msg.getLen());\rout.writeBytes(msg.getContent());\r}\r}\r 解码器\npublic class MyMessageDecoder extends ReplayingDecoder\u0026lt;Void\u0026gt; {\r@Override\rprotected void decode(ChannelHandlerContext ctx, ByteBuf in, List\u0026lt;object\u0026gt; out) throws Exception {\r//将得到的二进制字节码转换为MessageProtocol 自定义协议包(对象)\rint length = in.readInt();\rbyte[] content = new byte[length] ;\rin.readBytes(content);\r//封装成MessageProtocol对象，放入out,传递给下一个handler处理\rMessageProtocol messageProtocol = new MessageProtocol();\rmessageProtocol.setLen(length);\rmessageProtocol.setContent(content);\rout.add(messageProtocol);\r}\r}\r ","id":14,"section":"posts","summary":"前言：TCP是面向连接的，面向流的，提供高可靠性服务。收发两端(客户端和服务器端)都要有一一成对的socket，因此发送端为了将多个发给接收","tags":null,"title":"TCP粘包和拆包问题","uri":"https://bluestaree.github.io/2020/06/tcp%E7%B2%98%E5%8C%85%E5%92%8C%E6%8B%86%E5%8C%85%E9%97%AE%E9%A2%98/","year":"2020"},{"content":"  参考：Quartz文档\n cron表达式基本语法：秒 分 时 日 月 周 年 (共7位，其中第7位 年 在Spring中不支持)\n特殊字符:\n,：枚举;\n (cron=\u0026quot;7,9,23 * * * * ?\u0026quot;)：任意时刻的7,9, 23 秒启动这个任务;  -：范围;\n (cron=\u0026quot;7-20 * * * * ?\u0026quot;)：任意时刻的7-20秒之间，每秒启动一次  *：任意;\n 指定位置的任意时刻都可以  /：步长;\n  (cron=\u0026quot;7/5 * * * * ?\u0026quot;)：第7秒启动，每5秒一次;\n  (cron=\u0026rdquo;*/5 * * * * ?\u0026quot;)：任意秒启动，每5秒一次;\n  ? ：(出现在日和周几的位置)：为了防止日和周冲突，在周和日上如果要写通配符使用?\n (cron=\u0026rdquo;* * * 1 * ?\u0026quot;)：每月的1号，而且必须是周二然后启动这个任务;  L：(出现在日和周的位置)，表示last：最后一个\n (cron=\u0026rdquo;* * * ? * 3L\u0026rdquo;)：每月的最后一个周二  W：表示Work Day：工作日\n  (cron=\u0026rdquo;* * * W * ?\u0026quot;)：每个月的工作日触发\n  (cron=\u0026rdquo;* * * L W * ?\u0026quot;)：每个月的最后一个工作日触发\n  #：第几个\n (cron=\u0026rdquo;* * * ? * 5#2\u0026rdquo;)：每个月的第2个周4  ","id":15,"section":"posts","summary":"参考：Quartz文档 cron表达式基本语法：秒 分 时 日 月 周 年 (共7位，其中第7位 年 在Spring中不支持) 特殊字符: ,：枚举; (cron=\u0026quot;7,9,23 * * * * ?\u0026","tags":null,"title":"定时器-cron表达式","uri":"https://bluestaree.github.io/2020/06/%E5%AE%9A%E6%97%B6%E5%99%A8-cron%E8%A1%A8%E8%BE%BE%E5%BC%8F/","year":"2020"},{"content":" Netty的编解码器 当Netty发送或者接受一个消息的时候，就将会发生一次数据转换。入站消息会被解码：从字节转换为另一种格式(比如java对象)；如果是出站消息，它会被编码成字节。\nNetty提供一系列实用的编解码器，他们都实现了ChannelInboundHadnler或者ChannelOutboundHandler接口。在这些类中，channelRead方法已经被重写了。以入站为例，对于每个从入站Channel读取的消息，这个方法会被调用。随后，它将调用由解码器所提供的decode()方法进行解码，并将已经解码的字节转发给ChannelPipeline中的下一个ChannellnboundHandler.\n举个栗子\n关于一个ByteToMessageDecoder(入站解码器)实例分析\npublic class ToIntegerDecoder extends ByteToMessageDecoder {\r@Override\rprotected void decode(ChannelHandlerContext ctx, ByteBuf in, List\u0026lt;Object\u0026gt; out) throws Exception{\r//按照每4字节，即一个int类型进行解码，将读取的数据放入out数组中\r//并将其传入下一个Handler处理器\r//该方法将根据消息内容大小被调用多次\rif (in.readableBytes()\u0026gt;=4){ //判断缓存区(ByteBuf)的数据是否足够，防止拆包和粘包问题\rout.add(in.readInt());\r}\r}\r}\r 说明\n decode 解码器会根据接收的数据，被调用多次，直到确定没有新的元素被添加到list，或者是ByteBuf 没有更多的可读字节为止 如果list不为空，就会将list的内容传递给下一个Handler处理，该处理器的方法也会被调用多次，比如一个8字节的数据，经过上述解码器解码，会调用两次decode方法， 并执行两次解码器之后的Handler的业务处理方法，(简单来说就是客户端发送一个8字节数据，服务端将会应答2次) 编写encode编码器时，需要注意指定编码数据的类型，在发送数据时，其底层会判断当前发送的数据类型是否与之匹配，如果不符合，会直接将数据写出，不会进行相关编码操作  结论\n  不论解码器handler还是编码器handler即接收的消息类型必须与待处理的消息类型一致，否则handler不会被执行\n  在解码器进行数据解码时，需要判断缓存区(ByteBuf)的数据是否足够，否则接收到的结果会期望结果可能不一致\n  ReplayingDecoder ReplayingDecoder扩展了ByteToMessageDecoder类，使用这个类，我们不必调用readableBytes()方法。参数S指定了用户状态管理的类型，其中Void代表不需要状态管理\npublic class MyByteToLongDecoder extends ReplayingDecoder\u0026lt;Void\u0026gt; {\r@Override\rprotected void decode(ChannelHandlerContext ctx, ByteBuf in, List\u0026lt;object\u0026gt; out) throws Exception {\r//在ReplayingDecoder不需要判断数据是否足够读取，内部会进行处理判断\rout.add(in.readLong());\r}\r ReplayingDecoder使用方便， 但它也有一些局限性:\n1.并不是所有的ByteBuf操作都被支持如果调用了一个不被支持的方法，将会抛出一个UnsupportedOperationException。\n2.ReplayingDecoder在某些情况下可能稍慢于ByteToMessageDecoder，例如网络缓慢并且消息格式复杂时，消\n息会被拆成了多个碎片，速度变慢\n其它解码器\n LineBasedFrameDecoder: 这个类在Netty内部也有使用，它使用行尾控制字符(\\n或者\\r\\n)作为分隔符来解析  数据。\n DelimiterBasedFrameDecoder: 使用自定义的特殊字符作为消息的分隔符进行解码。\n  HttpObjectDecoder: 一个HTTP数据的解码器\n  LengthFieldBasedFrameDecoder: 通过指定长度来标识整包消息，这样就可以自动的处理黏包和半包消息。\n  其他编码器\n  ObjectEncoder : 简单地说就是把对象序列化后，转为ChannelBuffer并返回\n  Base64Encoder : base64编码器\n  StringEncoder : 消息转成String编码器\n  ZlibEncoder ：压缩数据\n  ","id":16,"section":"posts","summary":"Netty的编解码器 当Netty发送或者接受一个消息的时候，就将会发生一次数据转换。入站消息会被解码：从字节转换为另一种格式(比如java对","tags":["Netty"],"title":"Netty编解码器","uri":"https://bluestaree.github.io/2020/06/netty%E7%9A%84%E7%BC%96%E8%A7%A3%E7%A0%81%E5%99%A8/","year":"2020"},{"content":"  前言：Netty中ChannelHandler 的作用就是处理IO事件或拦截IO事件，并将其处理结果转发给下一个Handler，那么Handler链的调用机制又是怎样的呢\n 出站和入站机制 ChannelHandler充当了处理入站和出站数据的应用程序逻辑的容器。例如，实现ChannelInboundHandler接口(或ChannelInboundHandlerAdapter)，你就可以接收入站事件和数据，这些数据会被业务逻辑处理。当要给客户端发送响应时，也可以从ChannelInboundHandler冲刷数据。业务逻辑通常写在一个或者多个ChannelInboundHandler中。ChannelOutboundHandler原理一 样，只不过它是用来处理出站数据的\n ChannelPipeline提供了ChannelHandler链的容器。出站和入站方向是相对的，以客户端应用程序为例。如果事\n件的运动方向是从客户端到服务端的，那么我们称这些事件为出站的，即客户端发送给服务端的数据会通过\npipeline中的一系列ChannelOutboundHandler，并被这些Handler处理，反之则称为入站的\n官方图解\n一般来说\n出站要编码，入站要解码\n出站对应写，入站对应读\n","id":17,"section":"posts","summary":"前言：Netty中ChannelHandler 的作用就是处理IO事件或拦截IO事件，并将其处理结果转发给下一个Handler，那么Handl","tags":["Netty"],"title":"Netty-Handler链的调用机制","uri":"https://bluestaree.github.io/2020/06/handler%E9%93%BE%E7%9A%84%E8%B0%83%E7%94%A8%E6%9C%BA%E5%88%B6/","year":"2020"},{"content":" 总览   Bootstrap or ServerBootstrap EventLoop or EventLoopGroup ChannelInitializer ChannelHandler ChannelPipeline ChannelHandlerContext Future or ChannelFuture   Bootstrap or ServerBootstrap 都是用来启动一个Netty应用的配置类，它主要作用是配置整个Netty程序，串联起各个组件。\nEventLoop or EventLoopGroup   EventLoopGroup 是一组EventLoop的抽象，Netty 为了更好的利用多核CPU资源，一般会有多个EventLoop同时工作，每个EventLoop维护着一个Selector实例。\n  EventLoopGroup 提供next接口，可以从组里面按照一定规则获取其中一个EventLoop来处理任务。在Netty服务器端编程中，我们一般都需要提供两个EventLoopGroup，例如: BossEventLoopGroup 和WorkerEventLoopGroup。\n  客户端连接处理流程如下图\nChannelInitializer channel的初始化容器，我们就是在这里面设置自定义的处理器\n相关API\nbootstrap.group(bossGroup, workerGroup) .handler(new NettyBossHandler()) // 给bossGroup的EventLoop对应的管道设置处理器\r.childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() {\r//给pipeline设置处理器\r@Override\rprotected void initChannel(SocketChannel ch) throws Exception {\r//获取当前通道对应的管道,在末尾添加一个自定义的处理器\rch.pipeline().addLast(new NettyWorkerHandler()); }\r}); // 给workerGroup的EventLoop对应的管道设置处理器\r ChannelHandler ChannelHandler 的作用就是处理IO事件或拦截IO事件，并将其转发给下一个处理程序ChannelHandler。Handler处理事件是分入站和出站的，两个方向的操作都是不同的，因此，Netty 定义了两个子接口继承ChannelHandler\n ChannelInboundHandler 处理入站事件接口   ChannelOutboundHandler 处理出站事件接口  此外，ChannelDuplexHandler 类能够同时处理出站和入站事件\n每个客户端Channel 都独享自己的 Handle\nChannelPipeline 在Netty中每个Channel都有且仅有一个ChannelPipeline与之对应，pipeline和channel是相互包含关系 即双方都可以获取对方的实例。它们的组成关系如下图所示\n一个Channel包含了一个ChannelPipeline，而ChannelPipeline 中又维护了一个由ChannelHandlerContext组成的双向链表，并且每个ChannelHandlerContext中又关联着一个ChannelHandler\n入站事件和出站事件在一个双向链表中，入站事件会从链表head往后传递到最后一个入站的handler,出站事件会从链表tail往前传递到最前一个出站的handler,两种类型的handler互不干扰\nChannelHandlerContext 多个ChannelHandlerContext组成了一个双向链表，Context是对Handler的封装。\n  保存了Channel相关的所有上下文信息，同时关联一个ChannelHandler 对象\n  即ChannelHandlerContext中包含一个具体的事件处理器ChannelHandler,同时也绑定了对应的pipeline和Channel的信息，方便对ChannelHandler进行调用.\n  常用方法\n   ChanelFuture close(), 关闭通道 ChannelOutboundInvoker flush()，刷新 ChannelFuture writeAndFlush(Object msg)， 将数据写到ChannelPipeline中当前ChannelHandler 的下一个ChannelHandler开始处理(出站)  Future or ChannelFuture Netty的异步模型\n基本介绍\n  异步的概念和同步相对。当一个异步过程调用发出后,调用者不能立刻得到结果。实际处理这个调用的组件在完成后,通过状态、通知和回调来通知调用者。\n  Nett中的I/0操作是异步的,包括Bind、 Write、 Connect等操作会简单的返回一个ChannelFuture。\n  调用者并不能立刻获得结果,而是通过 Future-Listener机制,用户可以方便的主动获取或者通过通知机制获得IO操作结果\n  Netty的异步模型是建立在 future和 callback的之上的。 callback就是回调。重点说Future,它的核心思想是:假设一个方法fun,计算过程可能非常耗时,等待fun返回显然不合适。那么可以在调用fun的时候,立马返回一个 Future,后续可以通过Future去监控方法fun的处理过程(即: Future-Listener机制)\n    注：当 Future对象刚刚创建时,处于非完成状态,调用者可以通过返回的 ChannelFuture来获取操作执行的状态,注册监听函数来执行完成后的操作\n 常见有如下操作\n  通过 isDone 方法来判断当前操作是否完成;\n  通过 isSuccess 方法来判断已完成的当前操作是否成功;\n  通过 getCause 方法来获取已完成的当前操作失败的原因;\n  通过 isCancelled 方法来判断已完成的当前操作是否被取消;\n  通过 addlistener 方法来注册监听器,当操作已完成( isDone方法返回完成),将会通知指定的监听器;如果 Future对象已完成,则通知指定的监听器;\n  举个栗子\n//启动服务器(并绑定端口)\rChannelFuture cf = bootstrap.bind(6668).sync();\r//给cf 注册监听器，监控我们关心的事件\rcf.addListener(new ChannelFutureListener() {\r@Override\rpublic void operationComplete(ChannelFuture future) throws Exception {\rif (cf.isSuccess()) {\rSystem.out.println(\u0026quot;监听端口 6668 成功\u0026quot;);\r} else {\rSystem.out.println(\u0026quot;监听端口 6668 失败\u0026quot;);\r}\r}\r});\r ","id":18,"section":"posts","summary":"总览 Bootstrap or ServerBootstrap EventLoop or EventLoopGroup ChannelInitializer ChannelHandler ChannelPipeline ChannelHandlerContext Future or ChannelFuture Bootstrap or ServerBootstrap 都是用来启动一个Netty应用的配置类，它主要作用是配置整个Netty程序，串联起各个组件。 EventLoop or EventLoopGroup EventLoopGroup 是一","tags":["Netty"],"title":"Netty基础组件","uri":"https://bluestaree.github.io/2020/06/netty%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D/","year":"2020"},{"content":"  前言：通过Netty完成一个简单的多客户端与单服务端交互的demo\n Netty初体验 服务端\npublic class NettyServer {\rpublic static void main(String[] args) throws Exception {\r//1. 创建两个线程组 bossGroup 和 workerGroup\r//2. bossGroup 只是处理连接请求 , 真正的和客户端业务处理，会交给 workerGroup完成\r//3. 两个都是无限循环\r//4. bossGroup 和 workerGroup 含有的子线程(NioEventLoop)的个数可以在参数中指定\r// 默认数量为实际 cpu核数 * 2\rEventLoopGroup bossGroup = new NioEventLoopGroup(1);//通常bossGroup只需要1个\rEventLoopGroup workerGroup = new NioEventLoopGroup(); try {\r//创建服务器端的启动引导类对象，可以配置服务器参数\rServerBootstrap bootstrap = new ServerBootstrap();\r//使用链式编程来进行设置\rbootstrap.group(bossGroup, workerGroup) //设置两个线程组\r//使用NioSocketChannel 作为服务器的通道实现\r.channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 128) // 设置线程队列得到连接个数\r.childOption(ChannelOption.SO_KEEPALIVE, true) //设置保持活动连接状态\r// .handler(null) // 该 handler对应 bossGroup设置 , childHandler 对应 workerGroup\r.childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() {//创建一个通道初始化对象(匿名对象)\r//给pipeline 设置处理器\r@Override\rprotected void initChannel(SocketChannel ch) throws Exception {\r//这里的SocketChannel 是客户端通道实例\r//获取当前通道对应的管道,在末尾添加一个自定义的处理器\rch.pipeline().addLast(new NettyServerHandler()); }\r}); // 给我们的workerGroup 的 EventLoop 对应的管道设置处理器\r//绑定一个端口，同步执行(阻塞当前线程), 返回一个 ChannelFuture 对象(netty的异步模型)，\r//可通过此对象获取方法执行结果\r//启动服务器(并绑定端口)\rChannelFuture cf = bootstrap.bind(6668).sync();\r//服务端管道关闭的监听器,并同步阻塞,直到channel关闭,线程才会往下执行,进入finally关闭通道结束进程\rcf.channel().closeFuture().sync();\r}finally {\r//优r雅的关闭\rbossGroup.shutdownGracefully();\rworkerGroup.shutdownGracefully();\r}\r}\r}\r 自定义服务端Handler\npublic class NettyServerHandler extends SimpleChannelInboundHandler\u0026lt;String\u0026gt; {\r//通道一旦链接，此方法第一个执行\r@Override\rpublic void handlerAdded(ChannelHandlerContext ctx) throws Exception {\r//通过上线文获取通道信息\rChannel channel = ctx.channel();\r//业务处理\r}\r//断开链接\r@Override\rpublic void handlerRemoved(ChannelHandlerContext ctx) throws Exception {\r}\r//通道处于活跃状态\r@Override\rpublic void channelActive(ChannelHandlerContext ctx) throws Exception {\r}\r//非活跃状态\r@Override\rpublic void channelInactive(ChannelHandlerContext ctx) throws Exception {\r}\r//异常处理,一般是需要关闭通道\r@Override\rpublic void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\rctx.close();\r}\r//通道有数据可读，第二个参数是消息内容\r@Override\rprotected void channelRead0(ChannelHandlerContext channelHandlerContext, String s) throws Exception {\r//writeAndFlush 是 write + flush\r//将数据写入到缓存，并刷新\r//一般，我们会对这个发送的数据进行编码\rctx.writeAndFlush(Unpooled.copiedBuffer(\u0026quot;hello, 客户端~\u0026quot;, CharsetUtil.UTF_8));\r}\r}\r 客户端\npublic class NettyClient {\rpublic static void main(String[] args) throws Exception {\r//客户端需要一个事件循环组\rEventLoopGroup group = new NioEventLoopGroup();\rtry {\r//创建客户端启动对象\r//注意客户端使用的不是 ServerBootstrap 而是 Bootstrap\rBootstrap bootstrap = new Bootstrap();\r//设置相关参数\rbootstrap.group(group) //设置线程组\r.channel(NioSocketChannel.class) // 设置客户端通道的实现类\r.handler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() {\r@Override\rprotected void initChannel(SocketChannel ch) throws Exception {\r//这里可以加入自己的处理器\rch.pipeline().addLast(new NettyClientHandler()); }\r});\r//启动客户端去连接服务器端\rChannelFuture channelFuture = bootstrap.connect(\u0026quot;127.0.0.1\u0026quot;, 6668).sync();\r//给关闭通道进行监听\rchannelFuture.channel().closeFuture().sync();\r}finally {\rgroup.shutdownGracefully();\r}\r}\r}\r 自定义客户端Handler\npublic class NettyClientHandler extends ChannelInboundHandlerAdapter {\r//当通道就绪就会触发该方法\r@Override\rpublic void channelActive(ChannelHandlerContext ctx) throws Exception {\rSystem.out.println(\u0026quot;client \u0026quot; + ctx);\rctx.writeAndFlush(Unpooled.copiedBuffer(\u0026quot;hello, server\u0026quot;, CharsetUtil.UTF_8));\r}\r//当通道有读取事件时，会触发\r@Override\rpublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\rByteBuf buf = (ByteBuf) msg;\rSystem.out.println(\u0026quot;服务器回复的消息:\u0026quot; + buf.toString(CharsetUtil.UTF_8));\rSystem.out.println(\u0026quot;服务器的地址： \u0026quot;+ ctx.channel().remoteAddress());\r}\r@Override\rpublic void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\rcause.printStackTrace();\rctx.close();\r}\r}\r 关于Channel类型设置\n不同协议、不同的阻塞类型的连接都有不同的 Channel类型与之对应,常用的Channel类型:\n NioSocketChannel,异步的客户端 TCP Socket连接 NioServerSocketChannel,异步的服务器端 TCP Socket连接。 NioDatagramChannel,异步的UDP连接。 NioSctpChannel,异步的客户端Sctp连接。 NioSctpServerChannel,异步的Sctp服务器端连接,这些通道涵盖了UDP和TCP网络IO以及文件IO。  关于ChannelOption参数设置\n参数如下\n ChannelOption.SO_BACKLOG  对应TCP/IP协议listen函数中的backlog参数，用来初始化服务器可连接队列大小。服务端处理客户端连接请求是顺序处理的，所以同一时间只能处理一个客户端连接。 多个客户端来的时候，服务端将不能处理的客户端连接请求放在队列中等待处理，backlog 参数指定了队列的大小。\n ChannelOption.SO_KEEPALIVE  一直保持连接活动状态\n相关代码API\nbootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 128) //给bossGroup通道设置参数\r.childOption(ChannelOption.SO_KEEPALIVE, true) //给workerGroup通道设置参数\r ","id":19,"section":"posts","summary":"前言：通过Netty完成一个简单的多客户端与单服务端交互的demo Netty初体验 服务端 public class NettyServer { public static void main(String[] args) throws Exception { //1. 创建两个线程组 bossGroup 和 workerGroup //2. bossGroup 只","tags":["Netty"],"title":"Netty初体验","uri":"https://bluestaree.github.io/2020/06/netty%E5%88%9D%E4%BD%93%E9%AA%8C/","year":"2020"},{"content":"  转载 · 原文链接：https://www.jianshu.com/p/275602182f39\n 前言 零拷贝这三个字，一直是服务器网络编程的关键字，任何性能优化都离不开。在 Java 程序员的世界，常用的零拷贝有 mmap 和 sendFile。那么，他们在 OS 里，到底是怎么样的一个的设计？本文将简单聊聊 mmap 和 sendFile 这两个零拷贝。\n传统数据读写的劣势 初学 Java 时，我们在学习 IO 和 网络编程时，会使用以下代码：\nFile file = new File(\u0026quot;index.html\u0026quot;);\rRandomAccessFile raf = new RandomAccessFile(file, \u0026quot;rw\u0026quot;);\rbyte[] arr = new byte[(int) file.length()];\rraf.read(arr);\rSocket socket = new ServerSocket(8080).accept();\rsocket.getOutputStream().write(arr);\r 我们会调用 read 方法读取 index.html 的内容—— 变成字节数组，然后调用 write 方法，将 index.html 字节流写到 socket 中，那么，我们调用这两个方法，在 OS 底层发生了什么呢？我这里借鉴了一张其他文字的图片，尝试解释这个过程。\n传统 IO 操作\n上图中，上半部分表示用户态和内核态的上下文切换。下半部分表示数据复制操作。下面说说他们的步骤：\n read 调用导致用户态到内核态的一次变化，同时，第一次复制开始：DMA（Direct Memory Access，直接内存存取，即不使用 CPU 拷贝数据到内存，而是 DMA 引擎传输数据到内存，用于解放 CPU） 引擎从磁盘读取 index.html 文件，并将数据放入到内核缓冲区。 发生第二次数据拷贝，即：将内核缓冲区的数据拷贝到用户缓冲区，同时，发生了一次用内核态到用户态的上下文切换。 发生第三次数据拷贝，我们调用 write 方法，系统将用户缓冲区的数据拷贝到 Socket 缓冲区。此时，又发生了一次用户态到内核态的上下文切换。 第四次拷贝，数据异步的从 Socket 缓冲区，使用 DMA 引擎拷贝到网络协议引擎。这一段，不需要进行上下文切换。 write 方法返回，再次从内核态切换到用户态。  如你所见，复制拷贝操作太多了。如何优化这些流程？\nmmap 优化 mmap 通过内存映射，将文件映射到内核缓冲区，同时，用户空间可以共享内核空间的数据。这样，在进行网络传输时，就可以减少内核空间到用户控件的拷贝次数。如下图：\nmmap 流程\n如上图，user buffer 和 kernel buffer 共享 index.html。如果你想把硬盘的 index.html 传输到网络中，再也不用拷贝到用户空间，再从用户空间拷贝到 Socket 缓冲区。\n现在，你只需要从内核缓冲区拷贝到 Socket 缓冲区即可，这将减少一次内存拷贝（从 4 次变成了 3 次），但不减少上下文切换次数。\nsendFile 那么，我们还能继续优化吗？ Linux 2.1 版本 提供了 sendFile 函数，其基本原理如下：数据根本不经过用户态，直接从内核缓冲区进入到 Socket Buffer，同时，由于和用户态完全无关，就减少了一次上下文切换。\nsnedFile 2.1 版本\n如上图，我们进行 sendFile 系统调用时，数据被 DMA 引擎从文件复制到内核缓冲区，然后调用，然后掉一共 write 方法时，从内核缓冲区进入到 Socket，这时，是没有上下文切换的，因为在一个用户空间。\n最后，数据从 Socket 缓冲区进入到协议栈。\n此时，数据经过了 3 次拷贝，3 次上下文切换。\n那么，还能不能再继续优化呢？ 例如直接从内核缓冲区拷贝到网络协议栈？\n实际上，Linux 在 2.4 版本中，做了一些修改，避免了从内核缓冲区拷贝到 Socket buffer 的操作，直接拷贝到协议栈，从而再一次减少了数据拷贝。具体如下图：\nsendFile 在 2.4 版本的再一次优化\n现在，index.html 要从文件进入到网络协议栈，只需 2 次拷贝：第一次使用 DMA 引擎从文件拷贝到内核缓冲区，第二次从内核缓冲区将数据拷贝到网络协议栈；内核缓存区只会拷贝一些 offset 和 length 信息到 SocketBuffer，基本无消耗。\n等一下，不是说零拷贝吗？为什么还是要 2 次拷贝？\n答：首先我们说零拷贝，是从操作系统的角度来说的。因为内核缓冲区之间，没有数据是重复的（只有 kernel buffer 有一份数据，sendFile 2.1 版本实际上有 2 份数据，算不上零拷贝）。例如我们刚开始的例子，内核缓存区和 Socket 缓冲区的数据就是重复的。\n而零拷贝不仅仅带来更少的数据复制，还能带来其他的性能优势，例如更少的上下文切换，更少的 CPU 缓存伪共享以及无 CPU 校验和计算。\n再稍微讲讲 mmap 和 sendFile 的区别。\n mmap 适合小数据量读写，sendFile 适合大文件传输。 mmap 需要 4 次上下文切换，3 次数据拷贝；sendFile 需要 3 次上下文切换，最少 2 次数据拷贝。 sendFile 可以利用 DMA 方式，减少 CPU 拷贝，mmap 则不能（必须从内核拷贝到 Socket 缓冲区）。  在这个选择上：rocketMQ 在消费消息时，使用了 mmap。kafka 使用了 sendFile。\nJava 世界的例子 kafka 在客户端和 broker 进行数据传输时，会使用 transferTo 和 transferFrom 方法，即对应 Linux 的 sendFile。\ntomcat 内部在进行文件拷贝的时候，也会使用 transferto 方法。\ntomcat 在处理一下心跳保活时，也会调用该 sendFile 方法。\n在 pulsar 项目中，下载文件时，也会使用 sendFile。如下图：\n所以，如果你需要优化网络传输的性能，或者文件读写的速度，请尽量使用零拷贝。他不仅能较少复制拷贝次数，还能较少上下文切换，缓存行污染。\n作者：莫那一鲁道 来源：简书\n ","id":20,"section":"posts","summary":"转载 · 原文链接：https://www.jianshu.com/p/275602182f39 前言 零拷贝这三个字，一直是服务器网络编程的关键字","tags":null,"title":"零拷贝","uri":"https://bluestaree.github.io/2020/06/%E9%9B%B6%E6%8B%B7%E8%B4%9D/","year":"2020"},{"content":" 前言  IO模型：就是用什么样的通道进行数据的发送和接收,很大程度上决定了程序通信的性能\n而netty是一款基于NIO(Nonblocking I/O,非阻塞IO)所开发的网络通信框架。\n 下面介绍三种I/O模型。\nBIO，传统同步阻塞 ： 服务器实现模式为一个连接一个线程,即客户端有连接请求时服务器端就需要启动一个线程\n进行处理,如果这个连接不做任何事情会造成不必要的线程开销\nNIO，同步非阻塞：服务器实现模式为一个线程处理多个请求(连接),即客户端发送的连接请求都会注册到多路复用\n器上,多路复用器轮询到连接有IO请求就进行处理\nAIO，异步非阻塞：AIO引入异步通道的概念,采用了 Proactor模式,简化了程序编写,有效的请求才启动线程,它的特\n点是先由操作系统完成后才通知服务端程序启动线程去处理,一般适用于连接数较多且连接时间较长的应用\nBIO、NIO、AIO适用场景分析  BIO方式适用于连接数目比较小且固定的架构,这种方式对服务器资源要求比较高并发局限于应用中,JDK1.4以前  的唯一选择,但程序简单易理解。\n NIO方式适用于连接数目多且连接比较短(轻操作)的架构,比如聊天服务器,弹幕系统,服务器间通讯等。编程比较复杂,JDK1.4开始支持\n  AIO方式使用于连接数目多且连接比较长(重操作)的架构,比如相册服务器,充分调用OS参与并发操作,编程比较复\n  杂,JDK7开始支持\nNIO的三大核心组件 \u0026ndash; Channel , Selector , Buffer 缓冲区( Buffer ) 缓冲区本质上是一个可以读写数据的内存块,可以理解成是一个容器对象(含数组),该对象提供了一组方法,可以更轻\n松地使用内存块，缓冲区对象内置了一些机制,，能够跟踪和记录缓冲区的状态变化情况。 Channel提供从文件、\n网络读取数据的渠道，但是读取或写入的数据都必须经由 Buffer，常用的Buffer缓冲区：ByteBuffer\n除了Boolean，java中的其他原生数据类型都有与之对应的Buffer\nBuffer的分散和聚集 NIO还支持通过多个Buffer(即Buffer数组)完成读写操作，即Scattering和Gathering\n Scattering：将数据写入到buffer时，可以采用buffer数组的形式，依次写入【分散】 Gathering：从buffer读取数据时，可以采用buffer数组，依次读  通道( Channel ) NIO的通道类似于流,但有些区别如下\n 通道可以同时进行读写,而流只能读或者只能写 通道可以实现异步读写数据 通道可以从缓冲读数据,也可以写数据到缓冲:  常用的通道：FileChannel(文件读写)、DatagramChannel(对UDP数据读写)、ServerSocketChannel(TCP数据读写)、SocketChannel(TCP数据读写)\nChannel 可从原生IO中获取\n// 创建一个输出流- \u0026gt;channel\rFileOutputStream fileOutputStream = new FileOutputStream(\u0026quot;d:\\\\file01.txt\u0026quot;);\r//通过fileOutputStream获取对应的FileChannel\r//这个fileChannel真实类型是FileChannelImpl\rFileChannel fileChannel = fileOutputStream.getChannel();\r NIO还提供了 MappedByteBuffer，可以让文件直接在内存(堆外的内存)中进行修改，而如何同步到文件由NIO来完成.\nRandomAccessFile randomAccessFile = new RandomAccessFile(\u0026quot;1.txt\u0026quot;,\u0026quot;rw\u0026quot;);\r//获取对应的通道\rFileChannel channel = randomAccessFile.getChannel();\r/**\r*参数1: FileChannel.MapMode.READ_WRITE使用的读写模式\r*参数2: 0:可以直接修改的起始位置\r*参数3: 5:是映射到内存的大小, 即将1.txt的多少个字节映射到内存\r*可以直接修改的范围就是 0-5\r*/\rMappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, 5);\rmappedByteBuffer.put(0,(byte)'H');\rmappedByteBuffer.put(3,(byte)'9');\r 选择器( Selector )   Java的NIO，用非阻塞的IO方式。可以用一个线程，处理多个的客户端连接，就会使用到 Selector(选择器)\n  Selector能够检测多个注册的通道上是否有事件发生(注意:多个 Channel以事件的方式可以注册到同一个\n  Selector)，如果有事件发生，便获取事件然后针对每个事件进行相应的处理。这样就可以只用一个单线程去管理\n多个通道，也就是管理多个连接和请求。\n 只有在连接真正有读写事件发生时，才会进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程\n  避免了多线程之间的上下文切换导致的开销\n  NIO初体验 使用NIO实现简单多人聊天功能\n服务端\nimport java.io.IOException;\rimport java.net.InetSocketAddress;\rimport java.nio.ByteBuffer;\rimport java.nio.channels.*;\rimport java.util.Iterator;\rimport java.util.Set;\r//实现简单多人聊天功能\r//服务端\rpublic class NioService {\rpublic ServerSocketChannel serverSocketChannel;\rpublic Selector selector;\rpublic static final int PORT = 8888;\r//初始化参数\rpublic NioService() throws IOException {\r//初始化serverSocketChannel\rserverSocketChannel = ServerSocketChannel.open();\r//初始化selector\rselector = Selector.open();\r//绑定监听端口\rserverSocketChannel.socket().bind(new InetSocketAddress(PORT));\r//设置非阻塞\rserverSocketChannel.configureBlocking(false);\r//注册至selector\rserverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\rSystem.out.println(\u0026quot;服务器初始化完成 = \u0026quot;);\r}\r//监听\rpublic void listen() {\rtry {\rwhile (true) {\rint i = selector.select();\rif (i \u0026gt; 0) { // 有事件发生\r//获取触发事件的所有SelectionKey\rIterator\u0026lt;SelectionKey\u0026gt; iterator = selector.selectedKeys().iterator();\r//遍历,\rwhile (iterator.hasNext()) {\rSelectionKey key = iterator.next();\r//连接事件\rif (key.isAcceptable()) {\r//获取客户端链接通道\rSocketChannel socketChannel = serverSocketChannel.accept();\r//设置非阻塞\rsocketChannel.configureBlocking(false);\r//注册至selector\rsocketChannel.register(selector, SelectionKey.OP_READ);\r//提示\rSystem.out.println(socketChannel.getRemoteAddress() + \u0026quot; 上线\u0026quot; );\r}\rif (key.isReadable()) {\r//读数据\rreceiverMessage(key);\r}\riterator.remove();\r}\r}\r}\r} catch (IOException e) {\re.printStackTrace();\r}\r}\r//接收数据\rpublic void receiverMessage(SelectionKey key) {\rif (key == null) {\rreturn;\r}\rSocketChannel socketChannel = (SocketChannel) key.channel();\rByteBuffer byteBuffer = ByteBuffer.allocate(1024);\rtry {\rsocketChannel.read(byteBuffer);\r//\rString msg = new String(byteBuffer.array());\rSystem.out.println(\u0026quot;转发 \u0026quot; + socketChannel.getRemoteAddress() + \u0026quot; :的信息\u0026quot; + msg);\r//转发信息\rsendMessage(msg,socketChannel);\r} catch (IOException e) {\re.printStackTrace();\rtry {\rSystem.out.println(socketChannel.getRemoteAddress() + \u0026quot; 离线了\u0026quot;);\rkey.channel();\rsocketChannel.close();\r} catch (IOException ex) {\rex.printStackTrace();\r}\r}\r}\r//转发信息\rpublic void sendMessage(String msg, SocketChannel self) throws IOException {\rSystem.out.println(\u0026quot;服务器转发消息中\u0026quot;);\r//获取所有已注册的通道(除去自己)\rSet\u0026lt;SelectionKey\u0026gt; keys = selector.keys();\rfor (SelectionKey key : keys) {\rChannel channel = key.channel();\rif (channel instanceof SocketChannel \u0026amp;\u0026amp; channel != self) {\rByteBuffer byteBuffer = ByteBuffer.wrap(msg.getBytes());\r((SocketChannel) channel).write(byteBuffer);\r}\r}\r}\rpublic static void main(String[] args) throws IOException {\rNioService nioService = new NioService();\rnioService.listen();\r}\r}\r 客户端\nimport java.io.IOException;\rimport java.net.InetSocketAddress;\rimport java.nio.ByteBuffer;\rimport java.nio.channels.SelectionKey;\rimport java.nio.channels.Selector;\rimport java.nio.channels.SocketChannel;\rimport java.util.Iterator;\rimport java.util.Scanner;\r//客户端\rpublic class NioClient {\rprivate SocketChannel socketChannel;\rprivate Selector selector;\rprivate static final String ADDRESS = \u0026quot;127.0.0.1\u0026quot;;\rprivate static final int PORT = 8888;\rprivate String username;\rpublic NioClient() throws IOException {\rsocketChannel = SocketChannel.open(new InetSocketAddress(ADDRESS, PORT));\rselector = Selector.open();\rsocketChannel.configureBlocking(false);\rsocketChannel.register(selector, SelectionKey.OP_READ);\rusername = socketChannel.getLocalAddress().toString().substring(1);\rSystem.out.println(username + \u0026quot;is ok...\u0026quot; );\r}\rpublic void sendMessage(String msg) throws IOException {\rmsg = username + \u0026quot; 说:\u0026quot; + msg;\rByteBuffer byteBuffer = ByteBuffer.wrap(msg.getBytes());\rsocketChannel.write(byteBuffer);\r}\rpublic void listen() throws IOException {\rint select = selector.select();\rif (select \u0026gt; 0) {\rIterator\u0026lt;SelectionKey\u0026gt; iterator = selector.selectedKeys().iterator();\rwhile (iterator.hasNext()) {\rSelectionKey key = iterator.next();\rif (key.isReadable()) {\rByteBuffer byteBuffer = ByteBuffer.allocate(1024);\rsocketChannel.read(byteBuffer);\rSystem.out.println(new String(byteBuffer.array()));\r}\r}\riterator.remove();\r}\r}\rpublic static void main(String[] args) throws Exception {\rNioClient nioClient = new NioClient();\r//开启一条线程监听消息\rnew Thread(){\r@Override\rpublic void run() {\rwhile(true) {\rtry {\rnioClient.listen();\rThread.currentThread().sleep(3000);\r} catch (Exception e) {\re.printStackTrace();\r}\r}\r}\r}.start();\r//主线程发送消息\rScanner scanner = new Scanner(System.in);\rwhile (scanner.hasNextLine()) {\rnioClient.sendMessage(scanner.next());\r}\r}\r}\r ","id":21,"section":"posts","summary":"前言 IO模型：就是用什么样的通道进行数据的发送和接收,很大程度上决定了程序通信的性能 而netty是一款基于NIO(Nonblocking I/","tags":["Netty"],"title":"Netty的IO模型","uri":"https://bluestaree.github.io/2020/06/io%E6%A8%A1%E5%9E%8B/","year":"2020"},{"content":" 前言  不同的线程模型，对程序的性能有很大的影响，Netty线程模型主要基于主从Reactor多线程模型做了一定的改进\n 目前存在的线程模型有：\n传统I/O服务模型 模型特点\n 1)采用阻塞I0模式获取输入的数据 2)每个连接都需要独立的线程完成数据的输入，业务处理，数据返回等操作  Reactor模式 针对传统阻塞I/0服务模型的2个缺点，解决方案:\n 基于I/O 复用模型:多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象等待，无需阻塞等待所有连接。当某个连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理 基于线程池复用线程资源:不必再为每个连接创建线程，将连接完成后的业务处理任务分配给线程进行处理，一个线程可以处理多个连接的业务。  I/0复用结合线程池，就是Reactor模式基本设计思想，\n根据Reactor的数量和处理资源池线程的数量不同，有3种典型的实现：\n  单Reactor单线程 流程说明\n  Select 是前面I/0复用模型介绍的标准网络编程API， 可以实现应用程序通过一个阻塞对象监听多路连接请求\n  Reactor 对象通过Select监控客户端请求事件，收到事件后通过Dispatch进行分发\n  如果是建立连接请求事件，则由Acceptor通过accept处理连接请求，然后创建一 个Handler对象处理连接完成后的后续业务处理\n  如果不是建立连接事件，则Reactor会分发调用连接对应的Handler来响应\n  Handler 会完成Read \u0026gt;业务处理\u0026gt;Send 的完整业务流程\n  模型分析\n  优点:模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成\n  缺点:性能问题，只有一个线程，无法完全发挥多核CPU的性能。Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈\n  缺点:可靠性问题，线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障\n    单Reactor多线程 流程说明\n  Reactor 对象通过select监控客户端请求事件，收到事件后，通过dispatch进行分发\n  如果建立连接请求，则右Acceptor通过accept处理连接请求，然后创建一个Handler对象处理完成连接后的各种事件\n  如果不是连接请求，则由reactor分发调用连接对应的handler来处理\n  handler只负责响应事件，不做具体的业务处理，通过read读取数据后，会分发给后面的worker线程池的某个线程处理业务\n  worker线程池会分配独立线程完成真正的业务，并将结果返回给handler\n  handler收到响应后 ，通过send 将结果返回给client\n  模型分析\n  优点:可以充分的利用多核cpu的处理能力。\n  缺点:多线程数据共享和访问比较复杂，reactor 处理所有的事件的监听和响应，在单线程运行，在高并发场景容易出现性能瓶颈。\n    主从Reactor多线程 流程说明\n  Reactor主线程MainReactor对象通过select监听连接事件，收到事件后，通过Acceptor处理连接事件\n  当Acceptor处理连接事件后，MainReactor将连接分配给SubReactor\n  subreactor将连接加入到连接队列进行监听,并创建handler进行各种事件处理\n  当有新事件发生时，subreactor 就会调用对应的handler处理\n  handler通过read读取数据，分发给后面的worker线程处理\n  worker线程池分配独立的worker线程进行业务处理，并返回结果\n  handler收到响应的结果后，再通过send将结果返回给client\n  注：Reactor主线程可以对应多个Reactor子线程，即MainRecator可以关联多个SubReactor\n模型分析\n  优点:父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。\n  优点:父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。\n  缺点:编程复杂度较高\n    Netty线程模式 主要基于主从Reactor多线程模型做了一定的改进，其中主从Reactor多线程模型中有多个Reactor\n流程说明\n  Netty抽象出两组线程池BossGroup专门负责接收客户端的连接，WorkerGroup专门负责网络读写\n  BossGroup和WorkerGroup类型都是NioEventLoopGroup\n  NioEventLoopGroup相当于一个事件循环组，这个组中含有多个事件循环，每一个事件循环是NioEventLoop\n  NioEventLoop 表示一个不断循环的执行处理任务的线程，每个NioEventLoop都有一个selector ,用于监听绑定在其上的socket的网络通讯\n  NioEventLoopGroup 可以有多个线程，即可以含有多个NioEventLoop\n  每个BossNioEventLoop循环执行的步骤有3步\n   ​\t轮询accept事件 ​\t处理accept事件,与client建立连接，生成NioSocketChannel ,并将其注册到某个worker NIOEventLoop上的selector，分配机制是看哪个线程空闲就分配，否则进入等待 ​\t处理任务队列的任务 ，即runAllTasks  每个Worker NIOEventLoop循环执行的步骤   ​\t轮询read, write事件 ​\t处理i/o事件，即read , write事件，在对应NioSocketChannel处理 ​\t处理任务队列的任务，即runAllTasks  处理过程中会使用到pipeline，其中包含了channel ，通过pipeline可以获取到对应通道，且其中维护了很多处理器，可以自定义处理器\n 总结：Boss Group只是处理连按请求,真正的和客户端业务处理,会交给Worker Group完成\nNioEventLoopGroup下包含多个NioEventLoop\n 每个 NioEventLoop中包含有一个 Selector,一个 taskQueue 每个 NioEventLoop的 Selector上可以注册监听多个 NioChannel 每个 Niochannel只会绑定在唯一的 NioEventLoop上 每个 NioChannel都绑定有一个自己的 ChannelPipeline  ","id":22,"section":"posts","summary":"前言 不同的线程模型，对程序的性能有很大的影响，Netty线程模型主要基于主从Reactor多线程模型做了一定的改进 目前存在的线程模型有： 传统","tags":["Netty"],"title":"Netty线程模型","uri":"https://bluestaree.github.io/2020/06/netty%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/","year":"2020"},{"content":" 所谓的正向与反向，都是对于我们自己的电脑来说\n正向代理：帮助客户端访问外部资源的，\n举个例子：如科学上网。如果我们需要访问谷歌，就需要代理服务器帮助我们访问获得数据，再由代理服务器返回\n给客户端，也就是帮助客户端进行访问连接的，这就是正向代理，\n正向代理作用：\n 访问原来无法访问的资源， 隐藏客户端信息  如何隐藏客户端的信息？因为客户端是将请求转发给代理服务器，此时对于谷歌而言，真正访问的是代理服务器，\n所能看到的地址也只是代理服务器的IP地址\n 反向代理：主要负责接收客户端的请求，并将其转发到内网服务器集群中。\n通常一些真正处理请求的服务器都是部署在内网中，并不会对外暴露真正的IP地址，这主要是为了防止网络攻击。\n那么我们要如何访问位于内网中的服务呢。这时候就需要使用反向代理服务器，如Nginx，对外暴露公网IP地址，\n将所接收到的请求转发到内网中，并将获得的结果返回给客户端。\n反向代理的作用：\n 负载均衡 保护内网安全  ","id":23,"section":"posts","summary":"所谓的正向与反向，都是对于我们自己的电脑来说 正向代理：帮助客户端访问外部资源的， 举个例子：如科学上网。如果我们需要访问谷歌，就需要代理服务器","tags":null,"title":"正向代理与方向代理","uri":"https://bluestaree.github.io/2020/06/%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86%E4%B8%8E%E6%96%B9%E5%90%91%E4%BB%A3%E7%90%86/","year":"2020"},{"content":" 1.PO(Persistant Object) 持久对象\nPO就是对应数据库中某个表中的一条记录,多个记录可以用PO的集合。PO中应该不包含任何对数据库的操作。\n 2.DO(Domain object) 领域对象\n就是从现实世界中抽象出来的有形或无形的业务实体\n 3.TO(Transfer Object) 数据传输对象\n不同的应用程序(服务)之间传输的对象\n 4.DTO(Data Transfer Object) 数据传输对象\n这个概念来源于J2EE的设计模式,原来的目的是为了EJB的分布式应用提供粗粒度的数据实体,以减少分布式调用的次\n数,从而提高分布式调用的性能和降低网络负载,但在这里,泛指用于展示层与服务层之间的数据传输对象。\n 5.VO(Value Object) 值对象\n通常用于业务层之间的数据传递,和PO一样也是仅仅包含数据而已。但应是抽象出的业务对象,可以和表对应,也可\n以不,这根据业务的需要。用new关键字创建,由GC回收的。\n也可以理解为 (View Object) 视图对象\n 接收页面传递过来的数据，封装成一个对象 经过业务处理完成后，封装成页面要用的数据   6.BO(Business Object) 业务对象\n从业务模型的角度看,见UML元件领域模型中的领域对象。封装业务逻辑的java对象,通过调用DAO方法，结合\nPO,VO进行业务操作。\nbusiness object:业务对象主要作用是把业务逻辑封装为一个对象。这个对象可以包括一个或多个其它的对象。比\n如一个简历,有教育经历、工作经历、社会关系等等。我们可以把教育经历对应一个PO,工作经历对应一个PO,社会\n关系对应一个PO。建立一个对应简历的Bo对象处理简历,每个BO包含这些PO。这样处理业务逻辑时,我们就可以针\n对BO去处理。\n 7.POJO(Plain Ordinary Java Object) 简单无规则的java对象\n传统意义的java对象。就是说在一些 Object/Relation Mapping工具中,能够做到维护数据库表记录的 persisent\nobject完全是一个符合 Java Bean规范的纯Java对象，没有增加别的属性和方法。\n我的理解就是最基本的 Java Bean,只有属性字段及 setter和 getter方法!\nPOJO是 DO / DTO / BO / VO 的统称。\n 8.DAO(Data Access Object) 数据访问对象\n是一个sun的一个标准j2ee设计模式，这个模式中有个接囗就是DAO，它负持久层的操作。为业务层提供接口。此\n对象用于访问数据库。通常和PO结合使用，DAO中包含了各种数据库的操作方法。通过它的方法，结合PO对数据\n库进行相关的操作。夹在业务逻辑与数据库资源中间。配合VO，提供数据库的CRUD操作。\n","id":24,"section":"posts","summary":"1.PO(Persistant Object) 持久对象 PO就是对应数据库中某个表中的一条记录,多个记录可以用PO的集合。PO中应该不包含任何对数据库的操作。 2.DO(Domain object) 领域对象 就是从现实世界","tags":null,"title":"Object划分","uri":"https://bluestaree.github.io/2020/06/object%E5%88%92%E5%88%86/","year":"2020"},{"content":" 前言  现在的项目大多都是前后端分离的项目，那么对于一些重要数据的校验，单单使用前端控制是不行的，我们可以使用一些http请求工具如 Postman ，就可以轻松的跳过前端验证直接请求后台服务。因此服务端的数据验证也是必不可少，本文介绍了对于JSR303校验标准的简单使用\n 使用步骤 1.对需要校验的Bean对应字段加上校验注解，并定义错误消息提示\n所支持的校验注解类型可以在 javax.validation.constraints 包下查看\n2.开启校验\n使用 @Valid 开启校验\n这样就能够完成校验功能了，是不是很简单，当然也允许使用自定义规则的校验注解，这里不再进行演示。\n异常信息处理 对于校验不通过的异常数据，通常需要我们自己来处理，如果我们没有进行异常处理，默认返回的结果就像这样一\n长串的错误信息，用户体验就不是很好了\n这样的数据肯定不是我们所希望的，\n处理方法 我们可以在校验方法上，添加 BindingResult 方法参数，就可以接收到异常信息，获取到校验的结果，并进行相应的逻辑处理\n当然这样也不是最好的解决方案，如果有很多服务都需要校验异常，那就太麻烦了，我们可以使用SprngMVC所提\n供控制器增强功能，进行全局异常捕获处理，针对MethodArgumentNotValidException异常进行捕获，并统\n一返回自定义的结果\n分组校验 分组校验适合多场景校验的情况，举个栗子，比如对于商品评论ID，规定在新增时不需要携带ID信息，使用自增\n长主键，而在修改时必须要携带ID信息。\n这样一来就需要在Bean中的ID字段添加多个校验注解,这时就需要用到分组校验\n注意，分组的标识必须为接口类型 ，可以自定义一个标记接口\n在校验的时候使用 @Validated 指定校验组即可\n 注意：如果存在没有指定分组的校验注解，在指定分组校验的情况下不会生效\n ","id":25,"section":"posts","summary":"前言 现在的项目大多都是前后端分离的项目，那么对于一些重要数据的校验，单单使用前端控制是不行的，我们可以使用一些http请求工具如 Postman ，就可以轻","tags":null,"title":"使用JSR303规范标准进行数据校验","uri":"https://bluestaree.github.io/2020/05/%E4%BD%BF%E7%94%A8jsr303%E8%A7%84%E8%8C%83%E6%A0%87%E5%87%86%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E6%A0%A1%E9%AA%8C/","year":"2020"},{"content":"  转载 · 原文链接：https://blog.csdn.net/wu1317581750/java/article/details/81662929\n hibernate运行原理： hibernate里面提供了3个核心接口 Configuration、SessionFactory、Session\nhibernate启动的时候利用Configuration读取xml配置文件\n通过配置文件创建SessionFactory对象，初始化hibernate基本信息\n获取session然后调用CRUD方法进行数据操作，hibernate会把我们的数据进行三种状态的划分，然后根据状态进行管理我们的数据，对应的发送SQL进行数据操作\n关闭session，如果有事务的情况下，需要手动获取事务并开启，然后事务结束后提交事务。\n在提交事务的时候，去验证我们的快照里面的数据和缓存数据是否一致，如果不一致，发送SQL进行修改，\nhibernate的get方法和load方法的区别 get和load都是利用主键策略查询数据，\nget默认不使用懒加载机制，load默认要使用懒加载机制，所谓的懒加载就是我们这个数据如果不使用，hibernate就不发送SQL到数据库查询数据。\n当查询数据库不存在的数据的时候，get方法返回null，load方法抛出空指针异常，\n原因是因为，load方法采用的动态代理的方式实现的，我们使用load方法的时候，hibernate会创建一个该实体的代理对象，该代理只保存了该对象的ID，当我们访问该实体对象其他属性，hibernate就发送SQL查询数据封装到代理对象，然后在利用代理对象返回给我们实际的数据，\nhibernate的数据三种状态 hibernate把他所管理的数据划分为三种状态\n瞬时的（刚new出来的数据–内存有，数据库没有）\n持久的 （从数据查询的，或者刚保存到数据库，session没关闭的， 数据库有，内存也有）\n游离的 、脱管的（数据库有，内存没有）\n实际上hibernate对数据划分三种状态，主要是为了管理我们持久的数据，在事务提交的时候，hibernate去对比处于持久状态的数据是否发生改变，(快照区、一级缓存区)，当我们会话结束前，对持久状态数据进行了修改的话，快照区的数据会跟着改变。当session提交事务的时候，如果发现快照区和一级缓存的数据不一致，就会发送SQL进行修改。\n简述hibernate的缓存机制 hibernate分为2级缓存\n一级缓存又叫session缓存，又叫事务级缓存，生命周期从事务开始到事务结束，一级缓存是hibernate自带的，暴力使用，当我们一创建session就已有这个缓存了。数据库就会自动往缓存存放，\n二级缓存是hibernate提供的一组开放的接口方式实现的，都是通过整合第三方的缓存框架来实现的，二级缓存又叫sessionFactory的缓存，可以跨session访问。常用的EHcache、OScache，这个需要一些配置。\n当我们每次 查询数据的时候，首先是到一级缓存查看是否存在该对象，如果有直接返回，如果没有就去二级缓存进行查看，如果有直接返回，如果没有在发送SQL到数据库查询数据，\n当SQL发送查询回该数据的时候，hibernate会把该对象以主键为标记的形式存储到二级缓存和一级缓存，如果返回的是集合，会把集合打散然后以主键的形式存储到缓存。一级缓存和二级缓存只针对以ID查询的方式生效，get、load方法。\n简述hibernate中getCurrentSession和openSession区别 getCurrentSession和openSession都是通过H的工厂去获取数据库的会话对象，\n1、getCurrentSession会绑定当前线程，而openSession不会，因为我们把hibernate交给我们的spring来管理之后，我们是有事务配置，这个有事务的线程就会绑定当前的工厂里面的每一个session，而openSession是创建一个新session。\n2、getCurrentSession事务是有spring来控制的，而openSession需要我们手动开启和手动提交事务，\n3、getCurrentSession是不需要我们手动关闭的，因为工厂会自己管理，而openSession需要我们手动关闭。\n4、而getCurrentSession需要我们手动设置 绑定事务的机制，有三种设置方式，jdbc本地的Thread、JTA、第三种是spring提供的事务管理机制org.springframework.orm.hibernate4.SpringSessionContext，而且srping默认使用该种事务管理机制，\n————————————————\n","id":26,"section":"posts","summary":"转载 · 原文链接：https://blog.csdn.net/wu1317581750/java/article/details/816629","tags":["hibernate"],"title":"Hibernate常见问题","uri":"https://bluestaree.github.io/2020/05/hibernate%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","year":"2020"},{"content":" 记录一个坑，我现在所用的MySQL数据库的版本是8.019，在尝试使用Navicat连接数据库时，出现1251错误\n解决方法： 进入docker容器修改MySQL的root用户加密规则\n ALTER USER \u0026lsquo;root\u0026rsquo;@\u0026lsquo;localhost\u0026rsquo; IDENTIFIED WITH mysql_native_password BY \u0026lsquo;password\u0026rsquo;; #修改加密规则 ALTER USER \u0026lsquo;root\u0026rsquo;@\u0026lsquo;localhost\u0026rsquo; IDENTIFIED BY \u0026lsquo;password\u0026rsquo; PASSWORD EXPIRE NEVER; #更新一下用户的密码 FLUSH PRIVILEGES; #刷新权限  \u0026lsquo;root\u0026rsquo; 为你自己定义的用户名\n\u0026lsquo;localhost\u0026rsquo; 指的是用户开放的IP，可以是\u0026rsquo;localhost\u0026rsquo;(仅本机访问，相当于127.0.0.1)，可以是具体的\u0026rsquo;...'(具体某一IP)，也可以是 \u0026lsquo;%\u0026rsquo; (所有IP均可访问)\n\u0026lsquo;password\u0026rsquo; 是你想使用的用户密码\n","id":27,"section":"posts","summary":"记录一个坑，我现在所用的MySQL数据库的版本是8.019，在尝试使用Navicat连接数据库时，出现1251错误 解决方法： 进入docker","tags":null,"title":"Navicat连接MySQL出现1251错误","uri":"https://bluestaree.github.io/2020/05/navicat-1251%E9%94%99%E8%AF%AF/","year":"2020"},{"content":"  转载 · 原文链接：https://blog.csdn.net/CSDN_Ty/article/details/98877883\n 本文的内容主要想解决一下几个问题：\n equals() 和 == 的作用是什么？ equals() 和 == 的区别是什么？ hashCode()的作用是什么？ hashCode()与equals()之间有什么联系？  equals() 和 == 的作用  == 是用来判断两个对象是否为同一个对象，通过判断两个对象的内存地址来区分它们是否相等。 equals() 是用来判断两个对象是否相等，equals()定义在Object类中，所有类都继承了该方法。  从源码可以看出，默认情况下，equals与==没有区别，equals就是调用的==来进行判断。\npublic boolean equals(Object obj) {\rreturn (this == obj);\r}\r 所以，通常我们都会重写equals方法：两对象内容相等，则返回true，否则返回false。举例：\n①没有重写equals()方法时：\npublic class Test {\r@AllArgsConstructor\r@Setter\r@Getter\rpublic static class Student {\rprivate String name;\rprivate int age;\r}\rpublic static void main(String[] args) {\rStudent stu1 = new Student(\u0026quot;ye17186\u0026quot;, 18);\rStudent stu2 = new Student(\u0026quot;ye17186\u0026quot;, 18);\rSystem.out.println(\u0026quot;stu1.equals(stu2): \u0026quot; + stu1.equals(stu2));\r}\r}\r 输出结果：\n\n解析：\n由于stu1、stu2都是直接new出来的对象，它们指向两块不同的内存地址，在未重写equals方法的情况下，调用equals()方法其实就是调用==，比较的是他们的内存地址是否相同，所以这里打印的结果的false。\n②重写equals()方法时：\npublic class Test {\r@AllArgsConstructor\r@Setter\r@Getter\rpublic static class Student {\rprivate String name;\rprivate int age;\r@Override\rpublic boolean equals(Object o) {\rif (this == o) {\rreturn true;\r}\rif (o == null || getClass() != o.getClass()) {\rreturn false;\r}\rStudent student = (Student) o;\rreturn name.equals(student.getName()) \u0026amp;\u0026amp; age == student.age;\r}\r}\rpublic static void main(String[] args) {\rStudent stu1 = new Student(\u0026quot;ye17186\u0026quot;, 18);\rStudent stu2 = new Student(\u0026quot;ye17186\u0026quot;, 18);\rSystem.out.println(\u0026quot;stu1.equals(stu2): \u0026quot; + stu1.equals(stu2));\r}\r}\r 输出结果：\n\n解析：\n重写equals方法后，就会使用equals方法内的逻辑来判断是否相等，例子中直接比较了name和age是否相等，stu1和stu2两个对象，他们的name都是ye17186，age都是18，所以这里输出的结果是true。\nequals()与==的区别 上面已经解析过了，从设计上说==是用来判断是否为同一个对象，equals()用来判断两个对象是否相等。如果我们没有重写equals()方法，那么二者其实是等价的。但一般我们会重写equals()方法，这样会按照我们重写的逻辑来判断两个对象是否相等。\nhashCode的作用  hashCode()的作用是获取哈希码，也成为了散列码，它实际上返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。 hashCode()定义在java.lang.Object中，这意味着JAVA中任何类都有这个函数。 虽然每个JAVA类都有hashCode函数，但是仅仅当创建某个“类的散列表”时，该类的hashCode()才有用（作用是确定该类的每一个对象在散列表中的位置），其他情况下（例如：创建类的单个对象，或者创建类的对象数组等），类的hashCode()没有作用。 上面的散列表，指的是JAVA集合中本质是散列表的类，如HashMap、HashTable、HashSet。 也就是说，hashCode()在散列表中有用，在其他情况下没用。在散列表中hashCode()用于获取对象的散列码，从而确定该对象在散列表中的位置。 如果两个对象相等，他们的散列码一定相等；但是如果散列码相等，它们不一定相等  hashCode()与equals之间的联系 在非”本质是散列表的类”中，两者没有任何关系。而在”本质是散列表的类”中，在HashSet中，如果两个对象的hashCode相同，即使equals不等，它们在集合中也只会存储一个。\n","id":28,"section":"posts","summary":"转载 · 原文链接：https://blog.csdn.net/CSDN_Ty/article/details/98877883 本文的内容主要想","tags":["hashCode","equals"],"title":"hashCode和equals的相关问题","uri":"https://bluestaree.github.io/2020/05/hashcode%E5%92%8Cequals%E7%9A%84%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/","year":"2020"},{"content":" Feign调用流程  构造请求对象，将对象转为json 发送执行请求(执行成功会解码响应得数据) 获取结果  从代码中可以看出，如何请求出现异常，就会执行 retryer.continueOrPropagate(e) 方法进行重试，直到重试次数到指定的值，或者重试成功为止\nfeign get请求传对象 ","id":29,"section":"posts","summary":"Feign调用流程 构造请求对象，将对象转为json 发送执行请求(执行成功会解码响应得数据) 获取结果 从代码中可以看出，如何请求出现异常，就会执","tags":null,"title":"Feign的一些使用问题","uri":"https://bluestaree.github.io/2020/05/feign%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6/","year":"2020"},{"content":"  Spring Security 是spring项目之中的一个安全模块，可以非常方便与spring项目无缝集成。特别是在spring boot项目中加入spring security更是十分简单。本篇主要记录spring security的验证与授权流程，以及spring security在web应用中的相关配置。\n另外推荐大家阅读这位大佬的文章：Spring Security 工作原理概览\n 认证流程 Spring Security的认证流程如下:\n授权流程 Spring Security使用标准Filter建立了对web请求的拦截,最终实现对资源的授权访问。\nSpring Security的授权流程如下:\n会话控制 我们可以通过以下选项准确控制会话何时创建以及Spring Security如何与之交互:\n   机制 描述     always 如果没有session存在就创建一个   ifRequired 如果需要就创建一个Session (默认) 登录时   never SpringSecurity将不会创建Session ,但是如果应用中其他地方创建了Session ,那么SpringSecurity将会使用它。   stateless SpringSecurity将绝对不会创建Session，也不使用Session    通过以下配置方式对该选项进行配置:\n@Override\rprotected void configure (HttpSecurity http) throws Exception {\rhttp.sessionManagement()\r.sessionCreationPolicy(SessionCreationPolicy.IFREQUIRED);\r}\r ​\t默认情况下, Spring Security会为每个登录成功的用户会新建一个Session ,就是ifRequired。\n​\t若选用never ,则指示Spring Security对登录成功的用户不创建Session了,但若你的应用程序在某地方新建了session ,那么Spring Security会用它的。\n​\t若使用stateless ,则说明Spring Security对登录成功的用户不会创建Session了,你的应用程序也不会允许新建session。并且它会暗示不使用cookie ,所以每个请求都需要重新进行身份验证。这种无状态架构适用于REST API及其无状态认证机制。\n安全拦截配置-HttpSecurity spring security提供了用户名密码登录、退出、会话管理等认证功能,只需要配置即可使用。\nHttpSecurity配置列表:\n   方法 说明     openidLogin() 用于基于Openld的验证   headers() 将安全标头添加到响应   cors() 配置跨域资源共享( CORS )   sessionManagement() 允许配置会话管理   portMapper() 允许配置一个PortMapper(HttpSecurity#(getSharedObject(lass))) ,其他提供SecurityConfigurer的对象使用PortMapper从HTTP重定向到HTTPS或者从HTTPS重定向到HTTP.默认情况下, Spring Security使用一个PortMapperlmp映射HTTP端口8080到HTTPS端口8443 , HTTP端口80到HTTPS端口443   jee() 配置基于容器的预认证。在这种情况下 ,认证由Servlet容器管理   x509() 配置基于x509的认证   rememberMe 允许配置\u0026quot;记住我\u0026quot;的验证   authorizeRequests() 允许基于使用HttpServletRequest限制访问   requestCache() 允许配置请求缓存   exceptionHandling() 允许配置错误处理   securityContext() 在HttpServletRequests之间的SecurityContextHolder上设置SecurityContext的管理。当使用WebSecurityConfigurerAdapter时 ，这将自动应用   servletApi() 将HttpServletRequest方法与在其上找到的值集成到SecurityContext中。当使用WebSecurityConfigurerAdapter时,这将自动应用   csrf() 添加CSRF支持,使用WebSecurityConfigurerAdapter时,默认启用   logout() 添加退出登录支持。当使用WebSecurityConfigurerAdapter时 ,这将自动应用。默认情况是,访问URL\u0026rdquo;/ logout\u0026rdquo; ,使HTTP Session无效来清除用户,清除已配置的任何#rememberMe()身份验证,清除SecurityContextHolder ,然后重定向到\u0026rdquo;/login?success\u0026rdquo;   anonymous() 允许配置匿名用户的表示方法。 当与WebSecurityConfigurerAdapter结合使用时,这将自动应用。默认情况下,匿名用户将使用org.springframework.security.authentication.AnonymousAuthenticationToker表示，并包含角色\u0026quot;ROLE ANONYMOUS\u0026rdquo;   formLogin() 指定支持基于表单的身份验证。如果未指定FormLoginConfigurer#loginPage(String) ,则将生成默认登录页面   oauth2Login() 根据外部OAuth 2.0或OpenID Connect 1.0提供程序配置身份验证   requiresChannel() 配置通道安全。为了使该配置有用,必须提供至少一个到所需信道的映射   httpBasic() 配置Http Basic验证   addFilterAt() 在指定的Filter类的位置添加过滤器    web授权 如何能够对访问路径进行灵活的控制呢？我们可以通过给 http. authorizeRequests() 添加多个子节点来定制需求到我们的URL ,如下代码\n@Override\rprotected void configure(HttpSecurity http) throws Exception {\rhttp\r.authorizeRequests()\r.antMatchers(\u0026quot;/r/r1\u0026quot;).hasAuthority(\u0026quot;p1\u0026quot;)\r.antMaychers(\u0026quot;/r/r2\u0026quot;).hasAuthority(\u0026quot;p2\u0026quot;)\r.antMatchers(\u0026quot;/r/r3\u0026quot;).access(\u0026quot;hasAuthority('p1') and hasAuthority('p2')\u0026quot;)\r.antMatchers(\u0026quot;/r/**\u0026quot;).authenticated()\r.anyRequest().permitAll();\r//...\r}\r 保护URL常用的方法有:\n  authenticated() 保护URL ,需要用户登录\n  permitAll() 指定URL无需保护, 一般应用与静态资源文件\n  hasRole(String role) 限制单个角色访问,角色将被增加\u0026quot;ROLE_”.所以\u0026quot;ADMIN\u0026quot;将和\u0026quot;ROLE ADMIN\u0026quot;进行比较\n  hasAuthority(String authority) 限制单个权限访问\n  hasAnyRole(String\u0026hellip; roles) 允许多个角色访问.\n  hasAnyAuthority(String\u0026hellip; authorities) 允许多个权限访问\n  access(String attribute) 该方法使用SpEL表达式,所以可以创建复杂的限制.\n  haslpAddress(String ipaddressExpression) 限制IP地址或子网\n  这里需要注意的是:\n规则的顺序是重要的,更具体的规则应该先写,现在以/admin开始的所有内容都需要具有ADMIN角色的身份验证用户,即使是/admin/login路径(因为/admin/login已经被/admin/**规则匹配,因此第二个规则被忽略).\n.antMatchers(\u0026quot;/admin/**\u0026quot;).hasRole(\u0026quot;ADMIN\u0026quot;)\r.antMatchers(\u0026quot;/admin/login\u0026quot;).permitAll()\r 因此,登录页面的具体规则应该在/admin/**规则之前.例如.\n.antMatchers(\u0026quot;/admin/login\u0026quot;).permitAll()\r.antMatchers(\u0026quot;/admin/**\u0026quot;).hasRole(\u0026quot;ADMIN\u0026quot;)\r 方法授权 除了对web路径进行访问授权外，我们还可以对方法进行访问限制，主要依赖于3个注解:@PreAuthorize,@PostAuthorize,@Secured实现\n使用如下代码可启用@prePost注解的支持\n@EnableGlobalMethodSecurity(prePostEnabled = true)\rpublic class MethodSecurityConfig {\r//...\r}\r 相对应java代码如下：\npublic interface BankService {\r@PreAuthorize(\u0026quot;isAnonymous()\u0026quot;)\rpublic Account readAccount(Long id);\r@PreAuthorize(\u0026quot;isAnonymous()\u0026quot;)\rpublic Account[] findAccounts();\r@PreAuthorize(\u0026quot;hasAuthority('p_transfer') and hasAuthority('p_read_account')\u0026quot;)\rpublic Account post(Account account, double amount);\r}\r 以上配置标明readAccount. findAccounts方法可匿名访问 , post方法需要同时拥有p_transfer和 p_read. account权限才能访问,底层使用WebExpressionVoter投票器,可从AffirmativeBased第23行代码跟踪\n","id":30,"section":"posts","summary":"Spring Security 是spring项目之中的一个安全模块，可以非常方便与spring项目无缝集成。特别是在spring boot项目中加入spring secu","tags":["SpringSecurity"],"title":"SpringSecurity流程与配置","uri":"https://bluestaree.github.io/2020/05/spring-security%E6%B5%81%E7%A8%8B%E4%B8%8E%E9%85%8D%E7%BD%AE/","year":"2020"},{"content":" 最近在学习中遇到了新的包管理工具 - Gradle 。\n上网查询了下Gradle 的依赖方式，方便与Maven区分对比 。\n 转载 · 原文链接：https://blog.csdn.net/zyt_524744325/article/details/86535463\n 依赖配置-Gradle 目前Gradle版本支持的依赖配置有：implementation、api、compileOnly、runtimeOnly和annotationProcessor，已经废弃的配置有：compile、provided、apk、providedCompile。此外依赖配置还可以加一些配置项，例如AndroidTestImplementation、debugApi等等。\n implementation  与compile对应，会添加依赖到编译路径，并且会将依赖打包到输出（aar或apk），但是在编译时不会将依赖的实现暴露给其他module，也就是只有在运行时其他module才能访问这个依赖中的实现。使用这个配置，可以显著提升构建时间，因为它可以减少重新编译的module的数量。建议，尽量使用这个依赖配置。\n api  与compile对应，功能完全一样，会添加依赖到编译路径，并且会将依赖打包到输出（aar或apk），与implementation不同，这个依赖可以传递，其他module无论在编译时和运行时都可以访问这个依赖的实现，也就是会泄漏一些不应该不使用的实现。举个例子，A依赖B，B依赖C，如果都是使用api配置的话，A可以直接使用C中的类（编译时和运行时），而如果是使用implementation配置的话，在编译时，A是无法访问C中的类的。\n compileOnly  与provided对应，Gradle把依赖加到编译路径，编译时使用，不会打包到输出（aar或apk）。这可以减少输出的体积，在只在编译时需要，在运行时可选的情况，很有用。\n runtimeOnly  与apk对应，gradle添加依赖只打包到APK，运行时使用，但不会添加到编译路径。这个没有使用过。\n annotationProcessor  与compile对应，用于注解处理器的依赖配置，这个没用过。\n 依赖配置-Maven  compile  默认scope为compile，表示为当前依赖参与项目的编译、测试和运行阶段，属于强依赖。打包之时，会达到包里去。\n test  该依赖仅仅参与测试相关的内容，包括测试用例的编译和执行，比如定性的Junit。\n runtime  依赖仅参与运行周期中的使用。一般这种类库都是接口与实现相分离的类库，比如JDBC类库，在编译之时仅依赖相关的接口，在具体的运行之时，才需要具体的mysql、oracle等等数据的驱动程序。\n此类的驱动都是为runtime的类库。\n provided  该依赖在打包过程中，不需要打进去，这个由运行的环境来提供，比如tomcat或者基础类库等等，事实上，该依赖可以参与编译、测试和运行等周期，与compile等同。区别在于打包阶段进行了exclude操作。\n system  使用上与provided相同，不同之处在于该依赖不从maven仓库中提取，而是从本地文件系统中提取，其会参照systemPath的属性进行提取依赖。\n import  这个是maven2.0.9版本后出的属性，import只能在dependencyManagement的中使用，能解决maven单继承问题，import依赖关系实际上并不参与限制依赖关系的传递性。\n","id":31,"section":"posts","summary":"最近在学习中遇到了新的包管理工具 - Gradle 。 上网查询了下Gradle 的依赖方式，方便与Maven区分对比 。 转载 · 原文链接：https://blog","tags":["Maven","Gradle"],"title":"Maven,Gradle依赖","uri":"https://bluestaree.github.io/2020/05/mavengradle%E4%BE%9D%E8%B5%96/","year":"2020"},{"content":"  转载 · 原文链接：https://blog.csdn.net/qw463800202/article/details/103221651\n 一、动态sql使用 1.1、在项目中涉及多个动态查询条件，一般我们是通过 where 1 = 1，这样可以处理where后面对应条件全空的情况，我们可以使用标签，该标签可以自动处理,主要是当我们的sql查询条件以AND和OR结尾时，会自动去除，如\n\u0026lt;where\u0026gt; \u0026lt;if test=\u0026quot;keyword != null\u0026quot;\u0026gt; and title like concat('%',trim(#{keyword}),'%') \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt;\r\u0026lt;where\u0026gt; \u0026lt;if test=\u0026quot;name != null\u0026quot;\u0026gt; or name=#{name} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026quot;keyword != null\u0026quot;\u0026gt; or title like concat('%',trim(#{keyword}),'%') \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt;\r 1.2、在项目中涉及多个动态update条件时，传统的项目需要我们去除最后一个条件的逗号，但是在mybatis中我们可以使用标签，如\nUPDATE user\r\u0026lt;set\u0026gt;\r\u0026lt;if test ='null != name'\u0026gt;name = #{name},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != email'\u0026gt;email = #{email},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != headUrl'\u0026gt;head_url = #{headUrl},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != linkData'\u0026gt;link_data = #{linkData},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != createTime'\u0026gt;create_time = #{createTime},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != updateTime'\u0026gt;update_time = #{updateTime}\u0026lt;/if\u0026gt;\r\u0026lt;/set\u0026gt;\r ​ 1.3、动态if else语句，在mybatis中使用choose、when、otherwise来处理，如下代码\nmybatis 中 SQL 写在mapper.xml文件中，而xml解析 \u0026lt; 、\u0026gt;、\u0026lt;=、\u0026gt;= 时会出错，这时应该使用转义写法，如下\n   \u0026lt; \u0026lt;= \u0026gt; \u0026gt;= \u0026amp; ' \u0026quot;     \u0026amp;lt; \u0026amp;lt;= \u0026amp;gt; \u0026amp;gt;= \u0026amp;amp; \u0026amp;apos; \u0026amp;quot;    三、mybatis循环标签 3.1、循环查询in语句，代码如下\n \u0026lt;select id=\u0026quot;findBy\u0026quot; resultMap=\u0026quot;BaseResultMap\u0026quot;\u0026gt;\rselect * from user where user_id in\r\u0026lt;foreach item=\u0026quot;item\u0026quot; index=\u0026quot;index\u0026quot; collection=\u0026quot;list\u0026quot; open=\u0026quot;(\u0026quot; separator=\u0026quot;,\u0026quot; close=\u0026quot;)\u0026quot;\u0026gt;\r#{item}\r\u0026lt;/foreach\u0026gt;\r\u0026lt;/select\u0026gt;\r 3.2、批量插入使用循环,代码如下\n\u0026lt;insert id=\u0026quot;insertList\u0026quot; parameterType=\u0026quot;java.util.List\u0026quot;\u0026gt;\rinsert into user\r( name,sex,email,remark)\rvalues\r\u0026lt;foreach collection=\u0026quot;list\u0026quot; item=\u0026quot;item\u0026quot; index=\u0026quot;index\u0026quot; separator=\u0026quot;,\u0026quot;\u0026gt;\r(\r#{item.name},\r#{item.sex},\r#{item.email},\r#{item.remark}\r)\r\u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt;  四、重复的sql片段整合在一起使用include标签 定义：\r\u0026lt;sql id=\u0026quot;Base_Column_List\u0026quot; \u0026gt; id, name, url, priority, logo, img \u0026lt;/sql\u0026gt; 引用：\r\u0026lt;include refid=\u0026quot;Base_Column_List\u0026quot; /\u0026gt;  ————————————————\n更多详细的标签介绍可以看下这个大佬的文章，很详细了：\nhttps://blog.csdn.net/cwx397562/article/details/100334210\n","id":32,"section":"posts","summary":"转载 · 原文链接：https://blog.csdn.net/qw463800202/article/details/103221651 一、动","tags":["Mybatis"],"title":"Mybatis中Mapper标签总结大全","uri":"https://bluestaree.github.io/2020/04/mybatis%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%E6%B1%87%E6%80%BB/","year":"2020"},{"content":"  转载 · 原文链接：https://www.runoob.com/java/java8-new-features.html\n java 8 新特性 Java8 新增了非常多的特性，我们主要讨论以下几个：\n Lambda 表达式 − Lambda 允许把函数作为一个方法的参数（函数作为参数传递到方法中）。 方法引用 − 方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。 默认方法 − 默认方法就是一个在接口里面有了一个实现的方法。 新工具 − 新的编译工具，如：Nashorn引擎 jjs、 类依赖分析器jdeps。 Stream API −新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。 Date Time API − 加强对日期与时间的处理。 Optional 类 − Optional 类已经成为 Java 8 类库的一部分，用来解决空指针异常。 Nashorn, JavaScript 引擎 − Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用  先来看看排序方式的对比把\n// 使用 java 7 排序\rprivate void sortUsingJava7(List\u0026lt;String\u0026gt; names){ Collections.sort(names, new Comparator\u0026lt;String\u0026gt;() {\r@Override\rpublic int compare(String s1, String s2) {\rreturn s1.compareTo(s2);\r}\r});\r}\r// 使用 java 8 排序\rprivate void sortUsingJava8(List\u0026lt;String\u0026gt; names){\rCollections.sort(names, (s1, s2) -\u0026gt; s1.compareTo(s2));\r}\r 怎么样，是不是感觉代码简化了不少，让我们继续深入学习java8的那些新特性\nLambda 表达式实例 Lambda 表达式的简单例子:\n// 1. 不需要参数,返回值为 5 () -\u0026gt; 5 // 2. 接收一个参数(数字类型),返回其2倍的值 x -\u0026gt; 2 * x // 3. 接受2个参数(数字),并返回他们的差值 (x, y) -\u0026gt; x – y // 4. 接收2个int型整数,返回他们的和 (int x, int y) -\u0026gt; x + y // 5. 接受一个 string 对象,并在控制台打印,不返回任何值(看起来像是返回void) (String s) -\u0026gt; System.out.print(s)\r 使用 Lambda 表达式需要注意以下两点：\n Lambda 表达式主要用来定义行内执行的方法类型接口，例如，一个简单方法接口。在上面例子中，我们使用各种类型的Lambda表达式来定义MathOperation接口的方法。然后我们定义了sayMessage的执行。 Lambda 表达式免去了使用匿名方法的麻烦，并且给予Java简单但是强大的函数化的编程能力。  Java 8 方法引用 方法引用通过方法的名字来指向一个方法。\n方法引用可以使语言的构造更紧凑简洁，减少冗余代码。\n方法引用使用一对冒号 :: 。\n 构造器引用它的语法是Class::new，或者更一般的Class\u0026lt; T \u0026gt;::new实例如下：  final Car car = Car.create( Car::new );\rfinal List\u0026lt; Car \u0026gt; cars = Arrays.asList( car );\r  静态方法引用它的语法是Class::static_method，实例如下：  cars.forEach( Car::collide );\r  特定类的任意对象的方法引用它的语法是Class::method实例如下：  cars.forEach( Car::repair );\r  特定对象的方法引用它的语法是instance::method实例如下：  final Car police = Car.create( Car::new );\rcars.forEach( police::follow );\r Java 8 Stream Java 8 API添加了一个新的抽象称为流Stream，可以让你以一种声明的方式处理数据。\nStream 使用一种类似用 SQL 语句从数据库查询数据的直观方式来提供一种对 Java 集合运算和表达的高阶抽象。\nStream API可以极大提高Java程序员的生产力，让程序员写出高效率、干净、简洁的代码。\n这种风格将要处理的元素集合看作一种流， 流在管道中传输， 并且可以在管道的节点上进行处理， 比如筛选， 排序，聚合等。\n元素流在管道中经过中间操作（intermediate operation）的处理，最后由最终操作(terminal operation)得到前面处理的结果。\n生成流\n在 Java 8 中, 集合接口有两个方法来生成流：\n stream() − 为集合创建串行流。 parallelStream() − 为集合创建并行流。  List\u0026lt;String\u0026gt; strings = Arrays.asList(\u0026quot;abc\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;bc\u0026quot;, \u0026quot;efg\u0026quot;, \u0026quot;abcd\u0026quot;,\u0026quot;\u0026quot;, \u0026quot;jkl\u0026quot;);\rList\u0026lt;String\u0026gt; filtered = strings.stream().filter(string -\u0026gt; !string.isEmpty()).collect(Collectors.toList());\r  forEach\nStream 提供了新的方法 \u0026lsquo;forEach\u0026rsquo; 来迭代流中的每个数据。以下代码片段使用 forEach 输出了10个随机数：\nRandom random = new Random();\rrandom.ints().limit(10).forEach(System.out::println);\r  map\nmap 方法用于映射每个元素到对应的结果，以下代码片段使用 map 输出了元素对应的平方数：\nList\u0026lt;Integer\u0026gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\r// 获取对应的平方数\rList\u0026lt;Integer\u0026gt; squaresList = numbers.stream().map( i -\u0026gt; i*i).distinct().collect(Collectors.toList());\r  filter\nfilter 方法用于通过设置的条件过滤出元素。以下代码片段使用 filter 方法过滤出空字符串：\nList\u0026lt;String\u0026gt;strings = Arrays.asList(\u0026quot;abc\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;bc\u0026quot;, \u0026quot;efg\u0026quot;, \u0026quot;abcd\u0026quot;,\u0026quot;\u0026quot;, \u0026quot;jkl\u0026quot;);\r// 获取空字符串的数量\rlong count = strings.stream().filter(string -\u0026gt; string.isEmpty()).count();\r  limit\nlimit 方法用于获取指定数量的流。 以下代码片段使用 limit 方法打印出 10 条数据：\nRandom random = new Random();\rrandom.ints().limit(10).forEach(System.out::println);\r  sorted\nsorted 方法用于对流进行排序。以下代码片段使用 sorted 方法对输出的 10 个随机数进行排序：\nRandom random = new Random();\rrandom.ints().limit(10).sorted().forEach(System.out::println);\r  并行（parallel）程序\nparallelStream 是流并行处理程序的代替方法。以下实例我们使用 parallelStream 来输出空字符串的数量：\nList\u0026lt;String\u0026gt; strings = Arrays.asList(\u0026quot;abc\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;bc\u0026quot;, \u0026quot;efg\u0026quot;, \u0026quot;abcd\u0026quot;,\u0026quot;\u0026quot;, \u0026quot;jkl\u0026quot;);\r// 获取空字符串的数量\rint count = strings.parallelStream().filter(string -\u0026gt; string.isEmpty()).count();\r 我们可以很容易的在顺序运行和并行直接切换。\n Collectors\nCollectors 类实现了很多归约操作，例如将流转换成集合和聚合元素。Collectors 可用于返回列表或字符串：\nList\u0026lt;String\u0026gt; strings = Arrays.asList(\u0026quot;abc\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;bc\u0026quot;, \u0026quot;efg\u0026quot;, \u0026quot;abcd\u0026quot;,\u0026quot;\u0026quot;, \u0026quot;jkl\u0026quot;);\rList\u0026lt;String\u0026gt; filtered = strings.stream().filter(string -\u0026gt; !string.isEmpty()).collect(Collectors.toList());\rSystem.out.println(\u0026quot;筛选列表: \u0026quot; + filtered);\rString mergedString = strings.stream().filter(string -\u0026gt; !string.isEmpty()).collect(Collectors.joining(\u0026quot;, \u0026quot;));\rSystem.out.println(\u0026quot;合并字符串: \u0026quot; + mergedString);\r  统计\n另外，一些产生统计结果的收集器也非常有用。它们主要用于int、double、long等基本类型上，它们可以用来产生类似如下的统计结果。\nList\u0026lt;Integer\u0026gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\rIntSummaryStatistics stats = numbers.stream().mapToInt((x) -\u0026gt; x).summaryStatistics();\rSystem.out.println(\u0026quot;列表中最大的数 : \u0026quot; + stats.getMax());\rSystem.out.println(\u0026quot;列表中最小的数 : \u0026quot; + stats.getMin());\rSystem.out.println(\u0026quot;所有数之和 : \u0026quot; + stats.getSum());\rSystem.out.println(\u0026quot;平均数 : \u0026quot; + stats.getAverage());\r 默认方法 Java 8 新增了接口的默认方法。\n简单说，默认方法就是接口可以有实现方法，而且不需要实现类去实现其方法。\n我们只需在方法名前面加个 default 关键字即可实现默认方法。\n语法\n默认方法语法格式如下：\npublic interface Vehicle {\rdefault void print(){\rSystem.out.println(\u0026quot;我是一辆车!\u0026quot;);\r}\r}\r Java 8 函数式接口 函数式接口(Functional Interface)就是一个有且仅有一个抽象方法，但是可以有多个非抽象方法的接口。\n函数式接口可以被隐式转换为 lambda 表达式。\nLambda 表达式和方法引用（实际上也可认为是Lambda表达式）上。\n如定义了一个函数式接口如下：\n@FunctionalInterface\rinterface GreetingService {\rvoid sayMessage(String message);\r}\r 那么就可以使用Lambda表达式来表示该接口的一个实现(注：JAVA 8 之前一般是用匿名类实现的)：\nGreetingService greetService1 = message -\u0026gt; System.out.println(\u0026quot;Hello \u0026quot; + message);\r Java 8 Optional 类 Optional 类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。\nOptional 是个容器：它可以保存类型T的值，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测。\nOptional 类的引入很好的解决空指针异常。\n类方法    序号 方法 \u0026amp; 描述     1 static Optional empty() 返回空的 Optional 实例。   2 boolean equals(Object obj) 判断其他对象是否等于 Optional。   3 Optional filter(Predicate predicate) 如果值存在，并且这个值匹配给定的 predicate，返回一个Optional用以描述这个值，否则返回一个空的Optional。   4 Optional flatMap(Function\u0026gt; mapper) 如果值存在，返回基于Optional包含的映射方法的值，否则返回一个空的Optional   5 T get() 如果在这个Optional中包含这个值，返回值，否则抛出异常：NoSuchElementException   6 int hashCode() 返回存在值的哈希码，如果值不存在 返回 0。   7 void ifPresent(Consumer consumer) 如果值存在则使用该值调用 consumer , 否则不做任何事情。   8 boolean isPresent() 如果值存在则方法会返回true，否则返回 false。   9 Optional map(Function mapper) 如果有值，则对其执行调用映射函数得到返回值。如果返回值不为 null，则创建包含映射返回值的Optional作为map方法返回值，否则返回空Optional。   10 static Optional of(T value) 返回一个指定非null值的Optional。   11 static Optional ofNullable(T value) 如果为非空，返回 Optional 描述的指定值，否则返回空的 Optional。   12 T orElse(T other) 如果存在该值，返回值， 否则返回 other。   13 T orElseGet(Supplier other) 如果存在该值，返回值， 否则触发 other，并返回 other 调用的结果。   14 T orElseThrow(Supplier exceptionSupplier) 如果存在该值，返回包含的值，否则抛出由 Supplier 继承的异常   15 String toString() 返回一个Optional的非空字符串，用来调试    注意： 这些方法是从 java.lang.Object 类继承来的。\nJava 8 日期时间 API Java 8通过发布新的Date-Time API (JSR 310)来进一步加强对日期与时间的处理。\n在旧版的 Java 中，日期时间 API 存在诸多问题，其中有：\n 非线程安全 − java.util.Date 是非线程安全的，所有的日期类都是可变的，这是Java日期类最大的问题之一。 设计很差 − Java的日期/时间类的定义并不一致，在java.util和java.sql的包中都有日期类，此外用于格式化和解析的类在java.text包中定义。java.util.Date同时包含日期和时间，而java.sql.Date仅包含日期，将其纳入java.sql包并不合理。另外这两个类都有相同的名字，这本身就是一个非常糟糕的设计。 时区处理麻烦 − 日期类并不提供国际化，没有时区支持，因此Java引入了java.util.Calendar和java.util.TimeZone类，但他们同样存在上述所有的问题。  Java 8 在 java.time 包下提供了很多新的 API。以下为两个比较重要的 API：\n Local(本地) − 简化了日期时间的处理，没有时区的问题。 Zoned(时区) − 通过制定的时区处理日期时间。  新的java.time包涵盖了所有处理日期，时间，日期/时间，时区，时刻（instants），过程（during）与时钟（clock）的操作。\n本地化日期时间 API\nLocalDate/LocalTime 和 LocalDateTime 类可以在处理时区不是必须的情况。代码如下：\nJava8Tester.java 文件\nimport java.time.LocalDate;\rimport java.time.LocalTime;\rimport java.time.LocalDateTime;\rimport java.time.Month;\rpublic class Java8Tester {\rpublic static void main(String args[]){\rJava8Tester java8tester = new Java8Tester();\rjava8tester.testLocalDateTime();\r}\rpublic void testLocalDateTime(){\r// 获取当前的日期时间\rLocalDateTime currentTime = LocalDateTime.now();\rSystem.out.println(\u0026quot;当前时间: \u0026quot; + currentTime);\rLocalDate date1 = currentTime.toLocalDate();\rSystem.out.println(\u0026quot;date1: \u0026quot; + date1);\rMonth month = currentTime.getMonth();\rint day = currentTime.getDayOfMonth();\rint seconds = currentTime.getSecond();\rSystem.out.println(\u0026quot;月: \u0026quot; + month +\u0026quot;, 日: \u0026quot; + day +\u0026quot;, 秒: \u0026quot; + seconds);\rLocalDateTime date2 = currentTime.withDayOfMonth(10).withYear(2012);\rSystem.out.println(\u0026quot;date2: \u0026quot; + date2);\r// 12 december 2014\rLocalDate date3 = LocalDate.of(2014, Month.DECEMBER, 12);\rSystem.out.println(\u0026quot;date3: \u0026quot; + date3);\r// 22 小时 15 分钟\rLocalTime date4 = LocalTime.of(22, 15);\rSystem.out.println(\u0026quot;date4: \u0026quot; + date4);\r// 解析字符串\rLocalTime date5 = LocalTime.parse(\u0026quot;20:15:30\u0026quot;);\rSystem.out.println(\u0026quot;date5: \u0026quot; + date5);\r}\r}\r 执行以上脚本，输出结果为：\n$ javac Java8Tester.java $ java Java8Tester\r当前时间: 2016-04-15T16:55:48.668\rdate1: 2016-04-15\r月: APRIL, 日: 15, 秒: 48\rdate2: 2012-04-10T16:55:48.668\rdate3: 2014-12-12\rdate4: 22:15\rdate5: 20:15:30\r ","id":33,"section":"posts","summary":"转载 · 原文链接：https://www.runoob.com/java/java8-new-features.html java 8 新特性 Java8 新增了非常","tags":["jdk8"],"title":"JDK 8 的那些新特性","uri":"https://bluestaree.github.io/2020/04/jdk-8%E7%9A%84%E9%82%A3%E4%BA%9B%E6%96%B0%E7%89%B9%E6%80%A7/","year":"2020"},{"content":" 原反补的相互转换 今天在学习算法时遇到了这个问题，然后大脑就突然宕机。什么情况w(ﾟДﾟ)w！\n在此上网查询资料后记录下，\n 转载 · 原文链接：https://blog.csdn.net/chaochaoaiyuer/article/details/82868761\n 原码转反码\n 符号位不变，数值位按位取反  反码转原码\n 符号位不变，数值位按位取反  原码转补码\n  正数：正数的补码就是其本身。\n  负数：在原码的基础上，符号位不变，其余的各个位取反，最后+1.（反码+1）\n  补码转原码\n 符号位不变，数值位按位取反，末位再加１．即补码的补码等于原码，  已知补码，求原码的负数的补码\n 符号位和数值位都按位取反，末位再加１   总结：  计算机在进行减法时，都是在做加法运算。 正数原码、反码、补码是一样。 负数的反码，在原码的基础上，符号位不变，其余的各个位取反（1变0，0变1）。 负数的补码，就是反码+1.   ","id":34,"section":"posts","summary":"原反补的相互转换 今天在学习算法时遇到了这个问题，然后大脑就突然宕机。什么情况w(ﾟДﾟ)w！ 在此上网查询资料后记录下， 转载 · 原文链接：htt","tags":null,"title":"原码、反码和补码","uri":"https://bluestaree.github.io/2020/04/%E5%8E%9F%E7%A0%81%E5%8F%8D%E7%A0%81%E8%A1%A5%E7%A0%81/","year":"2020"},{"content":"  转载 · 原文链接：https://www.codesheep.cn/2018/09/04/springboot-startup-process/\n 结合 SpringBoot 2.0的源码，来看看SpringBoot应用程序的启动流程！\n概述 说到接触 SpringBoot 伊始，给我第一映像最深的是有两个关键元素：\n对照上面的典型代码，这个两个元素分别是：\n @SpringBootApplication SpringApplication 以及 run() 方法  那么本文我们就来看看这个 SpringApplication 以及 run() 方法 到底是个什么鬼，它背后又隐藏了哪些奥秘呢？\n SpringApplication 惊鸿一瞥 SpringApplication 这个类应该算是 SpringBoot 框架 的“创新”产物了，原始的 Spring中并没有这个类，SpringApplication 里面封装了一套 Spring 应用的启动流程，然而这对用户完全透明，因此我们上手 SpringBoot 时感觉简洁、轻量。\n一般来说默认的 SpringApplication 执行流程已经可以满足大部分需求，但是 若用户想干预这个过程，则可以通过 SpringApplication 在流程某些地方开启的 扩展点 来完成对流程的扩展，典型的扩展方案那就是使用 set 方法。\n我们来举一个栗子，把我们天天司空见惯的 SpringBoot 应用的启动类来拆解一下写出来：\n@SpringBootApplication\rpublic class CodeSheepApplication {\rpublic static void main( String[] args ) {\r// SpringApplication.run( CodeSheepApplication.class args ); // 这是传统SpringBoot应用的启动，一行代码搞定，内部默认做了很多事\rSpringApplication app = new SpringApplication( CodeSheepApplication.class );\rapp.setXXX( ... ); // 用户自定的扩展在此 ！！！\rapp.run( args );\r}\r}\r 这样一拆解后我们发现，我们也需要先构造 SpringApplication 类对象，然后调用该对象的 run() 方法。那么接下来就讲讲 SpringApplication 的构造过程 以及其 run() 方法的流程，搞清楚了这个，那么也就搞清楚了SpringBoot应用是如何运行起来的！\n SpringApplication 实例的初始化 我们对照代码来看：\n四个关键的步骤已标注在图中，分别解释如下：\n ① 推断应用的类型：创建的是 REACTIVE应用、SERVLET应用、NONE 三种中的某一种   ② 使用 SpringFactoriesLoader查找并加载 classpath下 META-INF/spring.factories文件中所有可用的 ApplicationContextInitializer   ③ 使用 SpringFactoriesLoader查找并加载 classpath下 META-INF/spring.factories文件中的所有可用的 ApplicationListener   ④ 推断并设置 main方法的定义类    SpringApplication 的run()方法探秘 先看看代码长啥样子：\n各个主要步骤我已经标注在上图之中了，除此之外，我也按照自己的理解画了一个流程图如下所示，可以对照数字标示看一下：\n我们将各步骤总结精炼如下：\n 通过 SpringFactoriesLoader 加载 META-INF/spring.factories 文件，获取并创建 SpringApplicationRunListener 对象 然后由 SpringApplicationRunListener 来发出 starting 消息 创建参数，并配置当前 SpringBoot 应用将要使用的 Environment 完成之后，依然由 SpringApplicationRunListener 来发出 environmentPrepared 消息 创建 ApplicationContext 初始化 ApplicationContext，并设置 Environment，加载相关配置等 由 SpringApplicationRunListener 来发出 contextPrepared 消息，告知SpringBoot 应用使用的 ApplicationContext 已准备OK 将各种 beans 装载入 ApplicationContext，继续由 SpringApplicationRunListener 来发出 contextLoaded 消息，告知 SpringBoot 应用使用的 ApplicationContext 已装填OK refresh ApplicationContext，完成IoC容器可用的最后一步 由 SpringApplicationRunListener 来发出 started 消息 完成最终的程序的启动 由 SpringApplicationRunListener 来发出 running 消息，告知程序已运行起来了至此，全流程结束！  ","id":35,"section":"posts","summary":"转载 · 原文链接：https://www.codesheep.cn/2018/09/04/springboot-startup-process","tags":["Spring Boot"],"title":"SpringBoot应用程序启动过程","uri":"https://bluestaree.github.io/2020/04/springboot%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/","year":"2020"},{"content":"  转载 · 原文链接：https://www.codesheep.cn/2018/07/30/at-SpringBootApplication-zhujie/\n 概 述 我们在开发基于 SpringBoot 的应用时，用到了一些新的注解和类，正式由于其存在，才让JavaEE的开发如鱼得水。这其中我们用的最多的注解之一，当属 SpringBoot 应用启动类上的 @SpringBootApplication 注解了\n本文就来看看它到底是个啥！\n@SpringBootApplication 背后到底是什么？ @SpringBootApplication注解实际上是SpringBoot提供的一个复合注解，我们来看一看其源码：\n@Target(ElementType.TYPE)\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\r@Inherited\r@SpringBootConfiguration\r@EnableAutoConfiguration\r@ComponentScan(excludeFilters = {\r@Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),\r@Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })\rpublic @interface SpringBootApplication {\r...\r}\r 看得很清楚，其是一个合成体，但其中最重要的三个注解分别是：\n @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan  我们不妨称其为 “ 三体结构 ” 吧！\n如果我们不怕麻烦，在 SpringBoot 应用的启动类上用这个三个注解代替@SpringBootApplication 注解发现也是没问题的：\n@SpringBootConfiguration\r@EnableAutoConfiguration\r@ComponentScan\rpublic class TestSpringBootApplication {\r...\r}\r 下面分别剖析一下这三个注解的功效！\n  @SpringBootConfiguration 看代码吧，代码里是这样写的：\n@Target(ElementType.TYPE)\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\r@Configuration\rpublic @interface SpringBootConfiguration {\r}\r 这说明 @SpringBootConfiguration 也是来源于 @Configuration，二者功能都是将当前类标注为配置类，并将当前类里以 @Bean 注解标记的方法的实例注入到srping容器中，实例名即为方法名。\n至于@Configuration，我想在非SpringBoot时代大家应该不陌生吧，作用是配置Spring容器，也即 JavaConfig 形式的 Spring IoC 容器的配置类所使用。\n到目前来看，好像还没有什么新东西！！！\n  @EnableAutoConfiguration 再继续看代码，代码是这样的：\n@Target(ElementType.TYPE)\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\r@Inherited\r@AutoConfigurationPackage\r@Import(AutoConfigurationImportSelector.class)\rpublic @interface EnableAutoConfiguration {\r...\r}\r @EnableAutoConfiguration 注解启用自动配置，其可以帮助 SpringBoot 应用将所有符合条件的 @Configuration 配置都加载到当前 IoC 容器之中，可以简要用图形示意如下：\n@EnableAutoConfiguration 幕后的组件调用关系\n接下来我们对照源码，来解释一下这个流程：\n @EnableAutoConfiguration 借助 AutoConfigurationImportSelector 的帮助，而后者通过实现 selectImports() 方法来导出 Configuration  selectImports()\n AutoConfigurationImportSelector 类的 selectImports() 方法里面通过调用Spring Core 包里 SpringFactoriesLoader 类的 loadFactoryNames() 方法  SpringFactoriesLoader.loadFactoryNames()\n 最终通过 SpringFactoriesLoader.loadFactoryNames() 读取了 ClassPath 下面的 META-INF/spring.factories 文件来获取所有导出类。  而spring.factories 文件里关于 EnableAutoConfiguration 的配置其实就是一个键值对结构，样子大概长下面这样：\nspring.factories\n说了这么多，如果从稍微宏观一点的角度 概括总结 上述这一过程那就是：\n从 ClassPath下扫描所有的 META-INF/spring.factories 配置文件，并将spring.factories 文件中的 EnableAutoConfiguration 对应的配置项通过反射机制实例化为对应标注了 @Configuration 的形式的IoC容器配置类，然后注入IoC容器。\n@ComponentScan\n@ComponentScan 对应于XML配置形式中的 context:component-scan，用于将一些标注了特定注解的bean定义批量采集注册到Spring的IoC容器之中，这些特定的注解大致包括：\n @Controller @Entity @Component @Service @Repository  等等\n对于该注解，还可以通过 basePackages 属性来更细粒度的控制该注解的自动扫描范围，比如：\n@ComponentScan(basePackages = {\u0026quot;cn.codesheep.controller\u0026quot;,\u0026quot;cn.codesheep.entity\u0026quot;})\r 可见 这个注解也并不是什么新东西！\n","id":36,"section":"posts","summary":"转载 · 原文链接：https://www.codesheep.cn/2018/07/30/at-SpringBootApplication-z","tags":["Spring Boot"],"title":"@SpringBootApplication注解","uri":"https://bluestaree.github.io/2020/04/springbootapplication%E6%B3%A8%E8%A7%A3/","year":"2020"},{"content":" 查看当前所有镜像\ndocker images\n查看所有容器\ndocker ps -a\n根据一个镜像创建一个容器并运行 (windows环境)\ndocker run -d \u0026ndash;name mysql_3308 -e MYSQL_ROOT_HOST=% -e MYSQL_ROOT_PASSWORD=tdt123 -p 3307:3306 -v //f/docker/mysql_3308:/var/lib/mysql mysql:5.5\n \u0026ndash;name mysql_3308 \u0026hellip; mysql:5.5 设置容器名，及选用镜像（如果没有tag即5.5，则会自动下载最新版的mysql） -e MYSQL_ROOT_HOST=% 允许远程登录 -e MYSQL_ROOT_PASSWORD=123456 root登录密码 -p 3308:3306 端口映射至宿主机3308 -d 后台运行容器，并返回容器ID； -v //f/docker/mysql_3308:/var/lib/mysql 绑定镜像位置到宿主机上 \u0026ndash;lower_case_table_names=1 不区分大小写   其他栗子\ndocker run \u0026ndash;name mysql -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -v //e/docker/share/mysql_3306:/var/lib/mysql mysql\ndocker create \u0026ndash;name tracker \u0026ndash;net host -v //e/docker/data/tracker:/var/fdfs delron/fastdfs tracker\ndocker create \u0026ndash;name es -p 9200:9200 -p 9300:9300 -e \u0026ldquo;discovery.type=single-node\u0026rdquo; -v //e/docker/es/data/:/usr/share/elasticsearch/data elasticsearch:6.5.4\ndocker create \u0026ndash;name kibana -p 5601:5601 -v //e/docker/es/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml kibana:6.5.4\ndocker create \u0026ndash;name redis -p 6379:6379 -v //e/docker/redis/data:/data redis:5.0.2\n复制当前目录文件至指定容器位置\ndocker cp elasticsearch-analysis-ik-6.5.4.zip es:/usr/share/elasticsearch/plugins/\n启动容器并显示启动日志\ndocker start rabbitmq \u0026amp;\u0026amp; docker logs -f rabbitmq\n进入容器\ndocker exec -it 775c7c9ee1e1 /bin/bash (进入容器控制台)\n 775c7c9ee1e1 为容器ID  查看容器信息\ndokcer inspect 容器名\n查找文件\nfind / -name tracker.conf\n保存镜像文件\ndocker save\ndocker save -o python_3.tar python:3\n加载镜像文件\ndocker load\ndocker load -i python_3.tar\n-\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\n","id":37,"section":"posts","summary":"查看当前所有镜像 docker images 查看所有容器 docker ps -a 根据一个镜像创建一个容器并运行 (windows环境) docker run -d \u0026ndash;name mysql_3308 -e MYSQL_ROOT_HOST=% -e MYSQL_ROOT_PASSWORD=tdt123 -p 3307:3306 -v //f/docker/mysql_3308:/var/lib/mysql mysql:5.5 \u0026ndash;name mysql_3308 \u0026hellip; mysql:5.5 设置容器名，及","tags":["docker"],"title":"Docker常用命令","uri":"https://bluestaree.github.io/2020/04/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","year":"2020"},{"content":"  转载 · 原文链接：SpringBoot应用部署于外置Tomcat容器\n 0x01. 概述 SpringBoot平时我们用的爽歪歪，爽到它自己连Tomcat都自集成了，我们可以直接编写SBT启动类，然后一键开启内置的Tomcat容器服务，确实是很好上手。但考虑到实际的情形中，我们的Tomcat服务器一般是另外部署好了的，有专门的维护方式。此时我们需要剥离掉SBT应用内置的Tomcat服务器，进而将应用发布并部署到外置的Tomcat容器之中，本文就实践一下这个。\n0x02. 修改打包方式 修改项目的pom.xml配置，我们修改其打包方式为war方式，如：\n\u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;demo\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt;\r\u0026lt;packaging\u0026gt;war\u0026lt;/packaging\u0026gt;\r  0x03. 移除SBT自带的嵌入式Tomcat 修改pom.xml，从maven的pom中移除springboot自带的的嵌入式tomcat插件\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt;\r\u0026lt;!-- 移除嵌入式tomcat插件 --\u0026gt;\r\u0026lt;exclusions\u0026gt;\r\u0026lt;exclusion\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-tomcat\u0026lt;/artifactId\u0026gt;\r\u0026lt;/exclusion\u0026gt;\r\u0026lt;/exclusions\u0026gt;\r\u0026lt;/dependency\u0026gt;\r  0x04. 添加servlet-api依赖 修改pom.xml，在maven的pom中添加servlet-api的依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;javax.servlet-api\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r  0x05. 修改启动类，并重写初始化方法 在SpringBoot中我们平常用main方法启动的方式，都有一个SpringBootApplication的启动类，类似代码如下：\n@SpringBootApplication\rpublic class Application {\rpublic static void main(String[] args) {\rSpringApplication.run(Application.class, args);\r}\r}\r 而我们现在需要类似于web.xml的配置方式来启动spring应用，为此，我们在Application类的同级添加一个SpringBootStartApplication类，其代码如下:\n// 修改启动类，继承 SpringBootServletInitializer 并重写 configure 方法\rpublic class SpringBootStartApplication extends SpringBootServletInitializer {\r@Override\rprotected SpringApplicationBuilder configure(SpringApplicationBuilder builder) {\r// 注意这里一定要指向原先用main方法执行的Application启动类\rreturn builder.sources(Application.class);\r}\r}\r  0x06. 部署到外部的Tomcat容器并验证  在项目根目录下（即包含pom.xml的目录）记性maven打包操作：  mvn clean package\r 等待打包完成，出现 [INFO] BUILD SUCCESS 即为打包成功\n 然后我们把target目录下生成的war包放到tomcat的webapps目录下，启动tomcat，即可自动解压部署。  最后在浏览器中验证:\nhttp://YOUR_IP:[端口号]/[打包项目名]\r ","id":38,"section":"posts","summary":"转载 · 原文链接：SpringBoot应用部署于外置Tomcat容器 0x01. 概述 SpringBoot平时我们用的爽歪歪，爽到它自己连Tomcat都自","tags":["Spring Boot"],"title":"SpringBoot应用部署于外置Tomcat容器","uri":"https://bluestaree.github.io/2020/04/springboot%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2%E4%BA%8E%E5%A4%96%E7%BD%AEtomcat%E5%AE%B9%E5%99%A8/","year":"2020"}],"tags":[{"title":"docker","uri":"https://bluestaree.github.io/tags/docker/"},{"title":"equals","uri":"https://bluestaree.github.io/tags/equals/"},{"title":"Gradle","uri":"https://bluestaree.github.io/tags/gradle/"},{"title":"hashCode","uri":"https://bluestaree.github.io/tags/hashcode/"},{"title":"hibernate","uri":"https://bluestaree.github.io/tags/hibernate/"},{"title":"jdk8","uri":"https://bluestaree.github.io/tags/jdk8/"},{"title":"Maven","uri":"https://bluestaree.github.io/tags/maven/"},{"title":"Mybatis","uri":"https://bluestaree.github.io/tags/mybatis/"},{"title":"Nacos","uri":"https://bluestaree.github.io/tags/nacos/"},{"title":"Netty","uri":"https://bluestaree.github.io/tags/netty/"},{"title":"redisson","uri":"https://bluestaree.github.io/tags/redisson/"},{"title":"Seata","uri":"https://bluestaree.github.io/tags/seata/"},{"title":"Sentinel","uri":"https://bluestaree.github.io/tags/sentinel/"},{"title":"Spring Boot","uri":"https://bluestaree.github.io/tags/spring-boot/"},{"title":"Spring Cache","uri":"https://bluestaree.github.io/tags/spring-cache/"},{"title":"SpringSecurity","uri":"https://bluestaree.github.io/tags/springsecurity/"},{"title":"缓存","uri":"https://bluestaree.github.io/tags/%E7%BC%93%E5%AD%98/"}]}