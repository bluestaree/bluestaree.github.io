{"categories":[{"title":"charles","uri":"https://bluestaree.github.io/categories/charles/"},{"title":"elasticsearch","uri":"https://bluestaree.github.io/categories/elasticsearch/"},{"title":"Idea","uri":"https://bluestaree.github.io/categories/idea/"},{"title":"milvus","uri":"https://bluestaree.github.io/categories/milvus/"},{"title":"Netty","uri":"https://bluestaree.github.io/categories/netty/"},{"title":"nginx","uri":"https://bluestaree.github.io/categories/nginx/"},{"title":"rabbitmq","uri":"https://bluestaree.github.io/categories/rabbitmq/"},{"title":"redis","uri":"https://bluestaree.github.io/categories/redis/"},{"title":"Spring Boot","uri":"https://bluestaree.github.io/categories/spring-boot/"},{"title":"Spring Cloud Alibaba","uri":"https://bluestaree.github.io/categories/spring-cloud-alibaba/"},{"title":"spring-security","uri":"https://bluestaree.github.io/categories/spring-security/"},{"title":"笔记","uri":"https://bluestaree.github.io/categories/%E7%AC%94%E8%AE%B0/"}],"posts":[{"content":" JAVA实现图片转PDF文件  转载文章：https://www.freesion.com/article/40861570631/\n 今天记录个小知识点，主要是将图片转为pdf文档。 首先引入依赖：\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.itextpdf\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;itextpdf\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;5.5.13\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 依赖版本大家可以自己看着用，没有做过太多了解。 代码如下：\npublic static void main(String[] arg){\rimgOfPdf();\r}\rpublic static void imgOfPdf() {\rtry {\r//创建个存放图片地址的集合\rList\u0026lt;String\u0026gt; imageUrlList = new ArrayList();\r//添加图片地址到集合\rimageUrlList.add(\u0026quot;C:\\\\Users\\\\Lenovo\\\\Pictures\\\\Saved Pictures\\\\123.jpg\u0026quot;);\r//存放pdf文件的路径\rString pdfUrl = \u0026quot;D:\\\\123.pdf\u0026quot;;\rFile file = PdfUtilImg.pdf(imageUrlList, pdfUrl);//生成pdf\rfile.createNewFile();\r} catch (IOException e) {\re.printStackTrace();\r}\r}\r 上面代码中可以将集合和存放pdf地址当做参数传进来，这里我是直接写死的，也就不用做图片是否存在的校验了。校验步骤可以在使用此方法前完成。\nOK，接下来是我们的主菜：\npublic static File pdf(List\u0026lt;String\u0026gt; imageUrllist, String pdfUrl) {\r//new一个pdf文档\rDocument doc = new Document(PageSize.A4, 20, 20, 20, 20); try {\r//pdf写入\rPdfWriter.getInstance(doc, new FileOutputStream(pdfUrl));\r//打开文档\rdoc.open();\r//遍历集合，将图片放在pdf文件\rfor (int i = 0; i \u0026lt; imageUrllist.size(); i++) {\r//在pdf创建一页 主：此处为每一张图片是pdf文件的一页\rdoc.newPage(); //通过文件路径获取image\rImage png1 = Image.getInstance(imageUrllist.get(i));\rfloat heigth = png1.getHeight();\rfloat width = png1.getWidth();\rint percent = getPercent2(heigth, width);\rpng1.setAlignment(Image.MIDDLE);\r// 表示是原来图像的比例;\rpng1.scalePercent(percent+3);\rdoc.add(png1);\r}\rdoc.close();\r} catch (FileNotFoundException e) {\re.printStackTrace();\r} catch (DocumentException e) {\re.printStackTrace();\r} catch (IOException e) {\re.printStackTrace();\r}\r//输出流\rFile mOutputPdfFile = new File(pdfUrl); if (!mOutputPdfFile.exists()) {\rmOutputPdfFile.deleteOnExit();\rreturn null;\r}\r//反回文件输出流\rreturn mOutputPdfFile;\r}\rpublic static int getPercent(float h, float w) {\rint p = 0;\rfloat p2 = 0.0f;\rif (h \u0026gt; w) {\rp2 = 297 / h * 100;\r} else {\rp2 = 210 / w * 100;\r}\rp = Math.round(p2);\rreturn p;\r}\rpublic static int getPercent2(float h, float w) {\rint p = 0;\rfloat p2 = 0.0f;\rp2 = 530 / w * 100;\rp = Math.round(p2);\rreturn p;\r}\r 代码到此结束\n","id":0,"section":"posts","summary":"JAVA实现图片转PDF文件 转载文章：https://www.freesion.com/article/40861570631/ 今天记录个小","tags":null,"title":"JAVA实现图片转PDF文件","uri":"https://bluestaree.github.io/2023/07/java%E5%AE%9E%E7%8E%B0%E5%9B%BE%E7%89%87%E8%BD%ACpdf%E6%96%87%E4%BB%B6/","year":"2023"},{"content":"  最近在项目测试中发现一个问题，在xxljob 中设置得 0点定时任务，到点后xxljob后台显示调用成功。但服务端后台却\u0026rsquo;未执行\u0026rsquo; ： 服务器没有打印执行中得日志信息（任务未另外开启异步线程调用）\n 查看服务日志，发现当天最早的日志记录如下，没有error错误日志打印，说明没有抛异常\n登录xxljob后台查看调度日志\n对应执行日志：\n这就有点奇怪了 ，正常情况这里应该会有一些执行日志信息\n再来查看记录，按日志关键字搜索，发现了不对劲的地方，执行时间应该是0点执行，提前了1分30秒左右\n问题原因：\nxxljob所在服务器 与 任务执行器服务时间不同，\n调度器服务器时间：\nxxljob服务器时间：\n解决:\n更新调度器 服务时间：\n校准时间命令\rntpdate cn.pool.ntp.org\r如果没有权限：\rsudo -i\r操作完成之后，查看时间是否准确\rdate\r 12-22号更新\n在矫正时间后，过了一天 继续检查服务器时间，发现依旧存在偏移，\n尝试修改其他配置：\n12-23号更新\n还是出现了时间偏移情况，改用定时任务方式，定时校验时间\ncrontab -e\r# 添加定时任务\r# 0 */1 * * * /sbin/ntpdate cn.pool.ntp.org #每隔一个小时同步一次\r30 23 * * * /sbin/ntpdate cn.pool.ntp.org #每晚的23:30同步一次\r 12-26号更新\n零点定时任务执行正常\n","id":1,"section":"posts","summary":"最近在项目测试中发现一个问题，在xxljob 中设置得 0点定时任务，到点后xxljob后台显示调用成功。但服务端后台却\u0026rsquo;未执行\u0026r","tags":null,"title":"xxljob调用成功却'未执行任务'?","uri":"https://bluestaree.github.io/2023/06/xxljob%E8%B0%83%E7%94%A8%E6%88%90%E5%8A%9F%E5%8D%B4%E6%9C%AA%E6%89%A7%E8%A1%8C%E4%BB%BB%E5%8A%A1/","year":"2023"},{"content":"  需求 ​\t根据用户输入的关键词进行短语匹配后，全匹配的数据要排在前面，其次是分词后匹配的数据，然后是部分分词匹配的数据（单个字的分词匹配度 需要低于 词组分词匹配度），最后这些数据要根据人均消费进行排序\n创建索引 用到了ik分词器\nPUT /local_shop1\r{\r\u0026quot;settings\u0026quot;: {\r\u0026quot;analysis\u0026quot;: {\r\u0026quot;filter\u0026quot;: {\r\u0026quot;len\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;length\u0026quot;,\r\u0026quot;min\u0026quot;: 2\r}\r},\r\u0026quot;analyzer\u0026quot;: {\r\u0026quot;ik_smart_filter_length_less_2\u0026quot;: {\r\u0026quot;tokenizer\u0026quot;: \u0026quot;ik_smart\u0026quot;,\r\u0026quot;filter\u0026quot;: [\r\u0026quot;len\u0026quot;\r]\r}\r}\r}\r}\r,\r\u0026quot;mappings\u0026quot; : {\r\u0026quot;properties\u0026quot; : {\r\u0026quot;cost\u0026quot; : {\r\u0026quot;type\u0026quot; : \u0026quot;double\u0026quot;\r},\r\u0026quot;shopName\u0026quot; : {\r\u0026quot;type\u0026quot; : \u0026quot;text\u0026quot;,\r\u0026quot;analyzer\u0026quot; : \u0026quot;ik_max_word\u0026quot;\r}\r}\r}\r}\r  这里使用到了自定义分词器， 在ik_smart的基础上 添加Token Length Filter，主要是为了控制分词最小粒度，其效果如下（模拟用户输错情况）：\n # 使用ik_smart\rGET local_shop1/_analyze\r{\r\u0026quot;analyzer\u0026quot; : \u0026quot;ik_smart_filter_length_less_2\u0026quot;,\r\u0026quot;text\u0026quot; : \u0026quot;八合里海记速我配牛肉\u0026quot;\r} # 结果:\r{\r\u0026quot;tokens\u0026quot; : [\r{\r\u0026quot;token\u0026quot; : \u0026quot;八合里\u0026quot;,\r\u0026quot;start_offset\u0026quot; : 0,\r\u0026quot;end_offset\u0026quot; : 3,\r\u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\r\u0026quot;position\u0026quot; : 0\r},\r{\r\u0026quot;token\u0026quot; : \u0026quot;牛肉\u0026quot;,\r\u0026quot;start_offset\u0026quot; : 8,\r\u0026quot;end_offset\u0026quot; : 10,\r\u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\r\u0026quot;position\u0026quot; : 6\r}\r]\r}\r# 使用自定义分词器\rGET my_test_index/_analyze\r{\r\u0026quot;analyzer\u0026quot; : \u0026quot;ik_smart_filter_length_less_2\u0026quot;,\r\u0026quot;text\u0026quot; : \u0026quot;八合里海记速我配牛肉\u0026quot;\r} # 结果:\r{\r\u0026quot;tokens\u0026quot; : [\r{\r\u0026quot;token\u0026quot; : \u0026quot;八合里\u0026quot;,\r\u0026quot;start_offset\u0026quot; : 0,\r\u0026quot;end_offset\u0026quot; : 3,\r\u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\r\u0026quot;position\u0026quot; : 0\r},\r{\r\u0026quot;token\u0026quot; : \u0026quot;海\u0026quot;,\r\u0026quot;start_offset\u0026quot; : 3,\r\u0026quot;end_offset\u0026quot; : 4,\r\u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\r\u0026quot;position\u0026quot; : 1\r},\r{\r\u0026quot;token\u0026quot; : \u0026quot;记\u0026quot;,\r\u0026quot;start_offset\u0026quot; : 4,\r\u0026quot;end_offset\u0026quot; : 5,\r\u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\r\u0026quot;position\u0026quot; : 2\r},\r{\r\u0026quot;token\u0026quot; : \u0026quot;速\u0026quot;,\r\u0026quot;start_offset\u0026quot; : 5,\r\u0026quot;end_offset\u0026quot; : 6,\r\u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\r\u0026quot;position\u0026quot; : 3\r},\r{\r\u0026quot;token\u0026quot; : \u0026quot;我\u0026quot;,\r\u0026quot;start_offset\u0026quot; : 6,\r\u0026quot;end_offset\u0026quot; : 7,\r\u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\r\u0026quot;position\u0026quot; : 4\r},\r{\r\u0026quot;token\u0026quot; : \u0026quot;配\u0026quot;,\r\u0026quot;start_offset\u0026quot; : 7,\r\u0026quot;end_offset\u0026quot; : 8,\r\u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\r\u0026quot;position\u0026quot; : 5\r},\r{\r\u0026quot;token\u0026quot; : \u0026quot;牛肉\u0026quot;,\r\u0026quot;start_offset\u0026quot; : 8,\r\u0026quot;end_offset\u0026quot; : 10,\r\u0026quot;type\u0026quot; : \u0026quot;CN_WORD\u0026quot;,\r\u0026quot;position\u0026quot; : 6\r}\r]\r}\r 查询语句 POST /local_shop1/_doc/_search\r{\r\u0026quot;query\u0026quot;: {\r\u0026quot;function_score\u0026quot;: {\r\u0026quot;query\u0026quot;: {\r\u0026quot;bool\u0026quot;: {\r\u0026quot;must\u0026quot;: [\r{\r\u0026quot;match\u0026quot;: {\r\u0026quot;shopName\u0026quot;: {\r\u0026quot;query\u0026quot;: \u0026quot;八合里海记速我配牛肉\u0026quot;\r}\r}\r}\r]\r}\r},\r\u0026quot;functions\u0026quot;: [\r{\r\u0026quot;filter\u0026quot;: {\r\u0026quot;match_phrase\u0026quot;: {\r\u0026quot;shopName\u0026quot;: {\r\u0026quot;query\u0026quot;: \u0026quot;八合里海记速我配牛肉\u0026quot;\r}\r}\r},\r\u0026quot;weight\u0026quot;: 2\r},\r{\r\u0026quot;filter\u0026quot;: {\r\u0026quot;match_phrase\u0026quot;: {\r\u0026quot;shopName\u0026quot;: {\r\u0026quot;query\u0026quot;: \u0026quot;八合里海记速我配牛肉\u0026quot;,\r\u0026quot;slop\u0026quot;: 4\r}\r}\r},\r\u0026quot;weight\u0026quot;: 2\r},\r{\r\u0026quot;filter\u0026quot;: {\r\u0026quot;match_phrase\u0026quot;: {\r\u0026quot;shopName\u0026quot;: {\r\u0026quot;query\u0026quot;: \u0026quot;八合里海记速我配牛肉\u0026quot;,\r\u0026quot;slop\u0026quot;: 10\r}\r}\r},\r\u0026quot;weight\u0026quot;: 2\r},\r{\r\u0026quot;filter\u0026quot;: {\r\u0026quot;match\u0026quot;: {\r\u0026quot;shopName\u0026quot;: {\r\u0026quot;query\u0026quot;: \u0026quot;八合里海记速我配牛肉\u0026quot;,\r\u0026quot;minimum_should_match\u0026quot;: \u0026quot;2\u0026quot;\r}\r}\r},\r\u0026quot;weight\u0026quot;: 2\r},\r{\r\u0026quot;filter\u0026quot;: {\r\u0026quot;match\u0026quot;: {\r\u0026quot;shopName\u0026quot;: {\r\u0026quot;query\u0026quot;: \u0026quot;八合里海记速我配牛肉\u0026quot;\r}\r}\r},\r\u0026quot;weight\u0026quot;: 2\r} ,\r{\r\u0026quot;filter\u0026quot;: {\r\u0026quot;match\u0026quot;: {\r\u0026quot;shopName\u0026quot;: {\r\u0026quot;query\u0026quot;: \u0026quot;八合里海记速我配牛肉\u0026quot;,\r\u0026quot;analyzer\u0026quot; : \u0026quot;ik_smart_filter_length_less_2\u0026quot;,\r\u0026quot;minimum_should_match\u0026quot;: \u0026quot;2\u0026quot;\r}\r}\r},\r\u0026quot;weight\u0026quot;: 2\r}\r],\r\u0026quot;boost_mode\u0026quot;: \u0026quot;replace\u0026quot;\r}\r},\r\u0026quot;sort\u0026quot;: [\r{\r\u0026quot;_score\u0026quot;: {\r\u0026quot;order\u0026quot;: \u0026quot;desc\u0026quot;\r}\r},\r{\r\u0026quot;cost\u0026quot;: { \u0026quot;order\u0026quot;: \u0026quot;desc\u0026quot; }\r}\r]\r}\r 使用functions 结合filter，每满足一个条件都会将结果得分乘2。\n这里指定 boost_mode = replace ，最终得分将替换掉 原match计算的得分。 默认为（最终的分 = 原匹配得分 * functions得分)\n结果 ","id":2,"section":"posts","summary":"需求 ​ 根据用户输入的关键词进行短语匹配后，全匹配的数据要排在前面，其次是分词后匹配的数据，然后是部分分词匹配的数据（单个字的分词匹配度 需要低","tags":["Elasticsearch"],"title":"Elasticsearch 多排序条件搜索","uri":"https://bluestaree.github.io/2023/05/elasticsearch-%E5%A4%9A%E6%8E%92%E5%BA%8F%E6%9D%A1%E4%BB%B6%E6%90%9C%E7%B4%A2/","year":"2023"},{"content":" Elasticsearch 搜索优化 概述 ​\t在使用ES一段时间后，发现搜索结果有的时候不太理想，因为默认搜索结果是按分词权重计算排序（关键词命中多且文本内容少的排名往往靠前），而在实际场景中往往需要基于一些业务来影响该得分：就比如需要根据用户输入的关键词获取结果，并按距离进行排序\nfunction_score 在官方文档 - 越近越好这篇文章中，说的就是如何实现通过距离影响计算得分。这里需要使用function_score查询，并配置其中 衰减函数（decay functions）。\nfunction_score查询有三种衰减函数—— linear 、 exp 和 gauss （线性、指数和高斯函数），它们可以操作数值、时间以及经纬度地理坐标点这样的字段。所有三个函数都能接受以下参数：\r- origin\r中心点 或字段可能的最佳值，落在原点 origin 上的文档评分 _score 为满分 1.0 。\r- scale\r衰减率，即一个文档从原点 origin 下落时，评分 _score 改变的速度。（例如，每 £10 欧元或每 100 米）。\r- decay\r从原点 origin 衰减到 scale 所得的评分 _score ，默认值为 0.5 。\r- offset\r以原点 origin 为中心点，为其设置一个非零的偏移量 offset 覆盖一个范围，而不只是单个原点。在范围 -offset \u0026lt;= origin \u0026lt;= +offset 内的所有评分 _score 都是 1.0 。\r 官方文档写的还是挺详细的，还有一个衰减函数曲线图解，这里就不再过多说明了。\n文档地址：https://www.elastic.co/guide/cn/elasticsearch/guide/current/decay-functions.html\n实现 构建查询条件\nPOST /shop/_doc/_search\r{\r\u0026quot;query\u0026quot;: {\r\u0026quot;function_score\u0026quot;: {\r\u0026quot;query\u0026quot;: {\r\u0026quot;bool\u0026quot;: {\r\u0026quot;should\u0026quot;: [\r{\r\u0026quot;match_phrase\u0026quot;: {\r\u0026quot;shopName\u0026quot;: {\r\u0026quot;query\u0026quot;: \u0026quot;苹果有线耳机\u0026quot;,\r\u0026quot;boost\u0026quot;: 50,\r\u0026quot;slop\u0026quot;: 5\r}\r}\r},\r{\r\u0026quot;match_phrase\u0026quot;: {\r\u0026quot;goodsName\u0026quot;: {\r\u0026quot;query\u0026quot;: \u0026quot;苹果有线耳机\u0026quot;,\r\u0026quot;boost\u0026quot;: 30,\r\u0026quot;slop\u0026quot;: 5\r}\r}\r},\r{\r\u0026quot;multi_match\u0026quot;: {\r\u0026quot;query\u0026quot;: \u0026quot;苹果有线耳机\u0026quot;,\r\u0026quot;fields\u0026quot;: [\r\u0026quot;shopName^10\u0026quot;,\r\u0026quot;goodsName\u0026quot;\r]\r}\r}\r],\r\u0026quot;minimum_should_match\u0026quot;: 1\r}\r},\r\u0026quot;functions\u0026quot;: [\r{\r\u0026quot;exp\u0026quot;: {\r\u0026quot;location\u0026quot;: {\r\u0026quot;origin\u0026quot;: {\r\u0026quot;lat\u0026quot;: 24.480775,\r\u0026quot;lon\u0026quot;: 118.119374\r},\r\u0026quot;offset\u0026quot;: \u0026quot;2km\u0026quot;,\r\u0026quot;scale\u0026quot;: \u0026quot;10km\u0026quot;\r}\r}\r}\r]\r}\r}\r}\r  说明：在query中使用 match_phrase 和 match关键字混合搜索 并设置 boost权重参数，可以实现将完整短语匹配的结果更靠前，而这些可能正是用户需要的。一些零散的关键词：\u0026ldquo;苹果\u0026rdquo;、\u0026ldquo;有限\u0026rdquo;、\u0026ldquo;耳机\u0026rdquo;，组合而成的结果将会排在后面\nfunctions 中使用到了 exp 衰减函数，主要实现的效果是 在中心点 2km 范围内，计算得分不会搜到影响。在 2-10km 范围中 计算得分结果会逐步衰减，而在10km范围外的 会较平缓的衰减。\n衰减速率可参考官方衰减函数曲线\n java代码实现\n// spring data es实现\r// 构造FunctionScore\rprivate FunctionScoreQueryBuilder getFilterFunctionBuilders(BoolQueryBuilder boolQueryBuilder, Double latitude, Double longitude) {\rFunctionScoreQueryBuilder.FilterFunctionBuilder[] filterFunctionBuilders = new FunctionScoreQueryBuilder.FilterFunctionBuilder[1];\rMap locationMap = new HashMap();\rlocationMap.put(\u0026quot;lat\u0026quot;, latitude);\rlocationMap.put(\u0026quot;lon\u0026quot;, longitude);\rGaussDecayFunctionBuilder distanceGaussDecayFunctionBuilder = ScoreFunctionBuilders\r.gaussDecayFunction(\u0026quot;location\u0026quot;, locationMap, \u0026quot;10km\u0026quot;, \u0026quot;2km\u0026quot;);\rfilterFunctionBuilders[0] = new FunctionScoreQueryBuilder.FilterFunctionBuilder(distanceGaussDecayFunctionBuilder);\rFunctionScoreQueryBuilder functionScoreQueryBuilder = QueryBuilders.functionScoreQuery(boolQueryBuilder, filterFunctionBuilders);\rreturn functionScoreQueryBuilder;\r} // ------------------------------------------\r//最后构造完FunctionScore需要放入NativeSearchQueryBuilder中，参数boolQueryBuilder为其它的一些业务查询条件\r//组装构建复杂条件查询器\rnativeSearchQueryBuilder.withQuery(functionScoreQueryBuilder);\r//进行数据查询\rSearchHits\u0026lt;ShopESListVO\u0026gt; search = elasticsearchRestTemplate.search(nativeSearchQueryBuilder.build(), ShopESListVO.class);\r  参考文章：elasticsearch 干货：使用 FunctionScore 对文档进行重新打分实例\n总是搜不到想要的内容？Elasticsearch搜索排名优化了解一下\n ","id":3,"section":"posts","summary":"Elasticsearch 搜索优化 概述 ​ 在使用ES一段时间后，发现搜索结果有的时候不太理想，因为默认搜索结果是按分词权重计算排序（关键词命中多且文本内容少的排名往往","tags":["Elasticsearch"],"title":"Elasticsearch 搜索优化之距离因素","uri":"https://bluestaree.github.io/2023/05/elasticsearch-%E6%90%9C%E7%B4%A2%E4%BC%98%E5%8C%96%E4%B9%8B%E8%B7%9D%E7%A6%BB%E5%9B%A0%E7%B4%A0/","year":"2023"},{"content":" 问题 一、热词配置过多后失效  我使用的es版本7.6.2，对应ik分词器版本7.6.2，经过反复测试，发现当词库数量超过一定数目时，ik分词器无法热更新刷新词库。初步判断与返回信息长度相关\n 1）查看ik分词器拉取远程词库相关源码：\n其中 entity.getContentLength() \u0026gt; 0 确实存在文本内容长度判断，但没有 具体长度限制。\n2）继续测试，判断是否由于内容文本过长，导致响应请求头中：Content-Length属性丢失\n这里可以看到有Content-Length 这个header属性\n当词库量增多的时候，发现无Content-Length\n参看相关文章，应该是为了提升传输的效率和对内容进行压缩\nIK插件可能是因为某种原因未对这中情况做支持,只有有Content-Length的时候才能正确的识别。\n解决\n我这里有走nginx，在 nginx进行如下配置\n##### ik分词器热更新接口，关闭gzip、chunked_transfer_encoding #####\rlocation /test/extDic/hot {\rproxy_pass http://gateway/test/extDic/hot;\rchunked_transfer_encoding off;\rgzip off;\r}\r## 更新配置文件后：\r## 使用命令 nginx -t 检查配置文件\r## 使用命令 nginx -s reload 重新加载配置文件\r 添加词库数据，这时候请求接口就会发现Content-Length 又出现了\n参看es控制台，有输出同步日志\nkibana分词测试，热词已生效，大功告成\n 参考文章：https://blog.csdn.net/u013200380/article/details/114266789\n  更新\n这个问题高版本应该已经解决了，[github相关 issues780、issues874 ] 大家可以根据需要升级测试\n 备注： (如果有使用springdata-es的注意版本兼容。 详阅： https://docs.spring.io/spring-data/elasticsearch/docs/current/reference/html/#preface)\n 二、部分词组无法切分单个词 场景：用户常常会在搜索时，只输入一个汉字。如果我们使用默认ik分词器的配置，有些短语：比如苹果手机，就只会分为 苹果、手机 这两个词 [使用ik_max_word]。单单输入 苹 这个字无法搜索出对应内容，当然有些单词我们并不希望进行分词，如 的、与、又 。\n解决方案：\n​\t1、把中文的常用的单个汉字作为扩展词组加入到ik扩展词典中\n​\t2、把不需要分词的词库加入到ik扩展停用词典中\n打开 IK 分词器的核心配置文件：IKAnalyzer.cfg.xml，修改如下配置\n\u0026lt;properties\u0026gt;\r\u0026lt;comment\u0026gt;IK Analyzer 扩展配置\u0026lt;/comment\u0026gt;\r\u0026lt;!--用户可以在这里配置自己的扩展字典 --\u0026gt;\r\u0026lt;entry key=\u0026quot;ext_dict\u0026quot;\u0026gt;extra_single_word.dic;\u0026lt;/entry\u0026gt;\r\u0026lt;!--用户可以在这里配置自己的扩展停止词字典--\u0026gt;\r\u0026lt;entry key=\u0026quot;ext_stopwords\u0026quot;\u0026gt;extra_stopword.dic;\u0026lt;/entry\u0026gt;\r\u0026lt;!--用户可以在这里配置远程扩展字典 --\u0026gt;\r\u0026lt;!-- \u0026lt;entry key=\u0026quot;remote_ext_dict\u0026quot;\u0026gt;words_location\u0026lt;/entry\u0026gt; --\u0026gt;\r\u0026lt;!--用户可以在这里配置远程扩展停止词字典--\u0026gt;\r\u0026lt;!-- \u0026lt;entry key=\u0026quot;remote_ext_stopwords\u0026quot;\u0026gt;words_location\u0026lt;/entry\u0026gt; --\u0026gt;\r\u0026lt;/properties\u0026gt;\r 添加扩展词典和停用词典配置,这里就用ik自带的扩展词库 extra_single_word.dic 、extra_stopword.dic为例 ，多个词库使用 分号 区分\n重启es，效果如下：\n该配置不会与远程词库冲突\n注意：配置完成后，如果存在旧文档需要重新导入，才能生效\n 参考文章：https://blog.csdn.net/zy158194/article/details/122088661\n ","id":4,"section":"posts","summary":"问题 一、热词配置过多后失效 我使用的es版本7.6.2，对应ik分词器版本7.6.2，经过反复测试，发现当词库数量超过一定数目时，ik分词器无","tags":["Elasticsearch"],"title":"ik分词器踩坑记录","uri":"https://bluestaree.github.io/2023/04/ik%E5%88%86%E8%AF%8D%E5%99%A8%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/","year":"2023"},{"content":" 实现ik分词器词库热更新  ik分词器热更新原理： 1.该 http 请求需要返回两个头部(header)，一个是 Last-Modified，一个是 ETag，这两者都是字符串类型，只要有一个发生变化，该插件就会去抓取新的分词进而更新词库。 2.该 http 请求返回的内容格式是一行一个分词，换行符用 \\n 即可。 即每次请求都会携带一个文件的最后修改时间和一个文件修改后生成的唯一值，去进行匹配，两者有其中一个不对应，即会重新读取新词典\n官方文档： https://github.com/medcl/elasticsearch-analysis-ik\n 一、修改ik分词器配置 IK 分词器的核心配置文件：IKAnalyzer.cfg.xml，主要修改如下配置\n\u0026lt;properties\u0026gt;\r\u0026lt;comment\u0026gt;IK Analyzer 扩展配置\u0026lt;/comment\u0026gt;\r\u0026lt;!--用户可以在这里配置自己的扩展字典 --\u0026gt;\r\u0026lt;entry key=\u0026quot;ext_dict\u0026quot;\u0026gt;\u0026lt;/entry\u0026gt;\r\u0026lt;!--用户可以在这里配置自己的扩展停止词字典--\u0026gt;\r\u0026lt;entry key=\u0026quot;ext_stopwords\u0026quot;\u0026gt;extra_stopword.dic;\u0026lt;/entry\u0026gt;\r\u0026lt;!--用户可以在这里配置远程扩展字典 --\u0026gt;\r\u0026lt;entry key=\u0026quot;remote_ext_dict\u0026quot;\u0026gt;words_location\u0026lt;/entry\u0026gt;\r\u0026lt;!--用户可以在这里配置远程扩展停止词字典--\u0026gt;\r\u0026lt;entry key=\u0026quot;remote_ext_stopwords\u0026quot;\u0026gt;words_location\u0026lt;/entry\u0026gt;\r\u0026lt;/properties\u0026gt;\r 其中 words_location是指一个 服务器接口url，比如 http://shop.cn/getDic，该请求只需满足上述条件即可完成分词热更新。不需要重启ES\n二、服务接口准备 1.数据库 这里将词库放在mysql中进行管理，新建一个词库表\nCREATE TABLE `local_dic` (\r`dic_id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '词id',\r`dict_text` varchar(255) NOT NULL DEFAULT '' COMMENT '词内容',\r`type` int(1) NOT NULL DEFAULT '1' COMMENT '词类型 1：热词 2：停用词',\r`create_time` datetime DEFAULT NULL COMMENT '创建时间',\r`update_time` datetime DEFAULT NULL COMMENT '修改时间',\rPRIMARY KEY (`dic_id`) USING BTREE\r) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='词库表';\r 2.服务器接口 枚举类\npublic enum LocalDicEnum {\rHOT_DIC(1, \u0026quot;热词\u0026quot;),\rSTOP_DIC(2, \u0026quot;停用词\u0026quot;);\rprivate int val;\rprivate String desc;\rprivate LocalDicEnum(int val, String desc) {\rthis.val = val;\rthis.desc = desc;\r}\rpublic int val() {\rreturn this.val;\r}\rpublic String desc() {\rreturn this.desc;\r}\r}\r Controller层\n注意两个接口，一个是检查当前词库是否需要同步， 一个是获取词库内容，地址相同，只是请求方式不同\n@Slf4j\r@RestController\rpublic class LocalDicController {\r@Autowired\rprivate ILocalDicService localDicService;\r/**\r* ik热词同步检查\r*\r* @author Administrator\r* @date 2023/4/10 9:38\r* @param request\r* @param response\r* @return Result\r*/\r@RequestMapping(value = \u0026quot;/extDic/hot\u0026quot;, method = RequestMethod.HEAD)\rpublic void extDicHotCheck(HttpServletRequest request, HttpServletResponse response) {\rlocalDicService.extDicHotCheck(request, response);\r}\r/**\r* ik热词同步\r*\r* @author Administrator\r* @date 2023/4/10 9:38\r* @param request\r* @param response\r* @return Result\r*/\r@RequestMapping(value = \u0026quot;/extDic/hot\u0026quot;, method = RequestMethod.GET)\rpublic String extDicHot(HttpServletRequest request, HttpServletResponse response) {\rreturn localDicService.extDicHot(request, response);\r}\r}\r Service层\n其中使用了hutool工具类 DateUtil、CollUtil\n@Service\rpublic class LocalDicServiceImpl extends ServiceImpl\u0026lt;LocalDicMapper, LocalDic\u0026gt; implements ILocalDicService {\r/**\r* ik热词同步检查\r*\r* @author Administrator\r* @date 2023/4/10 9:38\r* @param request\r* @param response\r* @return void\r*/\r@Override\rpublic void extDicHotCheck(HttpServletRequest request, HttpServletResponse response) {\r// String modified = request.getHeader(\u0026quot;If-Modified-Since\u0026quot;);\r// String eTag = request.getHeader(\u0026quot;If-None-Match\u0026quot;);\r// log.info(\u0026quot;[ik热词同步检查] modified：{} ，eTag：{}\u0026quot;, modified, eTag);\rDate newModified = this.baseMapper.getCurrentModified(LocalDicEnum.HOT_DIC.val());\rresponse.setHeader(\u0026quot;Last-Modified\u0026quot;, DateUtil.formatDateTime(newModified));\rresponse.setHeader(\u0026quot;ETag\u0026quot;, \u0026quot;extDicHot\u0026quot;);\r}\r/**\r* ik热词同步\r*\r* @author Administrator\r* @date 2023/4/10 9:38\r* @param request\r* @param response\r* @return String\r*/\r@Override\rpublic String extDicHot(HttpServletRequest request, HttpServletResponse response) {\rList\u0026lt;LocalDic\u0026gt; list = list(new LambdaQueryWrapper\u0026lt;LocalDic\u0026gt;()\r.eq(LocalDic::getType, LocalDicEnum.HOT_DIC.val())\r.select(LocalDic::getDictText, LocalDic::getUpdateTime)\r.orderByDesc(LocalDic::getUpdateTime));\rif(CollUtil.isEmpty(list)) {\rreturn StrUtil.EMPTY;\r}\rresponse.setHeader(\u0026quot;Last-Modified\u0026quot;, DateUtil.formatDateTime(list.get(0).getUpdateTime()));\rresponse.setHeader(\u0026quot;ETag\u0026quot;, \u0026quot;extDicHot\u0026quot;);\rreturn String.join(\u0026quot;\\n\u0026quot;, list.stream().map(LocalDic::getDictText).collect(Collectors.toSet()));\r}\r}\r mapper\npublic interface LocalDicMapper extends BaseMapper\u0026lt;LocalDic\u0026gt; {\r/**\r* 获取最新修改时间\r*\r* @author Administrator\r* @date 2023/4/10 10:35\r* @param\r* @return Date\r*/\rpublic Date getCurrentModified(Integer type);\r}\r mapper.xml\n\u0026lt;select id=\u0026quot;getCurrentModified\u0026quot; resultType=\u0026quot;java.util.Date\u0026quot;\u0026gt;\rSELECT update_time\rFROM local_dic\rWHERE `type` = #{type}\rORDER BY update_time DESC\rLIMIT 1\r\u0026lt;/select\u0026gt;\r 三、同步测试 重启es后，观察服务器日志，每分钟会打印日志信息 [ik热词同步检查] 日志信息\n此时更新数据库记录，添加一条最新记录信息，\n观察ES日志\n热更新成功\n","id":5,"section":"posts","summary":"实现ik分词器词库热更新 ik分词器热更新原理： 1.该 http 请求需要返回两个头部(header)，一个是 Last-Modified，一个是 ETag","tags":["Elasticsearch"],"title":"实现ik分词器词库热更新","uri":"https://bluestaree.github.io/2023/04/%E5%AE%9E%E7%8E%B0ik%E5%88%86%E8%AF%8D%E5%99%A8%E8%AF%8D%E5%BA%93%E7%83%AD%E6%9B%B4%E6%96%B0/","year":"2023"},{"content":" Elasticsearch 搜索推荐 - Suggest 概述 ​\t搜索一般都会要求具有“搜索推荐”或者叫\u0026quot;搜索补全\u0026quot;的功能，即在用户输入搜索的过程中，进行自动补全或者纠错。以此来提高搜索文档的匹配精准度，进而提升用户的搜索体验，这就是Suggest。\n1.Term Suggester  官方文档: https://www.elastic.co/guide/en/elasticsearch/reference/7.2/search-suggesters.html\n 正如其名，只基于tokenizer之后的单个term匹配建议词，并不会者虑多个term之间的关系\n语法格式如下 POST \u0026lt;index\u0026gt;/_search\r{\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;\u0026lt;suggest_name\u0026gt;\u0026quot;: {\r\u0026quot;text\u0026quot;:\u0026quot;\u0026lt;search_content\u0026gt;\u0026quot;,\r\u0026quot;term\u0026quot;:{\r\u0026quot;suggest_mode\u0026quot;:\u0026quot;\u0026lt;suggest_mode\u0026gt;\u0026quot;,\r\u0026quot;field\u0026quot;:\u0026quot;\u0026lt;field_name\u0026gt;\u0026quot;\r}\r}\r}\r}\r Options:\n  text: 用户搜索的文本\n  field: 要从哪个字段选取推荐数据\n  analyzer: 使用哪种分词器\n  size: 每个建议返回的最大结果数\n  sort: 如何按照提示词项排序，参数值只可以是以下两个枚举:\n score: 分数\u0026gt;词频\u0026gt;词项本身 frequency: 词频\u0026gt;分数\u0026gt;词项本身    suggest_mode: 搜索推荐的推荐模式，参数值亦是枚举:\n missing: 默认值，仅为不在索引中的词项生成建议词 popular: 仅返回与搜索词文档词频或文档词频更高的建议词 always: 根据建议文本中的词项推荐任何匹配的建议词    max_edits: 可以具有最大偏移距离候选建议以便被认为是建议。只能是1到2之间的值。任何其他值都将导致引发错误的请求错误。默认为2\n  prefix_length: 前缀匹配的时候，必须满足的最少字符\n  min_word_length: 最少包含的单词数量\n  min_doc_freq: 最少的文档频率\n  max_term_freq: 最大的词频\n  测试示例：\n#term suggest\rDELETE news\rPOST _bulk\r{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;news\u0026quot;,\u0026quot;_id\u0026quot;:1 } }\r{ \u0026quot;title\u0026quot;: \u0026quot;baoqiang bought a new hat with the same color of this font, which is very beautiful baoqiangba baoqiangda baoqiangdada baoqian baoqia\u0026quot;}\r{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;news\u0026quot;,\u0026quot;_id\u0026quot;:2 } }\r{ \u0026quot;title\u0026quot;: \u0026quot;baoqiangge gave birth to two children, one is upstairs, one is downstairs baoqiangba baoqiangda baoqiangdada baoqian baoqia\u0026quot;}\r{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;news\u0026quot;,\u0026quot;_id\u0026quot;:3} }\r{ \u0026quot;title\u0026quot;: \u0026quot;baoqiangge 's money was rolled away baoqiangba baoqiangda baoqiangdada baoqian baoqia\u0026quot;}\r{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;news\u0026quot;,\u0026quot;_id\u0026quot;:4} }\r{ \u0026quot;title\u0026quot;: \u0026quot;baoqiangda baoqiangda baoqiangda baoqiangda baoqiangda baoqian baoqia\u0026quot;}\rGET news/_mapping\rPOST _analyze\r{\r\u0026quot;text\u0026quot;: [\r\u0026quot;BaoQiang bought a new hat with the same color of this font, which is very beautiful\u0026quot;,\r\u0026quot;BaoQiangGe gave birth to two children, one is upstairs, one is downstairs\u0026quot;,\r\u0026quot;BaoQiangGe 's money was rolled away\u0026quot;\r]\r}\rPOST /news/_search\r{\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;my-suggestion\u0026quot;: {\r\u0026quot;text\u0026quot;: \u0026quot;baoqing baoqiang\u0026quot;,\r\u0026quot;term\u0026quot;: {\r\u0026quot;suggest_mode\u0026quot;:\u0026quot;always\u0026quot;,\r\u0026quot;field\u0026quot;: \u0026quot;title\u0026quot;,\r\u0026quot;min_doc_freq\u0026quot;: 3\r}\r}\r}\r}\rGET /news/_search\r{ \u0026quot;suggest\u0026quot;: {\r\u0026quot;my-suggestion\u0026quot;: {\r\u0026quot;text\u0026quot;: \u0026quot;baoqing baoqiang\u0026quot;,\r\u0026quot;term\u0026quot;: {\r\u0026quot;suggest_mode\u0026quot;: \u0026quot;popular\u0026quot;,\r\u0026quot;field\u0026quot;: \u0026quot;title\u0026quot;\r}\r}\r}\r}\rGET /news/_search\r{ \u0026quot;suggest\u0026quot;: {\r\u0026quot;my-suggestion\u0026quot;: {\r\u0026quot;text\u0026quot;: \u0026quot;baoqing baoqiang\u0026quot;,\r\u0026quot;term\u0026quot;: {\r\u0026quot;suggest_mode\u0026quot;: \u0026quot;popular\u0026quot;,\r\u0026quot;field\u0026quot;: \u0026quot;title\u0026quot;,\r\u0026quot;max_edits\u0026quot;:2,\r\u0026quot;max_term_freq\u0026quot;:1\r}\r}\r}\r}\rGET /news/_search\r{ \u0026quot;suggest\u0026quot;: {\r\u0026quot;my-suggestion\u0026quot;: {\r\u0026quot;text\u0026quot;: \u0026quot;baoqing baoqiang\u0026quot;,\r\u0026quot;term\u0026quot;: {\r\u0026quot;suggest_mode\u0026quot;: \u0026quot;always\u0026quot;,\r\u0026quot;field\u0026quot;: \u0026quot;title\u0026quot;,\r\u0026quot;max_edits\u0026quot;:2\r}\r}\r}\r}\rDELETE news2\rPOST _bulk\r{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;news2\u0026quot;,\u0026quot;_id\u0026quot;:1 } }\r{ \u0026quot;title\u0026quot;: \u0026quot;baoqiang4\u0026quot;}\r{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;news2\u0026quot;,\u0026quot;_id\u0026quot;:2 } }\r{ \u0026quot;title\u0026quot;: \u0026quot;baoqiang4 baoqiang3\u0026quot;}\r{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;news2\u0026quot;,\u0026quot;_id\u0026quot;:3 } }\r{ \u0026quot;title\u0026quot;: \u0026quot;baoqiang4 baoqiang3 baoqiang2\u0026quot;}\r{ \u0026quot;index\u0026quot; : { \u0026quot;_index\u0026quot; : \u0026quot;news2\u0026quot;,\u0026quot;_id\u0026quot;:4 } }\r{ \u0026quot;title\u0026quot;: \u0026quot;baoqiang4 baoqiang3 baoqiang2 baoqiang\u0026quot;}\rPOST /news2/_search\r{ \u0026quot;suggest\u0026quot;: {\r\u0026quot;second-suggestion\u0026quot;: {\r\u0026quot;text\u0026quot;: \u0026quot;baoqian baoqiang baoqiang2 baoqiang3\u0026quot;,\r\u0026quot;term\u0026quot;: {\r\u0026quot;suggest_mode\u0026quot;: \u0026quot;popular\u0026quot;,\r\u0026quot;field\u0026quot;: \u0026quot;title\u0026quot;\r}\r}\r}\r}\r 2.Phrase Suggester term_suggester可以对单个term进行建议或者纠错，不会考虑多个term之间的关系，但是phrase_suggester在term_suggester的基础上，考虑多个term之间的关系，比如是否同时出现一个索引原文中，相邻程度以及词频等等\n前置条件，需要在创建索引映射时进行配置，以下为官方示例：\nPUT test\r{\r\u0026quot;settings\u0026quot;: {\r\u0026quot;index\u0026quot;: {\r\u0026quot;number_of_shards\u0026quot;: 1,\r\u0026quot;analysis\u0026quot;: {\r\u0026quot;analyzer\u0026quot;: {\r\u0026quot;trigram\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;custom\u0026quot;,\r\u0026quot;tokenizer\u0026quot;: \u0026quot;standard\u0026quot;,\r\u0026quot;filter\u0026quot;: [\u0026quot;lowercase\u0026quot;,\u0026quot;shingle\u0026quot;]\r},\r\u0026quot;reverse\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;custom\u0026quot;,\r\u0026quot;tokenizer\u0026quot;: \u0026quot;standard\u0026quot;,\r\u0026quot;filter\u0026quot;: [\u0026quot;lowercase\u0026quot;,\u0026quot;reverse\u0026quot;]\r}\r},\r\u0026quot;filter\u0026quot;: {\r\u0026quot;shingle\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;shingle\u0026quot;,\r\u0026quot;min_shingle_size\u0026quot;: 2,\r\u0026quot;max_shingle_size\u0026quot;: 3\r}\r}\r}\r}\r},\r\u0026quot;mappings\u0026quot;: {\r\u0026quot;properties\u0026quot;: {\r\u0026quot;title\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\r\u0026quot;fields\u0026quot;: {\r\u0026quot;trigram\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\r\u0026quot;analyzer\u0026quot;: \u0026quot;trigram\u0026quot;\r},\r\u0026quot;reverse\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\r\u0026quot;analyzer\u0026quot;: \u0026quot;reverse\u0026quot;\r}\r}\r}\r}\r}\r}\r Options:\n real_word_error_likelihood: 此选项的默认值为 0.95。此选项告诉 Elasticsearch 索引中 5%的术语拼写错误。这意味着随着这个参数的值越来越低Elasticsearch 会将越来越多存在于索引中的术语视为拼写错误，即使它们是正确的 max_errors: 为了形成更正，最多被认为是拼写错误的术语的最大百分比。默认值为 1 confidence: 默认值是1.0，最大值也是。该值用作与建议得分相关的阈值。仅显示分数超过此值的那些建议。例如，置信度为1.0只会返回得分高于输入短语的建议。 highlight: 高亮功能是最有用的搜索功能之一。也可以在短语建议程序中启用它。更正的单词将使用此关键字突出显示。如以上查询所示，我们还可以采用哪个标签来突出显示（这里我们使用了标签）。 collate: 告诉 Elasticsearch 根据指定的查询来检查每个建议，以删除索引中不存在匹配文档的建议。在这种情况下，它是一个匹配查询。由于此查询是模板查询，因此搜索查询是当前建议，位于查询的参数下。可以在查询下的 “params”对象中添加更多字段。同样，当参数 “prune” 设置为 true 时，响应中将有一个附加字段 “collate_match”，指示建议结果中是否所有校正后的关键字都匹配。 direct_generator: phrase suggester使用候选生成器生成给定文本中每个项可能的项的列表。单个候选生成器类似于为文本中的每个单独的调用term suggester。生成器的输出随后与建议候选项中的候选项结合打分。目前只支持一种候选生成器，即direct_generator。建议API接受密钥直接生成器下的生成器列表;列表中的每个生成器都按原始文本中的每个项调用  测试示例：\n#phrase suggester\rDELETE test\rPUT test\r{\r\u0026quot;settings\u0026quot;: {\r\u0026quot;index\u0026quot;: {\r\u0026quot;number_of_shards\u0026quot;: 1,\r\u0026quot;number_of_replicas\u0026quot;: 0,\r\u0026quot;analysis\u0026quot;: {\r\u0026quot;analyzer\u0026quot;: {\r\u0026quot;trigram\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;custom\u0026quot;,\r\u0026quot;tokenizer\u0026quot;: \u0026quot;standard\u0026quot;,\r\u0026quot;filter\u0026quot;: [\r\u0026quot;lowercase\u0026quot;,\r\u0026quot;shingle\u0026quot;\r]\r}\r},\r\u0026quot;filter\u0026quot;: {\r\u0026quot;shingle\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;shingle\u0026quot;,\r\u0026quot;min_shingle_size\u0026quot;: 2,\r\u0026quot;max_shingle_size\u0026quot;: 3\r}\r}\r}\r}\r},\r\u0026quot;mappings\u0026quot;: {\r\u0026quot;properties\u0026quot;: {\r\u0026quot;title\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\r\u0026quot;fields\u0026quot;: {\r\u0026quot;trigram\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\r\u0026quot;analyzer\u0026quot;: \u0026quot;trigram\u0026quot;\r}\r}\r}\r}\r}\r}\rGET /_analyze\r{\r\u0026quot;tokenizer\u0026quot;: \u0026quot;standard\u0026quot;,\r\u0026quot;filter\u0026quot;: [\r{\r\u0026quot;type\u0026quot;: \u0026quot;shingle\u0026quot;,\r\u0026quot;min_shingle_size\u0026quot;: 2,\r\u0026quot;max_shingle_size\u0026quot;: 3\r}\r],\r\u0026quot;text\u0026quot;: \u0026quot;lucene and elasticsearch\u0026quot;\r}\r# \u0026quot;min_shingle_size\u0026quot;: 2,\r# \u0026quot;max_shingle_size\u0026quot;: 3\rGET test/_analyze\r{\r\u0026quot;analyzer\u0026quot;: \u0026quot;trigram\u0026quot;, \u0026quot;text\u0026quot; : \u0026quot;lucene and elasticsearch\u0026quot;\r}\rDELETE test\rPOST test/_bulk\r{ \u0026quot;index\u0026quot; : { \u0026quot;_id\u0026quot;:1} }\r{\u0026quot;title\u0026quot;: \u0026quot;lucene and elasticsearch\u0026quot;}\r{ \u0026quot;index\u0026quot; : {\u0026quot;_id\u0026quot;:2} }\r{\u0026quot;title\u0026quot;: \u0026quot;lucene and elasticsearhc\u0026quot;}\r{ \u0026quot;index\u0026quot; : { \u0026quot;_id\u0026quot;:3} }\r{\u0026quot;title\u0026quot;: \u0026quot;luceen and elasticsearch\u0026quot;}\rPOST test/_search\rGET test/_mapping\rPOST test/_search\r{\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;text\u0026quot;: \u0026quot;Luceen and elasticsearhc\u0026quot;,\r\u0026quot;simple_phrase\u0026quot;: {\r\u0026quot;phrase\u0026quot;: {\r\u0026quot;field\u0026quot;: \u0026quot;title.trigram\u0026quot;,\r\u0026quot;max_errors\u0026quot;: 2,\r\u0026quot;gram_size\u0026quot;: 1,\r\u0026quot;confidence\u0026quot;:0,\r\u0026quot;direct_generator\u0026quot;: [\r{\r\u0026quot;field\u0026quot;: \u0026quot;title.trigram\u0026quot;,\r\u0026quot;suggest_mode\u0026quot;: \u0026quot;always\u0026quot;\r}\r],\r\u0026quot;highlight\u0026quot;: {\r\u0026quot;pre_tag\u0026quot;: \u0026quot;\u0026lt;em\u0026gt;\u0026quot;,\r\u0026quot;post_tag\u0026quot;: \u0026quot;\u0026lt;/em\u0026gt;\u0026quot;\r}\r}\r}\r}\r}\r 3.Completion Suggester 自动补全，目动完成。支持3种查询查询【前缀查询 prefix) 模糊查询 (fuzzy) 正则表达式查询 (regex)】 ，主要针对的应用场景就是\u0026quot;Auto Completion\u0026rdquo;。此场景下用户每输入一个字符的时候，就需要即时发送一次查询请求到后端查找匹配项，在用户输入速度较高的情况下对后端响应速度要求比较苛刻。因此实现上它和前面两个Suggester采用了不同的数据结构，索引并非通过倒排来完成，而是将analyze通过的数据编码成FST和索引一起存放。对于一个open状态的索引，FST会被ES整个装载到内存里的，进行前缀查找速度极快。但是FST只能用于前缀查找，这也是Completion Suggester的局限所在\n基于内存而非索引，性能强悍。需要结合特定的 completion 类型。\n 1:内存代价太大，原话是:性能高是通过大量的内存换来的\n2: 只能前缀搜索,假如用户输入的不是前缀 召回率可能很低\n 前置条件，需要在创建索引映射时进行配置，以下为官方示例：\nPUT music\r{\r\u0026quot;mappings\u0026quot;: {\r\u0026quot;properties\u0026quot; : {\r\u0026quot;suggest\u0026quot; : {\r\u0026quot;type\u0026quot; : \u0026quot;completion\u0026quot;\r},\r\u0026quot;title\u0026quot; : {\r\u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot;\r}\r}\r}\r}\r completion: es的一种特有类型，专门为suggest提供，基于内存，性能很高\n  prefix query: 基于前缀查询的搜索提示，是最常用的一种搜索推荐查询。  prefix: 客户端搜索词 field: 建议词字 size: 需要返回的建议词数量 (默认5) skip_duplicates: 是否过滤掉重复建议，默认false    GET test/_search\r{\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;your_suggest_name\u0026quot;: {\r\u0026quot;prefix\u0026quot;: \u0026quot;your_search_prefix_content\u0026quot;,\r\u0026quot;completion\u0026quot;: {\r\u0026quot;field\u0026quot;: \u0026quot;title.suggest\u0026quot;\r}\r}\r}\r}\r  fuzzy query: fuzziness: 允许的偏移量，默认auto transpositions: 如果设置为true，则换位计为一次更改而不是两次更改，默认为true。 min_length: 返回模糊建议之前的最小输入长度，默认3 prefix_length: 输入的最小长度 (不检查模糊替代项) , 默认为1 unicode_aware: 如果为true，则所有度量 (如模糊编辑距离，换位和长度)均以Unicode代码点而不是以字节为单位。这比原始字节略慢，因此默认情况下将其设置为false。  GET test/_search\r{\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;your_suggest_name\u0026quot;: {\r\u0026quot;prefix\u0026quot;: \u0026quot;your_search_content\u0026quot;,\r\u0026quot;completion\u0026quot;: {\r\u0026quot;field\u0026quot;: \u0026quot;title.suggest\u0026quot;,\r\u0026quot;skip_duplicates\u0026quot;: true,\r\u0026quot;fuzzy\u0026quot;: {\r\u0026quot;fuzziness\u0026quot;: 2\r}\r}\r}\r}\r}\r  regex query: 可以用正则表示前缀，不建议使用  GET test/_search\r{\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;your_suggest_name\u0026quot;: {\r\u0026quot;regex\u0026quot;: \u0026quot;your_regex_expressions\u0026quot;,\r\u0026quot;completion\u0026quot;: {\r\u0026quot;field\u0026quot;: \u0026quot;title.suggest\u0026quot;,\r\u0026quot;size\u0026quot;: 10\r}\r}\r}\r}\r 测试示例：\n#complate suggester\rDELETE suggest_carinfo\rPUT suggest_carinfo\r{\r\u0026quot;mappings\u0026quot;: {\r\u0026quot;properties\u0026quot;: {\r\u0026quot;title\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\r\u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;,\r\u0026quot;fields\u0026quot;: {\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;completion\u0026quot;,\r\u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;\r}\r}\r},\r\u0026quot;content\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;text\u0026quot;,\r\u0026quot;analyzer\u0026quot;: \u0026quot;ik_max_word\u0026quot;\r}\r}\r}\r}\rPOST _bulk\r{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;suggest_carinfo\u0026quot;,\u0026quot;_id\u0026quot;:1}}\r{\u0026quot;title\u0026quot;:\u0026quot;宝马X5 两万公里准新车\u0026quot;,\u0026quot;content\u0026quot;:\u0026quot;这里是宝马X5图文描述\u0026quot;}\r{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;suggest_carinfo\u0026quot;,\u0026quot;_id\u0026quot;:2}}\r{\u0026quot;title\u0026quot;:\u0026quot;宝马5系\u0026quot;,\u0026quot;content\u0026quot;:\u0026quot;这里是奥迪A6图文描述\u0026quot;}\r{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;suggest_carinfo\u0026quot;,\u0026quot;_id\u0026quot;:3}}\r{\u0026quot;title\u0026quot;:\u0026quot;宝马3系\u0026quot;,\u0026quot;content\u0026quot;:\u0026quot;这里是奔驰图文描述\u0026quot;}\r{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;suggest_carinfo\u0026quot;,\u0026quot;_id\u0026quot;:4}}\r{\u0026quot;title\u0026quot;:\u0026quot;奥迪Q5 两万公里准新车\u0026quot;,\u0026quot;content\u0026quot;:\u0026quot;这里是宝马X5图文描述\u0026quot;}\r{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;suggest_carinfo\u0026quot;,\u0026quot;_id\u0026quot;:5}}\r{\u0026quot;title\u0026quot;:\u0026quot;奥迪A6 无敌车况\u0026quot;,\u0026quot;content\u0026quot;:\u0026quot;这里是奥迪A6图文描述\u0026quot;}\r{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;suggest_carinfo\u0026quot;,\u0026quot;_id\u0026quot;:6}}\r{\u0026quot;title\u0026quot;:\u0026quot;奥迪双钻\u0026quot;,\u0026quot;content\u0026quot;:\u0026quot;这里是奔驰图文描述\u0026quot;}\r{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;suggest_carinfo\u0026quot;,\u0026quot;_id\u0026quot;:7}}\r{\u0026quot;title\u0026quot;:\u0026quot;奔驰AMG 两万公里准新车\u0026quot;,\u0026quot;content\u0026quot;:\u0026quot;这里是宝马X5图文描述\u0026quot;}\r{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;suggest_carinfo\u0026quot;,\u0026quot;_id\u0026quot;:8}}\r{\u0026quot;title\u0026quot;:\u0026quot;奔驰大G 无敌车况\u0026quot;,\u0026quot;content\u0026quot;:\u0026quot;这里是奥迪A6图文描述\u0026quot;}\r{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;suggest_carinfo\u0026quot;,\u0026quot;_id\u0026quot;:9}}\r{\u0026quot;title\u0026quot;:\u0026quot;奔驰C260\u0026quot;,\u0026quot;content\u0026quot;:\u0026quot;这里是奔驰图文描述\u0026quot;}\r{\u0026quot;index\u0026quot;:{\u0026quot;_index\u0026quot;:\u0026quot;suggest_carinfo\u0026quot;,\u0026quot;_id\u0026quot;:10}}\r{\u0026quot;title\u0026quot;:\u0026quot;nir奔驰C260\u0026quot;,\u0026quot;content\u0026quot;:\u0026quot;这里是奔驰图文描述\u0026quot;}\r 4.Completion Suggester 完成建议者会考虑索引中的所有文档，但是通常来说，我们在进行智能推荐的时候最好通过某些条件过滤，并且有可能会针对某些特性提升权重。\n contexts：上下文对象，可以定义多个  name：context的名字，用于区分同一个索引中不同的context对象。需要在查询的时候指定当前name type：context对象的类型，目前支持两种：category和geo，分别用于对suggest item分类和指定地理位置。 boost：权重值，用于提升排名   path：如果没有path，相当于在PUT数据的时候需要指定context.name字段，如果在Mapping中指定了path，在PUT数据的时候就不需要了，因为 Mapping是一次性的，而PUT数据是频繁操作，这样就简化了代码。这段解释有木有很牛逼，网上搜到的都是官方文档的翻译，觉悟雷同。  测试示例：\n# context suggester\r# 定义一个名为 place_type 的类别上下文，其中类别必须与建议一起发送。\r# 定义一个名为 location 的地理上下文，类别必须与建议一起发送\rDELETE place\rPUT place\r{\r\u0026quot;mappings\u0026quot;: {\r\u0026quot;properties\u0026quot;: {\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;completion\u0026quot;,\r\u0026quot;contexts\u0026quot;: [\r{\r\u0026quot;name\u0026quot;: \u0026quot;place_type\u0026quot;,\r\u0026quot;type\u0026quot;: \u0026quot;category\u0026quot;\r},\r{\r\u0026quot;name\u0026quot;: \u0026quot;location\u0026quot;,\r\u0026quot;type\u0026quot;: \u0026quot;geo\u0026quot;,\r\u0026quot;precision\u0026quot;: 4\r}\r]\r}\r}\r}\r}\rPUT place/_doc/1\r{\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;input\u0026quot;: [ \u0026quot;timmy's\u0026quot;, \u0026quot;starbucks\u0026quot;, \u0026quot;dunkin donuts\u0026quot; ],\r\u0026quot;contexts\u0026quot;: {\r\u0026quot;place_type\u0026quot;: [ \u0026quot;cafe\u0026quot;, \u0026quot;food\u0026quot; ] }\r}\r}\rPUT place/_doc/2\r{\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;input\u0026quot;: [ \u0026quot;monkey\u0026quot;, \u0026quot;timmy's\u0026quot;, \u0026quot;Lamborghini\u0026quot; ],\r\u0026quot;contexts\u0026quot;: {\r\u0026quot;place_type\u0026quot;: [ \u0026quot;money\u0026quot;] }\r}\r}\rGET place/_search\rPOST place/_search?pretty\r{\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;place_suggestion\u0026quot;: {\r\u0026quot;prefix\u0026quot;: \u0026quot;sta\u0026quot;,\r\u0026quot;completion\u0026quot;: {\r\u0026quot;field\u0026quot;: \u0026quot;suggest\u0026quot;,\r\u0026quot;size\u0026quot;: 10,\r\u0026quot;contexts\u0026quot;: {\r\u0026quot;place_type\u0026quot;: [ \u0026quot;cafe\u0026quot;, \u0026quot;restaurants\u0026quot; ]\r}\r}\r}\r}\r}\r# 某些类别的建议可以比其他类别提升得更高。以下按类别过滤建议，并额外提升与某些类别相关的建议\rGET place/_search\rPOST place/_search?pretty\r{\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;place_suggestion\u0026quot;: {\r\u0026quot;prefix\u0026quot;: \u0026quot;tim\u0026quot;,\r\u0026quot;completion\u0026quot;: {\r\u0026quot;field\u0026quot;: \u0026quot;suggest\u0026quot;,\r\u0026quot;contexts\u0026quot;: {\r\u0026quot;place_type\u0026quot;: [ { \u0026quot;context\u0026quot;: \u0026quot;cafe\u0026quot; },\r{ \u0026quot;context\u0026quot;: \u0026quot;money\u0026quot;, \u0026quot;boost\u0026quot;: 2 }\r]\r}\r}\r}\r}\r}\r# 地理位置筛选器\rPUT place/_doc/3\r{\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;input\u0026quot;: \u0026quot;timmy's\u0026quot;,\r\u0026quot;contexts\u0026quot;: {\r\u0026quot;location\u0026quot;: [\r{\r\u0026quot;lat\u0026quot;: 43.6624803,\r\u0026quot;lon\u0026quot;: -79.3863353\r},\r{\r\u0026quot;lat\u0026quot;: 43.6624718,\r\u0026quot;lon\u0026quot;: -79.3873227\r}\r]\r}\r}\r}\rPOST place/_search\r{\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;place_suggestion\u0026quot;: {\r\u0026quot;prefix\u0026quot;: \u0026quot;tim\u0026quot;,\r\u0026quot;completion\u0026quot;: {\r\u0026quot;field\u0026quot;: \u0026quot;suggest\u0026quot;,\r\u0026quot;contexts\u0026quot;: {\r\u0026quot;location\u0026quot;: {\r\u0026quot;lat\u0026quot;: 43.662,\r\u0026quot;lon\u0026quot;: -79.380\r}\r}\r}\r}\r}\r}\r# 定义一个名为 place_type 的类别上下文，其中类别是从 cat 字段中读取的。\r# 定义一个名为 location 的地理上下文，其中的类别是从 loc 字段中读取的\rDELETE place_path_category\rPUT place_path_category\r{\r\u0026quot;mappings\u0026quot;: {\r\u0026quot;properties\u0026quot;: {\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;completion\u0026quot;,\r\u0026quot;contexts\u0026quot;: [\r{\r\u0026quot;name\u0026quot;: \u0026quot;place_type\u0026quot;,\r\u0026quot;type\u0026quot;: \u0026quot;category\u0026quot;,\r\u0026quot;path\u0026quot;: \u0026quot;cat\u0026quot;\r},\r{\r\u0026quot;name\u0026quot;: \u0026quot;location\u0026quot;,\r\u0026quot;type\u0026quot;: \u0026quot;geo\u0026quot;,\r\u0026quot;precision\u0026quot;: 4,\r\u0026quot;path\u0026quot;: \u0026quot;loc\u0026quot;\r}\r]\r},\r\u0026quot;loc\u0026quot;: {\r\u0026quot;type\u0026quot;: \u0026quot;geo_point\u0026quot;\r}\r}\r}\r}\r# 如果映射有路径，那么以下索引请求就足以添加类别\r# 这些建议将与咖啡馆和食品类别相关联\r# 如果上下文映射引用另一个字段并且类别被明确索引，则建议将使用两组类别进行索引\rPUT place_path_category/_doc/1\r{\r\u0026quot;suggest\u0026quot;: [\u0026quot;timmy's\u0026quot;, \u0026quot;starbucks\u0026quot;, \u0026quot;dunkin donuts\u0026quot;],\r\u0026quot;cat\u0026quot;: [\u0026quot;cafe\u0026quot;, \u0026quot;food\u0026quot;] }\rPOST place_path_category/_search?pretty\r{\r\u0026quot;suggest\u0026quot;: {\r\u0026quot;place_suggestion\u0026quot;: {\r\u0026quot;prefix\u0026quot;: \u0026quot;tim\u0026quot;,\r\u0026quot;completion\u0026quot;: {\r\u0026quot;field\u0026quot;: \u0026quot;suggest\u0026quot;,\r\u0026quot;contexts\u0026quot;: {\r\u0026quot;place_type\u0026quot;: [ { \u0026quot;context\u0026quot;: \u0026quot;cafe\u0026quot; }\r]\r}\r}\r}\r}\r}\r ","id":6,"section":"posts","summary":"Elasticsearch 搜索推荐 - Suggest 概述 ​ 搜索一般都会要求具有“搜索推荐”或者叫\u0026quot;搜索补全\u0026quot;的功能，即在用户输入搜索的过程中，进行自动补全或者","tags":["Elasticsearch"],"title":"Elasticsearch 实现搜索推荐相关API","uri":"https://bluestaree.github.io/2023/03/elasticsearch-%E5%AE%9E%E7%8E%B0%E6%90%9C%E7%B4%A2%E6%8E%A8%E8%8D%90%E7%9B%B8%E5%85%B3api/","year":"2023"},{"content":" Elasticsearch 常用搜索API 1.查看es中有哪些索引 GET /_cat/indices?v\r es 中会默认存在一个名为.kibana的索引\n表头的含义\n   health green(集群完整) yellow(单点正常、集群不完整) red(单点不正常)     status 索引打开、关闭状态   index 索引名   uuid 索引统一编号   pri 主分片数量   rep 副本数量   docs.count 可用文档数量   docs.deleted 文档被删了多少（逻辑删除）   store.size 整体（主分片和副分片）占空间大小   pri.store.size 主分片占空间大小   cluster 整个elasticsearch 默认就是集群状态，整个集群是一份完整、互备的数据。   node 集群中的一个节点，一般只一个进程就是一个node   shard 分片，即使是一个节点中的数据也会通过hash算法，分成多个片存放，默认是5片。   index 相当于rdbms的database, 对于用户来说是一个逻辑数据库，虽然物理上会被分多个shard存放，也可能存放在多个node中。   type 类似于rdbms的table，但是与其说像table，其实更像面向对象中的class , 同一Json的格式的数据集合。   Document(json) 类似于rdbms的 row、面向对象里的object   field 相当于字段、属性    2.增加一个索引(库） PUT /movie_index\r 3.删除一个索引 DELETE /movie_index\r 4.新增文档 // 格式 /索引/类型/id PUT /movie_index/_doc/1\r{\r\u0026quot;id\u0026quot;: 1,\r\u0026quot;name\u0026quot;: \u0026quot;operation red sea\u0026quot;,\r\u0026quot;doubanScore\u0026quot;: 8.5,\r\u0026quot;actorList\u0026quot;: [\r{\r\u0026quot;id\u0026quot;: 1,\r\u0026quot;name\u0026quot;: \u0026quot;zhang yi\u0026quot;\r},\r{\r\u0026quot;id\u0026quot;: 2,\r\u0026quot;name\u0026quot;: \u0026quot;hai qing\u0026quot;\r},\r{\r\u0026quot;id\u0026quot;: 3,\r\u0026quot;name\u0026quot;: \u0026quot;zhang han yu\u0026quot;\r}\r]\r}\rPUT /movie_index/_doc/2\r{\r\u0026quot;id\u0026quot;: 2,\r\u0026quot;name\u0026quot;: \u0026quot;operation meigong river\u0026quot;,\r\u0026quot;doubanScore\u0026quot;: 8,\r\u0026quot;actorList\u0026quot;: [\r{\r\u0026quot;id\u0026quot;: 3,\r\u0026quot;name\u0026quot;: \u0026quot;zhang han yu\u0026quot;\r}\r]\r}\r// 也可用POST请求，如果不指定id 将会随机生成\rPOST /movie_index/_doc/3\r{\r\u0026quot;id\u0026quot;: 3,\r\u0026quot;name\u0026quot;: \u0026quot;incident red sea\u0026quot;,\r\u0026quot;doubanScore\u0026quot;: 5,\r\u0026quot;actorList\u0026quot;: [\r{\r\u0026quot;id\u0026quot;: 4,\r\u0026quot;name\u0026quot;: \u0026quot;zhang chen\u0026quot;\r}\r]\r}\r 如果之前没建过index，es 会自动创建。\n5.直接用id查找 GET /movie_index/_doc/1\r 6.修改—整体替换 和新增没有区别, 注意返回信息中得_version值\nPUT /movie_index/_doc/3\r{\r\u0026quot;id\u0026quot;: \u0026quot;3\u0026quot;,\r\u0026quot;name\u0026quot;: \u0026quot;incident red sea\u0026quot;,\r\u0026quot;doubanScore\u0026quot;: \u0026quot;5.0\u0026quot;,\r\u0026quot;actorList\u0026quot;: [\r{\r\u0026quot;id\u0026quot;: \u0026quot;1\u0026quot;,\r\u0026quot;name\u0026quot;: \u0026quot;zhang chen\u0026quot;\r}\r]\r}\r// 返回信息\r{\r\u0026quot;_index\u0026quot; : \u0026quot;movie_index\u0026quot;,\r\u0026quot;_type\u0026quot; : \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot; : \u0026quot;3\u0026quot;,\r\u0026quot;_version\u0026quot; : 2,\r\u0026quot;result\u0026quot; : \u0026quot;updated\u0026quot;,\r\u0026quot;_shards\u0026quot; : {\r\u0026quot;total\u0026quot; : 2,\r\u0026quot;successful\u0026quot; : 1,\r\u0026quot;failed\u0026quot; : 0\r},\r\u0026quot;_seq_no\u0026quot; : 14,\r\u0026quot;_primary_term\u0026quot; : 1\r}\r 7.修改—某个字段 POST /movie_index/_update/3\r{ \u0026quot;doc\u0026quot;: {\r\u0026quot;doubanScore\u0026quot;:\u0026quot;7.0\u0026quot;\r} }\r 8.删除一个document DELETE /movie_index/movie/3\r 9.搜索type全部数据 GET /movie_index/_search\r//结果\r{\r\u0026quot;took\u0026quot;: 2, //耗费时间 毫秒\r\u0026quot;timed_out\u0026quot;: false, //是否超时\r\u0026quot;_shards\u0026quot;: {\r\u0026quot;total\u0026quot;: 5, //发送给全部5个分片\r\u0026quot;successful\u0026quot;: 5,\r\u0026quot;skipped\u0026quot;: 0,\r\u0026quot;failed\u0026quot;: 0\r},\r\u0026quot;hits\u0026quot;: {\r\u0026quot;total\u0026quot;: 3, //命中3条数据\r\u0026quot;max_score\u0026quot;: 1, //最大评分\r\u0026quot;hits\u0026quot;: [ // 结果\r{\r\u0026quot;_index\u0026quot;: \u0026quot;movie_index\u0026quot;,\r\u0026quot;_type\u0026quot;: \u0026quot;_doc\u0026quot;,\r\u0026quot;_id\u0026quot;: 2,\r\u0026quot;_score\u0026quot;: 1,\r\u0026quot;_source\u0026quot;: {\r\u0026quot;id\u0026quot;: \u0026quot;2\u0026quot;,\r\u0026quot;name\u0026quot;: \u0026quot;operation meigong river\u0026quot;,\r\u0026quot;doubanScore\u0026quot;: 8.0,\r\u0026quot;actorList\u0026quot;: [\r{\r\u0026quot;id\u0026quot;: \u0026quot;1\u0026quot;,\r\u0026quot;name\u0026quot;: \u0026quot;zhang han yu\u0026quot;\r}\r]\r}\r},\r{.........},\r{.........}\r]\r}\r}  10.按条件查询(全部) GET /movie_index/_search\r{\r\u0026quot;query\u0026quot;:{\r\u0026quot;match_all\u0026quot;: {}\r}\r}\r 11.多条件查询 GET /movie_index/_search\r{\r\u0026quot;query\u0026quot;: {\r\u0026quot;multi_match\u0026quot;: {\r\u0026quot;query\u0026quot;: \u0026quot;red\u0026quot;,\r\u0026quot;fields\u0026quot;: [\u0026quot;name\u0026quot;,\u0026quot;actorList.name\u0026quot;]\r}\r}\r}\r 12.按分词查询 GET /movie_index/_search\r{\r\u0026quot;query\u0026quot;:{\r\u0026quot;match\u0026quot;: {\u0026quot;name\u0026quot;:\u0026quot;red\u0026quot;}\r}\r}\r 13.按分词子属性查询 GET /movie_index/_search\r{\r\u0026quot;query\u0026quot;:{\r\u0026quot;match\u0026quot;: {\u0026quot;actorList.name\u0026quot;:\u0026quot;zhang\u0026quot;}\r}\r}\r 14.过滤\u0026ndash;查询后过滤 类似having\nGET /movie_index/_search\r{\r\u0026quot;query\u0026quot;:{\r\u0026quot;match\u0026quot;: {\u0026quot;name\u0026quot;:\u0026quot;red\u0026quot;}\r},\r\u0026quot;post_filter\u0026quot;:{\r\u0026quot;term\u0026quot;: {\r\u0026quot;actorList.id\u0026quot;: 3\r}\r}\r}\r 15.过滤\u0026ndash;查询前过滤（推荐） 类似where\nGET /movie_index/_search\r{ \u0026quot;query\u0026quot;:{\r\u0026quot;bool\u0026quot;:{\r\u0026quot;filter\u0026quot;:[ {\u0026quot;term\u0026quot;: { \u0026quot;actorList.id\u0026quot;: \u0026quot;1\u0026quot; }},\r{\u0026quot;term\u0026quot;: { \u0026quot;actorList.id\u0026quot;: \u0026quot;3\u0026quot; }}\r], \u0026quot;must\u0026quot;:{\u0026quot;match\u0026quot;:{\u0026quot;name\u0026quot;:\u0026quot;red\u0026quot;}}\r}\r}\r}\r 16.过滤\u0026ndash;按范围过滤 GET /movie_index/_search\r{\r\u0026quot;query\u0026quot;: {\r\u0026quot;bool\u0026quot;: {\r\u0026quot;filter\u0026quot;: {\r\u0026quot;range\u0026quot;: {\r\u0026quot;doubanScore\u0026quot;: {\u0026quot;gte\u0026quot;: 8}\r}\r}\r}\r}\r}\r 关于范围操作符\n   操作符 说明     gt 大于   lt 小于   gte 大于等于   lte 小于等于    17.排序 GET /movie_index/_search\r{\r\u0026quot;query\u0026quot;:{\r\u0026quot;match\u0026quot;: {\u0026quot;name\u0026quot;:\u0026quot;red sea\u0026quot;}\r}\r, \u0026quot;sort\u0026quot;: [\r{\r\u0026quot;doubanScore\u0026quot;: {\r\u0026quot;order\u0026quot;: \u0026quot;desc\u0026quot;\r}\r}\r]\r}\r 18.分页查询 GET /movie_index/_search\r{\t\u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} },\r\u0026quot;from\u0026quot;: 1,\r\u0026quot;size\u0026quot;: 1\r}\r 19.指定查询的字段 GET /movie_index/_search\r{\r\u0026quot;query\u0026quot;: { \u0026quot;match_all\u0026quot;: {} },\r\u0026quot;_source\u0026quot;: [\u0026quot;name\u0026quot;, \u0026quot;doubanScore\u0026quot;]\r}\r 20.高亮 GET /movie_index/_search\r{\r\u0026quot;query\u0026quot;:{\r\u0026quot;match\u0026quot;: {\u0026quot;name\u0026quot;:\u0026quot;red sea\u0026quot;}\r},\r\u0026quot;highlight\u0026quot;: {\r\u0026quot;fields\u0026quot;: {\u0026quot;name\u0026quot;:{} }\r}\r}\r 21.match_phrase 按短语查询\n注意:\n1,match_phrase 会分词\n2,被检索得字段必须包含match_phrase中所有词项并且顺序相同\n3,被检索字段包含得match_phrase中得词项 之间 不能有其他词项\nGET /movie_index/_search\r{\r\u0026quot;query\u0026quot;:{\r\u0026quot;match_phrase\u0026quot;: {\u0026quot;name\u0026quot;:\u0026quot;operation red\u0026quot;}\r}\r}\r   以下查询性能较低，不推荐使用\n 22.fuzzy 模糊查询 校正匹配分词，当一个单词都无法准确匹配，es通过一种算法对非常接近的单词也给与一定的评分，能够查询出来，但是消耗更多的性能。\n混淆字符(box -\u0026gt; fox) 缺少字符(black -\u0026gt; lack)\n多出字符(sic -\u0026gt; sick) 颠倒顺序(act -\u0026gt; cat)\nGET /movie_index/_search\r{\r\u0026quot;query\u0026quot;:{\r\u0026quot;fuzzy\u0026quot;: {\u0026quot;name\u0026quot;:\u0026quot;rad\u0026quot;}\r}\r}\r 23.prefix 前缀查询 GET /movie_index/_search\r{\t\u0026quot;query\u0026quot;: { \u0026quot;prefix\u0026quot;: {\r\u0026quot;name\u0026quot;: {\r\u0026quot;value\u0026quot;: \u0026quot;op\u0026quot;\r}\r}\r}\r}\r 24.wildcard 通配符 GET /movie_index/_search\r{\r\u0026quot;query\u0026quot;: {\r\u0026quot;wildcard\u0026quot;: {\r\u0026quot;name\u0026quot;: {\r\u0026quot;value\u0026quot;: \u0026quot;oper*tion\u0026quot;\r}\r}\r}\r}\r 25.regexp 正则 GET /movie_index/_search\r{\r\u0026quot;query\u0026quot;: {\r\u0026quot;regexp\u0026quot;: {\r\u0026quot;name\u0026quot;: {\r\u0026quot;value\u0026quot;: \u0026quot;[\\\\s\\\\S]*incident[\\\\s\\\\S]*\u0026quot;\r}\r}\r}\r}\r ","id":7,"section":"posts","summary":"Elasticsearch 常用搜索API 1.查看es中有哪些索引 GET /_cat/indices?v es 中会默认存在一个名为.kibana的索引 表头的含义 health green(集群完整) yellow(单点正","tags":["Elasticsearch"],"title":"Elasticsearch 常用搜索API","uri":"https://bluestaree.github.io/2023/03/elasticsearch-%E5%B8%B8%E7%94%A8%E6%90%9C%E7%B4%A2api/","year":"2023"},{"content":" Milvus单机部署配置 1、配置Milvus日志目录挂载 转载文章：https://www.jianshu.com/p/0c594a5a8f20\n目录结构\r├── configs\r│ └── milvus.yaml\r├── docker-compose.yml\r├── logs\r│ ├── standalone-2021-11-01T22-26-26.846.log\r│ └── standalone.log\r 说明：\n milvus.yaml 需要从 这里下载，目前我选择的分支是 2.0.0-rc7，然后随便新建一个文件夹 configs 放进去 logs 是新建的目录，用于存放日志 docker-compose.yml 我这里是 milvus 单机部署的文件，通过 wget https://github.com/milvus-io/milvus/releases/download/v2.0.0-rc7/milvus-standalone-docker-compose.yml -O docker-compose.yml 进行下载  修改下载的 milvus.yaml 文件  注意：/milvus/logs 是镜像 standalone 里使用的路径，配置的时候，把镜像外的路径挂载到这个目录便可\n ...\r# Configures the system log output.\rlog:\rlevel: debug # info, warn, error, panic, fatal\rfile:\rrootPath: /milvus/logs # 改这里\rmaxSize: 300 # MB\rmaxAge: 10 # day\rmaxBackups: 20\rformat: json # text / json\r...\r 修改下载的 docker-compose.yml 文件  把修改的日志目录挂载到镜像内便可\n ...\rstandalone:\rcontainer_name: milvus-standalone\rimage: milvusdb/milvus:v2.0.0-rc7-20211011-d567b21\rcommand: [\u0026quot;milvus\u0026quot;, \u0026quot;run\u0026quot;, \u0026quot;standalone\u0026quot;]\renvironment:\rETCD_ENDPOINTS: etcd:2379\rMINIO_ADDRESS: minio:9000\rvolumes:\r- ${DOCKER_VOLUME_DIRECTORY:-.}/volumes/milvus:/var/lib/milvus\r- /home/chenyixun/configs/milvus.yaml:/milvus/configs/milvus.yaml\r- /home/chenyixun/logs:/milvus/logs\r# 冒号前面是镜像外的路径，后面是镜像里面的路径\r# 镜像里 /milvus/configs/milvus.yaml 的目录是固定的\r# /milvus/logs 这个目录名字和 milvus.yaml 文件中配置的保持一致\r...\r 2、权限配置相关  注：我这里使用的是 v2.2.1 版本，早期版本肯定不支持此项配置\n 根据指定版本 下载milvus.yaml配置文件: https://raw.githubusercontent.com/milvus-io/milvus/v2.2.1/configs/milvus.yaml\n开启权限认证配置 common:\r# ... security:\rauthorizationEnabled: true # 这里默认是关闭的， 将其改为true即可生效\r# tls mode values [0, 1, 2]\r# 0 is close, 1 is one-way authentication, 2 is two-way authentication.\rtlsMode: 0\r  注意：开启后， 默认用户名为root 密码为 Milvus\n 更新用户密码 更新root用户密码 或是 添加新的用户信息\n目前好像暂时不支持配置文件添加\n需要使用api调用创建，参看官方文档，https://milvus.io/docs/authenticate.md\nAPI代码如下：\nUpdateCredentialParam param = UpdateCredentialParam.newBuilder()\r.withUsername(username)\r.withOldPassword(oldPassword)\r.withNewPassword(newPassword)\r.build();\rR\u0026lt;RpcStatus\u0026gt; response = milvusServiceClient.updateCredential(param);\rif (response.getStatus() != 0) {\rlog.error(\u0026quot;Milvus更新用户密码失败,原因 :{} \u0026quot;, response);\rreturn false;\r}\r 更改完 root用户密码后 ，如果当前使用的 是root用户，那么原链接将失效，需要重启服务，更新用户密码配置信息\n","id":8,"section":"posts","summary":"Milvus单机部署配置 1、配置Milvus日志目录挂载 转载文章：https://www.jianshu.com/p/0c594a5a8f2","tags":["milvus"],"title":"Milvus单机部署配置","uri":"https://bluestaree.github.io/2023/01/milvus%E5%8D%95%E6%9C%BA%E9%83%A8%E7%BD%B2%E9%85%8D%E7%BD%AE/","year":"2023"},{"content":" Milvus向量数据库安装及使用 ​\t项目需求包含以图搜人功能，查询目前相关解决方案，milvus热度较高，决定基于milvus进行以图搜人开发，原理是结合 虹软4.0 提取图片特征值，将特征值转为256位特征值向量， 存入milvus进行距离计算，以此估计图片相似度。通过百万数据测试，milvus距离大于0.55的，虹软匹配结果相似度在80%左右\nmilvus环境搭建 mivlus官方文档：https://milvus.io/docs/v2.1.x\n这里采用docker方式部署,注意文档中的最低版本要求\n Docker 19.03 or later Docker Compose 1.25.1 or later  docker-cpmpoese方式部署单机版本 参考文档，首页拉取 docker-cpmpoese 文件\nwget https://github.com/milvus-io/milvus/releases/download/v2.1.4/milvus-standalone-docker-compose.yml -O docker-compose.yml\r使用部署命令 docker-compose up -d\r如需停止所有相关组件： docker-compose stop\r如需启动所有相关组件： docker-compose start\r如需停止并删除容器： docker-compose down\r 查询容器 信息\n安装使用工具 根据需要，安装使用工具。这里使用 Aattu (可视化管理)。\n安装流程就不细说了，没什么需要注意的点，按官网文档给出的流程一步步走就ok\n另外还可以安装Milvus-CLI 命令行工具\n到目前位置milvus相关准备工作已经完成，\n代码接入 milvus 代码相关文档https://milvus.io/api-reference/java/v2.1.0/About.md\nmaven配置 \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;io.milvus\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;milvus-sdk-java\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.1.0\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 这里包含的日志实现，如果与当前使用冲突可以排除引用\n 主要配置 Milvus连接工厂\n@Component\rpublic class MilvusPoolFactory extends BasePooledObjectFactory\u0026lt;MilvusServiceClient\u0026gt; {\rpublic static MilvusPoolFactory milvusPoolFactory;\r@Autowired\rprivate MilvusConfig milvusConfig;\r@PostConstruct\rpublic void init() {\rmilvusPoolFactory = this;\rmilvusPoolFactory.milvusConfig = milvusConfig;\r// 链接预热\rMilvusServiceClient client = milvusPoolFactory.create();\rclient.hasCollection(HasCollectionParam.newBuilder()\r.withCollectionName(\u0026quot;test\u0026quot;)\r.build());\rclient.close();\r}\r@Override\rpublic MilvusServiceClient create() {\rConnectParam connectParam = ConnectParam.newBuilder()\r.withHost(milvusPoolFactory.milvusConfig.getHost())\r.withPort(milvusPoolFactory.milvusConfig.getPort())\r.build();\rMilvusServiceClient client = new MilvusServiceClient(connectParam);\rreturn client;\r}\r@Override\rpublic PooledObject\u0026lt;MilvusServiceClient\u0026gt; wrap(MilvusServiceClient milvusServiceClient) {\rreturn new DefaultPooledObject\u0026lt;\u0026gt;(milvusServiceClient);\r}\r}\r Milvus配置文件\n@Data\r@Component\r@ConfigurationProperties(prefix = \u0026quot;aiot.milvus\u0026quot;)\rpublic class MilvusConfig {\r/**\r* milvus所在服务器地址\r*/\rprivate String host;\r/**\r* milvus所在服务器端口\r*/\rprivate Integer port;\r/**\r* 以图搜人查询因子 越低查询得数据就越多，计算方式 前端传递相似度 * 查询因子 = milvus - score\r*/\rprivate BigDecimal factor;\r@Bean(\u0026quot;milvusServiceClientGenericObjectPool\u0026quot;)\rpublic GenericObjectPool milvusServiceClientGenericObjectPool() {\rMilvusPoolFactory milvusPoolFactory = new MilvusPoolFactory();\r// 对象池配置\rGenericObjectPoolConfig\u0026lt;FaceEngine\u0026gt; objectPoolConfig = new GenericObjectPoolConfig\u0026lt;\u0026gt;();\robjectPoolConfig.setMaxTotal(8);\robjectPoolConfig.setJmxEnabled(false);\rAbandonedConfig abandonedConfig = new AbandonedConfig();\r// 在Maintenance的时候检查是否有泄漏\rabandonedConfig.setRemoveAbandonedOnMaintenance(true);\r// borrow 的时候检查泄漏\rabandonedConfig.setRemoveAbandonedOnBorrow(true);\r// 如果一个对象borrow之后10秒还没有返还给pool，认为是泄漏的对象\rabandonedConfig.setRemoveAbandonedTimeout(5);\r// 对象池\rGenericObjectPool\u0026lt;MilvusServiceClient\u0026gt; milvusServiceClientGenericObjectPool = new GenericObjectPool(milvusPoolFactory, objectPoolConfig);\rmilvusServiceClientGenericObjectPool.setAbandonedConfig(abandonedConfig);\r// 5秒运行一次维护任务\rmilvusServiceClientGenericObjectPool.setTimeBetweenEvictionRunsMillis(5000);\rreturn milvusServiceClientGenericObjectPool;\r}\r}\r 项目启动配置文件\nmilvus:\rhost: 192.168.1.172\rport: 19530\r 方法实现 Milvus工具类\n@Data\r@Component\r@Slf4j\rpublic class MilvusOperateUtils {\r@Autowired\rprivate MilvusConfig milvusConfig;\r@Autowired\r@Qualifier(value = \u0026quot;milvusServiceClientGenericObjectPool\u0026quot;)\rprivate GenericObjectPool\u0026lt;MilvusServiceClient\u0026gt; milvusServiceClientGenericObjectPool;\r/**\r* 创建集合（库）\r*\r* @param collectionName 集合名\r* @param milvusServiceClient 操作客户端对象\r* @return void\r*/\rpublic boolean createCollection(String collectionName, MilvusServiceClient milvusServiceClient) {\r// 参数校验\rif(StrUtil.isEmpty(collectionName)) {\rlog.error(\u0026quot;未输入集合名称\u0026quot;);\rreturn false;\r}\rboolean needReturn = false;\rtry {\rif(milvusServiceClient == null) {\r// 通过对象池管理对象\rmilvusServiceClient = milvusServiceClientGenericObjectPool.borrowObject();\rneedReturn = true;\r}\rCreateCollectionParam createCollectionReq = null;\r// 判断是否存在集合信息\rboolean hasCollection = hasCollection(collectionName, milvusServiceClient);\rif (hasCollection) {\r// 集合已创建\rreturn true;\r}\rif(StrUtil.equals(collectionName, MilvusConstants.COLLECTION_FACE_NAME)) {\rFieldType collectionId = FieldType.newBuilder()\r.withName(MilvusConstants.FaceArchiveField.COLLECTION_ID)\r.withDescription(\u0026quot;集合主键id\u0026quot;)\r.withDataType(DataType.Int64)\r.withPrimaryKey(true)\r.withAutoID(false)\r.build();\rFieldType memberId = FieldType.newBuilder()\r.withName(MilvusConstants.FaceArchiveField.MEMBER_ID)\r.withDescription(\u0026quot;用户id\u0026quot;)\r.withDataType(DataType.Int64)\r.build();\rFieldType timestamp = FieldType.newBuilder()\r.withName(MilvusConstants.FaceArchiveField.TIMESTAMP)\r.withDescription(\u0026quot;时间戳\u0026quot;)\r.withDataType(DataType.Int64)\r.build();\rFieldType faceFeature = FieldType.newBuilder()\r.withName(MilvusConstants.FaceArchiveField.FACE_FEATURE)\r.withDescription(\u0026quot;人脸特征向量\u0026quot;)\r.withDataType(DataType.FloatVector)\r.withDimension(MilvusConstants.FEATURE_DIM)\r.build();\rcreateCollectionReq = CreateCollectionParam.newBuilder()\r.withCollectionName(collectionName)\r.withDescription(\u0026quot;人脸特征向量库\u0026quot;)\r.withShardsNum(MilvusConstants.SHARDS_NUM)\r.addFieldType(collectionId)\r.addFieldType(memberId)\r.addFieldType(timestamp)\r.addFieldType(faceFeature)\r.build();\r} else if(collectionName.startsWith(MilvusConstants.COLLECTION_LOG_PREFIX)) {\rFieldType collectionId = FieldType.newBuilder()\r.withName(MilvusConstants.FaceSnapshotField.COLLECTION_ID)\r.withDescription(\u0026quot;集合主键id\u0026quot;)\r.withDataType(DataType.Int64)\r.withPrimaryKey(true)\r.withAutoID(false)\r.build();\rFieldType logId = FieldType.newBuilder()\r.withName(MilvusConstants.FaceSnapshotField.LOG_ID)\r.withDescription(\u0026quot;日志id\u0026quot;)\r.withDataType(DataType.Int64)\r.build();\rFieldType logType = FieldType.newBuilder()\r.withName(MilvusConstants.FaceSnapshotField.LOG_TYPE)\r.withDescription(\u0026quot;日志类型\u0026quot;)\r.withDataType(DataType.Int32)\r.build();\rFieldType deviceId = FieldType.newBuilder()\r.withName(MilvusConstants.FaceSnapshotField.DEVICE_ID)\r.withDescription(\u0026quot;设备id\u0026quot;)\r.withDataType(DataType.Int64)\r.build();\rFieldType timestamp = FieldType.newBuilder()\r.withName(MilvusConstants.FaceSnapshotField.TIMESTAMP)\r.withDescription(\u0026quot;时间戳\u0026quot;)\r.withDataType(DataType.Int64)\r.build();\rFieldType faceFeature = FieldType.newBuilder()\r.withName(MilvusConstants.FaceSnapshotField.FACE_FEATURE)\r.withDescription(\u0026quot;图片特征向量\u0026quot;)\r.withDataType(DataType.FloatVector)\r.withDimension(MilvusConstants.FEATURE_DIM)\r.build();\rcreateCollectionReq = CreateCollectionParam.newBuilder()\r.withCollectionName(collectionName)\r.withDescription(\u0026quot;日志抓拍特征向量库\u0026quot;)\r.withShardsNum(MilvusConstants.SHARDS_NUM)\r.addFieldType(collectionId)\r.addFieldType(logId)\r.addFieldType(logType)\r.addFieldType(deviceId)\r.addFieldType(timestamp)\r.addFieldType(faceFeature)\r.build();\r} else {\rlog.error(\u0026quot;预设集合信息不存在\u0026quot;);\rreturn false;\r}\rR\u0026lt;RpcStatus\u0026gt; result = milvusServiceClient.createCollection(createCollectionReq);\rif (result.getStatus() != 0) {\rlog.error(\u0026quot;Milvus创建集合失败 集合:{}，结果：{}\u0026quot;, collectionName, result);\rreturn false;\r}\r// 创建索引\rcreateIndex(collectionName, MilvusConstants.FaceArchiveField.FACE_FEATURE, \u0026quot;{\\\u0026quot;nlist\\\u0026quot;:2048}\u0026quot;, milvusServiceClient);\rreturn true;\r} catch (Exception e) {\rlog.error(\u0026quot;创建集合异常 :{}\u0026quot;, e);\r} finally {\r// 回收对象到对象池\rif (milvusServiceClient != null \u0026amp;\u0026amp; needReturn) {\rmilvusServiceClientGenericObjectPool.returnObject(milvusServiceClient);\r}\r}\rreturn false;\r}\r/**\r* 创建索引\r*\r* @param collectionName 集合名\r* @param milvusServiceClient 操作客户端对象\r* @return void\r*/\rpublic boolean createIndex(String collectionName, String indexFileName, String extraParam, MilvusServiceClient milvusServiceClient) {\rboolean needReturn = false;\rtry {\rif(milvusServiceClient == null) {\r// 通过对象池管理对象\rmilvusServiceClient = milvusServiceClientGenericObjectPool.borrowObject();\rneedReturn = true;\r}\rR\u0026lt;RpcStatus\u0026gt; result = milvusServiceClient.createIndex(\rCreateIndexParam.newBuilder()\r// 集合名称\r.withCollectionName(collectionName)\r// 索引字段名称\r.withFieldName(indexFileName)\r// 索引类型\r.withIndexType(IndexType.IVF_FLAT)\r.withMetricType(MetricType.IP)\r// nlist 建议值为 4 × sqrt(n)，其中 n 指 segment 最多包含的 entity 条数\r.withExtraParam(extraParam)\r.withSyncMode(Boolean.FALSE)\r.build());\rif (result.getStatus() != 0) {\rlog.error(\u0026quot;Milvus创建集合索失败 集合:{}，结果：{}\u0026quot;, collectionName, result);\rreturn false;\r}\rreturn true;\r} catch (Exception e) {\rlog.error(\u0026quot;创建集合索引异常 :{}\u0026quot;, e);\r} finally {\r// 回收对象到对象池\rif (milvusServiceClient != null \u0026amp;\u0026amp; needReturn) {\rmilvusServiceClientGenericObjectPool.returnObject(milvusServiceClient);\r}\r}\rreturn false;\r}\r/**\r* 创建分区\r*\r* @param collectionName 集合名\r* @param milvusServiceClient 操作客户端对象\r* @return void\r*/\rpublic void createPartition(String collectionName, MilvusServiceClient milvusServiceClient) {\rboolean needReturn = false;\rtry {\rif(milvusServiceClient == null) {\r// 通过对象池管理对象\rmilvusServiceClient = milvusServiceClientGenericObjectPool.borrowObject();\rneedReturn = true;\r}\r// 根据定义分区数， 循环创建\rfor (int i = 0; i \u0026lt; MilvusConstants.PARTITION_NUM; i++) {\rString partitionName = MilvusConstants.PARTITION_PREFIX + i;\rR\u0026lt;RpcStatus\u0026gt; result = milvusServiceClient.createPartition(\rCreatePartitionParam.newBuilder()\r.withCollectionName(collectionName)\r.withPartitionName(partitionName)\r.build());\rif (result.getStatus() != 0) {\rlog.error(\u0026quot;Milvus创建集合分区失败 集合:{}，分区:{}，结果：{}\u0026quot;, collectionName, partitionName, result);\r}\r}\r} catch (Exception e) {\rlog.error(\u0026quot;创建分区异常 :{}\u0026quot;, e);\r} finally {\r// 回收对象到对象池\rif (milvusServiceClient != null \u0026amp;\u0026amp; needReturn) {\rmilvusServiceClientGenericObjectPool.returnObject(milvusServiceClient);\r}\r}\r}\r/**\r* 判断是否存在集合\r*\r* @param collectionName 集合名\r* @param milvusServiceClient 操作客户端对象\r* @return void\r*/\rpublic boolean hasCollection(String collectionName, MilvusServiceClient milvusServiceClient) {\rboolean needReturn = false;\rtry {\rif(milvusServiceClient == null) {\r// 通过对象池管理对象\rmilvusServiceClient = milvusServiceClientGenericObjectPool.borrowObject();\rneedReturn = true;\r}\r// 判断是否存在集合信息\rR\u0026lt;Boolean\u0026gt; result = milvusServiceClient.hasCollection(\rHasCollectionParam.newBuilder()\r.withCollectionName(collectionName)\r.build());\rif (result.getStatus() != 0) {\rlog.error(\u0026quot;Milvus判断是否存在集合失败,原因 :{} \u0026quot;, result);\rreturn false;\r}\rif (result.getStatus() == 0 \u0026amp;\u0026amp; Boolean.TRUE.booleanValue() == result.getData()) {\r// 集合已创建\rreturn true;\r}\r} catch (Exception e) {\rlog.error(\u0026quot;判断集合是否存在异常 :{}\u0026quot;, e);\r} finally {\r// 回收对象到对象池\rif (milvusServiceClient != null \u0026amp;\u0026amp; needReturn) {\rmilvusServiceClientGenericObjectPool.returnObject(milvusServiceClient);\r}\r}\rreturn false;\r}\r/**\r* 加载集合\r*\r* @param collectionName 集合名\r* @param milvusServiceClient 操作客户端对象\r* @return void\r*/\rpublic boolean loadingCollection(String collectionName, MilvusServiceClient milvusServiceClient) {\rboolean needReturn = false;\rtry {\rif(milvusServiceClient == null) {\r// 通过对象池管理对象\rmilvusServiceClient = milvusServiceClientGenericObjectPool.borrowObject();\rneedReturn = true;\r}\rR\u0026lt;RpcStatus\u0026gt; result = milvusServiceClient.loadCollection(\rLoadCollectionParam.newBuilder()\r.withCollectionName(collectionName)\r.build());\rif (result.getStatus() != 0) {\rlog.error(\u0026quot;Milvus加载集合失败,原因 :{} \u0026quot;, result);\rreturn false;\r}\rreturn true;\r} catch (Exception e) {\rlog.error(\u0026quot;加载集合异常 :{}\u0026quot;, e);\r} finally {\r// 回收对象到对象池\rif (milvusServiceClient != null \u0026amp;\u0026amp; needReturn) {\rmilvusServiceClientGenericObjectPool.returnObject(milvusServiceClient);\r}\r}\rreturn false;\r}\r/**\r* 释放集合\r*\r* @param collectionName 集合名\r* @param milvusServiceClient 操作客户端对象\r* @return void\r*/\rpublic boolean releaseCollection(String collectionName, MilvusServiceClient milvusServiceClient) {\rboolean needReturn = false;\rtry {\rif(milvusServiceClient == null) {\r// 通过对象池管理对象\rmilvusServiceClient = milvusServiceClientGenericObjectPool.borrowObject();\rneedReturn = true;\r}\rR\u0026lt;RpcStatus\u0026gt; result = milvusServiceClient.releaseCollection(\rReleaseCollectionParam.newBuilder()\r.withCollectionName(collectionName)\r.build());\rif (result.getStatus() != 0) {\rlog.error(\u0026quot;Milvus释放集合失败,原因 :{} \u0026quot;, result);\rreturn false;\r}\rreturn true;\r} catch (Exception e) {\rlog.error(\u0026quot;释放集合异常 :{}\u0026quot;, e);\r} finally {\r// 回收对象到对象池\rif (milvusServiceClient != null \u0026amp;\u0026amp; needReturn) {\rmilvusServiceClientGenericObjectPool.returnObject(milvusServiceClient);\r}\r}\rreturn false;\r}\r/**\r* 加载集合分区\r*\r* @param collectionName 集合名\r* @param partitionNames 分区名\r* @param milvusServiceClient 操作客户端对象\r* @return void\r*/\rpublic boolean loadingPartitions(String collectionName, List\u0026lt;String\u0026gt; partitionNames, MilvusServiceClient milvusServiceClient) {\rboolean needReturn = false;\rtry {\rif(milvusServiceClient == null) {\r// 通过对象池管理对象\rmilvusServiceClient = milvusServiceClientGenericObjectPool.borrowObject();\rneedReturn = true;\r}\r// 加载Partitions\rR\u0026lt;RpcStatus\u0026gt; result = milvusServiceClient.loadPartitions(\rLoadPartitionsParam.newBuilder()\r.withCollectionName(collectionName)\r.withPartitionNames(partitionNames)\r.build());\rif (result.getStatus() != 0) {\rlog.error(\u0026quot;Milvus加载集合分区失败,原因 :{} \u0026quot;, result);\rreturn false;\r}\rreturn true;\r} catch (Exception e) {\rlog.error(\u0026quot;加载集合异常 :{}\u0026quot;, e);\r} finally {\r// 回收对象到对象池\rif (milvusServiceClient != null \u0026amp;\u0026amp; needReturn) {\rmilvusServiceClientGenericObjectPool.returnObject(milvusServiceClient);\r}\r}\rreturn false;\r}\r/**\r* 释放集合分区\r*\r* @param collectionName 集合名\r* @param partitionNames 分区名\r* @param milvusServiceClient 操作客户端对象\r* @return void\r*/\rpublic boolean releasePartitions(String collectionName, List\u0026lt;String\u0026gt; partitionNames, MilvusServiceClient milvusServiceClient) {\rboolean needReturn = false;\rtry {\rif(milvusServiceClient == null) {\r// 通过对象池管理对象\rmilvusServiceClient = milvusServiceClientGenericObjectPool.borrowObject();\rneedReturn = true;\r}\r// 释放Partitions\rR\u0026lt;RpcStatus\u0026gt; result = milvusServiceClient.releasePartitions(\rReleasePartitionsParam.newBuilder()\r.withCollectionName(collectionName)\r.withPartitionNames(partitionNames)\r.build());\rif (result.getStatus() != 0) {\rlog.error(\u0026quot;Milvus释放集合分区失败,原因 :{} \u0026quot;, result);\rreturn false;\r}\rreturn true;\r} catch (Exception e) {\rlog.error(\u0026quot;加载集合异常 :{}\u0026quot;, e);\r} finally {\r// 回收对象到对象池\rif (milvusServiceClient != null \u0026amp;\u0026amp; needReturn) {\rmilvusServiceClientGenericObjectPool.returnObject(milvusServiceClient);\r}\r}\rreturn false;\r}\r/**\r* 删除集合\r*\r* @param collectionName 集合名\r* @return void\r*/\rpublic boolean delCollection(String collectionName) {\rMilvusServiceClient milvusServiceClient = null;\rtry {\r// 通过对象池管理对象\rmilvusServiceClient = milvusServiceClientGenericObjectPool.borrowObject();\rR\u0026lt;RpcStatus\u0026gt; result = milvusServiceClient.dropCollection(\rDropCollectionParam.newBuilder()\r.withCollectionName(collectionName)\r.build());\rif (result.getStatus() != 0) {\rlog.error(\u0026quot;Milvus删除集合失败,原因 :{} \u0026quot;, result);\rreturn false;\r}\rreturn true;\r} catch (Exception e) {\rlog.error(\u0026quot;删除集合异常 :{}\u0026quot;, e);\r} finally {\r// 回收对象到对象池\rif (milvusServiceClient != null) {\rmilvusServiceClientGenericObjectPool.returnObject(milvusServiceClient);\r}\r}\rreturn false;\r}\r/**\r* 删除实体\r*\r* @param collectionName 集合名\r* @param partitionName 分区名\r* @param expression 表达式\r* @param milvusServiceClient 操作客户端对象\r* @return void\r*/\rpublic boolean deleteEntity(String collectionName, String partitionName, String expression, MilvusServiceClient milvusServiceClient) {\rboolean needReturn = false;\rtry {\rif(milvusServiceClient == null) {\r// 通过对象池管理对象\rmilvusServiceClient = milvusServiceClientGenericObjectPool.borrowObject();\rneedReturn = true;\r}\r// 判断是否存在集合信息\rR\u0026lt;MutationResult\u0026gt; result = milvusServiceClient.delete(\rDeleteParam.newBuilder()\r.withCollectionName(collectionName)\r.withPartitionName(partitionName)\r// 操作表达式\r.withExpr(expression)\r.build());\rif (result.getStatus() != 0) {\rlog.error(\u0026quot;Milvus删除集合实体信息失败,原因 :{} \u0026quot;, result);\rreturn false;\r}\rreturn true;\r} catch (Exception e) {\rlog.error(\u0026quot;删除集合实体信息异常 :{}\u0026quot;, e);\r} finally {\r// 回收对象到对象池\rif (milvusServiceClient != null \u0026amp;\u0026amp; needReturn) {\rmilvusServiceClientGenericObjectPool.returnObject(milvusServiceClient);\r}\r}\rreturn false;\r}\r/**\r* 修改用户名密码 v2.2.1版本用\r*\r* @param username 用户名\r* @param oldPassword 旧密码\r* @param newPassword 新密码\r* @param milvusServiceClient 操作客户端对象\r* @return void\r*/\r// public boolean updateUserPwd(String username, String oldPassword, String newPassword, MilvusServiceClient milvusServiceClient) {\r// boolean needReturn = false;\r// try {\r// if(milvusServiceClient == null) {\r// // 通过对象池管理对象\r// milvusServiceClient = milvusServiceClientGenericObjectPool.borrowObject();\r// needReturn = true;\r// }\r// UpdateCredentialParam param = UpdateCredentialParam.newBuilder()\r// .withUsername(username)\r// .withOldPassword(oldPassword)\r// .withNewPassword(newPassword)\r// .build();\r// R\u0026lt;RpcStatus\u0026gt; response = milvusServiceClient.updateCredential(param);\r// if (response.getStatus() != 0) {\r// log.error(\u0026quot;Milvus更新用户密码失败,原因 :{} \u0026quot;, response);\r// return false;\r// }\r// return true;\r// } catch (Exception e) {\r// log.error(\u0026quot;更新用户密码异常 :{}\u0026quot;, e);\r// } finally {\r// // 回收对象到对象池\r// if (milvusServiceClient != null \u0026amp;\u0026amp; needReturn) {\r// milvusServiceClientGenericObjectPool.returnObject(milvusServiceClient);\r// }\r// }\r// return false;\r// }\r/**\r* 插入数据\r*\r* @param faceArchiveDto 传输数据\r* @return void\r*/\rpublic long insert(MilvusFaceArchiveDTO faceArchiveDto) {\rMilvusServiceClient milvusServiceClient = null;\rtry {\r// 获取插入集合信息\rString collectionName = MilvusConstants.getCollectionName(faceArchiveDto.getCollectionPrefix(), new Date());\r// 获取插入集合分区信息\rString partitionName = MilvusConstants.getPartitionName(faceArchiveDto.getTenantId());\r// 参数校验\rif(StrUtil.isEmpty(collectionName) || StrUtil.isEmpty(partitionName)) {\rlog.error(\u0026quot;插入数据失败： 无法获取集合名称或分区名称\u0026quot;);\rreturn 0;\r}\r// 通过对象池管理对象\rmilvusServiceClient = milvusServiceClientGenericObjectPool.borrowObject();\r// 组装字段数据\rList\u0026lt;InsertParam.Field\u0026gt; fields = new ArrayList\u0026lt;\u0026gt;();\rif(StrUtil.equals(collectionName, MilvusConstants.COLLECTION_FACE_NAME)) {\rfields.add(new InsertParam.Field(MilvusConstants.FaceArchiveField.COLLECTION_ID, faceArchiveDto.getCollectionIdList()));\rfields.add(new InsertParam.Field(MilvusConstants.FaceArchiveField.MEMBER_ID, faceArchiveDto.getMemberIdList()));\rfields.add(new InsertParam.Field(MilvusConstants.FaceArchiveField.TIMESTAMP, faceArchiveDto.getTimestampList()));\rfields.add(new InsertParam.Field(MilvusConstants.FaceArchiveField.FACE_FEATURE, faceArchiveDto.getFeatureList()));\r} else if(collectionName.startsWith(MilvusConstants.COLLECTION_LOG_PREFIX)) {\rfields.add(new InsertParam.Field(MilvusConstants.FaceSnapshotField.COLLECTION_ID, faceArchiveDto.getCollectionIdList()));\rfields.add(new InsertParam.Field(MilvusConstants.FaceSnapshotField.LOG_ID, faceArchiveDto.getLogIdList()));\rfields.add(new InsertParam.Field(MilvusConstants.FaceSnapshotField.LOG_TYPE, faceArchiveDto.getLogTypeList()));\rfields.add(new InsertParam.Field(MilvusConstants.FaceSnapshotField.DEVICE_ID, faceArchiveDto.getDeviceIdList()));\rfields.add(new InsertParam.Field(MilvusConstants.FaceSnapshotField.TIMESTAMP, faceArchiveDto.getTimestampList()));\rfields.add(new InsertParam.Field(MilvusConstants.FaceSnapshotField.FACE_FEATURE, faceArchiveDto.getFeatureList()));\r} else {\rlog.error(\u0026quot;预设集合信息不存在\u0026quot;);\rreturn 0;\r}\r// 判断是否存在集合信息\rboolean hasCollection = hasCollection(collectionName, milvusServiceClient);\rif (!hasCollection) {\r// 创建集合\rboolean b = createCollection(collectionName, milvusServiceClient);\rif(b) {\r// 创建分区\rcreatePartition(collectionName, milvusServiceClient);\r} else{\rlog.error(\u0026quot;Milvus数据上传失败,未成功创建集合\u0026quot;);\rreturn 0;\r}\r}\rInsertParam insertParam = InsertParam.newBuilder()\r.withCollectionName(collectionName)\r.withPartitionName(partitionName)\r.withFields(fields)\r.build();\rR\u0026lt;MutationResult\u0026gt; insertResult = milvusServiceClient.insert(insertParam);\rif (insertResult.getStatus() == 0) {\r// log.info(\u0026quot;Milvus数据上传成功,结果 :{} \u0026quot;, insertResult.getData().getIDs().getIntId());\rreturn insertResult.getData().getIDs().getIntId().getData(0);\r} else {\rlog.error(\u0026quot;Milvus数据上传失败,原因 :{} \u0026quot;, insertResult);\r}\r} catch (Exception e) {\rlog.error(\u0026quot;插入集合数据异常 :{}\u0026quot;, e);\r} finally {\r// 回收对象到对象池\rif (milvusServiceClient != null) {\rmilvusServiceClientGenericObjectPool.returnObject(milvusServiceClient);\r}\r}\rreturn 0;\r}\r/**\r* 根据向量搜索数据\r*\r* @param faceSearchVO 查询信息\r* @return void\r*/\rpublic List\u0026lt;MilvusSearchResultVO\u0026gt; searchByFeature(MilvusFaceSearchVO faceSearchVO) {\rreturn searchByFeature(faceSearchVO, null, null);\r}\r/**\r* 根据向量搜索数据\r*\r* @param faceSearchVO 查询信息\r* @param builder 查询条件\r* @param milvusServiceClient 操作客户端对象\r* @return void\r*/\rpublic List\u0026lt;MilvusSearchResultVO\u0026gt; searchByFeature(MilvusFaceSearchVO faceSearchVO, SearchParam.Builder builder, MilvusServiceClient milvusServiceClient) {\rboolean needReturn = false;\rList\u0026lt;MilvusSearchResultVO\u0026gt; resultVOS = new ArrayList\u0026lt;\u0026gt;();\rtry {\rif(milvusServiceClient == null) {\r// 通过对象池管理对象\rmilvusServiceClient = milvusServiceClientGenericObjectPool.borrowObject();\rneedReturn = true;\r}\rString collectionName = faceSearchVO.getCollectionName();\r// 参数校验\rif(StrUtil.isEmpty(collectionName)) {\rreturn resultVOS;\r}\rif(builder == null \u0026amp;\u0026amp; (builder = getSearchBuilder(faceSearchVO)) == null) {\rreturn resultVOS;\r}\r// 查询前加载集合进入缓存\rloadingCollection(collectionName, milvusServiceClient);\r// 发起搜索请求\rR\u0026lt;SearchResults\u0026gt; respSearch = milvusServiceClient.search(builder.build());\r// 组装结果数据\rif (respSearch.getStatus() == 0 \u0026amp;\u0026amp; !StrUtil.equals(respSearch.getData().getStatus().getReason(), MilvusConstants.EMPTY_REASON)){\rSearchResultsWrapper wrapperSearch = new SearchResultsWrapper(respSearch.getData().getResults());\r// 获取查询结果\rList\u0026lt;SearchResultsWrapper.IDScore\u0026gt; idScore = wrapperSearch.getIDScore(0);\r// log.info(\u0026quot;查询结果：{}\u0026quot;, idScore);\r}\r// 释放集合\r// releaseCollection(collectionName, milvusServiceClient);\r} catch (Exception e) {\rlog.error(\u0026quot;数据查询异常 :{}\u0026quot;, e);\r} finally {\r// 回收对象到对象池\rif (milvusServiceClient != null \u0026amp;\u0026amp; needReturn) {\rmilvusServiceClientGenericObjectPool.returnObject(milvusServiceClient);\r}\r}\rreturn resultVOS;\r}\r/**\r* 构建milvus查询条件\r*\r* @param faceSearchVO\r* @return Builder\r*/\rprivate SearchParam.Builder getSearchBuilder(MilvusFaceSearchVO faceSearchVO) {\rboolean timeScope = false;\rString collectionName = faceSearchVO.getCollectionName();\r// 定义输出字段\rList\u0026lt;String\u0026gt; searchOutputFields = new ArrayList\u0026lt;\u0026gt;();\rif(StrUtil.equals(collectionName, MilvusConstants.COLLECTION_FACE_NAME)) {\rsearchOutputFields.add(MilvusConstants.FaceArchiveField.COLLECTION_ID);\rsearchOutputFields.add(MilvusConstants.FaceArchiveField.MEMBER_ID);\r} else if(collectionName.startsWith(MilvusConstants.COLLECTION_LOG_PREFIX)) {\rsearchOutputFields.add(MilvusConstants.FaceSnapshotField.COLLECTION_ID);\rsearchOutputFields.add(MilvusConstants.FaceSnapshotField.LOG_ID);\rsearchOutputFields.add(MilvusConstants.FaceSnapshotField.LOG_TYPE);\rsearchOutputFields.add(MilvusConstants.FaceSnapshotField.DEVICE_ID);\rsearchOutputFields.add(MilvusConstants.FaceSnapshotField.TIMESTAMP);\rtimeScope = true;\r} else {\rlog.info(\u0026quot;查询失败：集合不存在\u0026quot;);\rreturn null;\r}\rList\u0026lt;String\u0026gt; partitionList = new ArrayList\u0026lt;\u0026gt;();\r// 获取租户id\rString tenantId = faceSearchVO.getTenantId();\rif (StrUtil.isNotEmpty(tenantId)) {\r// 计算当前租户查询分区\rString partitionName = MilvusConstants.getPartitionName(tenantId);\rpartitionList.add(partitionName);\r}\r// 构建查询参数\rSearchParam.Builder builder = SearchParam.newBuilder()\r// 查询集合\r.withCollectionName(collectionName)\r// 查询分区\r.withPartitionNames(partitionList)\r// 计算方式\r.withMetricType(MetricType.IP)\r// 输出字段\r.withOutFields(searchOutputFields)\r// 查询数据量\r.withTopK(faceSearchVO.getTopK())\r// 查询向量\r.withVectors(faceSearchVO.getSearchVectors())\r// 向量字段\r.withVectorFieldName(MilvusConstants.FaceArchiveField.FACE_FEATURE)\r// 查询参数\r.withParams(faceSearchVO.getParam());\r// 构建查询条件\rStringBuffer sb = new StringBuffer();\r// 设备id\rif (StrUtil.isNotEmpty(faceSearchVO.getDeviceId())) {\rString[] split = faceSearchVO.getDeviceId().split(StrUtil.COMMA);\rsb.append(\u0026quot; ( \u0026quot;);\rfor (int i = 0; i \u0026lt; split.length; i++) {\rsb.append(MilvusConstants.FaceSnapshotField.DEVICE_ID);\rsb.append(\u0026quot; == \u0026quot;);\rsb.append(split[i]);\rif(i != split.length - 1) {\rsb.append(\u0026quot; || \u0026quot;);\r}\r}\rsb.append(\u0026quot; ) \u0026quot;);\rsb.append(\u0026quot; \u0026amp;\u0026amp; \u0026quot;);\r}\r// 搜索范围\rInteger searchType = faceSearchVO.getSearchType();\rif(searchType != null) {\rsb.append(MilvusConstants.FaceSnapshotField.LOG_TYPE);\rsb.append(\u0026quot; == \u0026quot;);\rsb.append(searchType);\rsb.append(\u0026quot; \u0026amp;\u0026amp; \u0026quot;);\r}\r// 时间范围\rif(timeScope) {\rString beginTime = faceSearchVO.getBeginTime();\rString endTime = faceSearchVO.getEndTime();\rlong begin = 0L;\rlong end = 0L;\rif (StrUtil.isNotEmpty(beginTime) \u0026amp;\u0026amp; StrUtil.isNotEmpty(endTime)) {\rbegin = DateUtil.parseDateTime(beginTime).getTime();\rend = DateUtil.parseDateTime(endTime).getTime();\r} else {\r// 默认查询范围 30天\rDate now = new Date();\rend = now.getTime();\rbegin = DateUtil.offsetMonth(now, -1).getTime();\r}\rsb.append(MilvusConstants.FaceSnapshotField.TIMESTAMP);\rsb.append(\u0026quot; \u0026gt;= \u0026quot;);\rsb.append(begin);\rsb.append(\u0026quot; \u0026amp;\u0026amp; \u0026quot;);\rsb.append(MilvusConstants.FaceSnapshotField.TIMESTAMP);\rsb.append(\u0026quot; \u0026lt;= \u0026quot;);\rsb.append(end);\rsb.append(\u0026quot; \u0026amp;\u0026amp; \u0026quot;);\r}\rif(sb.length() \u0026gt; 0) {\rbuilder\r.withExpr(sb.substring(0, sb.length() - 4));\r}\rreturn builder;\r}\r}\r 附：虹软4.0特征向量转换方法 虹软4.0特征值 共2056个字节， 前8个字节固定是浮点数类型的2004,78（可能用于区别SDK的不同版本），后面的2048个字节是512个浮点数的且前256个是0。可以忽略。只需要把后256个特征向量复制出来就可以了。\n参考：https://blog.csdn.net/Memory2414/article/details/116583985\n/**\r* 虹软byte[]特征值转List\u0026lt;Float\u0026gt;\r* @param bytes\r* @return\r*/\rpublic static List\u0026lt;Float\u0026gt; arcsoftToFloat(byte[] bytes) {\rList\u0026lt;Float\u0026gt; list = Lists.newArrayList();\rfor (int i = 1024 + 8; i \u0026lt; bytes.length; i += 4) {\rbyte[] bytes1 = {bytes[i], bytes[i + 1], bytes[i + 2], bytes[i + 3]};\rlist.add(byte2float(bytes1, 0));\r}\rreturn list;\r}\r ","id":9,"section":"posts","summary":"Milvus向量数据库安装及使用 ​ 项目需求包含以图搜人功能，查询目前相关解决方案，milvus热度较高，决定基于milvus进行以图搜人开发","tags":["milvus"],"title":"Milvus向量数据库安装及使用","uri":"https://bluestaree.github.io/2023/01/milvus%E5%90%91%E9%87%8F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/","year":"2023"},{"content":"  转发：原文 爬取高德地图poi数据\n高德地图搜索poi的api官方文档\n ​\t当前想法是爬取目标区域（做者所在小县城）的全部poi数据，存到数据库中做为原始数据，而后供其它系统调用，由于以前爬取过百度地图的poi数据，因此此次工做就得心应手了。\n​\t一、首先注册一个高德地图的开发者帐号，申请一个绑定Web服务的key，而后把刚注册的开发者帐号认证一下： 申请帐号、key就不赘述了，去高德地图开发平台很简单就能完成了，将帐号认证是为了提升每日访问高德地图api接口的次数限制和并发请求。git\n​\t二、根据上方api地址里面的介绍，总共分为4中搜索： 关键字搜索：经过用POI的关键字进行条件搜索，例如：肯德基、朝阳公园等；同时支持设置POI类型搜索，例如：银行 周边搜索：在用户传入经纬度坐标点附近，在设定的范围内，按照关键字或POI类型搜索； 多边形搜索：在多边形区域内进行搜索 ID查询：经过POI ID，查询某个POI详情，建议可同输入提示API配合使用github\n​\t个人目标是某个区域的全部poi，因此选择的第三种：多边形搜索web\n​\t三、多边形搜索最重要的参数就是polygon-》经纬度坐标对，我在百度地图坐标拾取系统拾取了个人目标区域的经纬度坐标对，以下图：​\t3步准备工做到这里就差很少结束了，在正式开始码代码以前先作个测试吧，用浏览器直接访问接口看看返回的数据（固然，高德的api接口有返回数听说明）\n​\t如上图，这里比较重要的一个属性是count，根据api的介绍count是搜索方案数目(最大值为1000)，因此说每次请求都会返回当前所搜所包含的poi个数，而大于1000的poi是没有办法获取到的。那么我若是想查询某个区域的所有数据，能够将这个区域再划分红更小的区域（显然是个递归操做）的集合，而后把这几个能够查到全部poi的区域的全部poi数据结合起来就是我最终须要的数据。可能口述不明朗，能够见下方草图：\n​\t好，能够开始撸代码了：\n​\t由于，整个调用API的过程都离不开经纬度，因此首先定义一个经纬度描述的类\n//矩形块的经纬度标识， 左上角的经纬度 和右下角的经纬度\rclass RectangleCoordinate {\r/**\r* 矩形左上角经度\r*/\rprivate double x0;\r/**\r* 矩形左上角纬度\r*/\rprivate double y0;\r/**\r* 矩形右下角经度\r*/\rprivate double x1;\r/**\r* 矩形右下角纬度\r*/\rprivate double y1;\rpublic RectangleCoordinate(double x0, double y0, double x1, double y1) {\rthis.x0 = x0;\rthis.y0 = y0;\rthis.x1 = x1;\rthis.y1 = y1;\r}\r/**\r* [@return](https://my.oschina.net/u/556800) 获取矩形中心线的纬度\r*/\rpublic double getAverageY() {\rreturn (y0 + y1) / 2;\r}\r/**\r* [@return](https://my.oschina.net/u/556800) 获取矩形中心线的经度\r*/\rpublic double getAverageX() {\rreturn (x0 + x1) / 2;\r}\rpublic double getX0() {\rreturn x0;\r}\rpublic void setX0(double x0) {\rthis.x0 = x0;\r}\rpublic double getY0() {\rreturn y0;\r}\rpublic void setY0(double y0) {\rthis.y0 = y0;\r}\rpublic double getX1() {\rreturn x1;\r}\rpublic void setX1(double x1) {\rthis.x1 = x1;\r}\rpublic double getY1() {\rreturn y1;\r}\rpublic void setY1(double y1) {\rthis.y1 = y1;\r}\r[@Override](https://my.oschina.net/u/1162528)\rpublic String toString() {\rreturn x0 + \u0026quot;,\u0026quot; + y0 + \u0026quot;|\u0026quot; + x1 + \u0026quot;,\u0026quot; + y1;\r}\r}`\r ​\t而后须要一个调用api，获取返回数据的方法，这个方法参数就是矩形块，固然还须要一个页数，即当前方法获取的是某个矩形区域的第X页的数据（每页上线25个poi，默认20个poi）\n/**\r* @return 获取矩形块的poi数据\r*/\rprivate JSONObject getSearchResult(RectangleCoordinate coordinate, int page) {\rRestTemplate restTemplate = new RestTemplate();\rString url = getRequestGaodeUrl(coordinate,page);\rString result = restTemplate.getForObject(url, String.class);\rtry {\rtry {\rThread.sleep(50);\r} catch (InterruptedException e) {\re.printStackTrace();\r}\rreturn JSONObject.parseObject(result);\r} catch (Exception e) {\rlogger.error(\u0026quot;an error occurred when getting response of gaode map data for coordinate:[{}]\u0026quot;, coordinate.toString());\r}\rreturn null;\r}\r ​\t固然，上方已经说过，若是矩形块返回数据count=1000，就说明当前矩形块须要分割，个人想法比较简单，将矩形块按照上方草图，在水平中心和垂直分心分割，1个矩形块就分割成4个小矩形块了，方法以下：\n/**\r* @return 将矩形4等分红小矩形 而后返回4个 小矩形的经纬度集合\r*/\rprivate List\u0026lt;RectangleCoordinate\u0026gt; getSplitRectangleList(RectangleCoordinate coordinate) {\rList\u0026lt;RectangleCoordinate\u0026gt; splitRectangleList = new LinkedList\u0026lt;\u0026gt;();\rsplitRectangleList.add(new RectangleCoordinate(coordinate.getX0(), coordinate.getY0(), coordinate.getAverageX(), coordinate.getAverageY()));\rsplitRectangleList.add(new RectangleCoordinate(coordinate.getAverageX(), coordinate.getY0(), coordinate.getX1(), coordinate.getAverageY()));\rsplitRectangleList.add(new RectangleCoordinate(coordinate.getX0(), coordinate.getAverageY(), coordinate.getAverageX(), coordinate.getY1()));\rsplitRectangleList.add(new RectangleCoordinate(coordinate.getAverageX(), coordinate.getAverageY(), coordinate.getX1(), coordinate.getY1()));\rreturn splitRectangleList;\r}\r ​\t目前，能够获取到矩形区域经纬度对的集合了，也有获取api数据的方法了，而后就是遍历页数获取数据，自定义操做数据。 当某次分页请求返回的poi个数小于每页最大个数的时候就认为当前区域poi已经彻底请求到了。\nprivate void startAnaMainGaode(RectangleCoordinate coordinate) throws AnalysisException {\r//当前爬取的数据的页数索引\rint page_num = 0;\r//当前爬取内容是不是最后一页\rboolean isLastPage = false;\rJSONObject searchResult;\rJSONArray datas = null;\rlogger.info(\u0026quot;ready to analysis coordinate:[{}]\u0026quot;, coordinate.toString());\rwhile (!isLastPage) {\rlogger.info(\u0026quot;is going to get data for page_\u0026quot; + page_num);\rtry {\rsearchResult = getSearchResult(coordinate, page_num);\rdatas = searchResult.getJSONArray(\u0026quot;pois\u0026quot;);\r} catch (Exception e) {\rlogger.error(\u0026quot;an error occurred when getting response of gaode map data for coordinate:[{}]\u0026quot;, coordinate.toString());\r}\rif (datas != null \u0026amp;\u0026amp; datas.size() \u0026lt; 20) {\risLastPage = true;\rlogger.info(\u0026quot;get result counts is [{}], now page index is [{}]\u0026quot;, datas.size(), page_num);\r}\rsaveIntoDbGaode(datas);\rpage_num++;\r}\r}\rprivate void saveIntoDbGaode(JSONArray result) {\rJSONObject resultItem;\rfor (int i = 0; i \u0026lt; result.size(); i++) {\rresultItem = result.getJSONObject(i);\rtry {\rresults.add(getInsertUnitObject(resultItem));\r} catch (Exception e) {\rlogger.error(\u0026quot;生成数据时异常，e: {}\u0026quot;, e.getMessage());\re.printStackTrace();\r}\r}\rif (results.size() \u0026gt; BATCHINSERTLIMIT || ISLAST) {\rlogger.info(\u0026quot;is ready to batch insert into unit, total count is {}\u0026quot;, results.size());\rtry {\rdao.batchAddUnitGaode(results);\r} catch (Exception e) {\rlogger.error(\u0026quot;更新数据库异常，e: {}\u0026quot;, e.getMessage());\r}\rresults = new JSONArray();\r}\r}`\r ​\t到此，基本方法都介绍过了，所有代码以下（由于都是简单方法和逻辑，不明白的留言交流）\n//请求入口 public void GaodePoiSearch() { //徐水区 final RectangleCoordinate searchAreaCoordinate = new RectangleCoordinate(115.521773, 39.106335, 115.801182, 38.943988); //保定市\r//final RectangleCoordinate searchAreaCoordinate = new RectangleCoordinate(114.332719,39.574064, 116.588688,38.179144);\rList\u0026lt;RectangleCoordinate\u0026gt; validCoordinate = getValidCoordinate(searchAreaCoordinate);\rlogger.info(\u0026quot;get all valid coordinate,size is [{}]\u0026quot;, validCoordinate.size());\r/**\r* 获取到全部的小方块以后能够作一些处理， 好比存储到某个地方，以防发生异常，方便后面从新遍历，我这里暂未作处理\r*/\rvalidCoordinate.forEach(coor -\u0026gt; {\rtry {\rstartAnaMainGaode(coor);\r} catch (AnalysisException e) {\re.printStackTrace();\r}\r});\rISLAST = true;\rsaveIntoDbGaode(new JSONArray());\r}\r/**\r* [@return](https://my.oschina.net/u/556800) 获取矩形块中 符合 调用api的 小矩形块的集合\r* 由于高德地图某个矩形块只能获取前1000条，因此要将矩形块分割成能够获取到所有数据的矩形块\r* 若是当前矩形块请求数据返回的count\u0026lt;1000 即为符合条件的，不然将矩形块4等分 而后递归\r*/\rprivate List\u0026lt;RectangleCoordinate\u0026gt; getValidCoordinate(RectangleCoordinate coordinate) {\rList\u0026lt;RectangleCoordinate\u0026gt; validCoordinate = new LinkedList\u0026lt;\u0026gt;();\rJSONObject searchResult = getSearchResult(coordinate, 0);\rif (searchResult.getIntValue(\u0026quot;count\u0026quot;) \u0026gt;= 1000) {\rList\u0026lt;RectangleCoordinate\u0026gt; splitRectangleList = getSplitRectangleList(coordinate);\rsplitRectangleList.forEach(coor -\u0026gt; validCoordinate.addAll(getValidCoordinate(coor)));\r} else {\rlogger.info(\u0026quot;add a valid coordinate [{}]\u0026quot;, coordinate.toString());\rvalidCoordinate.add(coordinate);\r}\rreturn validCoordinate;\r}\r/**\r* [@return](https://my.oschina.net/u/556800) 将矩形4等分红小矩形 而后返回4个 小矩形的经纬度集合\r*/\rprivate List\u0026lt;RectangleCoordinate\u0026gt; getSplitRectangleList(RectangleCoordinate coordinate) {\rList\u0026lt;RectangleCoordinate\u0026gt; splitRectangleList = new LinkedList\u0026lt;\u0026gt;();\rsplitRectangleList.add(new RectangleCoordinate(coordinate.getX0(), coordinate.getY0(), coordinate.getAverageX(), coordinate.getAverageY()));\rsplitRectangleList.add(new RectangleCoordinate(coordinate.getAverageX(), coordinate.getY0(), coordinate.getX1(), coordinate.getAverageY()));\rsplitRectangleList.add(new RectangleCoordinate(coordinate.getX0(), coordinate.getAverageY(), coordinate.getAverageX(), coordinate.getY1()));\rsplitRectangleList.add(new RectangleCoordinate(coordinate.getAverageX(), coordinate.getAverageY(), coordinate.getX1(), coordinate.getY1()));\rreturn splitRectangleList;\r}\r/**\r* @return 获取矩形块的poi数据\r*/\rprivate JSONObject getSearchResult(RectangleCoordinate coordinate, int page) {\rRestTemplate restTemplate = new RestTemplate();\rString url = getRequestGaodeUrl(coordinate,page);\rString result = restTemplate.getForObject(url, String.class);\rtry {\rtry {\rThread.sleep(50);\r} catch (InterruptedException e) {\re.printStackTrace();\r}\rreturn JSONObject.parseObject(result);\r} catch (Exception e) {\rlogger.error(\u0026quot;an error occurred when getting response of gaode map data for coordinate:[{}]\u0026quot;, coordinate.toString());\r}\rreturn null;\r}\rprivate void startAnaMainGaode(RectangleCoordinate coordinate) throws AnalysisException {\r//当前爬取的数据的页数索引\rint page_num = 0;\r//当前爬取内容是不是最后一页\rboolean isLastPage = false;\rJSONObject searchResult;\rJSONArray datas = null;\rlogger.info(\u0026quot;ready to analysis coordinate:[{}]\u0026quot;, coordinate.toString());\rwhile (!isLastPage) {\rlogger.info(\u0026quot;is going to get data for page_\u0026quot; + page_num);\rtry {\rsearchResult = getSearchResult(coordinate, page_num);\rdatas = searchResult.getJSONArray(\u0026quot;pois\u0026quot;);\r} catch (Exception e) {\rlogger.error(\u0026quot;an error occurred when getting response of gaode map data for coordinate:[{}]\u0026quot;, coordinate.toString());\r}\rif (datas != null \u0026amp;\u0026amp; datas.size() \u0026lt; 20) {\risLastPage = true;\rlogger.info(\u0026quot;get result counts is [{}], now page index is [{}]\u0026quot;, datas.size(), page_num);\r}\rsaveIntoDbGaode(datas);\rpage_num++;\r}\r}\rprivate void saveIntoDbGaode(JSONArray result) {\rJSONObject resultItem;\rfor (int i = 0; i \u0026lt; result.size(); i++) {\rresultItem = result.getJSONObject(i);\rtry {\rresults.add(getInsertUnitObject(resultItem));\r} catch (Exception e) {\rlogger.error(\u0026quot;生成数据时异常，e: {}\u0026quot;, e.getMessage());\re.printStackTrace();\r}\r}\rif (results.size() \u0026gt; BATCHINSERTLIMIT || ISLAST) {\rlogger.info(\u0026quot;is ready to batch insert into unit, total count is {}\u0026quot;, results.size());\rtry {\rdao.batchAddUnitGaode(results);\r} catch (Exception e) {\rlogger.error(\u0026quot;更新数据库异常，e: {}\u0026quot;, e.getMessage());\r}\rresults = new JSONArray();\r}\r}\rprivate JSONObject getInsertUnitObject(JSONObject resultItem) {\rJSONObject unitDataObject = new JSONObject();\runitDataObject.put(\u0026quot;uid\u0026quot;, resultItem.getString(\u0026quot;id\u0026quot;));\runitDataObject.put(\u0026quot;name\u0026quot;, resultItem.getString(\u0026quot;name\u0026quot;));\runitDataObject.put(\u0026quot;type\u0026quot;, resultItem.getString(\u0026quot;type\u0026quot;));\runitDataObject.put(\u0026quot;tag\u0026quot;, resultItem.getString(\u0026quot;type\u0026quot;));\runitDataObject.put(\u0026quot;address\u0026quot;, resultItem.getString(\u0026quot;address\u0026quot;));\runitDataObject.put(\u0026quot;province\u0026quot;, resultItem.getString(\u0026quot;pname\u0026quot;));\runitDataObject.put(\u0026quot;city\u0026quot;, resultItem.getString(\u0026quot;cityname\u0026quot;));\runitDataObject.put(\u0026quot;area\u0026quot;, resultItem.getString(\u0026quot;adname\u0026quot;));\rString tel = resultItem.getString(\u0026quot;tel\u0026quot;);\rif (tel != null \u0026amp;\u0026amp; !\u0026quot;[]\u0026quot;.equals(tel)) {\runitDataObject.put(\u0026quot;telephone\u0026quot;, tel);\r}\rtry {\rJSONArray url = resultItem.getJSONArray(\u0026quot;website\u0026quot;);\rif (url != null \u0026amp;\u0026amp; url.size() \u0026gt; 0) {\runitDataObject.put(\u0026quot;detail_url\u0026quot;, url.getString(0));\r}\r} catch (Exception e) {\runitDataObject.put(\u0026quot;detail_url\u0026quot;, resultItem.getString(\u0026quot;website\u0026quot;));\r}\rJSONArray photos = resultItem.getJSONArray(\u0026quot;photos\u0026quot;);\rif (photos != null \u0026amp;\u0026amp; photos.size() \u0026gt; 0) {\rStringBuilder images = new StringBuilder();\rfor (int j = 0; j \u0026lt; photos.size(); j++) {\rimages.append(j == 0 ? \u0026quot;\u0026quot; : \u0026quot;;\u0026quot;).append(photos.getJSONObject(j).getString(\u0026quot;url\u0026quot;));\r}\runitDataObject.put(\u0026quot;images\u0026quot;, images.toString());\r}\rString entr_location = resultItem.getString(\u0026quot;location\u0026quot;);\rif (StringUtils.isEmpty(entr_location)) {\rentr_location = resultItem.getString(\u0026quot;entr_location\u0026quot;);\r}\rif (!StringUtils.isEmpty(entr_location)) {\runitDataObject.put(\u0026quot;lng\u0026quot;, entr_location.split(\u0026quot;,\u0026quot;)[0]);\runitDataObject.put(\u0026quot;lat\u0026quot;, entr_location.split(\u0026quot;,\u0026quot;)[1]);\r}\rreturn unitDataObject;\r}\rprivate String getRequestGaodeUrl(RectangleCoordinate coordinate, int page) {\rreturn \u0026quot;https://restapi.amap.com/v3/place/polygon?\u0026quot; +\r\u0026quot;key=xxxxxxxxxxxxxxxxxxxxxxx\u0026amp;polygon=\u0026quot; + coordinate.toString() + \u0026quot;\u0026amp;page=\u0026quot; + page + \u0026quot;\u0026amp;types=010000|\u0026quot; +\r\u0026quot;010100|010101|010102|010103|010104|010105|010107|010108|010109|010110|010111|010112|010200|010300|010400|\u0026quot; +\r\u0026quot;010401|010500|010600|010700|010800|010900|010901|011000|011100|020000|020100|020101|020102|020103|020104|\u0026quot; +\r\u0026quot;020105|020106|020200|020201|020202|020203|020300|020301|020400|020401|020402|020403|020404|020405|020406|\u0026quot; +\r\u0026quot;020407|020408|020600|020601|020602|020700|020701|020702|020703|020800|020900|020904|020905|021000|021001|\u0026quot; +\r\u0026quot;021002|021003|021004|021100|021200|021201|021202|021203|021300|021301|021400|021401|021500|021501|021600|\u0026quot; +\r\u0026quot;021601|021602|021700|021701|021702|021800|021802|021803|021804|021900|022000|022100|022200|022300|022301|\u0026quot; +\r\u0026quot;022400|022500|022501|022502|022600|022700|022800|022900|023000|023100|023200|023300|023301|023400|023500|\u0026quot; +\r\u0026quot;025000|025100|025200|025300|025400|025500|025600|025700|025800|025900|026000|026100|026200|026300|029900|\u0026quot; +\r\u0026quot;030000|030100|030200|030201|030202|030203|030204|030205|030206|030300|030301|030302|030303|030400|030401|\u0026quot; +\r\u0026quot;030500|030501|030502|030503|030504|030505|030506|030507|030508|030700|030701|030702|030800|030801|030802|\u0026quot; +\r\u0026quot;030803|030900|031000|031004|031005|031100|031101|031102|031103|031104|031200|031300|031301|031302|031303|\u0026quot; +\r\u0026quot;031400|031401|031500|031501|031600|031601|031700|031701|031702|031800|031801|031802|031900|031902|031903|\u0026quot; +\r\u0026quot;031904|032000|032100|032200|032300|032400|032401|032500|032600|032601|032602|032700|032800|032900|033000|\u0026quot; +\r\u0026quot;033100|033200|033300|033400|033401|033500|033600|035000|035100|035200|035300|035400|035500|035600|035700|\u0026quot; +\r\u0026quot;035800|035900|036000|036100|036200|036300|039900|040000|040100|040101|040200|040201|050000|050100|050101|\u0026quot; +\r\u0026quot;050102|050103|050104|050105|050106|050107|050108|050109|050110|050111|050112|050113|050114|050115|050116|\u0026quot; +\r\u0026quot;050117|050118|050119|050120|050121|050122|050123|050200|050201|050202|050203|050204|050205|050206|050207|\u0026quot; +\r\u0026quot;050208|050209|050210|050211|050212|050213|050214|050215|050216|050217|050300|050301|050302|050303|050304|\u0026quot; +\r\u0026quot;050305|050306|050307|050308|050309|050310|050311|050400|050500|050501|050502|050503|050504|050600|050700|\u0026quot; +\r\u0026quot;050800|050900|060000|060100|060101|060102|060103|060200|060201|060202|060300|060301|060302|060303|060304|\u0026quot; +\r\u0026quot;060305|060306|060307|060308|060400|060401|060402|060403|060404|060405|060406|060407|060408|060409|060411|\u0026quot; +\r\u0026quot;060413|060414|060415|060500|060501|060502|060600|060601|060602|060603|060604|060605|060606|060700|060701|\u0026quot; +\r\u0026quot;060702|060703|060704|060705|060706|060800|060900|060901|060902|060903|060904|060905|060906|060907|061000|\u0026quot; +\r\u0026quot;061001|061100|061101|061102|061103|061104|061200|061201|061202|061203|061204|061205|061206|061207|061208|\u0026quot; +\r\u0026quot;061209|061210|061211|061212|061213|061214|061300|061301|061302|061400|061401|070000|070100|070200|070201|\u0026quot; +\r\u0026quot;070202|070203|070300|070301|070302|070303|070304|070305|070306|070400|070401|070500|070501|070600|070601|\u0026quot; +\r\u0026quot;070603|070604|070605|070606|070607|070608|070609|070610|070700|070701|070702|070703|070704|070705|070706|\u0026quot; +\r\u0026quot;070800|070900|071000|071100|071200|071300|071400|071500|071600|071700|071800|071801|071900|071901|071902|\u0026quot; +\r\u0026quot;071903|072000|072001|080000|080100|080101|080102|080103|080104|080105|080106|080107|080108|080109|080110|\u0026quot; +\r\u0026quot;080111|080112|080113|080114|080115|080116|080117|080118|080119|080200|080201|080202|080300|080301|080302|\u0026quot; +\r\u0026quot;080303|080304|080305|080306|080307|080308|080400|080401|080402|080500|080501|080502|080503|080504|080505|\u0026quot; +\r\u0026quot;080600|080601|080602|080603|090000|090100|090101|090102|090200|090201|090202|090203|090204|090205|090206|\u0026quot; +\r\u0026quot;090207|090208|090209|090210|090211|090300|090400|090500|090600|090601|090602|090700|090701|090702|100000|\u0026quot; +\r\u0026quot;100100|100101|100102|100103|100104|100105|100200|100201|110000|110100|110101|110102|110103|110104|110105|\u0026quot; +\r\u0026quot;110106|110200|110201|110202|110203|110204|110205|110206|110207|110208|110209|120000|120100|120200|120201|\u0026quot; +\r\u0026quot;120202|120203|120300|120301|120302|120303|120304|130000|130100|130101|130102|130103|130104|130105|130106|\u0026quot; +\r\u0026quot;130107|130200|130201|130202|130300|130400|130401|130402|130403|130404|130405|130406|130407|130408|130409|\u0026quot; +\r\u0026quot;130500|130501|130502|130503|130504|130505|130506|130600|130601|130602|130603|130604|130605|130606|130700|\u0026quot; +\r\u0026quot;130701|130702|130703|140000|140100|140101|140102|140200|140201|140300|140400|140500|140600|140700|140800|\u0026quot; +\r\u0026quot;140900|141000|141100|141101|141102|141103|141104|141105|141200|141201|141202|141203|141204|141205|141206|\u0026quot; +\r\u0026quot;141207|141300|141400|141500|150000|150100|150101|150102|150104|150105|150106|150107|150200|150201|150202|\u0026quot; +\r\u0026quot;150203|150204|150205|150206|150207|150208|150209|150210|150300|150301|150302|150303|150304|150400|150500|\u0026quot; +\r\u0026quot;150501|150600|150700|150701|150702|150703|150800|150900|150903|150904|150905|150906|150907|150908|150909|\u0026quot; +\r\u0026quot;151000|151100|151200|151300|160000|160100|160101|160102|160103|160104|160105|160106|160107|160108|160109|\u0026quot; +\r\u0026quot;160110|160111|160112|160113|160114|160115|160117|160118|160119|160120|160121|160122|160123|160124|160125|\u0026quot; +\r\u0026quot;160126|160127|160128|160129|160130|160131|160132|160133|160134|160135|160136|160137|160138|160139|160140|\u0026quot; +\r\u0026quot;160141|160142|160143|160144|160145|160146|160147|160148|160149|160150|160151|160152|160200|160300|160301|\u0026quot; +\r\u0026quot;160302|160303|160304|160305|160306|160307|160308|160309|160310|160311|160312|160314|160315|160316|160317|\u0026quot; +\r\u0026quot;160318|160319|160320|160321|160322|160323|160324|160325|160326|160327|160328|160329|160330|160331|160332|\u0026quot; +\r\u0026quot;160333|160334|160335|160336|160337|160338|160339|160340|160341|160342|160343|160344|160345|160346|160347|\u0026quot; +\r\u0026quot;160348|160349|160400|160401|160402|160403|160404|160405|160406|160407|160408|160500|160501|160600|170000|\u0026quot; +\r\u0026quot;170100|170200|170201|170202|170203|170204|170205|170206|170207|170208|170209|170300|170400|170401|170402|\u0026quot; +\r\u0026quot;170403|170404|170405|170406|170407|170408|180000|180100|180101|180102|180103|180104|180200|180201|180202|\u0026quot; +\r\u0026quot;180203|180300|180301|180302|180400|180500|190000|190100|190101|190102|190103|190104|190105|190106|190107|\u0026quot; +\r\u0026quot;190108|190109|190200|190201|190202|190203|190204|190205|190300|190301|190302|190303|190304|190305|190306|\u0026quot; +\r\u0026quot;190307|190308|190309|190310|190311|190400|190401|190402|190403|190500|190600|190700|200000|200100|200200|\u0026quot; +\r\u0026quot;200300|200301|200302|200303|200304|200400|220000|220100|220101|220102|220103|220104|220105|220106|220107|\u0026quot; +\r\u0026quot;220200|220201|220202|220203|220204|220205|970000|990000|991000|991001|991400|991401|991500\u0026amp;extensions=all\u0026quot;;\r}\r/**\r* 矩形块的经纬度标识， 左上角的经纬度 和右下角的经纬度\r*/\rclass RectangleCoordinate {\r/**\r* 矩形左上角经度\r*/\rprivate double x0;\r/**\r* 矩形左上角纬度\r*/\rprivate double y0;\r/**\r* 矩形右下角经度\r*/\rprivate double x1;\r/**\r* 矩形右下角纬度\r*/\rprivate double y1;\rpublic RectangleCoordinate(double x0, double y0, double x1, double y1) {\rthis.x0 = x0;\rthis.y0 = y0;\rthis.x1 = x1;\rthis.y1 = y1;\r}\r/**\r* @return 获取矩形中心线的纬度\r*/\rpublic double getAverageY() {\rreturn (y0 + y1) / 2;\r}\r/**\r* @return 获取矩形中心线的经度\r*/\rpublic double getAverageX() {\rreturn (x0 + x1) / 2;\r}\rpublic double getX0() {\rreturn x0;\r}\rpublic void setX0(double x0) {\rthis.x0 = x0;\r}\rpublic double getY0() {\rreturn y0;\r}\rpublic void setY0(double y0) {\rthis.y0 = y0;\r}\rpublic double getX1() {\rreturn x1;\r}\rpublic void setX1(double x1) {\rthis.x1 = x1;\r}\rpublic double getY1() {\rreturn y1;\r}\rpublic void setY1(double y1) {\rthis.y1 = y1;\r}\r@Override\rpublic String toString() {\rreturn x0 + \u0026quot;,\u0026quot; + y0 + \u0026quot;|\u0026quot; + x1 + \u0026quot;,\u0026quot; + y1;\r}\r}`\r 更新（2018-09-20）：\n​\t一、时间问题，当前50ms请求一次api接口，跑完小县城的数据（几万条）大概须要十分钟左右吧，把整个市区主要数据跑完断断续续的用了一天吧，最后跑了近27W数据\n​\t二、应用问题，本来的想法就是作个简单的小程序，把跑来的数据加以利用，作个电话本相似的应用，具体能够扫下方小程序码体验\n更新（2019-01-28）：\n​\t有一些朋友向我要源码，可能大可能是新手，尽管思路给了，代码仍是写不出来。其实上方我把主要的代码基本都发布出来了，可是应各位要求，我把源码提交到github了，能够访问 个人github 查看\n更新（2019-07-24）\n​\t想到一个弊端，并找到了解决方法：\n​\t不少朋友使用上文提供的方法时，不免会获得一些”垃圾数据“，何为垃圾数据呢？好比我爬取保定的某些数据，开始大体选了一个区域，为了爬取到全部的数据，就要保证所选区域要涵盖保定，最后爬到的数据就不止保定的数据了，其余区域的数据就为垃圾数据，以下图：\n​\t看到没有，在尽量小的区域内，垃圾数据所在区域也几乎占了小一半了，除了临近的市区（任丘等），也包含了其余省（山西，北京等）的数据。除了区域不精准，更可怕的是像北京这种大城市，poi数量很大，因此会形成爬取的数据可能只有部分是目标数据。\n​\t有人会说，能够在爬完数据以后再处理。也不是不能够，不过这个过程当中调用api，io操做费时费力。\n​\t当前我想到的办法是，根据原文方法拿到要爬取的区域以后，先判断是不是咱们想要的区域（方形区域4个点至少有一个在目标区域内），不然就舍弃掉。好比上图右上角的区域，拿到以后发现都是北京的，舍弃。\n​\t具体方法还要调用百度或高德提供的逆地理编码接口。点这里看介绍。\n​\t根据区域的location，调用接口，获得返回的数据中会包含该location的country、province、city等。而后进行过滤就OK了。\n​\t优化核心相似：以前目标区域划分红的小矩形块有10万个，根据逆地理编码接口，过滤掉其余省市，剩余5千个，获取这5千个小矩形块的poi数据便可。\n","id":10,"section":"posts","summary":"转发：原文 爬取高德地图poi数据 高德地图搜索poi的api官方文档 ​ 当前想法是爬取目标区域（做者所在小县城）的全部poi数据，存到数据库中做","tags":null,"title":"爬取高德地图poi数据","uri":"https://bluestaree.github.io/2022/11/%E7%88%AC%E5%8F%96%E9%AB%98%E5%BE%B7%E5%9C%B0%E5%9B%BEpoi%E6%95%B0%E6%8D%AE/","year":"2022"},{"content":"  监测正式环境服务内存占用情况时，发现一服务 内存占用 即将超出docker内存限制，开始排查是否出现OOM\n 查看docker容器内存使用情况 使用如下命令\ndocker stats  可以看到服务内存占用已经快达到95%\n进入docker容器查看 进入容器后使用命令 jmap -heap 1 查询jvm内存使用情况，一切正常，前几天刚进行过一次fullgc，占有都比较小\n经过求和，发现其中 大约有1.5G 的空间不知所踪\n 猜测1： 是否docekr 统计问题 ， 相关文章： https://zhuanlan.zhihu.com/p/348613625\n结果：\n统计数据 差不多 约等于 4.2G；\n 猜测2： 是否堆外内存占用 ，使用arthas查看情况 官方文档： https://arthas.aliyun.com/doc/\n结果：\n堆外内存同样占有正常\n 猜测3： 参考文章 https://blog.csdn.net/fxh13579/article/details/104754340，\n可能JVM在 GC后 并没有向操作系统释放内存，需一进步观察， 如果一直稳定，也可以不需要关心，\n 11-4更新 服务并没有应用内存占用超出限制而被Killer掉，情况如猜测3所述一致，不需要太关心\n","id":11,"section":"posts","summary":"监测正式环境服务内存占用情况时，发现一服务 内存占用 即将超出docker内存限制，开始排查是否出现OOM 查看docker容器内存使用情况 使用如","tags":["jvm"],"title":"java进程占用系统内存过高分析","uri":"https://bluestaree.github.io/2022/10/java%E8%BF%9B%E7%A8%8B%E5%8D%A0%E7%94%A8%E7%B3%BB%E7%BB%9F%E5%86%85%E5%AD%98%E8%BF%87%E9%AB%98%E5%88%86%E6%9E%90/","year":"2022"},{"content":"  最近服务器上有服务每隔一段时间就会重启一下（20天左右），经过一段时间监控，判断应该是内存逐步提升，导致超过了docker容器的限制，进程被系统停止，重新启动。怀疑发生了内存泄漏。\n 排查步骤 1、首先进入docker容器中获取dump文件 jmap -dump:live,format=b,file=/ehaomiao/logs/heap-live.hprof 1\r 2、基于mat内存分析工具 通过mat分析工具 查询内存占用情况\n初步判断为 链接未正常关闭\n3.定位问题代码 public static URL generatePresignedUrl(OSS ossClient, String bucketName, String objectName, Date expiration, String style, HttpMethod method)\rthrows ClientException {\rGeneratePresignedUrlRequest request = new GeneratePresignedUrlRequest(bucketName, objectName);\rrequest.setExpiration(expiration);\rrequest.setMethod(method);\rif(StrUtil.isNotEmpty(style)) {\rrequest.setProcess(style);\r}\rreturn ossClient.generatePresignedUrl(request);\r}\r 修改代码如下：\npublic static URL generatePresignedUrl(OSS ossClient, String bucketName, String objectName, Date expiration, String style, HttpMethod method) {\rURL url = null;\rtry {\rGeneratePresignedUrlRequest request = new GeneratePresignedUrlRequest(bucketName, objectName);\rrequest.setExpiration(expiration);\rrequest.setMethod(method);\rif(StrUtil.isNotEmpty(style)) {\rrequest.setProcess(style);\r}\rurl = ossClient.generatePresignedUrl(request);\r} catch (Throwable throwable) {\rthrowable.printStackTrace();\r} finally {\rif (ossClient != null) {\r// 关闭OSSClient。\rossClient.shutdown();\r}\r}\rreturn url;\r}\r 10-21号更新 重新部署服务器后，未出现自动重启现象\n","id":12,"section":"posts","summary":"最近服务器上有服务每隔一段时间就会重启一下（20天左右），经过一段时间监控，判断应该是内存逐步提升，导致超过了docker容器的限制，进程被","tags":["jvm"],"title":"JVM内存泄漏问题排查","uri":"https://bluestaree.github.io/2022/09/jvm%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A5/","year":"2022"},{"content":"  最近发现服务器在部署一段时间后会自动重启，初步排查为内存原因，肯能存在内存泄漏，需进一步排查。这里记录一下相关学习记录\n JVM内存调优 1、JVM简介 ​\tJVM是java虚拟机，是用来执行java字节码的虚拟计算机，它运行在操作系统之上与硬件没有任何关\n系，简单来讲就是跨平台，一处编译到处运行。\n​\tJava程序的跨平台特性主要是指字节码文件可以在任何具有Java虚拟机的计算机或者电子设备上运\n行，Java虚拟机中的Java解释器负责将字节码文件解释成为特定的机器码进行运行。因此在运行时，\nJava源程序需要通过编译器编译成为.class文件。众所周知java.exe是java class文件的执行程序，但实际\n上java.exe程序只是一个执行的外壳，它会装载jvm.dll（windows下，下皆以windows平台为例，linux\n下和solaris下其实类似，为：libjvm.so），这个动态连接库才是java虚拟机的实际操作处理所在。\n​\tJVM是JRE的一部分。它是一个虚构出来的计算机，是通过在实际的计算机上仿真模拟各种计算机功\n能来实现的。JVM有自己完善的硬件架构，如处理器、堆栈、寄存器等，还具有相应的指令系统。Java\n语言最重要的特点就是跨平台运行。使用JVM就是为了支持与操作系统无关，实现跨平台。所以，JAVA\n虚拟机JVM是属于JRE的，而现在我们安装JDK时也附带安装了JRE(当然也可以单独安装JRE)。\n2、JVM内存 ​\t粗略分来，JVM的内部体系结构分为三部分，分别是：类装载器（ClassLoader）子系统，运行时数\n据区，和执行引擎。\n2.1、类装载器 ​\t每一个Java虚拟机都由一个类加载器子系统（class loader subsystem），负责加载程序中的类型\n（类和接口），并赋予唯一的名字。每一个Java虚拟机都有一个执行引擎（execution engine）负责执\n行被加载类中包含的指令。JVM的两种类装载器包括：启动类装载器和用户自定义类装载器，启动类装\n载器是JVM实现的一部分，用户自定义类装载器则是Java程序的一部分，必须是ClassLoader类的子类。\n2.2、执行引擎 ​\t它或者在执行字节码，或者执行本地方法。\n​\t主要的执行技术有:解释，即时编译，自适应优化、芯片级直接执行其中解释属于第一代JVM，即时\n编译JIT属于第二代JVM，自适应优化（目前Sun的HotspotJVM采用这种技术）则吸取第一代JVM和第二\n代JVM的经验，采用两者结合的方式 。\n​\t自适应优化：开始对所有的代码都采取解释执行的方式，并监视代码执行情况，然后对那些经常调\n用的方法启动一个后台线程，将其编译为本地代码，并进行仔细优化。若方法不再频繁使用，则取消编\n译过的代码，仍对其进行解释执行。\n2.3、运行时数据区 ​\t主要包括：方法区，堆，Java栈，PC寄存器，本地方法栈。\n2.3.1、程序计数器 ​\t程序计数器（Program Counter Register)是一块较小的内存空间，它可以是看作当前线程所执行的\n字节码的行号指示器。说简单一点就是一个计数器，当字节码解释器工作是能够通过改变这个计数器的\n值来选取下一条需要执行的字节码指令。在说明一点，各条线程之间计数器互不影响，独立存储，程序\n计数器器内存区域为线程私有的。\n​\t在JVM规范中规定，如果线程执行的是非native方法，则程序计数器中保存的是当前需要执行的指\n令的地址；如果线程执行的是native方法，则程序计数器中的值是undefined。由于程序计数器中存储\n的数据所占空间的大小不会随程序的执行而发生改变，因此，此内存区域是唯一一个在JVM规范中没有\n规定任何OutOfMemoryError情况的区域。\n2.3.2、本地方法栈 ​\t本地方法栈和虚拟机栈所发挥的作用是很相似的，它们之间的区别不过是 虚拟机栈为虚拟机执行\nJava方法（字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。Sun HotSpot 直接就把\n本地方法栈和虚拟机栈合二为一。本地方法栈也会抛出StackOverflowError和OutOfMemoryError异\n常。\n2.3.3、Java虚拟栈 ​\tJava栈也称作虚拟机栈（Java Vitual Machine Stack），也是常说的栈。Java栈是Java方法执行的内\n存模型。Java栈中存放的是一个个的栈帧，每个栈帧对应一个被调用的方法，在栈帧中包括局部变量表\n(Local Variables)、操作数栈(Operand Stack)、指向当前方法所属的类的运行时常量池（运行时常量池\n的概念在方法区部分会谈到）的引用(Reference to runtime constant pool)、方法返回地址(Return\nAddress)和一些额外的附加信息。栈也是线程私有的。\n  局部变量表\n用来存储java方法中的局部变量的（包括在方法中声明的非静态变量以及函数形参）。对于基本数\n  据类型的变量，则直接存储它的值，对于引用类型的变量，则存的是指向对象的引用。在编译期间就会\n分配方法局部变量表的最大容量，局部变量表以变量槽为单位，每个变量槽可以存储32位及32位以下的\n变量，具体大小根据变量实际占用内存而定，java的基本类型中除了long和double外其他类型都是32位\n以下，所以每个变量占用一个变量槽即可，而对于long和double类的变量，会占用两个变量槽，除了基\n本类型当然还有引用类型，引用类型变量长度JVM并没有明确定义。JVM通过索引的方式来访问变量表中\n的变量，索引从0开始。变量槽是可以重复使用的，当变量槽所存储的变量已经不在其作用域后，该变量\n槽就可以被其他变量占用。\n  操作数栈\n用于在方法运行时可以存放以及获取操作数，其所需要的最大栈深度也是在编译期间定下的，在方\n  法刚开始运行时，操作数栈是空的，在方法执行过程中会有各种操作指令往操作数栈中压入和获取内\n容，也就是出栈/入栈操作，比如一个加法指令对两个数据进行相加，运行到这里前会先将两个数据压入\n栈中，然后将这两个操作数取出相加；在实际情况中，方法的操作数栈之间并不完全独立，往往会公用\n部分空间，这样在方法调用时就不需要进行参数复制了。\n  动态链接\n前面说了常量池中会存储方法的符号引用，而每个栈帧中都会存储一个引用，用于指向常量池中该\n  方法对应的符号引用，字节码指令中方法的调用就以方法对应的符号引用为参数来进行，在类加载阶段\n的解析步骤中，部分符号引用会被解析为直接引用，称为静态解析，在方法的运行过程中，另一部分符\n号引用会被实时的解析为直接引用，称为动态连接。\n​\t被静态解析的条件：方法在运行前就有一个可确定的调用版本，其实也就是编译期就刻意确定改方\n法有没有可能通过继承或者其他方式被重写，在java中静态方法(与类型直接关联)，私有方法(外部不可\n访问)，构造方法，父类方法，final方法，这五种方法的符号引用可以被静态解析都不可能被重写，可以\n在运行前确定唯一的调用版本，满足被静态解析的条件，称为非虚方法。\n  方法返回地址\n方法的运行过程中，可能会正常退出，也可能会异常退出，不论是哪种退出方式，在退出后都会要\n  保证其上层调用者可以知道方法退出的位置，以便于程序继续执行，方法的返回地址就是用于确定退出\n位置的。\n2.3.4、Java堆 ​\t堆是jvm内存管理的最大的一块区域，此内存区域的唯一目的就是存放对象的实例，所有对象实例\n与数组都要在堆上分配内存。它也是垃圾收集器的主要管理区域。java对可以处于物理上不连续的空\n间，只要逻辑上是连续的即可。线程共享的区域。如果在堆中没有内存完成实例分配，并且堆也无法再\n扩展时，将抛出OutOfMemoryError异常。\n为了支持垃圾收集，堆被分为三个部分：\n 年轻代：常常又被划分为Eden区和Survivor（From Survivor To Survivor）区(Eden空间、From Survivor空间、To Survivor空间（空间分配比例是8：1：1） 老年代 永久代（jdk 8已移除永久代，被元数据代替）  （1）堆是JVM中所有线程共享的，因此在其上进行对象内存的分配均需要进行加锁，这也导致了new对\n象的开销是比较大的\n（2）Sun Hotspot JVM为了提升对象内存分配的效率，对于所创建的线程都会分配一块独立的空间\nTLAB（Thread Local Allocation Buffer），其大小由JVM根据运行的情况计算而得，在TLAB上分配对象\n时不需要加锁，因此JVM在给线程的对象分配内存时会尽量的在TLAB上分配，在这种情况下JVM中分配\n对象内存的性能和C基本是一样高效的，但如果对象过大的话则仍然是直接使用堆空间分配\n（3）TLAB仅作用于新生代的Eden Space，因此在编写Java程序时，通常多个小的对象比大的对象分配\n起来更加高效。\n（4）所有新创建的Object 都将会存储在新生代Yong Generation中。如果Young Generation的数据在\n一次或多次GC后存活下来，那么将被转移到OldGeneration。新的Object总是创建在Eden Space。\n这些知识在后面学习GC和内存调优方面非常重要。\n2.3.5、方法区 ​\t方法区在JVM中也是一个非常重要的区域，它与堆一样，是被线程共享的区域。在方法区中，存储\n了每个类的信息（包括类的名称、方法信息、字段信息）、静态变量、常量以及编译器编译后的代码\n等。方法区是堆的一个逻辑部分，为了区分Java堆，它还有一个别名Non-Heap（非堆）。相对而言，\nGC对于这个区域的收集是很少出现的。当方法区无法满足内存分配需求时，将抛出OutOfMemoryError\n异常。\n​\t在Java 7及之前版本，我们也习惯称方法区它为“永久代”（Permanent Generation），更确切来\n说，应该是“HotSpot使用永久代实现了方法区”！\n2.5.6、运行时常量 ​\t运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外,\n还有一项信息是常量池( Constant pool table)，用于存放编译期生成的各种字面量和符号引用，这部分\n内容将在类加载后进入运行时常量池中存放。运行时常量池相对于class文件常量池的另外一个特性是具\n备动态性，java语言并不要求常量一定只有编译器才产生，也就是并非预置入class文件中常量池的内容\n才能进入方法区运行时常量池，运行期间也可能将新的常量放入池中。\n2.5.7、直接内存 ​\t直接内存（Direct Memory）并不是虚拟机运行时数据区的一部分，也不是JVM规范中定义的内存\n区域。但这部分内存也被频繁的使用，而且也可能导致OutOfMemoryError异常出现。JDK1.4中新引入\n了NIO机制，它是一种基于通道与缓冲区的新I/O方式，可以直接从操作系统中分配直接内存，即直接堆\n外分配内存，这样能在一些场景中提高性能，因为避免了在Java堆和Native堆中来回复制数据。\n2.4、JDK7与JDK8内存模型对比 2.4.1、方法区变化 ​\t这里介绍的是JDK1.8 JVM内存模型。1.8同1.7比，最大的差别就是：元数据区取代了永久代，就是\nJDK8没有了PermSize相关的参数配置了。元空间的本质和永久代类似，都是对JVM规范中方法区的实\n现。不过元空间与永久代之间最大的区别在于：元数据空间并不在虚拟机中，而是使用本地内存。\n1）方法区与永久代的区别？\n 方法区只是JVM规范定义，而永久代为具体的实现，元空间也是方法区在jdk1.8中的一种实现。  2）为什么废除永久代？\n 官方文档：移除永久代是为融合HotSpot JVM与 JRockit VM而做出的努力，因为JRockit没有永久代，不需要配置永久代 PermGen很难调整，PermGen中类的元数据信息在每次FullGC的时候可能被收集，但成绩很难令人满意。 而且应该为PermGen分配多大的空间很难确定，因为PermSize的大小依赖于很多因素，比如JVM加载的class总数，常量池的大小，方法的大小等。 并且永久代内存经常不够用发生内存泄露。  2.4.2、运行时常量池变化 ​\t在近三个JDK版本（1.6、1.7、1.8）中， 运行时常量池（Runtime Constant Pool）的所处区域一\n直在不断的变化，在JDK1.6时它是方法区的一部分；1.7又把他放到了堆内存中；1.8之后出现了元空\n间，它又回到了方法区。其实，这也说明了官方对“永久代”的优化从1.7就已经开始了\n2.5、运行时异常    运行时区域 异常 主要原因     虚拟机栈和本地方法栈 StackOverflowError，OutOfMemoryError StackOverflowError：线程请求的栈深度大于虚拟机所允许的最大深度；OutOfMemoryError：虚拟机在扩展栈时无法申请足够的内存空间   程序计数器 无 无   堆 OutOfMemoryError 对象数量到达最大堆的容量，内存泄漏、内存溢出   方法区和运行时常量池 OutOfMemoryError 反射，动态代理：CGLib、JSP、OSGI等     内存泄露（Memory Leak）：程序在申请内存后，对象没有被GC所回收，它始终占用内存，内存泄漏的堆积最终会造成内存溢出。 内存溢出（Memory Overflow）：程序运行过程中无法申请到足够的内存而导致的一种错误。内存溢出通常发生于OLD段或Perm段垃圾回收后，仍然无内存空间容纳新的Java对象的情况。通常都是由于内存泄露导致堆栈内存不断增大，从而引发内存溢出。  3、JVM参数 3.1、查看JVM参数 java -XX:+PrintFlagsFinal -version\r 3.2、日志设置 -XX:+PrintFlagsFinal，打印JVM所有参数的值\r-XX:+PrintGC，打印GC信息\r-XX:+PrintGCDetails，打印GC详细信息\r-XX:+PrintGCTimeStamps，打印GC的时间戳\r-Xloggc:filename，设置GC log文件的位置\r-XX:+PrintTenuringDistribution，查看熬过收集后剩余对象的年龄分布信息\r 3.3、内存设置 -Xms，设置堆的初始化内存大小\r-Xmx，设置堆的最大内存\r-Xmn，设置新生代内存大小\r-Xss，设置线程栈大小\r-XX:NewRatio，新生代与老年代比值\r-XX:SurvivorRatio，新生代中Eden区与两个Survivor区的比值，默认为8，即Eden:Survivor:Survivor=8:1:1\r-XX:MaxTenuringThreshold，从年轻代到老年代，最大晋升年龄。CMS 下默认为 6，G1 下默认为 15\r-XX:MetaspaceSize，设置元空间的大小，第一次超过将触发 GC\r-XX:MaxMetaspaceSize，元空间最大值\r-XX:MaxDirectMemorySize，用于设置直接内存的最大值，限制通过 DirectByteBuffer 申请的内存\r-XX:ReservedCodeCacheSize，用于设置 JIT 编译后的代码存放区大小，如果观察到这个值有限制，可以适当调大，一般够用即可\r 3.4、垃圾收集设置 -XX:+UseSerialGC，设置串行收集器\r-XX:+UseParallelGC，设置并行收集器\r-XX:+UseConcMarkSweepGC，使用CMS收集器\r-XX:ParallelGCThreads，设置Parallel GC的线程数\r-XX:MaxGCPauseMillis，GC最大暂停时间 ms\r-XX:+UseG1GC，使用G1垃圾收集器\rCMS 垃圾回收器相关\r-XX:+UseCMSInitiatingOccupancyOnly\r-XX:CMSInitiatingOccupancyFraction，与前者配合使用，指定MajorGC的发生时机\r-XX:+ExplicitGCInvokesConcurrent，代码调用 System.gc() 开始并行 FullGC，建议加上这个参数\r-XX:+CMSScavengeBeforeRemark，表示开启或关闭在 CMS 重新标记阶段之前的清除(YGC)尝试，它可以降低 remark 时间，建议加上\r-XX:+ParallelRefProcEnabled，可以用来并行处理 Reference，以加快处理速度，缩短耗时\rG1 垃圾回收器相关\r-XX:MaxGCPauseMillis，用于设置目标停顿时间，G1 会尽力达成\r-XX:G1HeapRegionSize，用于设置小堆区大小，建议保持默认\r-XX:InitiatingHeapOccupancyPercent，表示当整个堆内存使用达到一定比例(默认是 45%)，并发标记阶段就会被启动\r-XX:ConcGCThreads，表示并发垃圾收集器使用的线程数量，默认值随 JVM 运行的平台不同而变动，不建议修改。\r参数查询官网地址：\rhttps://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html\r 4、JVM监视 4.1、jps ​\t显示当前运行的java进程以及相关参数。\njps [options]\r  -q：仅输出VM标识符，不包括classname,jar name,arguments in main method -m：输出main method的参数 -l：输出完全的包名，应用主类名，jar的完全路径名 -v：输出jvm参数 -V：输出通过flag文件传递到JVM中的参数(.hotspotrc文件或-XX:Flags=所指定的文件  4.2、jstat ​\t用于监控虚拟机各种运行状态信息的命令行工具。可以显示本地或远程虚拟机进程中的类装载、内\n存、垃圾收集、JIT编译等运行数据。\njstat [option vmid [interval[ s|ms] [count] ] ]\rjstat -gc [pid]\r ​\tvmid与lvmid需要特别说明下：如果是本地虚拟机进程，VMID和LVMID是一致的，如果是远程虚拟\n机进程，那vmid的格式应当是：[protocol:][//] lvmid [@hostname[:port]/servername]。\n​\tinterval代表查询间隔和次数，如果省略表示只查询一次。\n -class：监视类装载、卸载数量、总空间及类装载所耗费的时间 -gc：监视Java堆状况，包括Eden区、2个Survivor区、老年代、永久代等的容量 -gccapacity：监视内容与-gc基本相同，但输出主要关注Java堆各个区域使用到的最大和最小空间 -gcutil：监视内容与-gc基本相同，但输出主要关注已使用空间占总空间的百分比 -gccause：与-gcutil功能一样，但是会额外输出导致上一次GC产生的原因 -gcnew：监视新生代GC的状况 -gcnewcapacity：监视内容与-gcnew基本相同，输出主要关注使用到的最大和最小空间 -gcold 监视老年代GC的状况 -gcoldcapacity：监视内容与——gcold基本相同，输出主要关注使用到的最大和最小空间 -gcpermcapacity：输出永久代使用到的最大和最小空间 -compiler 输出JIT编译器编译过的方法、耗时等信息 -printcompilation 输出已经被JIT编译的方法  4.3、jstatd ​\tjstatd是一个基于RMI（Remove Method Invocation）的服务程序，它用于监控基于HotSpot的\nJVM中资源的创建及销毁，并且提供了一个远程接口允许远程的监控工具连接到本地的JVM执行命令。\n​\tjstatd是基于RMI的，所以在运行jstatd的服务器上必须存在RMI注册中心，如果没有通过选项”-p\nport”指定要连接的端口，jstatd会尝试连接RMI注册中心的默认端口。\n -nr 如果RMI注册中心没有找到，不会创建一个内部的RMI注册中心。 -p port RMI注册中心的端口号，默认为1099。 -n rminame 默认为JStatRemoteHost；如果同一台主机上同时运行了多个jstatd服务，rminame可以用于唯一确定一个jstatd服务；这里需要注意一下，如果开启了这个选项，那么监控客户端远程连接时，必须同时指定hostid及vmid，才可以唯一确定要连接的服务，这个可以参看jps章节中列出远程服务器上Java进程的示例。 -J 用于传递jvm选项到由javac调用的java加载器中，例如，“-J-Xms48m”将把启动内存设置为48M，使用-J选项可以非常方便的向基于Java的开发的底层虚拟机应用程序传递参数。  4.4、jmc ​\tJava Mission Control，JMC打开性能日志后，主要包括7部分性能报告，分别是一般信息、内存、\n代码、线程、I/O、系统、事件。其中，内存、代码、线程及I/O是系统分析的主要部分。\n5、故障排除 5.1、jcmd ​\t一个多功能的工具，可以用它来导出堆、查看Java进程、导出线程信息、执行GC、还可以进行采样\n分析。\n1 jcmd \u0026lt;pid | main class\u0026gt; \u0026lt;command ... | PerfCounter.print | -f file\u0026gt;\r2 jcmd -l\r3 jcmd -h\r   pid：接收诊断命令请求的进程ID。\nmain class ：接收诊断命令请求的进程的main类。匹配进程时，main类名称中包含指定子字符串\n的任何进程均是匹配的。如果多个正在运行的Java进程共享同一个main类，诊断命令请求将会发送\n到所有的这些进程中。\n  command：接收诊断命令请求的进程的main类。匹配进程时，main类名称中包含指定子字符串\n的任何进程均是匹配的。如果多个正在运行的Java进程共享同一个main类，诊断命令请求将会发送\n到所有的这些进程中。\n注意: 如果任何参数含有空格，你必须使用英文的单引号或双引号将其包围起来。 此外，你必须使\n用转义字符来转移参数中的单引号或双引号，以阻止操作系统shell处理这些引用标记。当然，你也\n可以在参数两侧加上单引号，然后在参数内使用双引号(或者，在参数两侧加上双引号，在参数中使\n用单引号)。\n  Perfcounter.print：打印目标Java进程上可用的性能计数器。性能计数器的列表可能会随着Java\n进程的不同而产生变化。\n  -f file：从文件file中读取命令，然后在目标Java进程上调用这些命令。在file中，每个命令必须写在\n单独的一行。以\u0026rdquo;#\u0026ldquo;开头的行会被忽略。当所有行的命令被调用完毕后，或者读取到含有stop关键\n字的命令，将会终止对file的处理。\n  -l：查看所有的进程列表信息。\n  -h：查看帮助信息。（同 -help）\n  5.2、jinfo ​\t可以用来查看正在运行的 java 应用程序的扩展参数，包括Java System属性和JVM命令行参数；也\n可以动态的修改正在运行的 JVM 一些参数。当系统崩溃时，jinfo可以从core文件里面知道崩溃的Java应\n用程序的配置信息。\njinfo -flag name pid\r   pid 对应jvm的进程id\n  executable core 产生core dump文件\n  [server-id@]remote server IP or hostname 远程的ip或者hostname，server-id标记服务的唯一性id\noption\n  no option 输出全部的参数和系统属性\n  -flag name 输出对应名称的参数\n  -flag [+|-]name 开启或者关闭对应名称的参数\n  -flag name=value 设定对应名称的参数\n  -flags 输出全部的参数\n  -sysprops 输出系统属性\n  5.3、jmap ​\t用于打印指定Java进程(或核心文件、远程调试服务器)的共享对象内存映射或堆内存细节。\n​\t堆Dump是反应Java堆使用情况的内存镜像，其中主要包括系统信息、虚拟机属性、完整的线程\nDump、所有类和对象的状态等。 一般，在内存不足、GC异常等情况下，我们就会怀疑有内存泄露。这\n个时候我们就可以制作堆Dump来查看具体情况。分析原因。\njmap [option] vmid\r  -dump：生成Java堆转储快照。格式为：-dump:[live,]format=b,file=，其中live子参数说明是否只dump出存活的对象 -finalizerinfo：显示在F-Queue中等待Finalizer线程执行finalize()方法的对象。只在Linux/Solaris平台下有效 -heap：显示Java堆详细信息，如使用哪种回收器、参数配置、分代状况等。只在Linux/Solaris平台下有效 -histo：显示堆中对象统计信息，包括类、实例数量和合计容量 -permstat：以ClassLoader为统计口径显示永久代内存状态。只在Linux/Solaris平台下有效 -F 当虚拟机进程对-dump选项没有响应时，可使用这个选项强制生成dump快照。只在Linux/Solaris平台下有效。  5.4、jstack ​\t用于生成java虚拟机当前时刻的线程快照（一般称为threaddump或javacore文件）。线程快照就\n是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的主要目的就是定位线程出现长\n时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等都是导致线程长时间停顿\n的常见原因。\njstack [option] vmid\r  - F : 当正常输出的请求不被响应时，强制输出线程堆栈； -l ： 除堆栈外，显示关于锁的附加信息； -m：如果调用到本地方法的话，可以显示C/C++的堆栈  可以通过Thread类的getAllStackTraces()获取所有线程的StackTraceElement对象。\n6、参数调优 6.1、直接内存 ​\t可以通过 -XX:MaxDirectMemorySize 参数来设置最大可用直接内存，如果启动时未设置则默认为\n最大堆内存大小，即与 -Xmx 相同。即假如最大堆内存为1G，则默认直接内存也为1G，那么 JVM 最大\n需要的内存大小为2G多一些。当直接内存达到最大限制时就会触发GC，如果回收失败则会引起\nOutOfMemoryError。\n7、内存问题定位 7.1、部署环境 ​\t采用docker-compose方式部署Java微服务程序。所以要排查内存泄露问题，就要进入docker容器进\n行调试排查。\n7.2、准备工作   微服务docker部署采用的jdk版本为：adoptopenjdk/openjdk8。\n  微服务构建脚本docker-compose增加配置并重新构建服务：\n  cap_add:\r- SYS_PTRACE\r  安装gdb调试工具：  apt-get update\rapt-get install gdb\r  ptrace系统配置修改：  sudo vi /etc/sysctl.d/10-ptrace.conf\r修改：kernel.yama.ptrace_scope = 0\r执行:service procps restart\r 7.3、排查过程  进入docker容器的挂载日志目录：  docker exec -it [容器id] /bin/bash\rcd logs\r  升序查看内存使用情况：  pmap -x [pid] | sort -n -k3\rpid为应用程序的id,通过jps命令可以查看，一般docker容器下的java程序的pid都是：1。\r对于iot-server-smart这个微服务：可以发现堆外内存有很多64mb左右的内存块，需要将这些内存\rdump下来查看相关的代码信息：\r00007fdb0c000000 61444 50540 50540 rw--- [ anon ]\r00007fdaa0000000 61444 50800 50800 rw--- [ anon ]\r00007fdb24000000 61444 51008 51008 rw--- [ anon ]\r00007fdb2c000000 61444 51008 51008 rw--- [ anon ]\r00007fdbe8000000 61500 51068 51068 rw--- [ anon ]\r00007fdba0000000 61528 51092 51092 rw--- [ anon ]\r00007fdbe4000000 61528 51336 51336 rw--- [ anon ]\r00007fdbc0000000 61640 51668 51668 rw--- [ anon ]\r00007fdbd4000000 63744 51856 51856 rw--- [ anon ]\r00007fdbbc000000 61512 52016 52016 rw--- [ anon ]\r00007fdbdc000000 61528 52044 52044 rw--- [ anon ]\r00007fdbe0000000 61524 52056 52056 rw--- [ anon ]\r00007fdb8c000000 61524 52060 52060 rw--- [ anon ]\r00007fdbcc000000 63684 52068 52068 rw--- [ anon ]\r00007fdbc4000000 61548 52136 52136 rw--- [ anon ]\r00007fdb94000000 61536 52148 52148 rw--- [ anon ]\r00007fdc04000000 61540 52152 52152 rw--- [ anon ]\r00007fdb9c000000 61660 52172 52172 rw--- [ anon ]\r00007fdbf4000000 61652 52200 52200 rw--- [ anon ]\r00007fdbfc000000 61628 52220 52220 rw--- [ anon ]\r00007fdbd8000000 61716 52272 52272 rw--- [ anon ]\r00007fdc00000000 61824 52324 52324 rw--- [ anon ]\r00007fdbd0000000 65008 52492 52492 rw--- [ anon ]\r00007fdb84000000 62248 52564 52564 rw--- [ anon ]\r00007fdb90000000 65136 54788 54788 rw--- [ anon ]\r  dump指定内存块信息：  1、查看内存块的详细信息：\rcat /proc/1/maps；\r2、查看指定内存块：\rcat /proc/1/maps | grep 7fdbd0000000 （7fdbd0000000，为上一步查看的结果）如下所\r示：\r7fdbd0000000-7fdbd3f7c000 rw-p 00000000 00:00 0\r3、dump指定内存：\rgdb --batch --pid 1 -ex \u0026quot;dump memory iot-server-smart.dump 0x7fdbd0000000\r0x7fdbd3f7c000\u0026quot;\r注意上面的命令开始和结束的内存地址要加上“0x”\r4、生成的dump文件会在logs目录下，同时可以在宿主机微服务logs下用less命令查看。通过观察运\r行的代码信息进一步排除内存泄露的原因\r手动触发full gc 保存内存信息文件\r5、jmap -dump:live,format=b,file=/ehaomiao/logs/heap-live.hprof 1\r  附：MAT工具使用参考：关于使用Eclipse Memory Analyzer的10点小技巧\n ","id":13,"section":"posts","summary":"最近发现服务器在部署一段时间后会自动重启，初步排查为内存原因，肯能存在内存泄漏，需进一步排查。这里记录一下相关学习记录 JVM内存调优 1、JV","tags":["jvm"],"title":"JVM内存调优","uri":"https://bluestaree.github.io/2022/09/jvm%E5%86%85%E5%AD%98%E8%B0%83%E4%BC%98/","year":"2022"},{"content":"  业务场景：基于以图搜人结果，无法在人脸向量数据库milvus中进行分页查询，只能将匹配的数据按照一定数量限制全部查询出来，再通过手动分页的方式展示给前端\n 正常开启分页方式\n// 获取分页参数\rMap\u0026lt;String, String\u0026gt; webParam = WebContextThreadLocal.get();\rPageDomain pageDomain = new PageDomain();\rif (webParam != null) {\rString pageDomainStr = webParam.get(\u0026quot;pageDomain\u0026quot;);\rif (StrUtil.isNotBlank(pageDomainStr)) {\rpageDomain = JSON.parseObject(pageDomainStr, PageDomain.class);\r}\r}\rInteger pageNum = pageDomain.getPageNum();\rInteger pageSize = pageDomain.getPageSize();\r// 开启分页\rPageHelper.startPage(pageNum, pageSize);\r// 查询集合\rlist = selectCommunityBuildingListByPage(building, communityIds, keywords);\rreturn new PageData\u0026lt;\u0026gt;(new PageInfo\u0026lt;\u0026gt;(list));\r 其中PageData是我们对 PageInfo 做了一个封装，相关代码如下：\nPageData类\npublic class PageData\u0026lt;T\u0026gt; implements Serializable {\rprivate static final long serialVersionUID = 1L;\rprivate long total;\rprivate List\u0026lt;T\u0026gt; rows;\rprivate long totalPage;\rprivate int pageSize;\rprivate int pageNum;\rpublic PageData() {\r}\r/** @deprecated */\r@Deprecated\rpublic PageData(List\u0026lt;T\u0026gt; list, int total) {\rthis.rows = list;\rthis.total = (long)total;\r}\rpublic PageData(List\u0026lt;T\u0026gt; list, long total, int pageNum, int pageSize) {\rthis.rows = list;\rthis.total = total;\rthis.pageNum = pageNum;\rthis.pageSize = pageSize;\rthis.totalPage = total % (long)pageSize == 0L ? total / (long)pageSize : total / (long)pageSize + 1L;\r}\rpublic PageData(PageInfo\u0026lt;T\u0026gt; pageInfo) {\rthis.total = pageInfo.getTotal();\rthis.rows = pageInfo.getList();\rthis.totalPage = (long)pageInfo.getPages();\rthis.pageSize = pageInfo.getPageSize();\rthis.pageNum = pageInfo.getPageNum();\r}\rpublic PageData convert(RecordConvert convert) {\rif (this.rows == null) {\rreturn this;\r} else {\rint i = 0;\rfor(int len = this.rows.size(); i \u0026lt; len; ++i) {\rObject rec = this.rows.get(i);\rObject newRec = convert.convert(rec);\rthis.rows.remove(i);\rif (newRec != null) {\rthis.rows.add(i, newRec);\r}\r}\rreturn this;\r}\r}\rpublic static PageDomain getPageDomain() {\rMap\u0026lt;String, String\u0026gt; webParam = WebContextThreadLocal.get();\rPageDomain pageDomain = new PageDomain();\rString pageDomainStr = (String)webParam.get(\u0026quot;pageDomain\u0026quot;);\rif (StrUtil.isNotBlank(pageDomainStr)) {\rpageDomain = (PageDomain)JSON.parseObject(pageDomainStr, PageDomain.class);\r}\rreturn pageDomain;\r}\rpublic static \u0026lt;T\u0026gt; PageData\u0026lt;T\u0026gt; buildSelectPage(ISelect select) {\rPageDomain pageDomain = getPageDomain();\rInteger pageNum = pageDomain.getPageNum();\rInteger pageSize = pageDomain.getPageSize();\rPageInfo\u0026lt;T\u0026gt; info = PageHelper.startPage(pageNum, pageSize).doSelectPageInfo(select);\rreturn new PageData(info);\r}\rpublic static \u0026lt;T\u0026gt; PageData\u0026lt;T\u0026gt; buildSelectPage(ISelect select, int pageNum) {\rPageDomain pageDomain = getPageDomain();\rInteger pageSize = pageDomain.getPageSize();\rPageInfo\u0026lt;T\u0026gt; info = PageHelper.startPage(pageNum, pageSize).doSelectPageInfo(select);\rreturn new PageData(info);\r}\rpublic long getTotalPage() {\rreturn this.totalPage;\r}\rpublic void setTotalPage(long totalPage) {\rthis.totalPage = totalPage;\r}\rpublic int getPageSize() {\rreturn this.pageSize;\r}\rpublic void setPageSize(int pageSize) {\rthis.pageSize = pageSize;\r}\rpublic int getPageNum() {\rreturn this.pageNum;\r}\rpublic void setPageNum(int pageNum) {\rthis.pageNum = pageNum;\r}\rpublic long getTotal() {\rreturn this.total;\r}\rpublic void setTotal(long total) {\rthis.total = total;\r}\rpublic List\u0026lt;T\u0026gt; getRows() {\rreturn this.rows;\r}\rpublic void setRows(List\u0026lt;T\u0026gt; rows) {\rthis.rows = rows;\r}\r}\r 手动实现分页\n需要先将需要分页的数据查询出来 ，然后自己对list结果进行处理为相应的分页效果，主要用list.sublist 实现\npublic \u0026lt;T\u0026gt; PageInfo\u0026lt;T\u0026gt; startPage(List\u0026lt;T\u0026gt; list, Integer pageNum, Integer pageSize) {\r//创建Page类\rPage page = new Page(pageNum, pageSize);\r//为Page类中的total属性赋值\rpage.setTotal(list.size());\r//计算当前需要显示的数据下标起始值\rint startIndex = (pageNum - 1) * pageSize;\rint endIndex = Math.min(startIndex + pageSize, list.size());\r//从链表中截取需要显示的子链表，并加入到Page\rpage.addAll(CollUtil.sub(list, startIndex, endIndex));\r//以Page创建PageInfo\rPageInfo pageInfo = new PageInfo\u0026lt;\u0026gt;(page);\rreturn pageInfo;\r}\r 调用完 再对其进行封装\nPageData\u0026lt;FaceLogSearchVO\u0026gt; faceLogSearchVOPage = new PageData\u0026lt;\u0026gt;();\rfaceLogSearchVOPage.setTotal(pageInfo.getTotal());\rfaceLogSearchVOPage.setRows(pageInfo.getList());\rfaceLogSearchVOPage.setPageSize(pageInfo.getPageSize());\rfaceLogSearchVOPage.setPageNum(pageInfo.getPageNum());\rfaceLogSearchVOPage.setTotalPage(pageInfo.getPages());\rreturn faceLogSearchVOPage;\r ","id":14,"section":"posts","summary":"业务场景：基于以图搜人结果，无法在人脸向量数据库milvus中进行分页查询，只能将匹配的数据按照一定数量限制全部查询出来，再通过手动分页的方","tags":null,"title":"pagehelper 实现假分页效果","uri":"https://bluestaree.github.io/2022/08/pagehelper-%E7%9C%9F%E5%81%87%E5%88%86%E9%A1%B5/","year":"2022"},{"content":"  日常开发中，同事在开发中遇到的一个问题，在使用自定义mapper方法时，出现Invalid bound statement，这里记录下问题及产生原因\n 自定义sql方法\n主要功能就是再 批量逻辑删除的 同时，更新 update_time 时间\npublic class DeleteBatchLogicIds extends AbstractMethod {\rpublic DeleteBatchLogicIds() {\r}\r@Override\rpublic MappedStatement injectMappedStatement(Class\u0026lt;?\u0026gt; mapperClass, Class\u0026lt;?\u0026gt; modelClass, TableInfo tableInfo) {\rHmSqlMethod sqlMethod = HmSqlMethod.LOGIC_DELETE_BATCH_BY_IDS_AND_UPDATE_TIME;\rString sql;\rif (tableInfo.isWithLogicDelete()) {\rList\u0026lt;TableFieldInfo\u0026gt; fieldInfos = tableInfo.getFieldList().stream()\r.filter(TableFieldInfo::isWithUpdateFill)\r.collect(toList());\rString setSql;\rif (CollectionUtils.isNotEmpty(fieldInfos)) {\rsetSql = \u0026quot;SET \u0026quot; + fieldInfos.stream()\r.map(i -\u0026gt; i.getSqlSet(ENTITY_DOT)).collect(joining(EMPTY))\r+ tableInfo.getLogicDeleteSql(false, false);\r} else {\r//setSql = this.sqlLogicSet(tableInfo) + SqlUtil.getUpdateTimeSetSql(tableInfo);\rsetSql = this.sqlLogicSet(tableInfo);\r}\rsql = String.format(sqlMethod.getSql(), tableInfo.getTableName(), setSql, tableInfo.getKeyColumn(), SqlScriptUtils.convertForeach(\u0026quot;#{item}\u0026quot;, \u0026quot;coll\u0026quot;, (String) null, \u0026quot;item\u0026quot;, \u0026quot;,\u0026quot;), tableInfo.getLogicDeleteSql(true, true));\r// UPDATE aiot_visitor_auth SET update_by = ?, update_time = ?, is_deleted = '1' WHERE visitor_auth_id IN (?) AND is_deleted = '0'\r// 以上sql后续还会经过字段填充配置\rSqlSource sqlSource;\rsqlSource = this.languageDriver.createSqlSource(this.configuration, sql, Object.class);\rreturn this.addUpdateMappedStatement(mapperClass, modelClass, sqlMethod.getMethod(), sqlSource);\r} else {\r// TODO:\rreturn null;\r}\r}\r}\r 测试使用该方法时出现如下错误：\n排查原因：\n注意自定义sql方法中的 if (tableInfo.isWithLogicDelete()) 条件，发现对应实体类没有加入 tableLogic注解\n补充添加注解后解决\n","id":15,"section":"posts","summary":"日常开发中，同事在开发中遇到的一个问题，在使用自定义mapper方法时，出现Invalid bound statement，这里记录下问题及产生原因 自定","tags":null,"title":"mybatis plus自定义sql报错Invalid bound statement解决","uri":"https://bluestaree.github.io/2022/07/mybatis-plus%E8%87%AA%E5%AE%9A%E4%B9%89sql%E6%8A%A5%E9%94%99invalid-bound-statement%E8%A7%A3%E5%86%B3/","year":"2022"},{"content":" Rabbitmq 动态队列实现 该功能，基于RabbitMq提供的API接口实现，能在项目运行中，动态生成队列及其监听实现\n项目目录结构： RabbitConfig 主要配置文件\n@Configuration\rpublic class RabbitConfig {\r@Autowired\rprivate QueueService queueService;\r@Autowired\rprivate MessageConsumerHandler handler;\r@Bean\rpublic TopicExchange topicExchange() {\rreturn new TopicExchange(ProducerUtil.EXCHANGE_NAME_PREFIX, true, false);\r}\r@Bean\rpublic RabbitTemplate createRabbitTemplate(ConnectionFactory connectionFactory) {\rRabbitTemplate rabbitTemplate = new RabbitTemplate();\rrabbitTemplate.setConnectionFactory(connectionFactory);\r//设置开启Mandatory,才能触发回调函数,无论消息推送结果怎么样都强制调用回调函数\rrabbitTemplate.setMandatory(true);\r/**\r* 以下配置 ，需要在配置文件中开启才会生效\r* rabbitmq:\r* #开启确认模式 用于确认消息是否成功抵达交换机 (ConfirmCallback)\r* publisher-confirm-type: correlated\r* #开启确认模式 用于确认消息是否成功由交换机抵达至队列 (ReturnCallback)\r* publisher-returns: true\r*/\r/**\r* 如果消息没有到exchange,则confirm回调,ack=false\r* 如果消息到达exchange,则confirm回调,ack=true\r* exchange到queue成功,则不回调return\r* exchange到queue失败,则回调return(需设置mandatory=true,否则不回回调,消息就丢了)\r*/\r//所有情况都会触发\rrabbitTemplate.setConfirmCallback(new RabbitTemplate.ConfirmCallback() {\r@Override\rpublic void confirm(CorrelationData correlationData, boolean ack, String cause) {\rSystem.out.println(\u0026quot;ConfirmCallback: \u0026quot; + \u0026quot;相关数据：\u0026quot; + correlationData);\rSystem.out.println(\u0026quot;ConfirmCallback: \u0026quot; + \u0026quot;确认情况：\u0026quot; + ack);\rSystem.out.println(\u0026quot;ConfirmCallback: \u0026quot; + \u0026quot;原因：\u0026quot; + cause);\r}\r});\r//只有没找到队列才会触发\rrabbitTemplate.setReturnCallback(new RabbitTemplate.ReturnCallback() {\r@Override\rpublic void returnedMessage(Message message, int replyCode, String replyText, String exchange, String routingKey) {\rSystem.out.println(\u0026quot;ReturnCallback: \u0026quot; + \u0026quot;消息：\u0026quot; + message);\rSystem.out.println(\u0026quot;ReturnCallback: \u0026quot; + \u0026quot;回应码：\u0026quot; + replyCode);\rSystem.out.println(\u0026quot;ReturnCallback: \u0026quot; + \u0026quot;回应信息：\u0026quot; + replyText);\rSystem.out.println(\u0026quot;ReturnCallback: \u0026quot; + \u0026quot;交换机：\u0026quot; + exchange);\rSystem.out.println(\u0026quot;ReturnCallback: \u0026quot; + \u0026quot;路由键：\u0026quot; + routingKey);\r}\r});\rreturn rabbitTemplate;\r}\r/**\r* 动态队列需要的配置\r*/\r@Bean\rpublic RabbitAdmin createRabbitAdmin(ConnectionFactory connectionFactory) {\rreturn new RabbitAdmin(connectionFactory);\r}\r@Bean\rpublic SimpleMessageListenerContainer mqMessageContainer(ConnectionFactory connectionFactory) throws AmqpException, IOException {\rSimpleMessageListenerContainer container = new SimpleMessageListenerContainer(connectionFactory);\rList\u0026lt;String\u0026gt; list = queueService.getMQJSONArray();\rcontainer.setQueueNames(list.toArray(new String[list.size()]));\rcontainer.setExposeListenerChannel(true);\rcontainer.setPrefetchCount(1);//设置每个消费者获取的最大的消息数量\rcontainer.setConcurrentConsumers(1);//消费者个数\rcontainer.setAcknowledgeMode(AcknowledgeMode.MANUAL);//设置确认模式为手工确认\rcontainer.setMessageListener(handler);//监听处理类\rreturn container;\r}\r}\r MyMessagePostProcessor 自定义消息参数信息，主要用户指定消息优先级\npublic class MyMessagePostProcessor implements MessagePostProcessor {\rprivate Integer priority;\rpublic MyMessagePostProcessor() {\r}\rpublic MyMessagePostProcessor(Integer priority) {\rthis.priority = priority;\r}\r@Override\rpublic Message postProcessMessage(Message message) throws AmqpException {\rmessage.getMessageProperties().setPriority(priority);\rreturn message;\r}\r}  MqConsumerFeign 服务器\nProducerUtil mq生产者工具类\n@Component\r@AllArgsConstructor\rpublic class ProducerUtil {\rprivate RabbitTemplate rabbit;\rprivate RabbitAdmin rabbitAdmin;\rprivate TopicExchange topicExchange;\r/**\r* MQ队列名前缀\r*/\rpublic static final String QUEUE_NAME_PREFIX = \u0026quot;comu.device.queue\u0026quot;;\r/**\r* MQ交换机前缀\r*/\rpublic static final String EXCHANGE_NAME_PREFIX = \u0026quot;comu.device.exchange\u0026quot;;\r/**\r* 删除队列\r*/\rpublic String deleteQueue(String queueName) {\rQueueInformation queueInfo = rabbitAdmin.getQueueInfo(queueName);\rif (queueInfo.getMessageCount() \u0026gt; 0) {\rSystem.out.println(\u0026quot;当期队列中存在消息，不能删除！\u0026quot;);\rreturn \u0026quot;当期队列中存在消息，不能删除！\u0026quot;;\r} else if (queueInfo.getConsumerCount() \u0026gt; 0) {\rSystem.out.println(\u0026quot;当期队列中存在消费者，不能删除！\u0026quot;);\rreturn \u0026quot;当期队列中存在消费者，不能删除！\u0026quot;;\r}\rtry {\rrabbitAdmin.deleteQueue(queueName, true, true);\r} catch (Exception e) {\re.printStackTrace();\r}\rreturn \u0026quot;队列已经清空\u0026quot;;\r}\r/**\r* 创建队列并发送信息\r*/\rpublic String produce(String message) {\rreturn produce(message, 0);\r}\r/**\r* 创建队列并发送信息，指定优先级\r*/\rpublic String produce(String message, int priority) {\rcreateMQIfNotExist(QUEUE_NAME_PREFIX, EXCHANGE_NAME_PREFIX);\r// 自定义消息参数\rMyMessagePostProcessor myMessagePostProcessor = new MyMessagePostProcessor(priority);\rrabbit.convertAndSend(EXCHANGE_NAME_PREFIX, QUEUE_NAME_PREFIX, (Object) message, myMessagePostProcessor);\rreturn \u0026quot;消息已经发送\u0026quot;;\r}\r/**\r* 创建队列\r*/\rprivate void createMQIfNotExist(String queueName, String exchangeName) {\r//判断队列是否存在\rProperties properties = rabbitAdmin.getQueueProperties(queueName);\rif (properties == null) {\r// 配置队列优先级\rMap\u0026lt;String, Object\u0026gt; arguments = new HashMap\u0026lt;\u0026gt;();\r// 一般为0-255，大于255出错\rarguments.put(\u0026quot;x-max-priority\u0026quot;, 128);\rQueue queue = new Queue(queueName, true, false, false, arguments);\r// FanoutExchange fanoutExchange = new FanoutExchange(exchangeName);\rrabbitAdmin.declareQueue(queue);\rrabbitAdmin.declareExchange(topicExchange);\rrabbitAdmin.declareBinding(BindingBuilder.bind(queue).to(topicExchange).with(queueName));\r//新启动一个线程，通知消费者新增listener\rnew Thread(new Runnable() {\r@Override\rpublic void run() {\rString res = callAddNewListener(queueName);\rif (!StringUtils.isEmpty(res)) {\rSystem.out.println(\u0026quot;--\u0026gt;\u0026gt;调用创建新的 listener feign 失败\u0026quot;);\r}\r}\r}).start();\r}\r}\r/**\r* description: 添加监听者\r* @Param: null\r* @return\r*/\rprivate String callAddNewListener(String queueName) {\r// 服务器动态添加监听的api地址 见MqConsumerFeign接口\rString url = \u0026quot;http://localhost:12181/add_new_listener\u0026quot;;\rMap\u0026lt;String, String\u0026gt; param = new HashMap\u0026lt;String, String\u0026gt;();\rparam.put(\u0026quot;queueName\u0026quot;, queueName);\rtry {\rOKHttpClientUtil.doGet(url, null, param);\r} catch (Exception e) {\re.printStackTrace();\rreturn \u0026quot;调用添加listener feign失败\u0026quot;;\r}\rreturn null;\r}\r}\r 实现动态队列的主要方法就是 createMQIfNotExist() ，\n","id":16,"section":"posts","summary":"Rabbitmq 动态队列实现 该功能，基于RabbitMq提供的API接口实现，能在项目运行中，动态生成队列及其监听实现 项目目录结构： RabbitConfig 主要配置文件 @Configuration public class RabbitConfig","tags":["Rabbitmq"],"title":"Rabbitmq 动态队列实现","uri":"https://bluestaree.github.io/2022/07/rabbitmq-%E5%8A%A8%E6%80%81%E9%98%9F%E5%88%97%E5%AE%9E%E7%8E%B0/","year":"2022"},{"content":" 前言  最近在做项目时遇到一个需求：需要根据用户设定得截止时间，将计划关闭。\n因为不可变性，定时任务效率低直接排除，最初考虑通过mq死信交换机得方式，通过设置不同消息TTL一达到预期效果，但在研究后发现了问题，死信队列得触发方式也算是基于队列，也就是说如果队列头得消息尚未过期，排在后面得消息就算过期了也需等待。无法实现需求\n ​\t查阅资料后发现了另外一种解决方式: mq延迟队列，但这种方式同样存在弊端：\n​\t在实际开发过程中利用RocketMQ延迟发消息的功能会遇到设定时间后不起效果，没有延迟立刻就会消费到消息这种问题：这里失败的原因就是与消息的过期事件（TTL）有直接的关系。在 RocketMQ中过期时间必须是非负32位整数即0\u0026lt;=n\u0026lt;= 2^32-1 以毫米为单位，2^32-1 = 4294967295 ,所以它的延迟消息的极限值就是4294967295毫秒，大概也就是49天最长时间。\n​\t这一点需要注意，不过目前需求是这个时间跨度最长为30天，所以上述技术选型能够满足要求，下面就看看如何使用延迟队列\nRabbitmq 延迟队列实现  参考技术文章: RabbitMQ-延迟队列\n 1. 简介 我们在上一篇博文中遗留了一个小问题，就是虽然TTL + DLX能实现延迟队列的功能，但是有两个问题。\n首先业务场景为：比如海底捞预约，每个人预约的时间段不一致，有个可能一个小时后，有的可能三个小时等，当快到预约时间点需要给用户进行短信通知。\n 通过给Queue设置过期时间的方式不现实，因为很有可能每条记录的过期时间都不一样，不可能设置那么多的Queue。 直接给Message设置过期时间，这种方式也不好，因为这种方式是**当该消息在队列头部时（消费时），才会单独判断这一消息是否过期。**例：现在有两条消息，第一条消息过期时间为30s，而第二条消息过期时间为15s，当过了15秒后，第二条消息不会立即过期，而是要等第一条消息被消费后，第二条消息被消费时，才会判断是否过期，也就是等到第二条消息投往DLX已经过去45s了。  这也就抛出了本章主题：延迟队列。\nRabbitMQ默认没有提供延迟队列功能，而是要通过插件提供的x-delayed-message（延迟交换机）来实现。\n延迟队列：用户可以使用该类型声明一个交换，x-delayed-message然后使用自定义标头发布消息，x-delay以毫秒为单位表示消息的延迟时间。消息将在x-delay毫秒后传递到相应的队列。\n2. 安装插件 官方插件地址：https://www.rabbitmq.com/community-plugins.html\n找到插件rabbitmq_delayed_message_exchange，进入GitHub下载本地RabbitMQ对应的插件版本（下载.ez文件）。\n我这里下载的是3.8.9版本，如图： \n下载到本地后将文件放置RabbitMQ的plugins目录。\n我这里本地是使用docker-compose安装的服务，image为rabbitmq:3.8.3-management（虽然版本没对起来，但是测试能用，但是使用3.9的版本会报错，插件安装失败）安装的服务，操作步骤如下：\n  将下载好的文件放置RabbitMQ插件目录\nrabbitmq：容器服务名\n$ docker cp /Users/ludangxin/Downloads/rabbitmq_delayed_message_exchange-3.8.9-0199d11c.ez rabbitmq:/opt/rabbitmq/plugins/\r   进入容器\n$ docker exec -it rabbitmq /bin/bash\r   查看现有的插件列表\n$ rabbitmq-plugins list\r# 输出部分内容如下 [E*] = 明确启用; e = 隐式启用\r[ ] rabbitmq_amqp1_0 3.8.3\r[ ] rabbitmq_auth_backend_cache 3.8.3\r[ ] rabbitmq_auth_backend_http 3.8.3\r[ ] rabbitmq_auth_backend_ldap 3.8.3\r[ ] rabbitmq_auth_backend_oauth2 3.8.3\r[ ] rabbitmq_auth_mechanism_ssl 3.8.3\r[ ] rabbitmq_consistent_hash_exchange 3.8.3\r[ ] rabbitmq_event_exchange 3.8.3\r[ ] rabbitmq_federation 3.8.3\r[ ] rabbitmq_federation_management 3.8.3\r[ ] rabbitmq_jms_topic_exchange 3.8.3\r[E*] rabbitmq_management 3.8.3\r[e*] rabbitmq_management_agent 3.8.3\r[ ] rabbitmq_mqtt 3.8.3\r   启用插件\n$ rabbitmq-plugins enable rabbitmq_delayed_message_exchange\r   再次查看安装列表就有了rabbitmq_delayed_message_exchange\n  安装完毕后登陆RabbitMQ控制台查看，会发现多了个x-delayed-message类型的Exchange。\n\n3. 实现延迟队列 3.1 引入所需依赖 \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-amqp\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt;\r\u0026lt;optional\u0026gt;true\u0026lt;/optional\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt;\r\u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.amqp\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-rabbit-test\u0026lt;/artifactId\u0026gt;\r\u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 3.2 application.yaml spring:\rrabbitmq:\rhost: localhost\rport: 5672\r# rabbit 默认的虚拟主机\rvirtual-host: /\r# rabbit 用户名密码\rusername: admin\rpassword: admin123\r 3.3 RabbitConfig import org.springframework.amqp.core.Binding;\rimport org.springframework.amqp.core.BindingBuilder;\rimport org.springframework.amqp.core.CustomExchange;\rimport org.springframework.amqp.core.Queue;\rimport org.springframework.amqp.core.QueueBuilder;\rimport org.springframework.beans.factory.annotation.Qualifier;\rimport org.springframework.context.annotation.Bean;\rimport org.springframework.context.annotation.Configuration;\rimport java.util.HashMap;\rimport java.util.Map;\r/**\r* 延迟队列配置\r*\r* @author ludangxin\r* @date 2021/9/16\r*/\r@Configuration\rpublic class RabbitDelayedConfig {\rpublic static final String QUEUE_NAME_DELAYED = \u0026quot;DELAY.QUEUE\u0026quot;;\rpublic static final String EXCHANGE_NAME_DELAYED = \u0026quot;DELAY.EXCHANGE\u0026quot;;\rpublic static final String ROUTING_KEY_DELAYED = \u0026quot;DELAY.#\u0026quot;;\r@Bean(QUEUE_NAME_DELAYED)\rpublic Queue queue() {\rreturn QueueBuilder.durable(QUEUE_NAME_DELAYED).build();\r}\r@Bean(EXCHANGE_NAME_DELAYED)\rpublic CustomExchange exchange() {\rMap\u0026lt;String, Object\u0026gt; arguments = new HashMap\u0026lt;\u0026gt;(1);\r// 在这里声明一个主题类型的延迟队列，当然其他类型的也可以。\rarguments.put(\u0026quot;x-delayed-type\u0026quot;, \u0026quot;topic\u0026quot;);\rreturn new CustomExchange(EXCHANGE_NAME_DELAYED, \u0026quot;x-delayed-message\u0026quot;, true, false, arguments);\r}\r@Bean\rpublic Binding bindingNotify(@Qualifier(QUEUE_NAME_DELAYED) Queue queue, @Qualifier(EXCHANGE_NAME_DELAYED) CustomExchange customExchange) {\rreturn BindingBuilder.bind(queue).to(customExchange).with(ROUTING_KEY_DELAYED).noargs();\r}\r}\r 3.4 Producer import com.ldx.rabbitmq.config.RabbitDelayedConfig;\rimport org.springframework.amqp.core.Message;\rimport org.springframework.amqp.core.MessageProperties;\rimport org.springframework.amqp.rabbit.core.RabbitTemplate;\rimport org.springframework.beans.factory.annotation.Autowired;\rimport org.springframework.stereotype.Component;\rimport java.time.LocalDateTime;\rimport java.time.format.DateTimeFormatter;\r/**\r* 延迟消息生产者\r*\r* @author ludangxin\r* @date 2021/9/9\r*/\r@Component\rpublic class DelayProducer {\r@Autowired\rprivate RabbitTemplate rabbitTemplate;\rpublic void sendDelayedMsg(String msg, Integer delay) {\rMessageProperties mp = new MessageProperties();\r// 设置过期时间\rmp.setDelay(delay);\rMessage message = new Message(msg.getBytes(), mp);\rrabbitTemplate.convertAndSend(RabbitDelayedConfig.EXCHANGE_NAME_DELAYED, \u0026quot;DELAY.MSG\u0026quot;, message);\r}\r}\r 3.5 Consumer import com.ldx.rabbitmq.config.RabbitDelayedConfig;\rimport lombok.extern.slf4j.Slf4j;\rimport org.springframework.amqp.core.Message;\rimport org.springframework.amqp.rabbit.annotation.RabbitListener;\rimport org.springframework.stereotype.Component;\rimport java.time.LocalDateTime;\rimport java.time.format.DateTimeFormatter;\r/**\r* 延迟消息消费者\r*\r* @author ludangxin\r* @date 2021/9/9\r*/\r@Slf4j\r@Component\rpublic class DelayConsumer {\r@RabbitListener(queues = {RabbitDelayedConfig.QUEUE_NAME_DELAYED})\rpublic void delayQueue(Message message){\rlog.info(new String(message.getBody()) + \u0026quot;，结束时间为：\u0026quot; + LocalDateTime.now().format(DateTimeFormatter.ofPattern(\u0026quot;yyyy-MM-dd HH:mm:ss\u0026quot;)));\r}\r}\r 3.6 测试代码 @Autowired\rprivate DelayProducer delayProducer;\r@Test\r@SneakyThrows\rpublic void sendDelayedMsg() {\rfor(int i = 16; i \u0026gt;= 10; i --) {\rString msg = \u0026quot;我将在\u0026quot; + i + \u0026quot;s后过期，开始时间为：\u0026quot; + LocalDateTime.now().format(DateTimeFormatter.ofPattern(\u0026quot;yyyy-MM-dd HH:mm:ss\u0026quot;));\rdelayProducer.sendDelayedMsg(msg,i * 1000);\r}\r// 使进程阻塞，方便Consumer监听输出Message\rSystem.in.read();\r}\r 3.7 启动测试 启动测试代码，连续发送7条消息输出内容如下：\n从日志内容可以看出，虽然我们先发送了16s的那条消息，但最终消息的过期顺序还是按照10-16s的顺序，符合预期。\n2021-09-16 23:40:10.806 INFO 7883 --- [ntContainer#0-1] c.ldx.rabbitmq.consumer.Delay2Consumer : 我将在10s后过期，开始时间为：2021-09-16 23:40:00，结束时间为：2021-09-16 23:40:10\r2021-09-16 23:40:11.792 INFO 7883 --- [ntContainer#0-1] c.ldx.rabbitmq.consumer.Delay2Consumer : 我将在11s后过期，开始时间为：2021-09-16 23:40:00，结束时间为：2021-09-16 23:40:11\r2021-09-16 23:40:12.791 INFO 7883 --- [ntContainer#0-1] c.ldx.rabbitmq.consumer.Delay2Consumer : 我将在12s后过期，开始时间为：2021-09-16 23:40:00，结束时间为：2021-09-16 23:40:12\r2021-09-16 23:40:13.791 INFO 7883 --- [ntContainer#0-1] c.ldx.rabbitmq.consumer.Delay2Consumer : 我将在13s后过期，开始时间为：2021-09-16 23:40:00，结束时间为：2021-09-16 23:40:13\r2021-09-16 23:40:14.788 INFO 7883 --- [ntContainer#0-1] c.ldx.rabbitmq.consumer.Delay2Consumer : 我将在14s后过期，开始时间为：2021-09-16 23:40:00，结束时间为：2021-09-16 23:40:14\r2021-09-16 23:40:15.785 INFO 7883 --- [ntContainer#0-1] c.ldx.rabbitmq.consumer.Delay2Consumer : 我将在15s后过期，开始时间为：2021-09-16 23:40:00，结束时间为：2021-09-16 23:40:15\r2021-09-16 23:40:16.785 INFO 7883 --- [ntContainer#0-1] c.ldx.rabbitmq.consumer.Delay2Consumer : 我将在16s后过期，开始时间为：2021-09-16 23:40:00，结束时间为：2021-09-16 23:40:16\r ","id":17,"section":"posts","summary":"前言 最近在做项目时遇到一个需求：需要根据用户设定得截止时间，将计划关闭。 因为不可变性，定时任务效率低直接排除，最初考虑通过mq死信交换机得方","tags":["Rabbitmq"],"title":"Rabbitmq 延迟队列实现","uri":"https://bluestaree.github.io/2022/06/rabbitmq-%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97%E5%AE%9E%E7%8E%B0/","year":"2022"},{"content":" 最近部署时，遇到此问题\n问题 现有服务A,B\nB服务内 有一个 spring工具类( 这个类主要就是从容器种获取实体类)，代码如下\n@Component\rpublic final class SpringBeanFactory implements ApplicationContextAware{\rprivate static ApplicationContext context;\rpublic static \u0026lt;T\u0026gt; T getBean(Class\u0026lt;T\u0026gt; c){\rreturn context.getBean(c);\r}\rpublic static \u0026lt;T\u0026gt; T getBean(String name,Class\u0026lt;T\u0026gt; clazz){\rreturn context.getBean(name,clazz);\r}\r@Override\rpublic void setApplicationContext(ApplicationContext applicationContext) throws BeansException {\rcontext = applicationContext;\r}\r}\r 服务B 能够正常运行\n但将如果B打成jar包， 在A服务种引用，并执行B服务方法\n服务A中伪代码如下：\n@Component\r@Slf4j\rpublic class NettyListen {\r// 引用服务B实体类\r@Autowired\rprivate NettyListenClient nettyListenClient;\r@PostConstruct\rpublic void start() throws Exception {\r//启动客户端 // 这里后续逻辑开启netty链接，其中会使用到上述工具类方法\rnettyListenClient.start();\r}\r}\r 使用的spring工具类 一直报空指针，导致无法正常启动\n排查后，应该是打成jar包后 会有加载顺序的问题。\n参考文章：\nhttps://blog.csdn.net/zzzmmmggg/article/details/121015435\nhttps://blog.csdn.net/fengyao1995/article/details/121908998\n解决方法 解决方法，在对应类上加上@DependsOn(\u0026ldquo;xxx\u0026rdquo;) 注解，强制初始化SpringUtil工具类即可\n@Component\r@DependsOn(\u0026quot;springBeanFactory\u0026quot;)\r@Slf4j\rpublic class NettyListen {\r@PostConstruct\rpublic void start() throws Exception {\r//启动客户端 nettyListenClient.start();\r}\r}\r ","id":18,"section":"posts","summary":"最近部署时，遇到此问题 问题 现有服务A,B B服务内 有一个 spring工具类( 这个类主要就是从容器种获取实体类)，代码如下 @Component public final class SpringBeanFactory implements ApplicationContextAware{ private static ApplicationContext context;","tags":null,"title":"@PostConstruct 注解方法下的Springutils.getBean时报空指针异常","uri":"https://bluestaree.github.io/2022/06/postconstruct-%E6%B3%A8%E8%A7%A3%E6%96%B9%E6%B3%95%E4%B8%8B%E7%9A%84springutils.getbean%E6%97%B6%E6%8A%A5%E7%A9%BA%E6%8C%87%E9%92%88%E5%BC%82%E5%B8%B8/","year":"2022"},{"content":"  概述： 记录下一个很好用的Idea开发工具插件Save Action，它能够再保存时自动格式化代码\n 一、安装save-action插件 1、安装插件 2、插件配置 3、注意事项 ​\tsave-action的配置只对当前项目生效，每个项目单独设置。没找到全局设置的地方。\n二、关闭Java-doc格式化 1、关闭原因 ​\t开启save-action自动格式代码以后，会触发java-doc注释的格式化。会对类和方法上面@的参数\n进行重新排序。\n2、配置路径 ​\tFile | Settings | Editor | Code Style | Java 。\n","id":19,"section":"posts","summary":"概述： 记录下一个很好用的Idea开发工具插件Save Action，它能够再保存时自动格式化代码 一、安装save-action插件 1、安装插件","tags":["Idea"],"title":"Idea保存自动格式化插件Save Action配置","uri":"https://bluestaree.github.io/2022/06/idea%E4%BF%9D%E5%AD%98%E8%87%AA%E5%8A%A8%E6%A0%BC%E5%BC%8F%E5%8C%96%E6%8F%92%E4%BB%B6save-action%E9%85%8D%E7%BD%AE/","year":"2022"},{"content":"  转载文章：Idea（JRebel 和 XRebel）\n Idea（JRebel 和 XRebel） 1：JRebel 和 XRebel的作用 JRebel：修改完代码，不想重启服务，就使想代码生效。\rXRebel：请求中，各个部分代码性能监控。例如：方法执行时间，出现的异常，SQL执行时间，输出的Log，MQ执行时间等。\r 2：安装JRebel 和 XRebel 3：JRebel的使用激活 1：使用 jrebel.qekang.com网址\r2：通过该网址生成 UUID https://www.guidgen.com/ 3：jrebel.qekang.com网址 拼上 UUID\rhttps://jrebel.qekang.com/7b42efd0-6ecf-48be-809b-291774eeb84b\r4:输入一个邮箱\r 4：JRebel的使用 使用JRebel启动服务，当修改了所启动服务的对应代码\rJRebel会对服务进行热部署\rJRebel: Reloading class 'com.example.security.demo.CookieDemo'.\rJRebel: Reconfiguring bean 'cookieDemo' [com.example.security.demo.CookieDemo]\r image.png\n5： XRebel的激活 使用XRebel启动\r点入http://localhost:8080/xrebel 跳转到对应的UI页面\r 使用邮箱注册：\r注册完点进setting：\r刷新页面\r 重新启动服务 XRebel显示已经进入试用期\r 6： XRebel的使用 1:点击闹钟按钮 查看花费时长\r ","id":20,"section":"posts","summary":"转载文章：Idea（JRebel 和 XRebel） Idea（JRebel 和 XRebel） 1：JRebel 和 XRebel的作用 JRebel：修改","tags":["Idea"],"title":"Idea热部署插件（JRebel 和 XRebel）","uri":"https://bluestaree.github.io/2022/06/idea%E7%83%AD%E9%83%A8%E7%BD%B2%E6%8F%92%E4%BB%B6jrebel-%E5%92%8C-xrebel/","year":"2022"},{"content":"  概述： 记录下Idea开发工具注释模板配置及使用，当前使用idea版本为2019.3.4，不同版本中配置可能无法共用\n 一、创建注释模板 1、Java类注释模板（创建类） a、配置路径 ​\tFile | Settings | Editor | File and Code Templates | File Header\nb、注释模板 /**\r* 必须添加类描述 *\r* @author ${USER} * @date ${DATE} ${TIME} * @version 1.0 */\r 2、Java类注释模板（已有类） a、配置路径 ​\tFile | Settings | Editor | Live Templates | user\nb、创建模板 ​\t点击上图中“+”号，选择Live Template选项创建一个注释模板。\nc、注释模板 /**\r* 必须添加类描述\r*\r* @author $user$\r* @date $date$ $time$\r* @Version 1.0\r*/\r d、编辑变量 e、使用方式 ​\t点击保存设置完成。在类的上方输入“/*header+Enter”即可生成类注释。\n3、Java方法注释模板 a、配置路径 ​\tFile | Settings | Editor | Live Templates | user\nb、创建模板 ​\t点击上图中“+”号，选择Live Template选项创建一个注释模板。\nc、注释模板 **\r* 必须添加方法描述\r*\r* @author $user$\r* @date $date$ $time$ $params$\r* @return $return$\r*/\r d、编辑变量 ​\tparams变量的Expression赋值为：\ngroovyScript(\u0026quot;def result=''; def params=\\\u0026quot;${_1}\\\u0026quot;.replaceAll('[\\\\\\\\[|\\\\\\\\]|\\\\\\\\s]', '').split(',').toList(); for(i = 0; i \u0026lt; params.size(); i++) {result+=' * @param ' + params[i] + ((i \u0026lt; params.size() - 1) ? '\\\\r\\\\n' : '')}; return result\u0026quot;, methodParameters())\r ​\treturn变量的Expression赋值为：\ngroovyScript(\u0026quot;def result=''; def params=\\\u0026quot;${_1}\\\u0026quot;.replaceAll('[\\\\\\\\[|\\\\\\\\]|\\\\\\\\s]', '').split('\u0026lt;').toList(); for(i = 0; i \u0026lt; params.size(); i++) {if(i!=0){result+='\u0026lt;';}; def p1=params[i].split(',').toList(); for(i2 = 0; i2 \u0026lt; p1.size(); i2++) { def p2=p1[i2].split('\\\\\\\\.').toList(); result+=p2[p2.size()-1]; if(i2!=p1.size()-1){result+=','} } ; }; return result\u0026quot;, methodReturnType())\r e、使用方式 ​\t点击保存设置完成。在类的上方输入“/**+Enter”即可生成方法注释。\n","id":21,"section":"posts","summary":"概述： 记录下Idea开发工具注释模板配置及使用，当前使用idea版本为2019.3.4，不同版本中配置可能无法共用 一、创建注释模板 1、Jav","tags":["Idea"],"title":"Idea注释模板配置","uri":"https://bluestaree.github.io/2022/06/idea%E6%B3%A8%E9%87%8A%E6%A8%A1%E6%9D%BF%E9%85%8D%E7%BD%AE/","year":"2022"},{"content":"linux防火墙打开对外开放端口号 （1）查看对外开放的端口状态   查询已开放的端口 netstat -ntulp | grep 端口号：可以具体查看某一个端口号\n  查询指定端口是否已开 firewall-cmd --query-port=666/tcp\n​\t提示 yes，表示开启；no表示未开启。\n  （2）查看防火墙状态   查看防火墙状态 systemctl status firewalld\n  开启防火墙 systemctl start firewalld\n  关闭防火墙 systemctl stop firewalld\n  开启防火墙 service firewalld start\n若遇到无法开启\n  先用：systemctl unmask firewalld.service\n  然后：systemctl start firewalld.service\n  （3）对外开发端口  查看想开的端口是否已开：firewall-cmd --query-port=6379/tcp 添加指定需要开放的端口：firewall-cmd --add-port=123/tcp --permanent 重载入添加的端口：firewall-cmd --reload 查询指定端口是否开启成功：firewall-cmd --query-port=123/tcp 移除指定端口：firewall-cmd --permanent --remove-port=123/tcp  ","id":22,"section":"posts","summary":"linux防火墙打开对外开放端口号 （1）查看对外开放的端口状态 查询已开放的端口 netstat -ntulp | grep 端口号：可以具体查看某一个端口号 查询指定端口是否已开 firewall-cmd","tags":null,"title":"linux防火墙打开对外开放端口号","uri":"https://bluestaree.github.io/2022/05/linux%E9%98%B2%E7%81%AB%E5%A2%99%E6%89%93%E5%BC%80%E5%AF%B9%E5%A4%96%E5%BC%80%E6%94%BE%E7%AB%AF%E5%8F%A3%E5%8F%B7/","year":"2022"},{"content":" 配置时注意 root 与 alias 配置的区别 第一种 root location /images/ {\rroot /opt/html/;\rindex index.html index.htm;\rtry_files $uri $uri/ /images/default.png; }\r 比如 请求 127.0.0.1/images/test.gif 会依次查找\n 文件 /opt/html/images/test.gif ( try_files $uri) 检查文件夹 /opt/html/images/test.gif/ 下是否存在index.html 或者 index.htm 文件(由 index 指定) ( try_files $uri/) 最后是**/images/default.png**  第二种 alias location /images/ {\ralias /opt/html/;\rindex index.html index.htm;\rtry_files $uri $uri/ /images/index.html; }\r 比如 请求 127.0.0.1/images/test.gif 会依次查找\n 文件/opt/html/test.gif （ try_files $uri ） 检查文件夹 /opt/html/test.gif/ 下是否存在index.html 或者 index.htm 文件(由 index 指定) ( try_files $uri/) 最后：检查 /opt/html/images/ 目录中是否存在 index.html 文件。如果存在，则返回文件；如果不存在，则返回 404。  其他注意事项\n​\ttry-files 如果不写上 $uri/，当直接访问一个目录路径时， 并不会去匹配目录下的索引页 即 访问\n127.0.0.1/images/ 不会去访问 127.0.0.1/images/index.html\nserver {\rlisten 81;\rserver_name test.net;\rlocation / {\r# 设置静态根目录\rroot /data/test/test-vue;\r#如果文件没找到 ，尝试到以下目录中查找， #浏览器访问 http://api.xxx.com/abc/login 时，当前的$uri值为/abc/login try_files $uri $uri/ @router; # 设置目录的默认文件为 index.html 、index.htm\rindex index.html index.htm;\r}\rlocation /dev {\ralias /data/test/test-vue-dev;\r#如果文件没找到 ，尝试到以下目录中查找，\r#浏览器访问 http://api.xxx.com/dev/login 时，当前的$uri值为/dev/login try_files $uri $uri/ /dev/index.html;\rindex index.html index.htm;\r}\rlocation /test {\rproxy_pass http://test.net:81/;\r}\rlocation /rc {\ralias /data/test/test-vue-rc;\r#如果文件没找到 ，尝试到以下目录中查找，\rtry_files $uri $uri/ /rc/index.html;\rindex index.html index.htm;\r}\r# 接口路由，直接转发至 网关， 再有网关转发至 具体微服务 location /dev/api/ {\rproxy_set_header Host $http_host;\rproxy_set_header X-Real-IP $remote_addr;\rproxy_set_header REMOTE-HOST $remote_addr;\rproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\rproxy_pass http://192.168.1.168:8000/;\r}\rlocation /test/api/ {\rproxy_set_header Host $http_host;\rproxy_set_header X-Real-IP $remote_addr;\rproxy_set_header REMOTE-HOST $remote_addr;\rproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\rproxy_pass http://gateway/;\r}\rlocation /rc/api/ {\rproxy_set_header Host $http_host;\rproxy_set_header X-Real-IP $remote_addr;\rproxy_set_header REMOTE-HOST $remote_addr;\rproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\rproxy_pass http://192.168.1.169:8000/;\r}\rlocation = /50x.html {\rroot html;\r}\rlocation @router {\rrewrite ^.*$ /index.html last;\r}\r# 记录访问日志\raccess_log /usr/local/nginx/logs/access.log access;\r}\r ","id":23,"section":"posts","summary":"配置时注意 root 与 alias 配置的区别 第一种 root location /images/ { root /opt/html/; index index.html index.htm; try_files $uri $uri/ /images/default.png; } 比如 请求 127.0.0.1/images/test.gif 会依次查找 文件 /opt/html/images/test.gif ( try_files $uri) 检查文件夹 /opt/html/images/test.gif/ 下是否存在index.html 或者 index.htm","tags":["nginx"],"title":"Nginx之try_files指令","uri":"https://bluestaree.github.io/2022/04/nginx-%E8%BD%AC%E5%8F%91try_files%E6%8C%87%E4%BB%A4/","year":"2022"},{"content":" Nginx 转发后 获取客户端真实ip地址 ​\t通过 proxy_set_header 设置自定义参数 X-Real-IP，将客户端IP传递给服务器，服务端通过request.getHeader(\u0026ldquo;X-Real-IP\u0026rdquo;) 获取\nserver {\rlisten 81;\rserver_name test.net;\rlocation /dev/api/ {\rproxy_set_header Host $http_host;\rproxy_set_header X-Real-IP $remote_addr;\rproxy_set_header REMOTE-HOST $remote_addr;\rproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\rproxy_pass http://192.168.1.168:8000/;\r}\rlocation /test/api/ {\rproxy_set_header Host $http_host;\rproxy_set_header X-Real-IP $remote_addr;\rproxy_set_header REMOTE-HOST $remote_addr;\rproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\rproxy_pass http://192.168.1.167:8000/;\r}\rlocation /rc/api/ {\rproxy_set_header Host $http_host;\rproxy_set_header X-Real-IP $remote_addr;\rproxy_set_header REMOTE-HOST $remote_addr;\rproxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\rproxy_pass http://192.168.1.169:8000/;\r}\rlocation @router {\rrewrite ^.*$ /index.html last;\r}\rlocation = /50x.html {\rroot html;\r}\raccess_log /usr/local/nginx/logs/access.log access;\r}\r ","id":24,"section":"posts","summary":"Nginx 转发后 获取客户端真实ip地址 ​ 通过 proxy_set_header 设置自定义参数 X-Real-IP，将客户端IP传递给服务器，服务端通过request.getHeade","tags":["nginx"],"title":"Nginx 转发后 获取客户端真实ip地址","uri":"https://bluestaree.github.io/2022/04/nginx-%E8%BD%AC%E5%8F%91%E5%90%8E-%E8%8E%B7%E5%8F%96%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9C%9F%E5%AE%9Eip%E5%9C%B0%E5%9D%80/","year":"2022"},{"content":"  参考文章：HttpSecurity常用方法详解 ，并补充一些个人见解\n antMatcher() 该方法配置题解原理可参考文章：WebSecurityConfigurerAdapter与ResourceServerConfigurerAdapter使用\n这里用一个官方的例子，记一下个人理解\n@EnableWebSecurity\rpublic class MultiHttpSecurityConfig {\r@Autowired\rpublic void configureGlobal(AuthenticationManagerBuilder auth) { 1\r// 配置默认登录用户信息，一般用不上\rauth\r.inMemoryAuthentication()\r.withUser(\u0026quot;user\u0026quot;).password(\u0026quot;password\u0026quot;).roles(\u0026quot;USER\u0026quot;).and()\r.withUser(\u0026quot;admin\u0026quot;).password(\u0026quot;password\u0026quot;).roles(\u0026quot;USER\u0026quot;, \u0026quot;ADMIN\u0026quot;);\r}\r// 注意，下面配置的两个类 都实现了 WebSecurityConfigurerAdapter\r// 这种情况下有两个HttpSecurity配置，未定义@Order就默认最后，多个未定义或者相同Order就按照定义顺序\r@Configuration\r@Order(1) 2\rpublic static class ApiWebSecurityConfigurationAdapter extends WebSecurityConfigurerAdapter {\rprotected void configure(HttpSecurity http) throws Exception {\r//.antMatcher(\u0026quot;/api/**\u0026quot;) 表示此HttpSecurity配置 只会在匹配/api/开头的请求时生效，而且匹配优先度高，如果不用antMatcher，所有请求都会匹配\r// 进入的请求只有两条路，拥有角色权限ADMIN 的User。\r// 或者导向login(authenticated)，但这里未开启，需要时可以加上.formLogin()配置\rhttp\r.antMatcher(\u0026quot;/api/**\u0026quot;) 3\r.authorizeRequests()\r.anyRequest().hasRole(\u0026quot;ADMIN\u0026quot;)\r.and()\r.httpBasic();\r}\r} @Configuration 4\rpublic static class FormLoginWebSecurityConfigurerAdapter extends WebSecurityConfigurerAdapter {\r@Override\rprotected void configure(HttpSecurity http) throws Exception {\r// 没有配置.antMatcher(\u0026quot;/xxx\u0026quot;), 表示所有请求都会经过该配置\r// 接下来，所有请求需求登录认证\r// 又因为该配置order默认值为100 比上面一个配置要低， 所以该过滤器优先级较低， 如果请求/api/** 就会被上面一个拦截器处理\rhttp\r.authorizeRequests()\r.anyRequest().authenticated()\r.and()\r.formLogin();\r}\r}\r}\r 其中需要注意 如果配置多个HttpSecurity规则，需求考虑到order顺序\n antMatchers() 为方便理解直接看两个例子把：\n例子1：\nhttp\r.antMatcher(\u0026quot;/xxx\u0026quot;)\r.authorizeRequests()\r.anyRequest()\r.authenticated();\r 例子2：\nhttp\r.requestMatchers()\r.antMatchers(\u0026quot;/xxx\u0026quot;)\r.and()\r.authorizeRequests()\r.anyRequest()\r.authenticated();\r ​\t上述两个例子实现的效果是一样的，区别在于 .requestMatchers().antMatchers()，可以配置多个生效入口 如 ： .requestMatchers().antMatchers(\u0026quot;/aaa\u0026rdquo;,\u0026quot;/xxx\u0026rdquo;)\n​\t注意 在同一个HttpSecurity实例上两次调用antMatcher()只会替换原始的antMatcher()。要将相同的HttpSecurity配置应用于多个antMatchers，需使用http.requestMatchers().antMatchers(\u0026quot;/aaa\u0026rdquo;,\u0026quot;/xxx\u0026rdquo;)。\n另一种方法是使用各自的antMatcher创建多个SecurityConfigurer，然后使用@order对其进行批注，以确保spring可以全部加载(参考文章头部 官方演示例子)。\nrequestMatchers() 取得RequestMatcherConfigurer对象并配置允许过滤的路由； 如requestMatchers().anyRequest()等同于http.authorizeRequests().anyRequest().access(“permitAll”)； 如下面两个例子：\n例1:\n@Override\rpublic void configure(HttpSecurity http) throws Exception {\t//requestMatchers().anyRequest()即表示该配置拦截所有接口请求（/**），并且只允许路由test开头的需要进行权限认证，其他的接口不需要权限认证；\thttp.requestMatchers().anyRequest().and().authorizeRequests().antMatchers(\u0026quot;/test/*\u0026quot;).authenticated();\r}\r 例2:\n@Override\rpublic void configure(HttpSecurity http) throws Exception {\r//只有以/test 开头的路由需要进行权限认证；其他路由不需要权限认证\rhttp.requestMatchers().antMatchers(\u0026quot;/test/**\u0026quot;).and().authorizeRequests().antMatchers(\u0026quot;/**\u0026quot;).authenticated();\r}\r 例3:\n// 存在两个.requestMatchers()相当于 配置两个URL匹配规则入口\rhttp\r// 1、以下对所有/rest2/**请求生效\r.requestMatchers()\r.antMatchers(\u0026quot;/rest2/**\u0026quot;)\r.and()\r// 请求的路径 通过/rest2/** 校验后，配置两个特殊路由处理 /rest/v1/test/hello以及/rest/v1/test/**，\r// 不过很明显，此处分叉规则均不会生效，因为入口前提是，请求的路径匹配/rest2/**\r// 当请求路径没有被规则匹配到时，默认放行，不需要权限认证，即.permitAll()\r.authorizeRequests()\r.antMatchers(\u0026quot;/rest/v1/test/hello\u0026quot;).permitAll()\r.antMatchers(\u0026quot;/rest/v1/test/**\u0026quot;).denyAll()\r.and()\r// ----上述配置结束----\r// 2、以下对所有/rest/**请求生效\r.requestMatchers()\r.antMatchers(\u0026quot;/rest/**\u0026quot;)\r.and()\r.authorizeRequests()\r.antMatchers(\u0026quot;/rest/v1/test/hello\u0026quot;).permitAll();\r// ----上述配置结束----\r 上述例子中配置1 的结果就相当于 所有 /rest2/** 接口请求 全部放行\n配置2的结果就相当于 所有 /rest/** 接口请求 全部放行\nauthorizeRequests() 授权管理控制的方法（），这个方法返回一个ExpressionUrlAuthorizationConfigurer.ExpressionInterceptUrlRegistry对象。Security所有的权限控制都基于这个类进行控制。 如：http.authorizeRequests().anyRequest().authenticated();要求所有接口都需要进行权限认证，这个类中的anyRequest()即所有接口， 等同于 http.authorizeRequests().antMatchers(\u0026quot;/\u0026quot;).authenticated() ;\n//所有接口都不需要权限认证\rhttp.authorizeRequests().antMatchers(\u0026quot;/**\u0026quot;).permitAll();\r//所有接口都不需要进行权限认证\rhttp.authorizeRequests().antMatchers(\u0026quot;/**\u0026quot;).authenticated();\r//只有以test开头的接口需要进行权限认证\rhttp.authorizeRequests().antMatchers(\u0026quot;/test/**\u0026quot;).authenticated();\r http.authorizeRequests().antMatchers(\u0026quot;/test/\u0026quot;).hasRole(“user”).antMatchers(\u0026quot;/\u0026quot;).authenticated();在这个代码中要求以/test开头的路由需要进行角色认证（这里要求user角色），而其他接口只要登录即可访问。当我们需要配置多个角色时可以通过hasAnyRole方法配置多个角色的访问权限，如\n// 在这个代码中要求以/test开头的路由需要进行角色认证（这里要求user角色），而其他接口只要登录即可访问\rhttp.authorizeRequests().antMatchers(\u0026quot;/test/**\u0026quot;).hasAnyRole(\u0026quot;user\u0026quot;,\u0026quot;admin\u0026quot;).antMatchers(\u0026quot;/**\u0026quot;).authenticated();\r 匹配规则 URL匹配  requestMatchers() 配置一个request Mather数组，参数为RequestMatcher 对象，其match 规则自定义,需要的时候放在最前面，对需要匹配的的规则进行自定义与过滤 authorizeRequests() URL权限配置 antMatchers() 配置一个request Mather 的 string数组，参数为 ant 路径格式， 直接匹配url anyRequest 匹配任意url，无参 ,最好放在最后面  保护URL  authenticated() 保护UrL，需要用户登录 permitAll() 指定URL无需保护，一般应用与静态资源文件 hasRole(String role) 限制单个角色访问，角色将被增加 “ROLE_” .所以”ADMIN” 将和 “ROLE_ADMIN”进行比较. 另一个方法是hasAuthority(String authority) hasAnyRole(String… roles) 允许多个角色访问. 另一个方法是hasAnyAuthority(String… authorities) access(String attribute) 该方法使用 SPEL, 所以可以创建复杂的限制 例如如access(“permitAll”), access(“hasRole(‘ADMIN’) and hasIpAddress(‘123.123.123.123’)”) hasIpAddress(String ipaddressExpression) 限制IP地址或子网  登录login  formLogin() 基于表单登录 loginPage() 登录页 defaultSuccessUrl 登录成功后的默认处理页 failuerHandler登录失败之后的处理器 successHandler登录成功之后的处理器 failuerUrl登录失败之后系统转向的url，默认是this.loginPage + “?error”  登出logout  logoutUrl 登出url ， 默认是/logout， 它可以是一个ant path url logoutSuccessUrl 登出成功后跳转的 url 默认是\u0026rdquo;/login?logout\u0026rdquo; logoutSuccessHandler 登出成功处理器，设置后会把logoutSuccessUrl 置为null  多个antMatchers顺序配置 ","id":25,"section":"posts","summary":"参考文章：HttpSecurity常用方法详解 ，并补充一些个人见解 antMatcher() 该方法配置题解原理可参考文章：WebSecurityConfigurer","tags":["spring-security"],"title":"Security之HttpSecurity常用方法详解","uri":"https://bluestaree.github.io/2022/03/security%E4%B9%8Bhttpsecurity%E5%B8%B8%E7%94%A8%E6%96%B9%E6%B3%95%E8%AF%A6%E8%A7%A3/","year":"2022"},{"content":" Security资源服务白名单过滤器 问题 最近在项目中，引入了security认证框架，由于我们项目的认证服务与资源服务是分开的，因此在资源服务中，配置文件如下\n@Configuration\r// 开启资源服务认证\r@EnableResourceServer\rpublic class ResourceServerConfig extends ResourceServerConfigurerAdapter {\r@Autowired\rTokenStore tokenStore;\r@Autowired\rprivate Oauth2AuthConfig oauth2AuthConfig;\r@Bean\rpublic JwtAuthenticationTokenFilter jwtAuthenticationTokenFilter() {\r// 自定义token解析认证过滤器 --- 位置在UsernamePasswordAuthenticationFilter 之前\rreturn new JwtAuthenticationTokenFilter();\r}\r/**\r* 在此注入PasswordEncoder，方便在其他配置中自动注入\r* Spring Security内部实现好的 BCryptPasswordEncoder。\r* BCryptPasswordEncoder的特点就是，对于一个相同的密码，每次加密出来的加密串都不同\r*/\r@Bean\rpublic PasswordEncoder passwordEncoder() {\rreturn new BCryptPasswordEncoder();\r}\r@Override\rpublic void configure(ResourceServerSecurityConfigurer resources) throws Exception {\r// 资源服务配置\rresources.resourceId(oauth2AuthConfig.getClientId()).tokenStore(tokenStore)\r// 自定义匿名用户访问无权限资源时异常处理\r.authenticationEntryPoint(new MyAuthExceptionEntryPoint())\r// 自定义发已认证用户访问无权限资源时异常处理\r.accessDeniedHandler(new MyAccessDeniedHandler());\r}\r@Override\rpublic void configure(HttpSecurity http) throws Exception {\rhttp.authorizeRequests()\r// 登录接口放行\r.antMatchers(\u0026quot;/*/userLogin/**\u0026quot;).permitAll()\r// 其他接口需携带token认证\r.anyRequest().authenticated()\r.and()\r.csrf().disable();\r// 在UsernamePasswordAuthenticationFilter之前添加自定义过滤器，用于互踢规则校验\rhttp.addFilterBefore(jwtAuthenticationTokenFilter(),UsernamePasswordAuthenticationFilter.class);\r}\r 但在进行测试时，发现一个问题，登录页面还是会进行拦截认证，经过排查，是因为前端传了错误的令牌信息，如下:\npostman模拟前端请求:\n后台错误信息：\n​\t在不携带异常 Authorization 请求头时 能够正常访问接口，说明配置 .antMatchers(\u0026quot;/*/userLogin/**\u0026quot;).permitAll() 没问题\n​\t可以看到 虽然我在 资源服务配置文件 ： ResourceServerConfig 中 将 /*/userLogin/** 下所有请求放行，但在请求时 携带 Authorization 请求头，该请求还是会被security 拦截并进行认证。\n​\t这与我所期望的效果不同，那么有什么方法能够解决呢\n解决方案 1、通过 WebSecurityConfigurerAdapter 进行配置\nURL强制拦截保护服务，可以配置哪些路径不需要保护，哪些需要保护。默认全都保护\n在该配置文件中放行的请求 ，无论是否携带 Authorization 请求头 ，都不会进行认证\n缺点： WebSecurityConfigurerAdapter 和 ResourceServerConfigurerAdapter 同时配置时 存在 配置\n覆盖情况。一般WebSecurityConfigurerAdapter的配置的拦截要优先于ResourceServerConfigurerAdapter\n2、自定义白名单认证过滤器， 要求 在认证 security 过滤器 OAuth2AuthenticationProcessingFilter 之前, ，这个过滤器的主要做用就是，去除header中的Authorization Bearer xxxx ,防止security后续再次认证，\n相关代码如下；\n添加PermitAuthenticationFilter类拦截指定请求，清空header中的Authorization Bearer xxxx\n@Component(\u0026quot;permitAuthenticationFilter\u0026quot;)\r@Slf4j\rpublic class PermitAuthenticationFilter extends OncePerRequestFilter {\r@Override\rprotected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain) throws ServletException, IOException {\rlog.info(\u0026quot;当前访问的地址:{}\u0026quot;, request.getRequestURI());\rRequestMatcher matcher = new AntPathRequestMatcher(\u0026quot;/*/userLogin/**\u0026quot;, HttpMethod.POST.toString());\rboolean matches = matcher.matches(request);\rif (matches) {\rrequest = new HttpServletRequestWrapper(request) {\rprivate Set\u0026lt;String\u0026gt; headerNameSet;\r@Override\rpublic Enumeration\u0026lt;String\u0026gt; getHeaderNames() {\rif (headerNameSet == null) {\rheaderNameSet = new HashSet\u0026lt;\u0026gt;();\rEnumeration\u0026lt;String\u0026gt; wrappedHeaderNames = super.getHeaderNames();\rwhile (wrappedHeaderNames.hasMoreElements()) {\rString headerName = wrappedHeaderNames.nextElement();\rif (!\u0026quot;Authorization\u0026quot;.equalsIgnoreCase(headerName)) {\rheaderNameSet.add(headerName);\r}\r}\r}\rreturn Collections.enumeration(headerNameSet);\r}\r@Override\rpublic Enumeration\u0026lt;String\u0026gt; getHeaders(String name) {\rif (\u0026quot;Authorization\u0026quot;.equalsIgnoreCase(name)) {\rreturn Collections.\u0026lt;String\u0026gt;emptyEnumeration();\r}\rreturn super.getHeaders(name);\r}\r@Override\rpublic String getHeader(String name) {\rif (\u0026quot;Authorization\u0026quot;.equalsIgnoreCase(name)) {\rreturn null;\r}\rreturn super.getHeader(name);\r}\r};\r}\rfilterChain.doFilter(request, response);\r}\r}\r 配置文件\n@Component(\u0026quot;permitAllSecurityConfig\u0026quot;)\rpublic class PermitAllSecurityConfig extends SecurityConfigurerAdapter\u0026lt;DefaultSecurityFilterChain, HttpSecurity\u0026gt; {\r@Autowired\rprivate Filter permitAuthenticationFilter;\r@Override\rpublic void configure(HttpSecurity http) throws Exception {\rhttp.addFilterBefore(permitAuthenticationFilter, OAuth2AuthenticationProcessingFilter.class);\r}\r}\r 修改ResourceServerConfig 认证配置\n@Override\rpublic void configure(HttpSecurity http) throws Exception {\rhttp\r// 应用配置文件\r.apply(permitAllSecurityConfig)\r.and()\r.authorizeRequests()\r// 登录接口放行\r.antMatchers(\u0026quot;/*/userLogin/**\u0026quot;).permitAll()\r// 其他接口需携带token认证\r.anyRequest().authenticated()\r.and()\r.csrf().disable();\rhttp.addFilterBefore(jwtAuthenticationTokenFilter(), UsernamePasswordAuthenticationFilter.class);\r}\r 参考文章： Spring Security permitAll开放页面权限 解除token验证的问题 \n","id":26,"section":"posts","summary":"Security资源服务白名单过滤器 问题 最近在项目中，引入了security认证框架，由于我们项目的认证服务与资源服务是分开的，因此在资源服","tags":["spring-security"],"title":"Security资源服务白名单过滤器","uri":"https://bluestaree.github.io/2022/03/security%E8%B5%84%E6%BA%90%E6%9C%8D%E5%8A%A1%E7%99%BD%E5%90%8D%E5%8D%95%E8%BF%87%E6%BB%A4%E5%99%A8/","year":"2022"},{"content":"  转：原文链接 https://blog.csdn.net/qq_44131750/article/details/115775159\n Session、Cookie 登陆认证 就是认证是否为合法用户，简单的说是登录。一般为匹对用户名和密码，即认证成功。\n在 Spring Security 认证中，只要解决如下几个问题：\n 哪个类表示用户？ 哪个属性表示用户名？ 哪个属性表示密码？ 怎么通过用户名取到对应的用户？ 密码的验证方式是什么？  所有的自定义行为都是围绕这几个问题展开的\n认证的执行流程就是\n 它会拿到用户输入的用户名密码； 根据用户名通过 UserDetailsService 的 loadUserByUsername(username) 方法获得一个用户对象； 获得一个 UserDetails 对象，获得内部的成员属性 password； 通过 PasswordEncoder 的 matchs(s1, s2) 方法对比用户的输入的密码和第3步的密码； 匹配成功；  获取用户名和密码 Spring Boot 整合 Spring Security（前后端分离时的json登录方式，解决获取不到用户名密码问题） springboot+security整合2\n默认的账户名和密码的参数名分别是 username、password 可以自定义账户和密码的参数名\nhttp\r.formLogin()\r.usernameParameter(\u0026quot;my_username\u0026quot;)\r.passwordParameter(\u0026quot;my_password\u0026quot;)\r 如果是自己验证用户名密码的话，Spring Security 仅仅支持传统的 form 表单方式（form-data）登录。这是一个比较大的坑点。现在都流行使用前后端分离，前端发送的是 json 格式数据。所以需要自己定制 UsernamePasswordAuthenticationFilter 这个类\n获取用户名密码是在 UsernamePasswordAuthenticationFilter 这个类里面的 attemptAuthentication 方法，如下\npublic Authentication attemptAuthentication(HttpServletRequest request,\rHttpServletResponse response) throws AuthenticationException {\rif (postOnly \u0026amp;\u0026amp; !request.getMethod().equals(\u0026quot;POST\u0026quot;)) {\rthrow new AuthenticationServiceException(\r\u0026quot;Authentication method not supported: \u0026quot; + request.getMethod());\r}\rString username = obtainUsername(request);\rString password = obtainPassword(request);\rif (username == null) {\rusername = \u0026quot;\u0026quot;;\r}\rif (password == null) {\rpassword = \u0026quot;\u0026quot;;\r}\rusername = username.trim();\rUsernamePasswordAuthenticationToken authRequest = new UsernamePasswordAuthenticationToken(\rusername, password);\r// Allow subclasses to set the \u0026quot;details\u0026quot; property\rsetDetails(request, authRequest);\rreturn this.getAuthenticationManager().authenticate(authRequest);\r}\r 再进一步可以看到获取用户名密码的方法\n// 这个 passwordParameter 为 password\r// 同理 usernameParameter 为 username\rprotected String obtainPassword(HttpServletRequest request) {\rreturn request.getParameter(passwordParameter);\r}\r 所以如果要从 JSON 里取得密码和用户名，需要继承这个 UsernamePasswordAuthenticationFilter 类，重写 attemptAuthentication 方法（例如添加验证码之类的操作也是在这里入手）\n例如这里增加一个验证码操作\npublic class MyUsernamePasswordAuthentication extends UsernamePasswordAuthenticationFilter{\rprivate Logger log = LoggerFactory.getLogger(this.getClass());\r@Override\rpublic Authentication attemptAuthentication(HttpServletRequest request, HttpServletResponse response)\rthrows AuthenticationException {\r//我们可以在这里进行额外的验证，如果验证失败抛出继承AuthenticationException的自定义错误。\rlog.info(\u0026quot;在这里进行验证码判断\u0026quot;);\r//只要最终的验证是账号密码形式就无需修改后续过程\rreturn super.attemptAuthentication(request, response);\r}\r@Override\rpublic void setAuthenticationManager(AuthenticationManager authenticationManager) {\r// TODO Auto-generated method stub\rsuper.setAuthenticationManager(authenticationManager);\r}\r}\r 将自定义登录配置到 Security 中\n@Override\rprotected void configure(HttpSecurity http) throws Exception {\rhttp\r.csrf() // 跨站\r.disable() // 关闭跨站检测\r// 自定义鉴权过程，无需下面设置\r// 验证策略\r.authorizeRequests()\r// 无需验证路径\r.antMatchers(\u0026quot;/public/**\u0026quot;).permitAll()\r.antMatchers(\u0026quot;/user/**\u0026quot;).permitAll()\r// 放行登录\r.antMatchers(\u0026quot;/login\u0026quot;).permitAll()\r.antMatchers(HttpMethod.GET, \u0026quot;/user\u0026quot;).hasAuthority(\u0026quot;getAllUser\u0026quot;) // 拥有权限才可访问\r// 拥有任一权限即可访问\r.antMatchers(HttpMethod.GET, \u0026quot;/user\u0026quot;).hasAnyAuthority(\u0026quot;1\u0026quot;,\u0026quot;2\u0026quot;)\r// 角色类似，hasRole(),hasAnyRole()\r.anyRequest().authenticated()\r.and()\r// 自定义异常处理\r.exceptionHandling()\r.authenticationEntryPoint(myAuthenticationEntryPoint) // 未登录处理\r.accessDeniedHandler(myAccessDeniedHandler)//权限不足处理\r.and()\r// 加入自定义登录校验\r.addFilterBefore(myUsernamePasswordAuthentication(),UsernamePasswordAuthenticationFilter.class)\r// 默认放在内存中\r.rememberMe()\r.rememberMeServices(rememberMeServices())\r.key(\u0026quot;INTERNAL_SECRET_KEY\u0026quot;)\r// 重写 usernamepasswordauthenticationFilter 后，下面的formLogin()设置将失效，需要手动设置到个性化过滤器中\r// .and()\r// .formLogin()\r// .loginPage(\u0026quot;/public/unlogin\u0026quot;) //未登录跳转页面,设置了authenticationentrypoint后无需设置未登录跳转面\r// .loginProcessingUrl(\u0026quot;/public/login\u0026quot;)//登录api\r// .successForwardUrl(\u0026quot;/success\u0026quot;)\r// .failureForwardUrl(\u0026quot;/failed\u0026quot;)\r// .usernameParameter(\u0026quot;id\u0026quot;)\r// .passwordParameter(\u0026quot;password\u0026quot;)\r// .failureHandler(myAuthFailedHandle) //登录失败处理\r// .successHandler(myAuthSuccessHandle)//登录成功处理\r// .usernameParameter(\u0026quot;id\u0026quot;)\r.and()\r.logout()//自定义登出\r.logoutUrl(\u0026quot;/public/logout\u0026quot;)\r.logoutSuccessUrl(\u0026quot;public/logoutSuccess\u0026quot;)\r.logoutSuccessHandler(myLogoutSuccessHandle);\r}\r// 然后再编写Bean，代码如下：\r@Bean\rpublic MyUsernamePasswordAuthentication myUsernamePasswordAuthentication(){\rMyUsernamePasswordAuthentication myUsernamePasswordAuthentication = new MyUsernamePasswordAuthentication();\rmyUsernamePasswordAuthentication.setAuthenticationFailureHandler(myAuthFailedHandle); //设置登录失败处理类\rmyUsernamePasswordAuthentication.setAuthenticationSuccessHandler(myAuthSuccessHandle);//设置登录成功处理类\rmyUsernamePasswordAuthentication.setFilterProcessesUrl(\u0026quot;/public/login\u0026quot;);\rmyUsernamePasswordAuthentication.setRememberMeServices(rememberMeServices()); //设置记住我\rmyUsernamePasswordAuthentication.setUsernameParameter(\u0026quot;id\u0026quot;);\rmyUsernamePasswordAuthentication.setPasswordParameter(\u0026quot;password\u0026quot;);\rreturn myUsernamePasswordAuthentication;\r}\r UserDetails 参考资料 Spring Security自定义用户认证\n这个接口就是下面的 UserDetailsService 的返回值，虽然 Spring Security 自带的实现类 org.springframework.security.core.userdetails.User 已经够强大了，但是还有有必要去了解这个接口，以便后续自定义\n该对象也是一个接口，包含一些用于描述用户信息的方法，源码如下：\npublic interface UserDetails extends Serializable {\rCollection\u0026lt;? extends GrantedAuthority\u0026gt; getAuthorities();\rString getPassword();\rString getUsername();\rboolean isAccountNonExpired();\rboolean isAccountNonLocked();\rboolean isCredentialsNonExpired();\rboolean isEnabled();\r}\r  getAuthorities 获取用户包含的权限，返回权限集合，权限是一个继承了 GrantedAuthority 的对象； getPassword 和 getUsername 用于获取密码和用户名； isAccountNonExpired 方法返回 boolean 类型，用于判断账户是否未过期，未过期返回 true 反之返回 false； isAccountNonLocked 方法用于判断账户是否未锁定； isCredentialsNonExpired 用于判断用户凭证是否没过期，即密码是否未过期； isEnabled 方法用于判断用户是否可用。  UserDetailsService 怎么通过用户名取到对应的用户？\n只需要去实现这个 UserDetailsService 接口，里面有个 loadUserByUsername 方法就是用来找到用户的\npublic interface UserDetailsService {\rUserDetails loadUserByUsername(String username) throws UsernameNotFoundException;\r}\r 在这个 loadUserByUsername(String username) 里面实现登陆逻辑，如果未找到用户可以抛出一个 UsernameNotFoundException 异常，返回值是一个 UserDetails 接口的实现类，默认会使用 Spring Security 定义的 User 类\n实现 UserDetailsService 接口例\n@Service\rpublic class UserDetailServiceImpl implements UserDetailsService {\r// 懒得连接数据库，这里直接使用 Map 替代\rprivate static final Map\u0026lt;String, String\u0026gt; dates;\rstatic {\rdates = new HashMap\u0026lt;\u0026gt;();\r// username, password\rdates.put(\u0026quot;admin\u0026quot;, \u0026quot;admin\u0026quot;);\r}\r@Autowired\rprivate PasswordEncoder passwordEncoder;\r@Override\rpublic UserDetails loadUserByUsername(String username) throws UsernameNotFoundException {\rString rawPassword = dates.get(username);\r// 这里模拟去数据库查询\rif (rawPassword == null) {\rthrow new UsernameNotFoundException(\u0026quot;用户名不存在\u0026quot;);\r}\r// 匹配成功则用其生成加密后的密文传入 UserDetails\rString password = passwordEncoder.encode(rawPassword);\r// 这个 commaSeparatedStringToAuthorityList 就是把输入的字符串根据逗号分割成 List\u0026lt;GrantedAuthority\u0026gt;\rreturn new User(username, password, AuthorityUtils\r.commaSeparatedStringToAuthorityList(\u0026quot;admin,normal\u0026quot;));\r}\r}\r 这里 User 对象返回值的第三个参数实际上就是权限列表 Collection\u0026lt;? extends GrantedAuthority\u0026gt; authorities\n这里通过 AuthorityUtils.commaSeparatedStringToAuthorityList() 这个工具类将权限转换成 GrantedAuthority 集合（使用 , 分割不同权限）\n比对权限是否存在的方式\n@Override\rpublic boolean hasPermission(HttpServletRequest request, Authentication authentication) {\r// 获取主体\rObject principal = authentication.getPrincipal();\rlog.info(request.getRequestURI());\r// 判断主体是否属于 UserDetails\rif (principal instanceof UserDetails) {\rUserDetails userDetails = (UserDetails) principal;\r// 获取权限列表\rCollection\u0026lt;? extends GrantedAuthority\u0026gt; authorities = userDetails.getAuthorities();\r// 判断请求的 URI 是否在权限里\rreturn authorities.contains(new SimpleGrantedAuthority(request.getRequestURI()));\r}\rreturn false;\r}\r PasswordEncoder loadUserByUsername 这个方法可以看到只有一个 username 参数，那密码在哪里比较呢？ 密码的比较使用的是 PasswordEncoder；它也是一个接口\npublic interface PasswordEncoder {\r// 加密密码\rString encode(CharSequence rawPassword);\r// 对密码进行比对\rboolean matches(CharSequence rawPassword, String encodedPassword);\r// 对已经加密的密码再次加密\rdefault boolean upgradeEncoding(String encodedPassword) {\rreturn false;\r}\r}\r 不过一般使用自带的实现类 BCryptPasswordEncoder 使用例\n@Test\rvoid testPasswordEncoder() {\rPasswordEncoder pw = new BCryptPasswordEncoder();\r// 加密密码\r// 注意 这个 BCrypt加密算法每次加密得到的密文都是不一样的，所以就算是一样的密码两次加密都不会相同\rString encode = pw.encode(\u0026quot;12345678\u0026quot;);\rlog.info(encode);\r// 比对密码\rboolean matches = pw.matches(\u0026quot;12345678\u0026quot;, encode);\rlog.info(String.valueOf(matches));\r}\r/** 输出如下\r* $2a$10$28sxxWLV85qKIIGK4mR9YuM/JjBGotUnaX8WROHjDV1IcLsmXIhOG\r* true\r*/\r 登陆成功处理器 就是去实现 AuthenticationSuccessHandler 接口\npublic class MyAuthenticationSuccessHandler implements AuthenticationSuccessHandler {\r@Override\rpublic void onAuthenticationSuccess(HttpServletRequest request, HttpServletResponse response, Authentication authentication) throws IOException, ServletException {\rRespBean ok = RespBean.ok(\u0026quot;登录成功！\u0026quot;, authentication.getPrincipal());\rresponse.setContentType(\u0026quot;application/json;charset=utf-8\u0026quot;);\rPrintWriter out = response.getWriter();\rout.write(new ObjectMapper().writeValueAsString(ok));\rout.flush();\rout.close();\r}\r}\r 然后再在配置里使用自定义的处理器就行了\nhttp\r...\r.successHandler(new MyAuthenticationSuccessHandler())\r 登陆失败处理器 去实现 AuthenticationFailureHandler 接口\npublic class MyAuthenticationFailureHandler implements AuthenticationFailureHandler {\r@Override\rpublic void onAuthenticationFailure(HttpServletRequest request, HttpServletResponse response, AuthenticationException exception) throws IOException, ServletException {\rRespBean error = RespBean.error(\u0026quot;登录失败\u0026quot;);\rresponse.setContentType(\u0026quot;application/json;charset=utf-8\u0026quot;);\rPrintWriter out = response.getWriter();\rout.write(new ObjectMapper().writeValueAsString(error));\rout.flush();\rout.close();\r}\r}\r 然后再在配置里使用自定义的处理器\nhttp\r...\r.failureHandler(new MyAuthenticationFailureHandler())\r 自定义 403 处理 去实现 AccessDeniedHandler 接口\npublic class MyAccessDeniedHandler implements AccessDeniedHandler {\r@Override\rpublic void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException, ServletException {\rRespBean error = RespBean.error(\u0026quot;权限不足，访问失败\u0026quot;);\rresponse.setStatus(403);\rresponse.setContentType(\u0026quot;application/json;charset=utf-8\u0026quot;);\rPrintWriter out = response.getWriter();\rout.write(new ObjectMapper().writeValueAsString(error));\rout.flush();\rout.close();\r}\r}\r 除了上面那种高度自定义的写法还可以像这样直接调用方法\n@Override\rpublic void handle(HttpServletRequest request, HttpServletResponse response, AccessDeniedException accessDeniedException) throws IOException {\rresponse.sendError(403, \u0026quot;权限不足，访问失败\u0026quot;);\r}\r 注册这个 Handle\nhttp\r.exceptionHandling()\r// 这个 Http403ForbiddenEntryPoint 是自带的实现类\r.authenticationEntryPoint(new Http403ForbiddenEntryPoint()) // 未登陆的请求处理\r.accessDeniedHandler(new MyAccessDeniedHandler()) // 未授权的请求处理\r 如何判断用户状态的？ 用户登陆后 Spring Security 是怎么知道用户已经登陆过了呢？答案就是 Cookie 和 Session，用户登陆后服务端会返回一个 Cookie\nJSESSIONID=41AEFF280BB9BF67CC23E9B9C740B075;\r 因为每次请求都会带上 Cookie，所以 Spring Security 能基于此完成对用户权限的鉴别\n 注意：如果使用的是 Ajax 跨域请求，需要配置一下，否则默认是不携带 Cookie 的\n 这里只讲 axios 的设置，后端的设置参看跨域请求那一篇文章\n// 因为默认 Spring Security 是通过 Cookie 和 Session 来验证身份的，所以需要配置携带 Cookie\raxios.interceptors.request.use(config =\u0026gt; {\rconfig.withCredentials = true;\rreturn config;\r});\r 自定义登陆页 默认 Spring Security 有一个自带的登陆界面，其账户名是 user 密码会在控制台打印出来，用户访问 /login 路径会跳转到这个登陆页，虽然集成了登陆页挺好的，但是一般都是需要各种客制化，所以还是需要掌握如何自定义登陆\n前端分离登陆 参考资料 Spring Security登录使用JSON格式数据 参考资料 spring security简单教程以及实现完全前后端分离\n现在大部分前后端分离的 Web 程序，尤其是前端普遍使用 Ajax 请求时，Spring Security 自带的登录系统就有一些不满足需求了。\n因为 Spring Security 有自己默认的登录页，自己默认的登录控制器。而登录成功或失败，都会返回一个 302 跳转。登录成功跳转到主页，失败跳转到登录页。如果未认证直接访问也会跳转到登录页。但是如果前端使用 Ajax 请求，Ajax 是无法处理 302 请求的。前后端分离 Web 中，规范是使用 Json 交互。我们希望登录成功或者失败都会返回一个 Json。\n 注：登录接口和登录页面的区别，登录页面就是浏览器展示出来的页面；登录接口则是提交登录数据的地方，就是登录页面里边的 form 表单的 action 属性对应的值。\n 在 Spring Security 中，如果我们不做任何配置，默认的登录页面和登录接口的地址都是 /login，也就是说，默认会存在如下两个请求：\nGET http://localhost:8080/login\rPOST http://localhost:8080/login\r  loginProcessingUrl：这个表示配置处理登录请求的接口地址，例如你是表单登录，那么 form 表单中 action 的值就是这里填的值。 loginPage：这个表示登录页的地址，例如当你访问一个需要登录后才能访问的资源时，系统就会自动给你通过重定向跳转到这个页面上来。（但是这个是前后端不分家时才使用的东西）  可以自定义 AuthenticationSuccessHandler、AuthenticationFailureHandler、AccessDeniedHandler 来返回不同的 JSON\n@Configuration\rpublic class SecurityConfig extends WebSecurityConfigurerAdapter {\r@Bean\rpublic PasswordEncoder passwordEncoder() {\rreturn new BCryptPasswordEncoder();\r}\r@Autowired\rprivate UserDetailServiceImpl userDetailsService;\r@Override\rprotected void configure(AuthenticationManagerBuilder auth) throws Exception {\r// 使用自定义的 UserDetailService\rauth.userDetailsService(userDetailsService).passwordEncoder(new BCryptPasswordEncoder());\r}\r@Override\rprotected void configure(HttpSecurity http) throws Exception {\rhttp\r// 验证策略\r.authorizeRequests()\r// 放行登录\r.antMatchers(HttpMethod.POST,\u0026quot;/doLogin\u0026quot;).permitAll()\r.anyRequest().authenticated()\r.and()\r.formLogin()\r.loginProcessingUrl(\u0026quot;/doLogin\u0026quot;)\r// 设置登陆成功后的处理（这个 MyAuthenticationSuccessHandler 是之前自定义的处理器，下面的同理）\r.successHandler(new MyAuthenticationSuccessHandler())\r// 设置登陆失败后的处理\r.failureHandler(new MyAuthenticationFailureHandler())\r.and()\r.csrf()// 要关掉这个 csrf\r.disable()\r.exceptionHandling()\r.authenticationEntryPoint(new Http403ForbiddenEntryPoint()) // 未登陆直接请求资源的处理（这里设置为返回 403）\r.accessDeniedHandler(new MyAccessDeniedHandler())\r.and().cors();\r}\r}\r  注意这里的坑点！！csrf().disable() 这里的 csrf 一定要关掉，否则会一直显示 “权限不足，访问失败”。在 Security 的默认拦截器里，默认会开启 CSRF 处理，判断请求是否携带了 token，如果没有就拒绝访问。\n 不要将 CORS(跨站资源共享) 和 CSRF(跨站请求伪造)弄混\n CORS(跨站资源共享) 是局部打破同源策略的限制，使在一定规则下 HTTP 请求可以突破浏览器限制，实现跨站访问。 CSRF 是一种网络攻击方式，也可以说是一种安全漏洞，这种安全漏洞在 web 开发中广泛存在。  退出登陆 http\r.logout()\r// 默认是 /logout\r.logoutUrl(\u0026quot;/doLogout\u0026quot;)\r//退出成功，返回json\r.logoutSuccessHandler((request,response,authentication) -\u0026gt; {\rRespBean ok = RespBean.ok(\u0026quot;退出成功！\u0026quot;, authentication.getPrincipal());\rresponse.setContentType(\u0026quot;application/json;charset=utf-8\u0026quot;);\rPrintWriter out = response.getWriter();\rout.write(new ObjectMapper().writeValueAsString(ok));\rout.flush();\rout.close();\r}).permitAll();\r 配置测试环境 使用 Vue 搭建一个测试环境\n\u0026lt;body\u0026gt;\r\u0026lt;div id=\u0026quot;app\u0026quot;\u0026gt;\r\u0026lt;div\u0026gt;\r\u0026lt;span\u0026gt;username：\u0026lt;/span\u0026gt;\r\u0026lt;input type=\u0026quot;text\u0026quot; v-model='username'\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;div\u0026gt;\r\u0026lt;span\u0026gt;password：\u0026lt;/span\u0026gt;\r\u0026lt;input type=\u0026quot;text\u0026quot; v-model='password'\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;button @click='sub'\u0026gt;提交\u0026lt;/button\u0026gt;\r\u0026lt;br\u0026gt;\r\u0026lt;br\u0026gt;\r\u0026lt;!-- 登陆成功后再访问这个 api --\u0026gt;\r\u0026lt;button @click=\u0026quot;sayHello()\u0026quot;\u0026gt;测试访问需要权限的 api\u0026lt;/button\u0026gt;\r\u0026lt;br\u0026gt;\r\u0026lt;br\u0026gt;\r\u0026lt;button @click=\u0026quot;logout()\u0026quot;\u0026gt;退出登陆\u0026lt;/button\u0026gt;\r\u0026lt;/div\u0026gt;\r\u0026lt;script src=\u0026quot;https://cdn.jsdelivr.net/npm/vue@2/dist/vue.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;\r\u0026lt;script src=\u0026quot;https://cdn.bootcss.com/qs/6.5.1/qs.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;\r\u0026lt;script src=\u0026quot;https://cdn.jsdelivr.net/npm/axios/dist/axios.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;\r\u0026lt;script\u0026gt;\rconst qs = Qs // 引入QS库把请求参数转成表单形式\rlet app = new Vue({\rel: '#app',\rcreated() {\raxios.defaults.baseURL = 'http://127.0.0.1:8080/'\r// 因为默认 Spring Security 是通过 Cookie 和 Session 来验证身份的，所以需要配置携带 Cookie\raxios.interceptors.request.use(config =\u0026gt; {\rconfig.withCredentials = true;\rreturn config;\r});\r},\rdata: {\rpassword: 'admin',\rusername: 'admin'\r},\rmethods: {\rsub() {\raxios.post('/doLogin', qs.stringify({\rusername: this.username,\rpassword: this.password\r}), {\rheaders: {\r'Content-Type': 'application/x-www-form-urlencoded'\r}\r})\r.then((result) =\u0026gt; {\rconsole.log(result.data);\r}).catch((err) =\u0026gt; {\rconsole.log(err);\r});\r},\rsayHello() {\raxios.get('/hello')\r.then((result) =\u0026gt; {\rconsole.log(result.data);\r}).catch((err) =\u0026gt; {\rconsole.log(err);\r});\r},\rlogout() {\raxios.post('/doLogout')\r.then((result) =\u0026gt; {\rconsole.log(result.data);\r}).catch((err) =\u0026gt; {\rconsole.log(err);\r});\r}\r},\r})\r\u0026lt;/script\u0026gt;\r\u0026lt;/body\u0026gt;\r ","id":27,"section":"posts","summary":"转：原文链接 https://blog.csdn.net/qq_44131750/article/details/115775159 Session、Cookie 登陆认证 就是认证是否为合法用户，简单的说是登录。一般为匹对用户名和密码，即认证成功。 在 Spring Security 认证中，","tags":["spring-security"],"title":"Spring Security 使用自带的 formLogin","uri":"https://bluestaree.github.io/2022/03/spring-security-%E4%BD%BF%E7%94%A8%E8%87%AA%E5%B8%A6%E7%9A%84-formlogin/","year":"2022"},{"content":" Redis + AOP分布式锁实现 基本思路：\n加锁基于Redis得setnx命令；\n释放锁基于lua脚本，可以避免由于方法执行时间过长而redis锁自动过期失效的时候误删其他线程的锁；\n结合AOP，对指定接口方法进行标记，方便使用；\n适用于抢卷等相关业务\n1.注解 @Target({ElementType.METHOD})\r@Retention(RetentionPolicy.RUNTIME)\r@Inherited\rpublic @interface RedisLock {\r/** 锁的资源，redis的key*/\rString value() default \u0026quot;default\u0026quot;;\r/** 持锁时间,单位毫秒*/\rlong keepMills() default 30000;\r/** 当获取失败时候动作*/\rLockFailAction action() default LockFailAction.CONTINUE;\rpublic enum LockFailAction{\r/** 放弃 */\rGIVEUP,\r/** 继续 */\rCONTINUE;\r}\r/** 重试的间隔时间,设置GIVEUP忽略此项*/\rlong sleepMills() default 200;\r/** 重试次数*/\rint retryTimes() default 5;\r}\r 2.切面 @Aspect\r@Component\rpublic class RedisLockAspect {\rprivate final Logger logger = LoggerFactory.getLogger(RedisLockAspect.class);\r@Autowired\rprivate DistributedLock distributedLock;\r@Autowired\rprivate ExpressionParser parser;\r@Autowired\rprivate LocalVariableTableParameterNameDiscoverer discoverer;\r@Pointcut(\u0026quot;@annotation(com.test.common.redis.lock.annotation.RedisLock)\u0026quot;)\rprivate void lockPoint() {\r}\r@Around(\u0026quot;lockPoint()\u0026quot;)\rpublic Object around(ProceedingJoinPoint pjp) throws Throwable {\rMethod method = ((MethodSignature) pjp.getSignature()).getMethod();\rRedisLock redisLock = method.getAnnotation(RedisLock.class);\rString key = redisLock.value();\rObject[] args = pjp.getArgs();\rkey = parse(key, method, args);\rint retryTimes = redisLock.action().equals(RedisLock.LockFailAction.CONTINUE) ? redisLock.retryTimes() : 0;\rboolean lock = distributedLock.lock(key, redisLock.keepMills(), retryTimes, redisLock.sleepMills());\rif (!lock) {\rlogger.debug(\u0026quot;get lock failed : \u0026quot; + key);\rreturn null;\r}\r//得到锁,执行方法，释放锁\rlogger.debug(\u0026quot;get lock success : \u0026quot; + key);\rtry {\rreturn pjp.proceed();\r} catch (Exception e) {\rlogger.error(\u0026quot;execute locked method occured an exception\u0026quot;, e);\rthrow e;\r} finally {\rboolean releaseResult = distributedLock.releaseLock(key);\rlogger.debug(\u0026quot;release lock : \u0026quot; + key + (releaseResult ? \u0026quot; success\u0026quot; : \u0026quot; failed\u0026quot;));\r}\r}\rprivate String parse(String key, Method method, Object[] args) {\rString[] params = discoverer.getParameterNames(method);\rEvaluationContext context = new StandardEvaluationContext();\rfor (int i = 0; i \u0026lt; params.length; i++) {\rcontext.setVariable(params[i], args[i]);\r}\rreturn parser.parseExpression(key).getValue(context, String.class);\r}\r}\r 3.加锁业务接口 public interface DistributedLock {\rpublic static final long TIMEOUT_MILLIS = 30000;\rpublic static final int RETRY_TIMES = Integer.MAX_VALUE;\rpublic static final long SLEEP_MILLIS = 500;\rpublic boolean lock(String key);\rpublic boolean lock(String key, int retryTimes);\rpublic boolean lock(String key, int retryTimes, long sleepMillis);\rpublic boolean lock(String key, long expire);\rpublic boolean lock(String key, long expire, int retryTimes);\rpublic boolean lock(String key, long expire, int retryTimes, long sleepMillis);\rpublic boolean releaseLock(String key);\r}\r 4.加锁实现抽象类 public abstract class AbstractDistributedLock implements DistributedLock{\r@Override\rpublic boolean lock(String key) {\rreturn lock(key, TIMEOUT_MILLIS, RETRY_TIMES, SLEEP_MILLIS);\r}\r@Override\rpublic boolean lock(String key, int retryTimes) {\rreturn lock(key, TIMEOUT_MILLIS, retryTimes, SLEEP_MILLIS);\r}\r@Override\rpublic boolean lock(String key, int retryTimes, long sleepMillis) {\rreturn lock(key, TIMEOUT_MILLIS, retryTimes, sleepMillis);\r}\r@Override\rpublic boolean lock(String key, long expire) {\rreturn lock(key, expire, RETRY_TIMES, SLEEP_MILLIS);\r}\r@Override\rpublic boolean lock(String key, long expire, int retryTimes) {\rreturn lock(key, expire, retryTimes, SLEEP_MILLIS);\r}\r}\r 5.具体实现类 public class RedisDistributedLock extends AbstractDistributedLock {\rprivate final Logger logger = LoggerFactory.getLogger(RedisDistributedLock.class);\rprivate RedisTemplate\u0026lt;Object, Object\u0026gt; redisTemplate;\rprivate ThreadLocal\u0026lt;String\u0026gt; lockFlag = new ThreadLocal\u0026lt;String\u0026gt;();\rpublic static final String UNLOCK_LUA;\rstatic {\rStringBuilder sb = new StringBuilder();\rsb.append(\u0026quot;if redis.call(\\\u0026quot;get\\\u0026quot;,KEYS[1]) == ARGV[1] \u0026quot;);\rsb.append(\u0026quot;then \u0026quot;);\rsb.append(\u0026quot; return redis.call(\\\u0026quot;del\\\u0026quot;,KEYS[1]) \u0026quot;);\rsb.append(\u0026quot;else \u0026quot;);\rsb.append(\u0026quot; return 0 \u0026quot;);\rsb.append(\u0026quot;end \u0026quot;);\rUNLOCK_LUA = sb.toString();\r}\rpublic RedisDistributedLock(RedisTemplate\u0026lt;Object, Object\u0026gt; redisTemplate) {\rsuper();\rthis.redisTemplate = redisTemplate;\r}\r@Override\rpublic boolean lock(String key, long expire, int retryTimes, long sleepMillis) {\rboolean result = setRedis(key, expire);\r// 如果获取锁失败，按照传入的重试次数进行重试\rwhile ((!result) \u0026amp;\u0026amp; retryTimes-- \u0026gt; 0) {\rtry {\rlogger.debug(\u0026quot;lock failed, retrying...\u0026quot; + retryTimes);\rThread.sleep(sleepMillis);\r} catch (InterruptedException e) {\rreturn false;\r}\rresult = setRedis(key, expire);\r}\rreturn result;\r}\rprivate boolean setRedis(String key, long expire) {\rtry {\rboolean result = redisTemplate.execute(new RedisCallback\u0026lt;Boolean\u0026gt;() {\r@Override\rpublic Boolean doInRedis(RedisConnection redisConnection) throws DataAccessException {\rString uuid = UUID.randomUUID().toString();\rlockFlag.set(uuid);\rreturn redisConnection.set(key.getBytes(), uuid.getBytes(), Expiration.from(expire, TimeUnit.SECONDS), RedisStringCommands.SetOption.SET_IF_ABSENT);\r}\r});\rreturn result;\r/**\r* 源代码适用的是JRedis\r* String result = redisTemplate.execute(new RedisCallback\u0026lt;String\u0026gt;() {\r* @Override\r* public String doInRedis(RedisConnection connection) throws DataAccessException {\r* JedisCommands commands = (JedisCommands) connection.getNativeConnection();\r* String uuid = UUID.randomUUID().toString();\r* lockFlag.set(uuid);\r* return commands.set(key, uuid, \u0026quot;NX\u0026quot;, \u0026quot;PX\u0026quot;, expire);\r* }\r* });\r* return !StringUtils.isEmpty(result);\r* -----------------------------------\r* Springboot-Redis分布式锁\r* https://blog.51cto.com/u_12302929/3331813\r*\r*/\r} catch (Exception e) {\rlogger.error(\u0026quot;set redis occured an exception\u0026quot;, e);\r}\rreturn false;\r}\r@Override\rpublic boolean releaseLock(String key) {\r// 释放锁的时候，有可能因为持锁之后方法执行时间大于锁的有效期，此时有可能已经被另外一个线程持有锁，所以不能直接删除\rtry {\r/* List\u0026lt;String\u0026gt; keys = new ArrayList\u0026lt;String\u0026gt;();\rkeys.add(key);\rList\u0026lt;String\u0026gt; args = new ArrayList\u0026lt;String\u0026gt;();\rargs.add(lockFlag.get());*/\r// 使用lua脚本删除redis中匹配value的key，可以避免由于方法执行时间过长而redis锁自动过期失效的时候误删其他线程的锁\r// spring自带的执行脚本方法中，集群模式直接抛出不支持执行脚本的异常，所以只能拿到原redis的connection来执行脚本\rboolean result = redisTemplate.execute(new RedisCallback\u0026lt;Boolean\u0026gt;() {\r@Override\rpublic Boolean doInRedis(RedisConnection redisConnection) throws DataAccessException {\r/*Object nativeConnection = connection.getNativeConnection();\r// 集群模式和单机模式虽然执行脚本的方法一样，但是没有共同的接口，所以只能分开执行\r// 集群模式\rif (nativeConnection instanceof JedisCluster) {\rreturn (Long) ((JedisCluster) nativeConnection).eval(UNLOCK_LUA, keys, args);\r}\r// 单机模式\relse if (nativeConnection instanceof Jedis) {\rreturn (Long) ((Jedis) nativeConnection).eval(UNLOCK_LUA, keys, args);\r}*/\rreturn redisConnection.eval(UNLOCK_LUA.getBytes(), ReturnType.BOOLEAN, 1, key.getBytes(), lockFlag.get().getBytes());\r}\r});\rreturn result;\r} catch (Exception e) {\rlogger.error(\u0026quot;release lock occured an exception\u0026quot;, e);\r}\rreturn false;\r}\r}\r 使用方式： 1、在对应需要加所得业务方法上添加注解（支持SpEL表达式）\n@RedisLock(\u0026quot;'lock:test:'.concat(#produtcId)\u0026quot;)\r ","id":28,"section":"posts","summary":"Redis + AOP分布式锁实现 基本思路： 加锁基于Redis得setnx命令； 释放锁基于lua脚本，可以避免由于方法执行时间过长而redis锁自动过期","tags":["redis"],"title":"redis + AOP分布式锁实现","uri":"https://bluestaree.github.io/2022/02/redis-aop%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0/","year":"2022"},{"content":"  转载文章：\nSpring Security Oauth2 认证（获取token/刷新token）流程（password模式）\nSpring Security 解析(七) —— Spring Security Oauth2 源码解析\n这两篇文章都写得挺详细得，对还不太清楚security认证流程得小伙伴会有很大得帮助\n 1.token认证会用到的相关请求 注：所有请求均为post请求。\n  获取access_token请求（/oauth/token） 请求所需参数：client_id、client_secret、grant_type、username、password\nhttp://localhost/oauth/token?client_id=demoClientId\u0026amp;client_secret=demoClientSecret\u0026amp;grant_type=password\u0026amp;username=demoUser\u0026amp;password=50575tyL86xp29O380t1\r   检查头肯是否有效请求（/oauth/check_token） 请求所需参数：token\nhttp://localhost/oauth/check_token?token=f57ce129-2d4d-4bd7-1111-f31ccc69d4d1\r   刷新token请求（/oauth/token） 请求所需参数：grant_type、refresh_token、client_id、client_secret 其中grant_type为固定值：grant_type=refresh_token\nhttp://localhost/oauth/token?grant_type=refresh_token\u0026amp;refresh_token=fbde81ee-f419-42b1-1234-9191f1f95be9\u0026amp;client_id=demoClientId\u0026amp;client_secret=demoClientSecret\r   2.认证核心流程  注：文中介绍的认证服务器端token存储在Reids，用户信息存储使用数据库，文中会包含相关的部分代码。\n 2.1.获取token的主要流程： 加粗内容为每一步的重点，不想细看的可以只看加粗内容：\n 用户发起获取token的请求。 过滤器会验证path是否是认证的请求/oauth/token，如果为false，则直接返回没有后续操作。 过滤器通过clientId查询生成一个Authentication对象。 然后会通过username和生成的Authentication对象生成一个UserDetails对象，并检查用户是否存在。 以上全部通过会进入地址/oauth/token，即TokenEndpoint的postAccessToken方法中。 postAccessToken方法中会验证Scope，然后验证是否是refreshToken请求等。 之后调用AbstractTokenGranter中的grant方法。 grant方法中调用AbstractUserDetailsAuthenticationProvider的authenticate方法，通过username和Authentication对象来检索用户是否存在。 然后通过DefaultTokenServices类从tokenStore中获取OAuth2AccessToken对象。 然后将OAuth2AccessToken对象包装进响应流返回。  2.2.刷新token（refresh token）的流程 刷新token（refresh token）的流程与获取token的流程只有⑨有所区别：\n 获取token调用的是AbstractTokenGranter中的getAccessToken方法，然后调用tokenStore中的getAccessToken方法获取token。 刷新token调用的是RefreshTokenGranter中的getAccessToken方法，然后使用tokenStore中的refreshAccessToken方法获取token。  2.3.tokenStore的特点 tokenStore通常情况为自定义实现，一般放置在缓存或者数据库中。此处可以利用自定义tokenStore来实现多种需求，如：\n 同已用户每次获取token，获取到的都是同一个token，只有token失效后才会获取新token。 同一用户每次获取token都生成一个完成周期的token并且保证每次生成的token都能够使用（多点登录）。 同一用户每次获取token都保证只有最后一个token能够使用，之前的token都设为无效（单点token）。  3.获取token的详细流程（代码截图） 3.1.代码截图梳理流程 1.一个比较重要的过滤器\n2.此处是①中的attemptAuthentication方法\n3.此处是②中调用的authenticate方法\n4.此处是③中调用的AbstractUserDetailsAuthenticationProvider类的authenticate方法\n5.此处是④中调用的DaoAuthenticationProvider类的retrieveUser方法\n6.此处为⑤中调用的ClientDetailsUserDetailsService类的loadUserByUsername方法，执行完后接着返回执行④之后的方法\n7.此处为④中调用的DaoAuthenticationProvider类的additionalAuthenticationChecks方法，此处执行完则主要过滤器执行完毕，后续会进入/oauth/token映射的方法。\n8.此处进入/oauth/token映射的TokenEndpoint类的postAccessToken方法\n9.此处为⑧中调用的AbstractTokenGranter类的grant方法\n10.此处为⑨中调用的ResourceOwnerPasswordTokenGranter类中的getOAuth2Authentication方法\n11.此处为⑩中调用的自定义的CustomUserAuthenticationProvider类中的authenticate方法，此处校验用户密码是否正确，此处执行完则返回⑨执行后续方法。\n12.此处为⑨中调用的DefaultTokenServices中的createAccessToken方法\n13.此处为12中调用的RedisTokenStore中的getAccessToken方法等，此处执行完，则一直向上返回到⑧中执行后续方法。\n14.此处为⑧中获取到token后需要包装返回流操作\n4.OAuth2AuthenticationProcessingFilter （资源服务器认证）解析 ​\t通过前面的解析我们最终获取到了token，但获取token 不是我们最终目的，我们最终的目的时拿到资源信息，所以我们还得通过获取到的token去调用资源服务器接口获取资源数据。那么接下来我们就来解析资源服务器是如何通过传入token去辨别用户并允许返回资源信息的。我们知道资源服务器在过滤器链新增了 OAuth2AuthenticationProcessingFilter 来拦截请求并认证，那就这个过滤器的实现\npublic void doFilter(ServletRequest req, ServletResponse res, FilterChain chain) throws IOException,\rServletException {\rfinal boolean debug = logger.isDebugEnabled();\rfinal HttpServletRequest request = (HttpServletRequest) req;\rfinal HttpServletResponse response = (HttpServletResponse) res;\rtry {\r// 1、 调用 tokenExtractor.extract() 方法从请求中解析出token信息并存放到 authentication 的 principal 字段 中\rAuthentication authentication = tokenExtractor.extract(request);\rif (authentication == null) {\rif (stateless \u0026amp;\u0026amp; isAuthenticated()) {\rif (debug) {\rlogger.debug(\u0026quot;Clearing security context.\u0026quot;);\r}\rSecurityContextHolder.clearContext();\r}\rif (debug) {\rlogger.debug(\u0026quot;No token in request, will continue chain.\u0026quot;);\r}\r}\relse {\rrequest.setAttribute(OAuth2AuthenticationDetails.ACCESS_TOKEN_VALUE, authentication.getPrincipal());\rif (authentication instanceof AbstractAuthenticationToken) {\rAbstractAuthenticationToken needsDetails = (AbstractAuthenticationToken) authentication;\rneedsDetails.setDetails(authenticationDetailsSource.buildDetails(request));\r}\r// 2、 调用 authenticationManager.authenticate() 认证过程： 注意此时的 authenticationManager 是 OAuth2AuthenticationManager Authentication authResult = authenticationManager.authenticate(authentication);\rif (debug) {\rlogger.debug(\u0026quot;Authentication success: \u0026quot; + authResult);\r}\reventPublisher.publishAuthenticationSuccess(authResult);\rSecurityContextHolder.getContext().setAuthentication(authResult);\r}\r}\rcatch (OAuth2Exception failed) {\rSecurityContextHolder.clearContext();\reventPublisher.publishAuthenticationFailure(new BadCredentialsException(failed.getMessage(), failed),\rnew PreAuthenticatedAuthenticationToken(\u0026quot;access-token\u0026quot;, \u0026quot;N/A\u0026quot;));\rauthenticationEntryPoint.commence(request, response,\rnew InsufficientAuthenticationException(failed.getMessage(), failed));\rreturn;\r}\rchain.doFilter(request, response);\r}\r 整个filter步骤最核心的是下面2个：\r  1、 调用 tokenExtractor.extract() 方法从请求中解析出token信息并存放到 authentication 的 principal 字段 中 **2、 调用 authenticationManager.authenticate() 认证过程： 注意此时的 authenticationManager 是 OAuth2AuthenticationManager **  ​\t在解析@EnableResourceServer 时我们讲过 OAuth2AuthenticationManager 与 OAuth2AuthenticationProcessingFilter 的关系，这里不再重述，我们直接看下 OAuth2AuthenticationManager 的 authenticate() 方法实现：\npublic Authentication authenticate(Authentication authentication) throws AuthenticationException {\rif (authentication == null) {\rthrow new InvalidTokenException(\u0026quot;Invalid token (token not found)\u0026quot;);\r}\r// 1、 从 authentication 中获取 token\rString token = (String) authentication.getPrincipal();\r// 2、 调用 tokenServices.loadAuthentication() 方法 通过 token 参数获取到 OAuth2Authentication 对象 ，这里的tokenServices 就是我们资源服务器配置的。\rOAuth2Authentication auth = tokenServices.loadAuthentication(token);\rif (auth == null) {\rthrow new InvalidTokenException(\u0026quot;Invalid token: \u0026quot; + token);\r}\rCollection\u0026lt;String\u0026gt; resourceIds = auth.getOAuth2Request().getResourceIds();\rif (resourceId != null \u0026amp;\u0026amp; resourceIds != null \u0026amp;\u0026amp; !resourceIds.isEmpty() \u0026amp;\u0026amp; !resourceIds.contains(resourceId)) {\rthrow new OAuth2AccessDeniedException(\u0026quot;Invalid token does not contain resource id (\u0026quot; + resourceId + \u0026quot;)\u0026quot;);\r}\r// 3、 检测客户端信息，由于我们采用授权服务器和资源服务器分离的设计，所以这个检测方法实际没有检测\rcheckClientDetails(auth);\rif (authentication.getDetails() instanceof OAuth2AuthenticationDetails) {\rOAuth2AuthenticationDetails details = (OAuth2AuthenticationDetails) authentication.getDetails();\r// Guard against a cached copy of the same details\rif (!details.equals(auth.getDetails())) {\r// Preserve the authentication details from the one loaded by token services\rdetails.setDecodedDetails(auth.getDetails());\r}\r}\r// 4、 设置认证成功标识并返回\rauth.setDetails(authentication.getDetails());\rauth.setAuthenticated(true);\rreturn auth;\r}\r 整个 认证逻辑分4步：\n 1、 从 authentication 中获取 token 2、 调用 tokenServices.loadAuthentication() 方法 通过 token 参数获取到 OAuth2Authentication 对象 ，这里的tokenServices 就是我们资源服务器配置的。 3、 检测客户端信息，由于我们采用授权服务器和资源服务器分离的设计，所以这个检测方法实际没有检测 4、 设置认证成功标识并返回 ，注意返回的是 OAuth2Authentication （Authentication 子类）。   后面的授权过程就是原汁原味的Security授权，所以至此整个资源服务器 通过获取到的token去调用接口获取资源数据 的解析完成。\n","id":29,"section":"posts","summary":"转载文章： Spring Security Oauth2 认证（获取token/刷新token）流程（password模式） Spring Security 解析(七) —— Spring Security Oauth2 源码解析 这两篇文章都写得挺详细得，","tags":["spring-security"],"title":"Spring Security Oauth2认证流程","uri":"https://bluestaree.github.io/2022/02/spring-security-oauth2%E8%AE%A4%E8%AF%81%E6%B5%81%E7%A8%8B/","year":"2022"},{"content":" 接口防重复提交AOP实现 基本思路：\n通过注解形式，对指定接口方法进行标记，使用AOP方式对所有标记了注解的方法进行防重处理\n防重处理类型 ：\n RID：需要前端传递32位不带“-”符号的uuid，不传的情况下不生效 KEY：根据body和query参数md5的唯一性判断，优先采用body参数，两个参数都没有传的情况下不生效。 ALL：优先判断并使用RID，其次是KEY。  1.枚举类 @Getter\r@AllArgsConstructor\rpublic enum IdeTypeEnum {\r/**\r* 优先判断并使用RID，其次是KEY。\r*/\rALL(0, \u0026quot;ALL\u0026quot;),\r/**\r* ruid 是针对每一次请求的\r*/\rRID(1, \u0026quot;RID\u0026quot;),\r/**\r* key+val 是针对相同参数请求\r*/\rKEY(2, \u0026quot;KEY\u0026quot;);\rprivate final Integer index;\rprivate final String title;\r}\r 2.工具类 获取请求携带的 body参数\npublic class HttpHelper {\rprivate static final Logger LOGGER = LoggerFactory.getLogger(HttpHelper.class);\rpublic static String getBodyString(ServletRequest request) {\rStringBuilder sb = new StringBuilder();\rBufferedReader reader = null;\rtry (InputStream inputStream = request.getInputStream()) {\rreader = new BufferedReader(new InputStreamReader(inputStream, Charset.forName(\u0026quot;UTF-8\u0026quot;)));\rString line = \u0026quot;\u0026quot;;\rwhile ((line = reader.readLine()) != null) {\rsb.append(line);\r}\r} catch (IOException e) {\rLOGGER.warn(\u0026quot;getBodyString出现问题！\u0026quot;);\r} finally {\rif (reader != null) {\rtry {\rreader.close();\r} catch (IOException e) {\rLOGGER.error(ExceptionUtils.getFullStackTrace(e));\r}\r}\r}\rreturn sb.toString();\r}\r}\r 3.HttpServletRequestWrapper（装饰模式的应用) 构建可重复读取inputStream的request\npublic class RepeatedlyRequestWrapper extends HttpServletRequestWrapper {\rprivate final byte[] body;\rprivate final String bodyString;\rpublic RepeatedlyRequestWrapper(HttpServletRequest request, ServletResponse response) throws IOException {\rsuper(request);\rrequest.setCharacterEncoding(\u0026quot;UTF-8\u0026quot;);\rresponse.setCharacterEncoding(\u0026quot;UTF-8\u0026quot;);\rbodyString = HttpHelper.getBodyString(request);\rbody = bodyString.getBytes(\u0026quot;UTF-8\u0026quot;);\rrequest.setAttribute(\u0026quot;bodyString\u0026quot;,bodyString);\r}\r@Override\rpublic BufferedReader getReader() throws IOException {\rreturn new BufferedReader(new InputStreamReader(getInputStream()));\r}\r@Override\rpublic ServletInputStream getInputStream() throws IOException {\rfinal ByteArrayInputStream bais = new ByteArrayInputStream(body);\rreturn new ServletInputStream() {\r@Override\rpublic int read() throws IOException {\rreturn bais.read();\r}\r@Override\rpublic boolean isFinished() {\rreturn false;\r}\r@Override\rpublic boolean isReady() {\rreturn false;\r}\r@Override\rpublic void setReadListener(ReadListener readListener) {\r}\r};\r}\r}\r 4.过滤器 public class RepeatableFilter implements Filter {\r@Override\rpublic void init(FilterConfig filterConfig) throws ServletException {\r}\r@Override\rpublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)\rthrows IOException, ServletException {\rServletRequest requestWrapper = null;\rSystem.out.println(\u0026quot;RepeatableFilter\u0026quot;);\rif (request instanceof HttpServletRequest) {\rrequestWrapper = new RepeatedlyRequestWrapper((HttpServletRequest) request, response);\r}\rif (null == requestWrapper) {\rchain.doFilter(request, response);\r} else {\rchain.doFilter(requestWrapper, response);\r}\r}\r@Override\rpublic void destroy() {\r}\r}\r 5.注册过滤器 这里使用@ConditionalOnProperty 可在配置文件中动态开启关闭\n@ConditionalOnProperty(name = \u0026quot;ide.enable\u0026quot;, havingValue = \u0026quot;true\u0026quot;)\r@Configuration\rpublic class IdeConfig {\r@Bean\rpublic FilterRegistrationBean ideFilterRegistration() {\rFilterRegistrationBean registration = new FilterRegistrationBean();\rregistration.setFilter(new RepeatableFilter());\rregistration.addUrlPatterns(\u0026quot;/*\u0026quot;);\rregistration.setName(\u0026quot;repeatableFilter\u0026quot;);\rregistration.setOrder(FilterRegistrationBean.LOWEST_PRECEDENCE);\rreturn registration;\r}\r}\r 6.redisServie工具类 @Component\rpublic class RedisService {\r@Autowired\rprivate RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate;\rpublic RedisTemplate getRedisTemplate() {\rreturn this.redisTemplate;\r}\r@Autowired\rprivate RedisLockUtil redisLockUtil;\r/**\r* 分布式锁\r*\r* @param key 分布式锁key\r* @param expireTime 持有锁的最长时间 (redis过期时间) 秒为单位\r* @return 返回获取锁状态 成功失败\r*/\rpublic boolean tryLock(String key, int expireTime) {\rfinal JSONObject lock = new JSONObject();\rlock.put(\u0026quot;id\u0026quot;, key);\r// startTime\rlock.put(\u0026quot;st\u0026quot;, System.currentTimeMillis());\r// keepSeconds\rlock.put(\u0026quot;ks\u0026quot;, expireTime);\rreturn redisLockUtil.tryLock(key, \u0026quot;\u0026quot;, expireTime);\r}\r}\r 7.分布式锁工具 加锁使用SETNX 命令 , 解锁使用lua脚本 保证原子性\npublic class RedisLockUtil {\rpublic RedisLockUtil(RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate) {\rthis.redisTemplate = redisTemplate;\r}\rprivate RedisTemplate\u0026lt;String, Object\u0026gt; redisTemplate;\rprivate static final byte[] SCRIPT_RELEASE_LOCK = \u0026quot;if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\u0026quot;.getBytes();\r/**\r* 尝试获取分布式锁\r*\r* @param key 键\r* @param requestId 请求ID\r* @param expire 锁的有效时间（秒）\r*/\rpublic synchronized Boolean tryLock(String key, String requestId, long expire) {\rreturn redisTemplate.execute((RedisCallback\u0026lt;Boolean\u0026gt;) redisConnection -\u0026gt; redisConnection.set(key.getBytes(), requestId.getBytes(), Expiration.from(expire, TimeUnit.SECONDS), RedisStringCommands.SetOption.SET_IF_ABSENT));\r}\r/**\r* 释放分布式锁\r*\r* @param key 键\r* @param requestId 请求ID\r*/\rpublic synchronized Boolean releaseLock(String key, String requestId) {\rreturn redisTemplate.execute((RedisCallback\u0026lt;Boolean\u0026gt;) redisConnection -\u0026gt; redisConnection.eval(SCRIPT_RELEASE_LOCK, ReturnType.BOOLEAN, 1, key.getBytes(), requestId.getBytes()));\r}\r}\r 8.切面基础类 提供公共方法\npublic abstract class BaseAspect {\r/**\r* 获取切面方法上包含的指定注解\r*\r* @param joinPoint\r* @param annotationClass\r* @param \u0026lt;T\u0026gt;\r* @return\r*/\rpublic \u0026lt;T extends Annotation\u0026gt; T getAnnotation(JoinPoint joinPoint, Class\u0026lt;T\u0026gt; annotationClass) {\rString methodName = joinPoint.getSignature().getName();\rObject[] arguments = joinPoint.getArgs();\rMethod[] methods = joinPoint.getSignature().getDeclaringType().getMethods();\rfor (Method m : methods) {\rif (m.getName().equals(methodName)) {\rif (m.getParameterTypes().length == arguments.length) {\rreturn m.getAnnotation(annotationClass);\r}\r}\r}\rreturn null;\r}\r/**\r* 默认key策略\r*\r* @param targetName\r* @param methodName\r* @param arguments\r* @return\r*/\rpublic String getCacheKey(String key, String targetName, String methodName,\rObject[] arguments) {\rStringBuilder sb = new StringBuilder();\rif (key != null \u0026amp;\u0026amp; key.length() \u0026gt; 0) {\rsb.append(key);\r} else {\rsb.append(targetName).append(\u0026quot;.\u0026quot;).append(methodName);\r}\rif (arguments != null \u0026amp;\u0026amp; (arguments.length != 0)) {\rsb.append(\u0026quot;#\u0026quot;).append(JSON.toJSONString(arguments));\r}\rreturn sb.toString().replace(\u0026quot;[\u0026quot;, \u0026quot;\u0026quot;).replace(\u0026quot;\\\u0026quot;\u0026quot;, \u0026quot;\u0026quot;).replace(\u0026quot;]\u0026quot;, \u0026quot;\u0026quot;).replace(\u0026quot;com.gofun.\u0026quot;, \u0026quot;\u0026quot;);\r}\r/**\r* 获取key\r* 根据condition\r*\r* @param key\r* @param condition\r* @param arguments\r* @return\r*/\rpublic String getCacheKey(String key, String condition, Object[] arguments) {\rStringBuilder sb = new StringBuilder();\rsb.append(key);\rString argJson = JSON.toJSONString(arguments);\rString[] params = null;\rif (condition != null \u0026amp;\u0026amp; condition.trim().startsWith(\u0026quot;#\u0026quot;)) {\rcondition = condition.trim();\rparams = condition.split(\u0026quot;,\u0026quot;);\rfor (String param : params) {\rparam = param.replace(\u0026quot;#\u0026quot;, \u0026quot;\u0026quot;);\rJSONObject val = (JSONObject) JSONPath.read(condition, param);\r}\r}\rreturn sb.toString();\r}\r}\r 9.切面 这里注意有个重要参数LOCK_WAIT_TIME ，具体重复提交间隔\n@Slf4j\r@Aspect\r@Component\r@RequiredArgsConstructor\r@ConditionalOnClass(RedisService.class)\rpublic class IdeAspect extends BaseAspect {\r/**\r* 配置注解后 默认开启\r*/\r@Value(\u0026quot;${ide.enable:false}\u0026quot;)\rprivate boolean enable;\r/**\r* request请求头中的key\r*/\rprivate final static String HEADER_RID_KEY = \u0026quot;rid\u0026quot;;\r/**\r* redis中锁的key前缀\r*/\rprivate static final String REDIS_KEY_PREFIX = \u0026quot;rid:\u0026quot;;\r/**\r* 锁等待时长\r*/\rprivate static final int LOCK_WAIT_TIME = 10;\rprivate final RedisService redisService;\r@Pointcut(\u0026quot;@annotation(com.ide.annotation.Ide)\u0026quot;)\rpublic void watchIde() {\r}\r@Before(\u0026quot;watchIde()\u0026quot;)\rpublic void doBefore(JoinPoint joinPoint) {\rIde ide = getAnnotation(joinPoint, Ide.class);\rif (enable \u0026amp;\u0026amp; null != ide) {\rServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();\rif (null == attributes) {\rthrow new BizException(\u0026quot;请求数据为空\u0026quot;);\r}\rHttpServletRequest request = attributes.getRequest();\rif (ide.ideTypeEnum() == IdeTypeEnum.RID) {\r//2.1.通过rid模式判断是否属于重复提交\rString rid = request.getHeader(HEADER_RID_KEY);\rif (StrUtil.isNotBlank(rid)) {\rideHandle(ide,rid);\r} else {\rlog.warn(\u0026quot;Header没有rid,防重复提交功能失效,,remoteHost={}\u0026quot; ,request.getRemoteHost());\r}\r} else if (ide.ideTypeEnum() == IdeTypeEnum.KEY) {\rString uri = request.getRequestURI();\rString ip = IpUtils.getIpAddr(request);\rString bodyString = (String) request.getAttribute(\u0026quot;bodyString\u0026quot;);\rString paramString = request.getQueryString();\rif (StrUtil.isBlank(bodyString) \u0026amp;\u0026amp; StrUtil.isBlank(paramString)) {\rlog.warn(\u0026quot;请求参数为空,防重复提交功能失效,,remoteHost={}\u0026quot; + request.getRemoteHost());\r}else {\rString key_rid = Md5Utils.hash(ip + uri + (StrUtil.isNotBlank(bodyString) == true ? bodyString : paramString));\rideHandle(ide,key_rid);\r}\r} else {\rString rid = request.getHeader(HEADER_RID_KEY);\rif (StrUtil.isNotBlank(rid)) {\rideHandle(ide,rid);\r} else {\rString uri = request.getRequestURI();\rString ip = IpUtils.getIpAddr(request);\rString bodyString = (String) request.getAttribute(\u0026quot;bodyString\u0026quot;);\rString paramString = request.getQueryString();\rif (StrUtil.isBlank(bodyString) \u0026amp;\u0026amp; StrUtil.isBlank(paramString)) {\rlog.warn(\u0026quot;Header没有rid且请求参数为空,防重复提交功能失效,,remoteHost={}\u0026quot; + request.getRemoteHost());\r}else {\rString key_rid = Md5Utils.hash(ip + uri + (StrUtil.isNotBlank(bodyString) == true ? bodyString : paramString));\rideHandle(ide,key_rid);\r}\r}\r}\r}\r}\r/**\r* 并发锁\r*\r* @param ide\r* @param rid\r* @return void\r*/\rprivate void ideHandle(Ide ide,String rid) {\rtry {\rBoolean result = redisService.tryLock(REDIS_KEY_PREFIX + ide.perFix() + \u0026quot;:\u0026quot; + rid, LOCK_WAIT_TIME);\rif (!result) {\rthrow new BizException(\u0026quot;不允许重复提交，请稍后再试...\u0026quot;);\r}\rlog.debug(\u0026quot;当前请求已成功记录,{}={}\u0026quot;, HEADER_RID_KEY, rid);\r} catch (BizException e) {\rthrow e;\r} catch (Exception e) {\rlog.error(\u0026quot;获取redis锁发生异常\u0026quot;, e);\rthrow e;\r}\r}\r}\r 10.防重复提交注解 @Target(ElementType.METHOD)\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\rpublic @interface Ide {\r/**\r* 自定义key的前缀用来区分业务\r*/\rString perFix() default \u0026quot;demo\u0026quot;;\r/**\r* 禁止重复提交的模式\r* 默认是全部使用\r*/\rIdeTypeEnum ideTypeEnum() default IdeTypeEnum.ALL;\r}\r 使用方式： 1、在application.yml增加如下配置，开启防止重复提交（10秒内不能重复提交[可提取为配置项]）\nide:\renable: true\r 2、在Controller的方法上面增加注解\n@Ide(perFix = \u0026quot;demo\u0026quot;, ideTypeEnum=IdeTypeEnum.RID)\r perFix：为redis的前缀key，根据业务进行区分（默认为:demo）。\nideTypeEnum：为防重复提交的类型（RID、KEY、ALL，默认为ALL）。\n","id":30,"section":"posts","summary":"接口防重复提交AOP实现 基本思路： 通过注解形式，对指定接口方法进行标记，使用AOP方式对所有标记了注解的方法进行防重处理 防重处理类型 ： RID","tags":["redis"],"title":"接口防重复提交AOP实现","uri":"https://bluestaree.github.io/2022/02/%E6%8E%A5%E5%8F%A3%E9%98%B2%E9%87%8D%E5%A4%8D%E6%8F%90%E4%BA%A4aop%E5%AE%9E%E7%8E%B0/","year":"2022"},{"content":"SpringBoot @PostMapping 接收HTTP 请求的流数据方式 @PostMapping(\u0026quot;/test\u0026quot;)\rpublic String pushMessage(@RequestBody byte[] data) {\rString json = new String(data, CharsetUtil.CHARSET_UTF_8);\rlog.info(\u0026quot;\u0026gt;\u0026gt;\u0026gt; 接收CP推送的消息：{}\u0026quot;, json);\rJSONObject jsonObject = JacksonUtils.jsonToBean(json, JSONObject.class);\rSystem.out.println(jsonObject.get(\u0026quot;key\u0026quot;));\rreturn “success”\r}\r ","id":31,"section":"posts","summary":"SpringBoot @PostMapping 接收HTTP 请求的流数据方式 @PostMapping(\u0026quot;/test\u0026quot;) public String pushMessage(@RequestBody byte[] data) { String json = new String(data, CharsetUtil.CHARSET_UTF_8); log.info(\u0026quot;\u0026gt;\u0026gt;\u0026gt; 接收CP推送的消息：{}\u0026quot;, json); JSONObject jsonObject = JacksonUtils.jsonToBean(json, JSONObject.class); System.out.println(jsonObject.get(\u0026quot;key\u0026quot;)); return “success” }","tags":null,"title":"SpringBoot @PostMapper 接收HTTP 请求的流数据方式","uri":"https://bluestaree.github.io/2022/01/springboot-postmapping-%E6%8E%A5%E6%94%B6http-%E8%AF%B7%E6%B1%82%E7%9A%84%E6%B5%81%E6%95%B0%E6%8D%AE%E6%96%B9%E5%BC%8F/","year":"2022"},{"content":"  官方文档地址：https://help.aliyun.com/document_detail/112503.html\n 阿里云语音通知Api接入实现 yml配置 aliyun:\rvoice:\raccessKeyId: xxx\raccessKeySecret: xxx\r# 所属区域\rregionId: cn-hangzhou\r# Tts模板ID\rttsCode: xxx\r# 语音播放播放次数\rplayTimes: 3\r# MNS消息回执 队列名称\rqueueName: Alicom-Queue-xxx-VoiceReport\r# MNS消息回执 消息类型\rmessageType: VoiceReport\r maven配置 \u0026lt;!--添加阿里云core依赖--\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.aliyun\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;aliyun-java-sdk-core\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;4.5.0\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;!--阿里云语音验证码jar包--\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.aliyun\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;aliyun-java-sdk-dyvmsapi\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.2.2\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;!--阿里云语音服务 MNS 消息回执jar包--\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.aliyun.mns\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;aliyun-sdk-mns\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.1.8\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;!-- 注意 ： 此包没有再maven中央仓库管理， 通过demo获得并存储至nexus--\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.aliyun\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;alicom-mns-receive-sdk\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;0.0.1\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;!-- 注意 ： 此包没有再maven中央仓库管理， 通过demo获得并存储至nexus--\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.aliyun\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;aliyun-java-sdk-dybaseapi\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 代码实现 1、服务配置类 读取配置文件信息\n@Data\r@Component\r@ConfigurationProperties(prefix = \u0026quot;aliyun.voice\u0026quot;)\rpublic class AliVoiceCallNotifyConfig {\r/**\r* accessKeyId\r*/\rprivate String accessKeyId;\r/**\r* accessKeySecret\r*/\rprivate String accessKeySecret;\r/**\r* 所属区域\r*/\rprivate String regionId;\r/**\r* Tts模板ID\r*/\rprivate String ttsCode;\r/**\r* 播放次数\r*/\rprivate Integer playTimes;\r/**\r* MNS消息回执 队列名称\r*/\rprivate String queueName;\r/**\r* MNS消息回执 消息类型\r*/\rprivate String messageType;\r}\r 2、调用阿里云语音Api 阿里云 有三种不同的呼叫方式,根据需要选择调用\n这里只使用到 阿里云文本转语音外呼API singleCallByTts ，其他方式参考接口文档传入必传参数即可\n接口文档：https://help.aliyun.com/document_detail/147008.html\n@Slf4j\r@Component\rpublic class AliVoiceCallService {\r@Autowired\rprivate AliVoiceCallNotifyConfig voiceCallNotifyConfig;\r/**\r* 阿里云文本转语音外呼API singleCallByTts\r*/\rpublic void singleCallByTts(CallMsgBO callMsgBO) {\r// 设置访问超时时间\rSystem.setProperty(\u0026quot;sun.net.client.defaultConnectTimeout\u0026quot;, \u0026quot;10000\u0026quot;);\rSystem.setProperty(\u0026quot;sun.net.client.defaultReadTimeout\u0026quot;, \u0026quot;10000\u0026quot;);\r// 初始化acsClient,暂不支持region化\rIClientProfile profile = DefaultProfile.getProfile(voiceCallNotifyConfig.getRegionId(), voiceCallNotifyConfig.getAccessKeyId(), voiceCallNotifyConfig.getAccessKeySecret());\rDefaultProfile.addEndpoint(voiceCallNotifyConfig.getRegionId(), AliVoiceCallConstant.PRODUCT, AliVoiceCallConstant.DOMAIN);\rIAcsClient acsClient = new DefaultAcsClient(profile);\r// 组装请求对象-具体描述见控制台-文档部分内容\rSingleCallByTtsRequest request = new SingleCallByTtsRequest();\r// 被叫显号，若您使用的模板为公共号池号码外呼模板，则该字段值必须为空；\r// 若您使用的模板为专属号码外呼模板，则必须传入已购买的号码，仅支持一个号码，您可以在语音服务控制台上查看已购买的号码。\rrequest.setCalledShowNumber(\u0026quot;\u0026quot;);\r// 必填-被叫号码\rrequest.setCalledNumber(callMsgBO.getMobilePhone());\r// 必填-Tts模板ID\rrequest.setTtsCode(voiceCallNotifyConfig.getTtsCode());\r// 可选-当模板中存在变量时需要设置此值\rrequest.setTtsParam(getTtsParam(callMsgBO));\r// 可选-速度\rrequest.setSpeed(-300);\r// 可选-播放次数\rrequest.setPlayTimes(voiceCallNotifyConfig.getPlayTimes());\r// 可选-外部扩展字段,此ID将在回执消息中带回给调用方\rrequest.setOutId(callMsgBO.getCallLogId().toString());\r// 发送请求\rSingleCallByTtsResponse singleCallByTtsResponse = null;\rtry {\rsingleCallByTtsResponse = acsClient.getAcsResponse(request);\r} catch (ClientException e) {\re.printStackTrace();\r}\rif (singleCallByTtsResponse == null) {\rlog.error(\u0026quot;[语音通知]调用阿里云语音验证码API失败，未能获取到返回结果信息\u0026quot;);\rreturn;\r}\rString code = singleCallByTtsResponse.getCode();\rlog.info(\u0026quot;[语音通知]调用阿里云语音验证码API结果 状态码:{} ，返回信息:{}\u0026quot;, code, singleCallByTtsResponse.getMessage());\rif (\u0026quot;OK\u0026quot;.equals(code)) {\r// 调用成功,更新呼叫记录的状态为成功,记录返回的信息\rlog.info(\u0026quot;[语音通知]调用阿里云语音验证码API成功，callId:{}\u0026quot;, singleCallByTtsResponse.getCallId());\r} else {\rlog.info(\u0026quot;[语音通知]调用阿里云语音验证码API失败，错误码:{}\u0026quot;, code);\r}\r}\r/**\r* 获取语音模板中内容参数\r*/\rpublic String getTtsParam(CallMsgBO callMsgBO) {\rMap\u0026lt;String, String\u0026gt; bodys = new HashMap();\rbodys.put(\u0026quot;param1\u0026quot;, callMsgBO.getParam1());\rbodys.put(\u0026quot;param2\u0026quot;, callMsgBO.getParam2());\rreturn JSONObject.toJSONString(bodys);\r}\r 3、通过MNS消息队列消费模式 获取回执信息 这里需要根据文档在阿里云控制台中进行配置：https://help.aliyun.com/document_detail/213833.html\n注意：启用的MNS消息服务订阅指定的消息类型（MessageType）时，系统会自动生成该类型的独立消息队列及名称（QueueName）。用户可使用此消息队列名称（QueueName）和消息类型（MessageType）\n配置类\n@Configuration\r@Profile(\u0026quot;prod\u0026quot;)\rpublic class AliVoiceListenerConfig {\r@Autowired\rprivate AliVoiceFeeMessageListener feeMessageListener;\r@Bean\rpublic DefaultAlicomMessagePuller initMessageListener(AliVoiceCallNotifyConfig voiceCallNotifyConfig) throws Exception {\rDefaultAlicomMessagePuller puller = new DefaultAlicomMessagePuller();\rString accessKeyId = voiceCallNotifyConfig.getAccessKeyId();\rString accessKeySecret = voiceCallNotifyConfig.getAccessKeySecret();\r/**\r*云通信产品下所有的回执消息类型:\r*1:短信回执：SmsReport，\r*2:短息上行：SmsUp\r*3:语音呼叫：VoiceReport\r*4:流量直冲：FlowReport\r*/\r//在云通信页面开通相应业务消息后，就能在页面上获得对应的queueName,每一个消息类型\rpuller.startReceiveMsg(accessKeyId, accessKeySecret, voiceCallNotifyConfig.getMessageType(), voiceCallNotifyConfig.getQueueName(), feeMessageListener);\rreturn puller;\r}\r}\r 监听类\n@Component\r@Slf4j\rpublic class AliVoiceFeeMessageListener implements MessageListener {\rprivate Gson gson = new Gson();\r@Override\rpublic boolean dealMessage(Message message) {\r// 消息的几个关键值\rlog.info(\u0026quot;[阿里云语音话单消息]消息接收时间[{}],message handle[{}],body[{}],id[{}],dequeue count[{}]\u0026quot;, DateUtil.now(), message.getReceiptHandle(),\rmessage.getMessageBodyAsString(), message.getMessageId(), message.getDequeueCount());\rlog.info(\u0026quot;[阿里云语音话单消息]监听到语音回执消息------------------------------{}\u0026quot;, message);\rtry {\rMap\u0026lt;String, Object\u0026gt; contentMap = gson.fromJson(message.getMessageBodyAsString(), HashMap.class);\r// 依据自己的消息类型，获取对应的字段\rString callId = (String) contentMap.get(\u0026quot;call_id\u0026quot;);\rString originateTime = (String) contentMap.get(\u0026quot;originate_time\u0026quot;);\rString ringTime = (String) contentMap.get(\u0026quot;ring_time\u0026quot;);\rString startTime = (String) contentMap.get(\u0026quot;start_time\u0026quot;);\rString endTime = (String) contentMap.get(\u0026quot;end_time\u0026quot;);\rString caller = (String) contentMap.get(\u0026quot;caller\u0026quot;);\rString callee = (String) contentMap.get(\u0026quot;callee\u0026quot;);\rString statusCode = (String) contentMap.get(\u0026quot;status_code\u0026quot;);\rString outId = (String) contentMap.get(\u0026quot;out_id\u0026quot;);\rlog.info(\u0026quot;[阿里云语音话单消息]-------------------语音话单回调开始处理， code:{}, callId:{}, outId:{}\u0026quot;, statusCode, callId, outId);\rif(!ValidateUtil.isNumeric(outId)) {\r// 过滤非正常数据\rlog.error(\u0026quot;[阿里云语音话单消息]!!!!!!!过滤信息!!!!!!!!，呼叫记录id非法 ,返回信息:{}\u0026quot;, contentMap);\rreturn true;\r}\r// 业务处理...\r} catch (com.google.gson.JsonSyntaxException e) {\rlog.error(\u0026quot;[阿里云语音话单消息]格式错误的消息error_json_format:{} , 异常信息:{}\u0026quot; + message.getMessageBodyAsString(), e);\r// 理论上不会出现格式错误的情况，所以遇见格式错误的消息，只能先delete,否则重新推送也会一直报错\rreturn true;\r} catch (Throwable e) {\r// 您自己的代码部分导致的异常，应该return false,这样消息不会被delete掉，而会根据策略进行重推\rlog.error(\u0026quot;[阿里云语音话单消息]系统内部异常,消息重试. 异常信息:{} \u0026quot;, e);\rreturn false;\r}\r// 消息处理成功，返回true, SDK将调用MNS的delete方法将消息从队列中删除掉\rreturn true;\r}\r}\r ","id":32,"section":"posts","summary":"官方文档地址：https://help.aliyun.com/document_detail/112503.html 阿里云语音通知Api接入","tags":null,"title":"阿里云语音通知Api接入实现","uri":"https://bluestaree.github.io/2021/12/%E9%98%BF%E9%87%8C%E4%BA%91%E8%AF%AD%E9%9F%B3%E9%80%9A%E7%9F%A5api%E6%8E%A5%E5%85%A5%E5%AE%9E%E7%8E%B0/","year":"2021"},{"content":"  概述： 在开发中涉及到APP应用服务开发，其自测时难免需要一款调试工具参看接口参数信息，就好比浏览器F12调式模式一样，以便定位问题。这里就简单介绍下手机抓包工具 Charles(HTTP代理服务器)使用\n 官网地址：https://www.charlesproxy.com/\nCharles使用 点击工具栏上的Proxy然后勾上macOS Proxy（看你下得是哪个版本，windows得话就是 Windows Proxy），此时电脑上所有的请求都能够展示出来了。\nCharles的手机抓包配置 首先确保手机和电脑在同一局域网内。\n打开Charles，点击Proxy Setting\n在打开的面板中，勾上Enable transparent HTTP proxying\n打开手机的wifi设置，点击wifi后面的图标查看详情\n然后点击最下面的配置代理，改为手动，输入电脑的ip以及配置好的8888端口\n经过这样设置之后，设置代理后，需要在电脑上打开Charles才能上网。\n在弹出的框中，选择\u0026quot;Allow\u0026quot;允许，就会出现手机的HTTP列表。\nHttps抓包 Https请求的抓包需要在http的基础上再设置\n在没有设置Https抓包之前的效果是这样\n1.安装SSL证书到手机设备 点击Help-\u0026gt;SSL Proxying-\u0026gt;Install Charles Root Certificate on a Mobile Device\n出现弹框\n2.然后在手机的Safari预览器中输入chls.pro/ssl，会提示你下载一个描述文件，下载完成之后，在手机设置的通用-\u0026gt;描述文件里安装此证书，如果有密码的手机需要输入密码 3.然后也是很关键的一点点击设置，通用-\u0026gt;关于本机-\u0026gt;证书信任设置,对此证书信息完全信任 4.电脑上安装证书 点击之后会出现钥匙串，将证书设置为始终信任\n5.最后一步，允许所有443，也就是htts请求 点击Proxy-\u0026gt;SSL Proxying Settings\n在弹出的弹框中勾选Enable SSL Proxying ，然后点击Add\n填上允许所有https请求，至此，就完成了所有https的配置。\n手机再次访问https请求，现在就这样在Charles里看到所有请求内容了。\n// Charles Proxy License\n// 适用于Charles任意版本的注册码，谁还会想要使用破解版呢。\n// Charles 4.2目前是最新版，可用。\nRegistered Name: https://zhile.io\nLicense Key: 48891cf209c6d32bf4，\n点击工具栏中的help →register ，输入以上的账号和密码便可使用。\n","id":33,"section":"posts","summary":"概述： 在开发中涉及到APP应用服务开发，其自测时难免需要一款调试工具参看接口参数信息，就好比浏览器F12调式模式一样，以便定位问题。这里就简","tags":["charles"],"title":"抓包工具charles安装和使用","uri":"https://bluestaree.github.io/2021/11/%E6%8A%93%E5%8C%85%E5%B7%A5%E5%85%B7charles%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","year":"2021"},{"content":"  概述：起因是测试时遇到一个业务响应异常缓慢问题，排查后发现时mysql链接等待导致业务超时，定位到具体业务逻辑，初步判断应该是事务问题。这个业务内部逻辑繁多，而且存在远程调用这种耗时较高的行为，因为当时排期紧张，在实现完业务后，便没有考虑到这方面隐藏问题，在方法入口上加了**@Transactional**注解后草草了事。后续经过优化解决\n 业务伪代码 @Transactional\rpublic int expireHouseholder(Householder householder){\r// 获取详情信息\rhouseholderInfoService.getById(id);\r// 规则判断\r...\r...\r// 更新数据\rhmBaseMapper.updateById(householder);\r// 远程调用\rrpcMethod();\r// 后续操作\rotherDoing();\rreturn householder.getId();\r}\r 问题：\n 事务中包含与跟新数据无法的业务逻辑，查询、各种规则判断等 事务中嵌套使用耗时服务（远程调用）  解决优化 TransactionTemplate 在不影响现有逻辑下，使用编程式事务 ： 通过 TransactionTemplate或者 TransactionManager 手动管理事务，将事务中包含与跟新数据无法的业务逻辑，查询、各种规则判断等提取到事务外中\n@Autowired\rprivate TransactionTemplate transactionTemplate;\rpublic int expireHouseholder(Householder householder){\r// 获取详情信息\rhouseholderInfoService.getById(id);\r// 规则判断\r...\r...\r// 开启事务\rtransactionTemplate.execute((status) -\u0026gt; { // 更新数据\rhmBaseMapper.updateById(householder);\r...\r... }); // 远程调用\rrpcMethod();\r// 后续操作\rotherDoing();\rreturn householder.getId();\r}\r TransactionSynchronizationManager 如果远程调用业务中，需要等待事务结束后操作，如发送系统消息等，需要明确等待事务提交完成后再执行（事务提交后，后续查询才能查出正确数据），可以结合使用TransactionSynchronizationManager\nTransactionSynchronizationManager中提供了让我们对事务注册的方法：\npublic static void registerSynchronization(TransactionSynchronization synchronization)\rthrows IllegalStateException {\rAssert.notNull(synchronization, \u0026quot;TransactionSynchronization must not be null\u0026quot;);\rSet\u0026lt;TransactionSynchronization\u0026gt; synchs = synchronizations.get();\rif (synchs == null) {\rthrow new IllegalStateException(\u0026quot;Transaction synchronization is not active\u0026quot;);\r}\rsynchs.add(synchronization);\r}\r 其中参数TransactionSynchronization 是一个接口，提供了一些钩子方法给我们， 可以根据需求实现对应的方法\npublic interface TransactionSynchronization extends Flushable {\rint STATUS_COMMITTED = 0;\rint STATUS_ROLLED_BACK = 1;\rint STATUS_UNKNOWN = 2;\r/**\r* 挂起时触发\r*/\rdefault void suspend() {\r}\r/**\r* 挂起事务抛出异常的时候 会触发\r*/\rdefault void resume() {\r}\r@Override\rdefault void flush() {\r}\r/**\r* 在事务提交之前触发\r*/\rdefault void beforeCommit(boolean readOnly) {\r}\r/**\r* 在事务完成之前触发\r*/\rdefault void beforeCompletion() {\r}\r/**\r* 在事务提交之后触发\r*/\rdefault void afterCommit() {\r}\r/**\r* 在事务完成之后触发\r*/\rdefault void afterCompletion(int status) {\r}\r}\r 使用TransactionSynchronizationManager在事务提交之后操作\n CallBackService\n @Component\rpublic class CallBackService {\rpublic void execute(final CallBackAction action) {\r// 事务是否处于活跃状态\rif (TransactionSynchronizationManager.isActualTransactionActive()) {\rTransactionSynchronizationManager\r.registerSynchronization(new TransactionSynchronizationAdapter() {\r// afterCompletion() 在事务完成之后触发\r@Override\rpublic void afterCompletion(int status) {\r// 判断事务是否已完成\rif (status == STATUS_COMMITTED){\r// 事务提交后，开启新线程，处理后续业务\rAsyncManager.me().execute(new TimerTask() {\r@Override\rpublic void run() {\r// 业务处理\raction.callback();\r}\r});\r}else {\r// 其他状态处理\r}\r}\r});\r} else {\r// 事务处于非活跃状态\rAsyncManager.me().execute(new TimerTask() {\r@Override\rpublic void run() {\raction.callback();\r}\r});\r}\r}\r}\r  CallBackAction\n public interface CallBackAction {\r/**\r* 函数式接口\r*/\rvoid callback();\r}\r 使用\n@Autowired\rprivate TransactionTemplate transactionTemplate;\r@Autowired\rprivate CallBackService callBackService;\rpublic int expireHouseholder(Householder householder){\r// 获取详情信息\rhouseholderInfoService.getById(id);\r// 规则判断\r...\r...\r// 开启事务\rtransactionTemplate.execute((status) -\u0026gt; { // 更新数据\rhmBaseMapper.updateById(householder);\r...\r...\r// 在事务提交后执行\rcallBackService.execute(() -\u0026gt; {\r// 远程调用 --这里发生异常 不会影响以上事务结果\rrpcMethod();\r});\r}); // 后续操作 --这里发生异常 不会影响以上事务结果\rotherDoing();\rreturn householder.getId();\r}\r 通过这种方式，可以将事务控制再较小范围内，确保 更新数据 事务的结果不会受到 远程调用，以及 后续操作 的影响。\n","id":34,"section":"posts","summary":"概述：起因是测试时遇到一个业务响应异常缓慢问题，排查后发现时mysql链接等待导致业务超时，定位到具体业务逻辑，初步判断应该是事务问题。这个","tags":null,"title":"大事务业务处理优化","uri":"https://bluestaree.github.io/2021/10/%E5%A4%A7%E4%BA%8B%E5%8A%A1%E4%B8%9A%E5%8A%A1%E5%A4%84%E7%90%86%E4%BC%98%E5%8C%96/","year":"2021"},{"content":" 废话不多说，直接上图\n1、排除编译过滤项 包括 *.TTC 文件 并将最终文件 放置/target下\n2、包括编译过滤项， 排除 *.yml , *.TTC 文件\n效果： 编译前文件位置：\n编译后文件位置：\n大功告成。\n后续只需要将文件部署到 linux 服务器即可\n这里以jekins 部署为例子\n jekins 部署时需注意，在脚本中 需要将对应文件 拷贝到指定服务器中*，否则 jekins 之后 执行docker脚本 将报找不到指定文件错误\n usercenter-server-auth/target/DockerFile, usercenter-server-auth/target/usercenter-server-auth-1.0.0.jar,usercenter-server-auth/target/docker-compose.yml,usercenter-server-auth/target/deploy.sh,usercenter-server-auth/target/SIMSUN.TTC\r ","id":35,"section":"posts","summary":"废话不多说，直接上图 1、排除编译过滤项 包括 *.TTC 文件 并将最终文件 放置/target下 2、包括编译过滤项， 排除 *.yml , *.TTC 文件 效果： 编译前文件位置： 编译","tags":null,"title":"java服务部署跳过编译文件 并转移到指定文件夹下","uri":"https://bluestaree.github.io/2021/09/java%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2%E8%B7%B3%E8%BF%87%E7%BC%96%E8%AF%91%E6%96%87%E4%BB%B6-%E5%B9%B6%E8%BD%AC%E7%A7%BB%E5%88%B0%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E5%A4%B9%E4%B8%8B/","year":"2021"},{"content":" 内部引用导致AOP注解不生效 今天同事遇到了一个bug，\n场景是这样的：在一个复杂业务逻辑，查询结果却与数据库不一致，并且其中部分字段为未更新前数据，如下图情况\n业务伪代码：\n@Transactional(rollbackFor = Exception.class, propagation = Propagation.REQUIRES_NEW)\rpublic void dealWithPoint(Point point) { // .....\r// 减积分操作 updatePoints(); // ....\r// 加积分 ， 第二次执行时出现问题，查看日志并没有select语句，确定mybatis进行了缓存\rupdatePoints(); } public void updatePoints() {\r// 获取数据库信息 , 注意这里，属于内部引用 导致AOP注解失效\rPoint inDb = queryData1(); //校验数据安全\rcheck(inDb);\r//更新字段内容\rinDb.setPoints = 1;\rinDb.setUserPoints = 1;\r// ......\r}\r@Transactional(rollbackFor = Exception.class, propagation = Propagation.NOT_SUPPORTED)\rpublic Point queryData1() { getById();\r}  而出现数据不一致的原因 也是因为在第一步操作中，我们更新了 inDb 实体类信息。\n 刚看到这个问题，首先觉得 是不是 mybatis 将查询数据缓存了\n于是尝试使用注解\n@Options(flushCache=Options.FlushCachePolicy.TRUE)\n 但还是一样的结果，然道注解没生效？？？？\n然后继续排查，发现其中一段逻辑是引用了内部方法，导致注解不生效，\n伪代码\npublic void updatePoints() {\r// 获取数据库信息 , 注意这里，属于内部引用 导致AOP注解失效\rPoint inDb = queryData1(); //校验数据安全\rcheck(inDb );\r//更新字段内容\rinDb.setPoints = 1;\rinDb.setUserPoints = 1;\r//...\r}\r@Transactional(rollbackFor = Exception.class, propagation = Propagation.NOT_SUPPORTED)\rpublic Point queryData1() { getById();\r}  解决方式\n在该Service类中注入自己\n如果不想再新加一个Service类，在该Service类中注入自己也是一种选择。具体代码如下：\\\n@Servcie public class ServiceA { @Autowired prvate ServiceA serviceA; public void save(User user) { queryData1(); queryData2(); serviceA.doSave(user); } @Transactional(rollbackFor=Exception.class) public void doSave(User user) { addData1(); updateData2(); } }  参考文章:\nhttps://developer.51cto.com/art/202011/633243.htm\nhttps://blog.csdn.net/qq_35853455/article/details/106614093\n","id":36,"section":"posts","summary":"内部引用导致AOP注解不生效 今天同事遇到了一个bug， 场景是这样的：在一个复杂业务逻辑，查询结果却与数据库不一致，并且其中部分字段为未更新前","tags":null,"title":"内部引用导致AOP注解不生效","uri":"https://bluestaree.github.io/2021/08/%E5%86%85%E9%83%A8%E5%BC%95%E7%94%A8%E5%AF%BC%E8%87%B4aop%E6%B3%A8%E8%A7%A3%E4%B8%8D%E7%94%9F%E6%95%88/","year":"2021"},{"content":" 验证码登录简单实现  思路：基于过滤器实现，拦截登录请求，获取前端传递的验证码code进行校验\n废话不多说直接上代码\n  ValidateCodeFilter\n@Component\rpublic class ValidateCodeFilter extends OncePerRequestFilter {\r@Autowired\rprivate ValidateCodeService validateCodeService;\r@Override\rprotected void doFilterInternal(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse,\rFilterChain filterChain) throws ServletException, IOException {\rRequestMatcher matcher = new AntPathRequestMatcher(\u0026quot;/oauth/token\u0026quot;, HttpMethod.POST.toString());\rif (matcher.matches(httpServletRequest)\r\u0026amp;\u0026amp; StringUtils.equalsIgnoreCase(httpServletRequest.getParameter(\u0026quot;grant_type\u0026quot;), \u0026quot;password\u0026quot;)) {\rtry {\rvalidateCode(httpServletRequest);\rfilterChain.doFilter(httpServletRequest, httpServletResponse);\r} catch (Exception e) {\rint code = HttpStatus.ERROR;\rString msg = e.getMessage();\rServletUtils.renderString(httpServletResponse, JSON.toJSONString(Result.error(code, msg)));\r}\r} else {\rfilterChain.doFilter(httpServletRequest, httpServletResponse);\r}\r}\rprivate void validateCode(HttpServletRequest httpServletRequest) {\rString code = httpServletRequest.getParameter(\u0026quot;code\u0026quot;);\rString uuid = httpServletRequest.getParameter(\u0026quot;uuid\u0026quot;);\rvalidateCodeService.check(code, uuid);\r}\r}\r ValidateCodeService\npublic interface ValidateCodeService {\r/**\r* 生成验证码\r*/\rpublic Result\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; create() throws IOException;\r/**\r* 校验验证码\r*\r* @param key\r* @param value\r*/\rpublic void check(String key, String value);\r}\r ValidateCodeServiceImpl\n@Service\rpublic class ValidateCodeServiceImpl implements ValidateCodeService {\r@Autowired\rprivate RedisService redisService;\r/**\r* 生成验证码\r*/\r@Override\rpublic Result\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; create() throws IOException {\r// 生成随机字串\rString verifyCode = VerifyCodeUtils.generateVerifyCode(4);\r// 唯一标识\rString uuid = IdUtils.simpleUUID();\rString verifyKey = Constants.CAPTCHA_CODE_KEY + uuid;\rredisService.set(verifyKey, verifyCode, Constants.CAPTCHA_EXPIRATION, TimeUnit.MINUTES);\r// 生成图片\rint w = 111, h = 36;\rByteArrayOutputStream stream = new ByteArrayOutputStream();\rVerifyCodeUtils.outputImage(w, h, stream, verifyCode);\rtry {\rMap\u0026lt;String, Object\u0026gt; data = new HashedMap\u0026lt;String, Object\u0026gt;();\rdata.put(\u0026quot;uuid\u0026quot;, uuid);\rdata.put(\u0026quot;img\u0026quot;, Base64.encode(stream.toByteArray()));\rreturn Result.successByData(data);\r} catch (Exception e) {\re.printStackTrace();\rreturn Result.error(e.getMessage());\r} finally {\rstream.close();\r}\r}\r/**\r* 校验验证码\r*/\r@Override\rpublic void check(String code, String uuid) {\rString verifyKey = Constants.CAPTCHA_CODE_KEY + uuid;\rString captcha = redisService.get(verifyKey,String.class);\rredisService.delete(verifyKey);\rif (captcha == null) {\rthrow new BizException(\u0026quot;验证码失效\u0026quot;);\r}\rif (!code.equalsIgnoreCase(captcha)) {\rthrow new BizException(\u0026quot;验证码错误\u0026quot;);\r}\r}\r}\r VerifyCodeUtils\npublic class VerifyCodeUtils {\rpublic static final String VERIFY_CODES = \u0026quot;123456789ABCDEFGHJKLMNPQRSTUVWXYZ\u0026quot;;\rprivate static Random random = new SecureRandom();\rpublic VerifyCodeUtils() {\r}\rpublic static String generateVerifyCode(int verifySize) {\rreturn generateVerifyCode(verifySize, \u0026quot;123456789ABCDEFGHJKLMNPQRSTUVWXYZ\u0026quot;);\r}\rpublic static String generateVerifyCode(int verifySize, String sources) {\rif (sources == null || sources.length() == 0) {\rsources = \u0026quot;123456789ABCDEFGHJKLMNPQRSTUVWXYZ\u0026quot;;\r}\rint codesLen = sources.length();\rRandom rand = new Random(System.currentTimeMillis());\rStringBuilder verifyCode = new StringBuilder(verifySize);\rfor(int i = 0; i \u0026lt; verifySize; ++i) {\rverifyCode.append(sources.charAt(rand.nextInt(codesLen - 1)));\r}\rreturn verifyCode.toString();\r}\rpublic static void outputImage(int w, int h, OutputStream os, String code) throws IOException {\rint verifySize = code.length();\rBufferedImage image = new BufferedImage(w, h, 1);\rRandom rand = new Random();\rGraphics2D g2 = image.createGraphics();\rg2.setRenderingHint(RenderingHints.KEY_ANTIALIASING, RenderingHints.VALUE_ANTIALIAS_ON);\rColor[] colors = new Color[5];\rColor[] colorSpaces = new Color[]{Color.WHITE, Color.CYAN, Color.GRAY, Color.LIGHT_GRAY, Color.MAGENTA, Color.ORANGE, Color.PINK, Color.YELLOW};\rfloat[] fractions = new float[colors.length];\rfor(int i = 0; i \u0026lt; colors.length; ++i) {\rcolors[i] = colorSpaces[rand.nextInt(colorSpaces.length)];\rfractions[i] = rand.nextFloat();\r}\rArrays.sort(fractions);\rg2.setColor(Color.GRAY);\rg2.fillRect(0, 0, w, h);\rColor c = getRandColor(200, 250);\rg2.setColor(c);\rg2.fillRect(0, 2, w, h - 4);\rRandom random = new Random();\rg2.setColor(getRandColor(160, 200));\rint area;\rint fontSize;\rint x;\rint y;\rfor(int i = 0; i \u0026lt; 20; ++i) {\rarea = random.nextInt(w - 1);\rfontSize = random.nextInt(h - 1);\rx = random.nextInt(6) + 1;\ry = random.nextInt(12) + 1;\rg2.drawLine(area, fontSize, area + x + 40, fontSize + y + 20);\r}\rfloat yawpRate = 0.05F;\rarea = (int)(yawpRate * (float)w * (float)h);\rint i;\rfor(fontSize = 0; fontSize \u0026lt; area; ++fontSize) {\rx = random.nextInt(w);\ry = random.nextInt(h);\ri = getRandomIntColor();\rimage.setRGB(x, y, i);\r}\rshear(g2, w, h, c);\rg2.setColor(getRandColor(100, 160));\rfontSize = h - 4;\rFont font = new Font(\u0026quot;Algerian\u0026quot;, 2, fontSize);\rg2.setFont(font);\rchar[] chars = code.toCharArray();\rfor(i = 0; i \u0026lt; verifySize; ++i) {\rAffineTransform affine = new AffineTransform();\raffine.setToRotation(0.7853981633974483D * rand.nextDouble() * (double)(rand.nextBoolean() ? 1 : -1), (double)(w / verifySize * i + fontSize / 2), (double)(h / 2));\rg2.setTransform(affine);\rg2.drawChars(chars, i, 1, (w - 10) / verifySize * i + 5, h / 2 + fontSize / 2 - 10);\r}\rg2.dispose();\rImageIO.write(image, \u0026quot;jpg\u0026quot;, os);\r}\rprivate static Color getRandColor(int fc, int bc) {\rif (fc \u0026gt; 255) {\rfc = 255;\r}\rif (bc \u0026gt; 255) {\rbc = 255;\r}\rint r = fc + random.nextInt(bc - fc);\rint g = fc + random.nextInt(bc - fc);\rint b = fc + random.nextInt(bc - fc);\rreturn new Color(r, g, b);\r}\rprivate static int getRandomIntColor() {\rint[] rgb = getRandomRgb();\rint color = 0;\rint[] var2 = rgb;\rint var3 = rgb.length;\rfor(int var4 = 0; var4 \u0026lt; var3; ++var4) {\rint c = var2[var4];\rcolor \u0026lt;\u0026lt;= 8;\rcolor |= c;\r}\rreturn color;\r}\rprivate static int[] getRandomRgb() {\rint[] rgb = new int[3];\rfor(int i = 0; i \u0026lt; 3; ++i) {\rrgb[i] = random.nextInt(255);\r}\rreturn rgb;\r}\rprivate static void shear(Graphics g, int w1, int h1, Color color) {\rshearX(g, w1, h1, color);\rshearY(g, w1, h1, color);\r}\rprivate static void shearX(Graphics g, int w1, int h1, Color color) {\rint period = random.nextInt(2);\rboolean borderGap = true;\rint frames = 1;\rint phase = random.nextInt(2);\rfor(int i = 0; i \u0026lt; h1; ++i) {\rdouble d = (double)(period \u0026gt;\u0026gt; 1) * Math.sin((double)i / (double)period + 6.283185307179586D * (double)phase / (double)frames);\rg.copyArea(0, i, w1, 1, (int)d, 0);\rif (borderGap) {\rg.setColor(color);\rg.drawLine((int)d, i, 0, i);\rg.drawLine((int)d + w1, i, w1, i);\r}\r}\r}\rprivate static void shearY(Graphics g, int w1, int h1, Color color) {\rint period = random.nextInt(40) + 10;\rboolean borderGap = true;\rint frames = 20;\rint phase = 7;\rfor(int i = 0; i \u0026lt; w1; ++i) {\rdouble d = (double)(period \u0026gt;\u0026gt; 1) * Math.sin((double)i / (double)period + 6.283185307179586D * (double)phase / (double)frames);\rg.copyArea(i, 0, 1, h1, 0, (int)d);\rif (borderGap) {\rg.setColor(color);\rg.drawLine(i, (int)d, i, 0);\rg.drawLine(i, (int)d + h1, i, h1);\r}\r}\r}\r}\r ","id":37,"section":"posts","summary":"验证码登录简单实现 思路：基于过滤器实现，拦截登录请求，获取前端传递的验证码code进行校验 废话不多说直接上代码 ValidateCodeFilter @Component public class ValidateCodeFilter extends OncePerRequestFilter { @Autowired private ValidateCodeService validateCodeService; @Override protected void","tags":null,"title":"验证码登录简单实现","uri":"https://bluestaree.github.io/2021/07/%E9%AA%8C%E8%AF%81%E7%A0%81%E7%99%BB%E5%BD%95%E7%AE%80%E5%8D%95%E5%AE%9E%E7%8E%B0/","year":"2021"},{"content":" Dubbo隐性传参-filter方式  使用场景： 服务提供方 需要校验 消费端是否具有权限调用接口，因此消费端在每次请求前都需要带上认证信息\n 原理: RpcContext内部有一个ThreadLocal变量，它是作为ThreadLocalMap的key，表明每个线程有一个RpcContext public class RpcContext {\rprivate static final ThreadLocal\u0026lt;RpcContext\u0026gt; LOCAL = new ThreadLocal\u0026lt;RpcContext\u0026gt;() {\r@Override\rprotected RpcContext initialValue() {\rreturn new RpcContext();\r}\r};\r// 获取initialValue 中的对象 public static RpcContext getContext() {\rreturn LOCAL.get();\r}\r}\r 配置文件 ##################\r### dubbo 服务端配置\r##################\rdubbo:\rapplication:\rname: ${spring.application.name}\rscan:\rbase-packages: com.dubbotest.**.facade\rprotocols:\rdubbo:\rname: dubbo\rport: 22181\rregistries:\raddress: spring-cloud://localhost\rcloud:\rsubscribed-services: iot-server-smart,iot-server-admin,iot-netty-route\rconsumer:\rcheck: false\rfilter: params\rprovider:\rfilter: ehmException,-exception,params\r 注意其中的consumer与provider 中 filter 配置 ： params\n过滤器 public class ParamsFilter implements Filter {\rprotected final Logger logger = LoggerFactory.getLogger(this.getClass());\rpublic ParamsFilter() {\r}\rpublic Result invoke(Invoker\u0026lt;?\u0026gt; invoker, Invocation invocation) throws RpcException {\rRpcContext rpcContext = RpcContext.getContext();\r// 是否服务提供方\rboolean isServer = rpcContext.isProviderSide();\rMap rpcMap;\rif (isServer) {\r// 获取参数\rrpcMap = RpcContext.getContext().getAttachments();\rif (rpcMap != null) {\r// 将参数封装到自定义上下文中 方便取值\rDubboContextThreadLocal.set(Maps.newHashMap(rpcMap));\r}\rthis.logger.info(\u0026quot;PROVIDER####params{}\u0026quot;, rpcMap);\r// 执行请求\rResult result = invoker.invoke(invocation);\r// 清空自定义上下文\rDubboContextThreadLocal.remove();\rreturn result;\r} else {\r// 将以后的参数先拿出来，在汇总到一起避免trace的跟踪参数被覆盖丢失\rrpcMap = RpcContext.getContext().getAttachments();\r// 自定义上下文内容\rMap\u0026lt;String, String\u0026gt; webMap = WebContextThreadLocal.get();\rif (webMap != null \u0026amp;\u0026amp; rpcMap != null) {\rwebMap.putAll(rpcMap);\r}\r// 重新设置上下文内容\rRpcContext.getContext().setAttachments(webMap);\r// RpcContext.getContext().set(\u0026quot;ip\u0026quot;, \u0026quot;192.168.1.235\u0026quot;);\rthis.logger.info(\u0026quot;CONSUMER###params{}\u0026quot;, webMap);\r// 执行请求\rResult result = invoker.invoke(invocation);\rreturn result;\r}\r}\r}\r 自定义dubbo上下文 , public class DubboContextThreadLocal {\rprivate static ThreadLocal\u0026lt;Map\u0026lt;String, String\u0026gt;\u0026gt; dubboContextThreadLocal = new ThreadLocal\u0026lt;Map\u0026lt;String, String\u0026gt;\u0026gt;();\rpublic static void set(Map\u0026lt;String, String\u0026gt; infoMap) {\rdubboContextThreadLocal.set(infoMap);\r}\rpublic static Map\u0026lt;String, String\u0026gt; get() {\rreturn dubboContextThreadLocal.get();\r}\rpublic static void remove() {\rdubboContextThreadLocal.remove();\r}\rpublic static String getUserId() {\rMap\u0026lt;String, String\u0026gt; operatorMap = get();\rif (operatorMap == null) {\rreturn null;\r} else {\rreturn operatorMap.get(\u0026quot;userId\u0026quot;);\r}\r}\rpublic static String getUserName() {\rMap\u0026lt;String, String\u0026gt; operatorMap = get();\rif (operatorMap == null) {\rreturn null;\r} else {\rreturn operatorMap.get(\u0026quot;userName\u0026quot;);\r}\r}\rpublic static String getApplicationName() {\rMap\u0026lt;String, String\u0026gt; operatorMap = get();\rif (operatorMap == null) {\rreturn null;\r} else {\rreturn operatorMap.get(\u0026quot;applicationName\u0026quot;);\r}\r}\rpublic static String getAccessKeyId() {\rMap\u0026lt;String, String\u0026gt; operatorMap = get();\rif (operatorMap == null) {\rreturn null;\r} else {\rreturn operatorMap.get(\u0026quot;accessKeyId\u0026quot;);\r}\r}\r}\r 自定义web参数上下文 public class WebContextThreadLocal {\rprivate static ThreadLocal\u0026lt;Map\u0026lt;String, String\u0026gt;\u0026gt; webContextThreadLocal = new ThreadLocal\u0026lt;Map\u0026lt;String, String\u0026gt;\u0026gt;();\rpublic static void set(Map\u0026lt;String, String\u0026gt; infoMap) {\rwebContextThreadLocal.set(infoMap);\r}\rpublic static Map\u0026lt;String, String\u0026gt; get() {\rreturn webContextThreadLocal.get();\r}\rpublic static void remove() {\rwebContextThreadLocal.remove();\r}\r}\r 比如一些公用的分页参数 pageNum , pageSize等 都可以 通过过滤器 / 拦截器 ，获取请求参数，存到web参数上下文中\n相关拦截器 @Component\rpublic class TraceInterceptor extends HandlerInterceptorAdapter {\rprivate Logger logger = LoggerFactory.getLogger(TraceInterceptor.class);\r@Override\rpublic boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler)\rthrows Exception {\r// 设置传递参数\rMap\u0026lt;String, String\u0026gt; context = Maps.newHashMap();\rtry {\r// 获取当前的用户\rLoginUser loginUser = SecurityUtils.getLoginUser();\rif (loginUser != null) {\rcontext.put(\u0026quot;userId\u0026quot;, String.valueOf(loginUser.getUserId()));\rcontext.put(\u0026quot;userName\u0026quot;, loginUser.getUsername());\r}\r} catch (Exception e) {\rlogger.debug(\u0026quot;无用户信息 \u0026quot;);\r}\rtry {\rPageDomain pageDomain = TableSupport.buildPageRequest();\rif (pageDomain.getPageNum() != null \u0026amp;\u0026amp; pageDomain.getPageSize() != null) {\rcontext.put(\u0026quot;pageDomain\u0026quot;, JSON.toJSONString(pageDomain));\r}\r} catch (Exception e) {\rlogger.debug(\u0026quot;无分页信息 \u0026quot;);\r}\rWebContextThreadLocal.set(context);\rreturn true;\r}\r@Override\rpublic void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler,\rModelAndView modelAndView) throws Exception {\rsuper.postHandle(request, response, handler, modelAndView);\r}\r@Override\rpublic void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex)\rthrows Exception {\rWebContextThreadLocal.remove();\r}\r}\r 拦截器注册 @Configuration\rpublic class ResourcesConfig implements WebMvcConfigurer {\r/**\r* 自定义拦截规则\r*/\r@Override\rpublic void addInterceptors(InterceptorRegistry registry) {\rregistry.addInterceptor(new TraceInterceptor()).addPathPatterns(\u0026quot;/**\u0026quot;);\r}\r}\r 自定义Dubbo 过滤器注册 META-INF 文件目录下 新增文件 org.apache.dubbo.rpc.Filter，并添加以下内容\nparams=com.ehaomiao.common.dubbo.filter.ParamsFilter\rehmException=com.ehaomiao.common.dubbo.filter.EhmExceptionFilter\r 结合yaml中的配置即可生效\n使用 ...\rMap\u0026lt;String, String\u0026gt; context = new HashMap\u0026lt;\u0026gt;();\rcontext.put(\u0026quot;accessKeyId\u0026quot;, accessKeyId);\r// 设置隐式传递参数\rRpcContext.getContext().setAttachments(context);\r// 调用接口\rIotDevice iotDevice = accessFacade.getDeviceByDeviceCode(deviceSncode);\r....\r ","id":38,"section":"posts","summary":"Dubbo隐性传参-filter方式 使用场景： 服务提供方 需要校验 消费端是否具有权限调用接口，因此消费端在每次请求前都需要带上认证信息 原理: R","tags":["dubbo"],"title":"Dubbo隐性传参-filter方式","uri":"https://bluestaree.github.io/2021/06/dubbo%E9%9A%90%E6%80%A7%E4%BC%A0%E5%8F%82-filter%E6%96%B9%E5%BC%8F/","year":"2021"},{"content":"  ' new\u0026rsquo; 对象也能使用@Autowire注解\n关键 使用静态常量机制 @PostConstruct 注解\n@PostConstruct 注解 生效时机 ： 构造方法 \u0026gt; @Autowired \u0026gt; @PostConstruct\n 思路： 先加 @Component 让此类由spring管理 项目启动时 ，spring会创建该类实列 ，之后会执行我们的@PostConstruct 的init方法 其中逻辑 就是将已经@Autowire 注入的属性 从，转而赋值到类的静态变量种，由于静态变量不可修改，所以 之后采用 普通 new 的方式 ，只要使用静态变量 调用 其中注入的属性 即可生效\n一个例子：\n@Component\rpublic class MessageConsumerHandler implements ChannelAwareMessageListener {\rprivate static final Logger log = LoggerFactory.getLogger(MessageConsumerHandler.class);\r@Autowired\rprivate SyncOperTasksMapper syncOperTasksMapper;\r@Autowired\rprivate DevicesMapper dMapper;\r@DubboReference\rprivate IIotMsgFacade iotMsgFacade;\rpublic static MessageConsumerHandler messageConsumerHandler;\rprivate String Qname;\rpublic MessageConsumerHandler() {\r}\rpublic MessageConsumerHandler(String qname) {\rQname = qname;\r}\r@PostConstruct\rpublic void init(){\rmessageConsumerHandler = this;\rmessageConsumerHandler.iotMsgFacade = iotMsgFacade;\rmessageConsumerHandler.syncOperTasksMapper = syncOperTasksMapper;\rmessageConsumerHandler.dMapper = dMapper;\r}\r@Override\rpublic void onMessage(Message message, Channel channel) throws Exception {\rSystem.out.format(\u0026quot;收到来自通道： %s 的消息\u0026quot;, Qname);\rSystem.out.println(\u0026quot;消息内容: \u0026quot; + message.getBody().toString());\rSystem.out.println(\u0026quot;消息详情: \u0026quot; + message.toString());\rHashMap reqData = new HashMap();\rString data = JSONObject.toJSONString(changeData);\rDevices deviceInfo = messageConsumerHandler.dMapper.selectOne(new QueryWrapper\u0026lt;Devices\u0026gt;().lambda().eq(Devices::getDeviceSncode, devicesSnCode));\rtry {\rmessageConsumerHandler.iotMsgFacade.sendMsg(sendMsgReqVO);\r} catch (Exception e) {\r// 异常处理\r}\r// ...\r}\r}\r  其他方法可参考文章\nhttps://blog.csdn.net/qq_28080659/article/details/99687074\n","id":39,"section":"posts","summary":"' new\u0026rsquo; 对象也能使用@Autowire注解 关键 使用静态常量机制 @PostConstruct 注解 @PostConstruct 注解 生效时机 ： 构造方法 \u0026gt; @Autowired \u0026gt; @PostConstruct 思路： 先加 @Component 让此类由spring管理 项目启动","tags":null,"title":"使用New创建对象与 spring @Autowire","uri":"https://bluestaree.github.io/2021/06/%E4%BD%BF%E7%94%A8new%E5%88%9B%E5%BB%BA%E5%AF%B9%E8%B1%A1%E4%B8%8E-spring-autowire/","year":"2021"},{"content":" 前言 我们在开发应用系统时，不可避免的要使用到我们自己定义的异常，所以我们一般通常会用到自定义的业务异常类BusinessException，这个异常会继承extends RuntimeException，当发生业务限制的时候，会throw出来。\n方法：对dubbo源码中ExceptionFilter类进行改，添加自定义业务异常处理 @Activate(\rgroup = {\u0026quot;provider\u0026quot;},\rorder = -999\r)\rpublic class EhmExceptionFilter implements Filter, Listener {\rprivate Logger logger = LoggerFactory.getLogger(EhmExceptionFilter.class);\rpublic EhmExceptionFilter() {\r}\rpublic Result invoke(Invoker\u0026lt;?\u0026gt; invoker, Invocation invocation) throws RpcException {\rreturn invoker.invoke(invocation);\r}\rpublic void onResponse(Result appResponse, Invoker\u0026lt;?\u0026gt; invoker, Invocation invocation) {\rif (appResponse.hasException() \u0026amp;\u0026amp; GenericService.class != invoker.getInterface()) {\rtry {\rThrowable exception = appResponse.getException();\rif (exception instanceof BizException) {\rreturn;\r}\rif (!(exception instanceof RuntimeException) \u0026amp;\u0026amp; exception instanceof Exception) {\rreturn;\r}\rtry {\rMethod method = invoker.getInterface().getMethod(invocation.getMethodName(), invocation.getParameterTypes());\rClass\u0026lt;?\u0026gt;[] exceptionClassses = method.getExceptionTypes();\rClass[] var7 = exceptionClassses;\rint var8 = exceptionClassses.length;\rfor(int var9 = 0; var9 \u0026lt; var8; ++var9) {\rClass\u0026lt;?\u0026gt; exceptionClass = var7[var9];\rif (exception.getClass().equals(exceptionClass)) {\rreturn;\r}\r}\r} catch (NoSuchMethodException var11) {\rreturn;\r}\rthis.logger.error(\u0026quot;Got unchecked and undeclared exception which called by \u0026quot; + RpcContext.getContext().getRemoteHost() + \u0026quot;. service: \u0026quot; + invoker.getInterface().getName() + \u0026quot;, method: \u0026quot; + invocation.getMethodName() + \u0026quot;, exception: \u0026quot; + exception.getClass().getName() + \u0026quot;: \u0026quot; + exception.getMessage(), exception);\rString serviceFile = ReflectUtils.getCodeBase(invoker.getInterface());\rString exceptionFile = ReflectUtils.getCodeBase(exception.getClass());\rif (serviceFile != null \u0026amp;\u0026amp; exceptionFile != null \u0026amp;\u0026amp; !serviceFile.equals(exceptionFile)) {\rString className = exception.getClass().getName();\rif (!className.startsWith(\u0026quot;java.\u0026quot;) \u0026amp;\u0026amp; !className.startsWith(\u0026quot;javax.\u0026quot;)) {\rif (exception instanceof RpcException) {\rreturn;\r}\rappResponse.setException(new RuntimeException(StringUtils.toString(exception)));\rreturn;\r}\rreturn;\r}\rreturn;\r} catch (Throwable var12) {\rthis.logger.warn(\u0026quot;Fail to ExceptionFilter when called by \u0026quot; + RpcContext.getContext().getRemoteHost() + \u0026quot;. service: \u0026quot; + invoker.getInterface().getName() + \u0026quot;, method: \u0026quot; + invocation.getMethodName() + \u0026quot;, exception: \u0026quot; + var12.getClass().getName() + \u0026quot;: \u0026quot; + var12.getMessage(), var12);\r}\r}\r}\rpublic void onError(Throwable e, Invoker\u0026lt;?\u0026gt; invoker, Invocation invocation) {\rthis.logger.error(\u0026quot;Got unchecked and undeclared exception which called by \u0026quot; + RpcContext.getContext().getRemoteHost() + \u0026quot;. service: \u0026quot; + invoker.getInterface().getName() + \u0026quot;, method: \u0026quot; + invocation.getMethodName() + \u0026quot;, exception: \u0026quot; + e.getClass().getName() + \u0026quot;: \u0026quot; + e.getMessage(), e);\r}\rpublic void setLogger(Logger logger) {\rthis.logger = logger;\r}\r}\r 关键代码片段\n...\rif (exception instanceof BusinessException) {\rreturn;\r}\r...\r 在resources目录下添加纯文本文件META-INF/dubbo/com.alibaba.dubbo.rpc.Filter并添加内容\ndubboExceptionFilter=com.rainbow.goods.server.filter. DubboExceptionFilter\r yml配置文件配置\ndubbo:\rprovider:\rfilter: ehmException,-exception\r 具体原理流程，可参考文章：https://www.freesion.com/article/1464444277/\n","id":40,"section":"posts","summary":"前言 我们在开发应用系统时，不可避免的要使用到我们自己定义的异常，所以我们一般通常会用到自定义的业务异常类BusinessException，","tags":["dubbo"],"title":"Dubbo处理业务异常配置","uri":"https://bluestaree.github.io/2021/05/dubbo%E8%87%AA%E5%AE%9A%E4%B9%89%E4%B8%9A%E5%8A%A1%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/","year":"2021"},{"content":" 免费ip地址解析api 百度\n http://opendata.baidu.com/api.php?query=120.204.100.171\u0026amp;co=\u0026amp;resource_id=6006\u0026amp;oe=utf8\nhttp://sp0.baidu.com/8aQDcjqpAAV3otqbppnN2DJv/api.php?query=120.204.100.171\u0026amp;co=\u0026amp;resource_id=6006\u0026amp;oe=utf8\n 其中请求路径中的 query 参数即为要解析的IP地址\n","id":41,"section":"posts","summary":"免费ip地址解析api 百度 http://opendata.baidu.com/api.php?query=120.204.100.171\u0026amp;co=\u0026amp;resource_id=6006\u0026amp;oe=utf8 http://sp0.baidu.com/8aQDcjqpAAV3otqbppnN2DJv/api.php?query=120.204.100.171\u0026amp;co=\u0026amp;resource_id=6006\u0026amp;oe=utf8 其中请求路径中的 query 参数即为要解析的IP地址","tags":null,"title":"免费ip地址解析api","uri":"https://bluestaree.github.io/2021/05/%E5%85%8D%E8%B4%B9ip%E5%9C%B0%E5%9D%80%E8%A7%A3%E6%9E%90api/","year":"2021"},{"content":" 最近业务上有需求，需要比较当前版本与最新版本，以此判断是否可进行更新升级\n代码：\npublic class VersionNoUtil {\r/**\r*\r* @date 2020/7/22 15:47\r* @param version1 版本号1\r* @param version2 版本号2\r* @return version1\u0026gt;version2 : 1 ；version1\u0026lt;version2 : -1 ；version1=version2 : 0\r*/\rpublic static int compareVersion(String version1, String version2) {\rString[] s1 = version1.split(\u0026quot;\\\\.\u0026quot;); //通过\\\\将.进行转义\rString[] s2 = version2.split(\u0026quot;\\\\.\u0026quot;);\rint len1 = s1.length;\rint len2 = s2.length;\rint i, j;\rfor (i = 0, j = 0; i \u0026lt; len1 \u0026amp;\u0026amp; j \u0026lt; len2; i++, j++) {\rif (Integer.parseInt(s1[i]) \u0026gt; Integer.parseInt(s2[j])) {\rreturn 1;\r} else if (Integer.parseInt(s1[i]) \u0026lt; Integer.parseInt(s2[j])) {\rreturn -1;\r}\r}\rwhile (i \u0026lt; len1) {\rif (Integer.parseInt(s1[i]) != 0) {\rreturn 1;\r}\ri++;\r}\rwhile (j \u0026lt; len2) {\rif (Integer.parseInt(s2[j]) != 0) {\rreturn -1;\r}\rj++;\r}\rreturn 0;\r}\r}\r 参考文章：https://blog.csdn.net/admans/article/details/81865652\n","id":42,"section":"posts","summary":"最近业务上有需求，需要比较当前版本与最新版本，以此判断是否可进行更新升级 代码： public class VersionNoUtil { /** * * @date 2020/7/22 15:47 * @param version1 版本号1 * @param version2 版本号2 * @return version1\u0026gt;version2 : 1 ；v","tags":null,"title":"Java 比较两个版本号的大小","uri":"https://bluestaree.github.io/2021/04/java-%E6%AF%94%E8%BE%83%E4%B8%A4%E4%B8%AA%E7%89%88%E6%9C%AC%E5%8F%B7%E7%9A%84%E5%A4%A7%E5%B0%8F/","year":"2021"},{"content":" 最近在自测是发现了不少与mybatis相关错误，虽然解决起来不是很困难，但还是特地记录一下，主要原因还是太粗心了。\n问题1：整数类型if语句判断未生效 解决方法：\n增加 or soft.rolled==0 或者 删除 soft.rolled!=\u0026rsquo;\u0026rsquo; 条件判断，让mybatis即使数值为0，也进入该判断即可 ,\n\u0026lt;if test=\u0026quot;user.status != null and user.status != '' or user.status == 0\u0026quot;\u0026gt; and status = #{user.status} \u0026lt;if\u0026gt;\r 问题2：抛出异常：There is no getter for property named xxx 解决方法：\n红框部分内容 应保持一致\n 另外在这里记录一个可能导致雪花算法生成主键未生效的问题\n 使用 基本数据类型 作为主键 类型， 新增 情况下 默认 主键为 0 且 无法置为null ，无法使用mybatis雪花算法\n ","id":43,"section":"posts","summary":"最近在自测是发现了不少与mybatis相关错误，虽然解决起来不是很困难，但还是特地记录一下，主要原因还是太粗心了。 问题1：整数类型if语句判","tags":["mybatis"],"title":"Mybatis踩坑记录","uri":"https://bluestaree.github.io/2021/03/mybatis-%E8%B8%A9%E5%9D%91%E8%AE%B0%E5%BD%95/","year":"2021"},{"content":" Docker容器安装及使用 一、非docker-ce版本卸载 yum remove docker \\ docker-client \\\rdocker-client-latest \\\rdocker-common \\\rdocker-latest \\\rdocker-latest-logrotate \\\rdocker-logrotate \\\rdocker-engine\rrm -rf /etc/systemd/system/docker.service.d\rrm -rf /var/lib/docker\rrm -rf /var/run/docker\r 二、docker-ce版本卸载 列出docker安装过的相关包\ryum list installed | grep docker\r删除相关安装包 yum -y remove containerd.io.x86_64\ryum -y remove docker-ce-cli.x86_64\ryum -y remove docker-ce.x86_64\r 三、安装指定版本docker 安装所需工具和配置 yum install -y yum-utils\ryum-config-manager --add-repo https://mirrors.aliyun.com/dockerce/linux/centos/docker-ce.repo\r查看版本\ryum list docker-ce --showduplicates|sort -r\r列出版本信息如下：\r* updates: mirrors.ustc.edu.cn Loading mirror speeds from cached hostfile Loaded plugins: fastestmirror Installed Packages * extras: mirrors.163.com docker-ce.x86_64 3:20.10.5-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.4-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.3-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.2-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.1-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.0-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.9-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.8-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.7-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.6-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.5-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.4-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.3-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.2-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.15-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.14-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.1-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.13-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.13-3.el7 @docker-ce-stable docker-ce.x86_64 3:19.03.12-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.11-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.10-3.el7 docker-ce-stable docker-ce.x86_64 3:19.03.0-3.el7 docker-ce-stable  选择指定版本安装，注意去掉字符串\u0026quot;3:\u0026quot;\ryum install -y docker-ce-19.03.13-3.el7 docker-ce-cli-19.03.13-3.el7 containerd.io\r 同时启动并设置开机自启 systemctl enable docker \u0026amp;\u0026amp; systemctl start docker 查看版本号 docker --version 或者 docker -v 查看信息 docker info\r 四、自定义配置 1、配置文件路径 ​\tvi /etc/docker/daemon.json\n2、增加如下配置 { #修改镜像源 \u0026quot;registry-mirrors\u0026quot;: [\u0026quot;https://registry.docker-cn.com\u0026quot;,\u0026quot;http://hubmirror.c.163.com\u0026quot;,\u0026quot;https://docker.mirrors.ustc.edu.cn\u0026quot;], #修改docker存储位置 \u0026quot;graph\u0026quot;:\u0026quot;/data/docker\u0026quot;, #修改日志存储大小和数量 \u0026quot;log-opts\u0026quot;: {\u0026quot;max-size\u0026quot;:\u0026quot;500m\u0026quot;, \u0026quot;max-file\u0026quot;:\u0026quot;3\u0026quot;} }\r 删除docker旧存储路径（确保新路径能正常使用在删除） rm -rf /var/lib/docker\r重启docker systemctl restart docker\r 五、非root账户安装运行 查看用户组及成员 sudo cat /etc/group | grep docker\r可以添加docker组 sudo groupadd docker 添加linux用户到docker组 sudo gpasswd -a ${USER} docker 增加读写权限 sudo chmod a+rw /var/run/docker.sock\r重启docker sudo systemctl restart docker\r 六、docker命令 1、网络操作命名 创建网络 docker network create --subnet=172.30.0.0/16 my-network\r查看网络内部信息 docker network inspect my-network\r列所有列表的网络 docker network ls\r移除指定的网络 docker network rm my-network\r 2、容器操作命令 启动docker systemctl start docker\r停止docker systemctl stop docker\r重启docker systemctl restart docker\r开机启动docker systemctl enable docker\r查看当前运行的容器 docker ps\r查看所有容器 docker ps -a\r查看镜像 docker images\r进入容器 docker exec -it 容器ID /bin/bash\r停止容器 docker stop 容器ID/容器名称\r删除容器 docker rm 容器ID/容器名称\r删除镜像 docker rmi 镜像ID\r 3、日志操作命令 语法：docker logs [OPTIONS] CONTAINER\rOPTIONS说明：\r-f : 跟踪日志输出\r--since :显示某个开始时间的所有日志\r-t : 显示时间戳\r--tail :仅列出最新N条容器日志\r获取容器日志 docker logs -f 容器ID\r查看容器从2016年7月1日后的最新10条日志 docker logs --since=\u0026quot;2016-07-01\u0026quot; --tail=10 容器ID\r 4、更多操作命令 https://www.runoob.com/docker/docker-command-manual.html\n七、docker-compose使用 1、安装运行 安装命令 curl -L https://github.com/docker/compose/releases/download/1.25.5/dockercompose-`uname -s`-`uname -m` \u0026gt; /usr/local/bin/docker-compose 设置权限 chmod +x /usr/local/bin/docker-compose\r运行命令 docker-compose -f docker-compose.yml up -d\r# 脚本中使用内存和cpu限制的情况下启动脚本要加--compatibility docker-compose -f docker-compose.yml --compatibility up -d\rps:在版本2中，可以通过services下的“ mem_limit”和“ cpu_shares”参数正常工作。 但是在使用版 本3时失败，除非我使用群模式，否则将它们置于部署部分似乎不值得。\r# 构建镜像并运行启动 docker-compose up -d --build\r 2、服务器部署示例 该脚本用于安装redis、mysql、rabbitmq应用服务，并使用创建的指定网络my-network。同时通 过cpus和memory限制机器资源。注意容器和宿主机时间同步的两种方式。\nversion: \u0026quot;3\u0026quot;\rnetworks: default: external: name: my-network\rservices: redis: image: redis container_name: my-redis-165-1 restart: always ports: - 6379:6379 environment: TZ: Asia/Shanghai volumes: - \u0026quot;./redis/redis.conf:/etc/redis/redis.conf\u0026quot; - \u0026quot;./redis/data/:/data\u0026quot; command: redis-server /etc/redis/redis.conf --appendonly yes --bind 0.0.0.0 deploy: resources: limits: cpus: '0.5' memory: 500M mysql5.7.31: image: mysql:5.7.31 container_name: my-mysql5.7.31-165-1 restart: always ports: - 3306:3306 volumes: - \u0026quot;./mysql5.7.31/data:/var/lib/mysql\u0026quot; - \u0026quot;./mysql5.7.31/conf/my.cnf:/etc/mysql/my.cnf\u0026quot; - \u0026quot;./mysql5.7.31/log:/var/log/mysql\u0026quot; - \u0026quot;./mysql5.7.31/init:/docker-entrypoint-initdb.d/\u0026quot; environment: TZ: Asia/Shanghai MYSQL_ROOT_PASSWORD: root MYSQL_ROOT_HOST: \u0026quot;%\u0026quot; deploy: resources: limits: cpus: '1' memory: 1G rabbitmq: image: rabbitmq:3.8.14-management container_name: my-rabbitmq-165-1 hostname: rabbitmq restart: always ports:\r- \u0026quot;15672:15672\u0026quot; #web管理口15672 - \u0026quot;4369:4369\u0026quot; #erlang发现口 - \u0026quot;5672:5672\u0026quot; #client端通信口 - \u0026quot;25672:25672\u0026quot; #server间内部通信口 environment: # TZ: Asia/Shanghai # 第一种时间调整无效 RABBITMQ_DEFAULT_USER: root RABBITMQ_DEFAULT_PASS: root volumes: - \u0026quot;./rabbitmq/data:/var/lib/rabbitmq\u0026quot; - \u0026quot;./rabbitmq/logs:/var/log/rabbitmq\u0026quot; - \u0026quot;./rabbitmq/conf:/etc/rabbitmq\u0026quot; - /etc/localtime:/etc/localtime:ro # 第二种时间调整有效 deploy: resources: limits: cpus: '0.5' memory: 500M\t 安装rabbitmq后如果要开启web管理的话，需要进入容器执行如下命令： rabbitmq-plugins enable rabbitmq_management\rrabbitmq 生产环境配置 https://www.cnblogs.com/operationhome/p/10483840.html\rrabbitmq 配置文件属性参考 https://www.rabbitmq.com/configure.html\r ","id":44,"section":"posts","summary":"Docker容器安装及使用 一、非docker-ce版本卸载 yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine rm -rf /etc/systemd/system/docker.service.d rm -rf /var/lib/docker rm -rf /var/run/docker 二、docker-ce版本卸载","tags":["docker"],"title":"Docker容器安装及使用","uri":"https://bluestaree.github.io/2021/03/docker%E5%AE%B9%E5%99%A8%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/","year":"2021"},{"content":"  转载 · 原文链接：https://www.douban.com/group/topic/15558388/\n 前言 最近在捣鼓VirtualBox，对网络模式一知半解，对此在网上找了份写了还不错我文章，记录一下\nVirtualBox的提供了四种网络接入模式  NAT 网络地址转换模式(NAT,Network Address Translation) Bridged Adapter 桥接模式 Internal 内部网络模式 Host-only Adapter 主机模式  第一种 NAT模式 NAT模式是最简单的实现虚拟机上网的方式，你可以这样理解：Vhost访问网络的所有数据都是由主机提供的，vhost并不真实存在于网络中，主机与网络中的任何机器都不能查看和访问到Vhost的存在。\n虚拟机与主机关系：\n只能单向访问，虚拟机可以通过网络访问到主机，主机无法通过网络访问到虚拟机。\n虚拟机与网络中其他主机的关系：\n只能单向访问，虚拟机可以访问到网络中其他主机，其他主机不能通过网络访问到虚拟机。\n虚拟机与虚拟机之间的关系：\n相互不能访问，虚拟机与虚拟机各自完全独立，相互间无法通过网络访问彼此。\n IP:10.0.2.15\n网关：10.0.2.2\nDNS：10.0.2.3\n 一台虚拟机的多个网卡可以被设定使用 NAT， 第一个网卡连接了到专用网 10.0.2.0，第二个网卡连接到专用网络 10.0.3.0，等等。默认得到的客户端ip（IP Address）是10.0.2.15，网关（Gateway）是10.0.2.2，域名服务器（DNS）是10.0.2.3，可以手动参考这个进行修改。\nNAT方案优缺点：\n笔记本已插网线时： 虚拟机可以访问主机，虚拟机可以访问互联网，在做了端口映射后（最后有说明），主机可以访问虚拟机上的服务（如数据库）。\n笔记本没插网线时： 主机的“本地连接”有红叉的，虚拟机可以访问主机，虚拟机不可以访问互联网，在做了端口映射后，主机可以访问虚拟机上的服务（如数据库）。\n第二种 Bridged Adapter模式 网桥模式是我最喜欢的用的一种模式，同时，模拟度也是相当完美。你可以这样理解，它是通过主机网卡，架设了一条桥，直接连入到网络中了。因此，它使得虚拟机能被分配到一个网络中独立的IP，所有网络功能完全和在网络中的真实机器一样。\n虚拟机与主机关系：\n可以相互访问，因为虚拟机在真实网络段中有独立IP，主机与虚拟机处于同一网络段中，彼此可以通过各自IP相互访问。\n虚拟机于网络中其他主机关系：\n可以相互访问，同样因为虚拟机在真实网络段中有独立IP，虚拟机与所有网络其他主机处于同一网络段中，彼此可以通过各自IP相互访问。\n虚拟机于虚拟机关系：\n可以相互访问，原因同上。\nIP：一般是DHCP分配的，与主机的“本地连接”的IP 是同一网段的。虚拟机就能与主机互相通信。\n笔记本已插网线时：（若网络中有DHCP服务器）主机与虚拟机会通过DHCP分别得到一个IP，这两个IP在同一网段。 主机与虚拟机可以ping通，虚拟机可以上互联网。\n笔记本没插网线时：主机与虚拟机不能通信。主机的“本地连接”有红叉，就不能手工指定IP。虚拟机也不能通过DHCP得到IP地址，手工指定IP后，也无法与主机通信，因为主机无IP。\n这时主机的VirtualBox Host-Only Network 网卡是有ip的，192.168.56.1。虚拟机就算手工指定了IP 192.168.56.*，也ping不能主机。\n第三种 Internal模式 内网模式，顾名思义就是内部网络模式，虚拟机与外网完全断开，只实现虚拟机于虚拟机之间的内部网络模式。\n虚拟机与主机关系：\n不能相互访问，彼此不属于同一个网络，无法相互访问。\n虚拟机与网络中其他主机关系：\n不能相互访问，理由同上。\n虚拟机与虚拟机关系：\n可以相互访问，前提是在设置网络时，两台虚拟机设置同一网络名称。如上配置图中，名称为intnet。\nIP: VirtualBox的DHCP服务器会为它分配IP ，一般得到的是192.168.56.101，因为是从101起分的，也可手工指定192.168.56.*。\n笔记本已插网线时：虚拟机可以与主机的VirtualBox Host-Only Network 网卡通信\n这种方案不受主机本地连接（网卡）是否有红叉的影响。\n第四种 Host-only Adapter模式 主机模式，这是一种比较复杂的模式，需要有比较扎实的网络基础知识才能玩转。可以说前面几种模式所实现的功能，在这种模式下，通过虚拟机及网卡的设置都可以被实现。\n我们可以理解为Vbox在主机中模拟出一张专供虚拟机使用的网卡，所有虚拟机都是连接到该网卡上的，我们可以通过设置这张网卡来实现上网及其他很多功能，比如（网卡共享、网卡桥接等）。\n虚拟机与主机关系\n默认不能相互访问，双方不属于同一IP段，host-only网卡默认IP段为192.168.56.X 子网掩码为255.255.255.0，后面的虚拟机被分配到的也都是这个网段。通过网卡共享、网卡桥接等，可以实现虚拟机于主机相互访问。\n虚拟机与网络主机关系\n默认不能相互访问，原因同上，通过设置，可以实现相互访问。\n虚拟机与虚拟机关系\n默认可以相互访问，都是同处于一个网段。\n虚拟机访问主机 用的是主机的VirtualBox Host-Only Network网卡的IP：192.168.56.1 ，不管主机“本地连接”有无红叉，永远通。\n主机访问虚拟机，用是的虚拟机的网卡3的IP： 192.168.56.101 ，不管主机“本地连接”有无红叉，永远通。\n虚拟机访问互联网，用的是自己的网卡2， 这时主机要能通过“本地连接”有线上网，（无线网卡不行）\n通过对以上几种网络模式的了解，我们就可以灵活运用，模拟组建出我们所想要的任何一种网络环境了。\n比如我想模拟出来一个一台主机，监控一个局域网上网情况的网络环境。\n首先我开启了两台虚拟机vhost1与vhost2，当然如果硬件允许，我同样可以再增加vhost3、vhost4…\n所有的vhost我都设置成internat内网模式，网络名称为intnal，网关为192.168.56.100，意思就是通过 192.168.56.100网卡上网。其中有一台vhost1我设置为双网卡，一张为内网模式（192.168.56.100），一张为网桥模式（192.168.1.101）。两张网卡\n设置双网卡共享上网\n虚拟机之间为局域网，其中有一台虚拟机vhost1通过与外网相连，所有局域网中的虚拟机又通过vhost1来实现上外网。这样vhost1就可以监控整个虚拟机局域网上网情况了。\nNAT 设置端口映射\n你可以设置一个虚拟机的服务（比如 WEB 服务），通过使用命令行工具 VboxManage 代理。你需要知道虚拟机的服务使用哪个端口，然后决定在主机上使用哪个端口（通常但不总是想要使虚拟机和主机使用同一个端口）。在主机上提供一个服务需要使用一个端口，你能使用在主机上没有准备用来提供服务的任何端口。一个怎样设置新的 NAT 例子，在虚拟机上连接到一个 ssh 服务器，需要下面的三个命令：\nVBoxManage setextradata 'Linux Guest' 'VBoxInternal/Devices/pcnet/0/LUN#0/Config/guestssh/Protocol' TCP\rVBoxManage setextradata 'Linux Guest' 'VBoxInternal/Devices/pcnet/0/LUN#0/Config/guestssh/GuestPort' 22\rVBoxManage setextradata 'Linux Guest' 'VBoxInternal/Devices/pcnet/0/LUN#0/Config/guestssh/HostPort' 2222\r 说明：VboxManage 是一个命令行程序，请查询你的 VirtualBox 安装目录，\u0026lsquo;Linux Guest\u0026rsquo; 是虚拟主机名。guestssh 是一个自定义的名称，你可以任意设置，通过上面的三个命令，把虚拟机的 22 端口 转发到主机的 2222 端口。\n又比如，我在虚拟机 debian 上安装了 apache2 服务器，使用 80 端口，映射到主机的 80 端口。使用下面的命令。\n'C:\\Program Files\\innotek VirtualBox\\VBoxManage.exe' setextradata 'debian' 'VBoxInternal/Devices/pcnet/0/LUN#0/Config/huzhangsheng/Protocol' TCP\r'C:\\Program Files\\innotek VirtualBox\\VBoxManage.exe' setextradata 'debian' 'VBoxInternal/Devices/pcnet/0/LUN#0/Config/huzhangsheng/GuestPort' 80\r'C:\\Program Files\\innotek VirtualBox\\VBoxManage.exe' setextradata 'debian' 'VBoxInternal/Devices/pcnet/0/LUN#0/Config/huzhangsheng/HostPort' 80\r  注意：要使设置生效，请关掉 VirtualBox 再运行虚拟机，我把 VirtualBox 安装在 winxp 上，在虚拟机中安装 debian 4.02r ，虚拟机名是 debian ，并安装了 apache2 php5 mysql-server ，在主机上用IE浏览 http://localhost，成功转发到虚拟机 debian 的 apache2 web 服务器上\n 个人感觉通过使用端口映射的方式很不爽，还不如直接桥接来的快，现在多数情况下连接到网络是没问题的，端口映射还需要在宿主跟虚拟机都额外开某个服务，感觉不爽。\n“网络”配置页面有4个方案：\n1：NAT 网络地址转换（Network Address Translation）\n2：Birdged Network 桥接\n3：Internal Network 内部网络（可以是虚拟机与虚拟机之间）\n4：Host-Only 只与主机通信（大概吧）\n安装完VirtualBox2.2后，主机多了一个“VirtualBox Host-Only Network ”本地网卡。\n我的网络环境：\n主机：\n系统：xp\n“本地连接”的IP：由于是笔记本，经常换工作网络环境，都是通过DHCP分配的，有时候还无网络，“本地连接”有红叉（对主机与虚拟机通信有影响）。\n“VirtualBox Host-Only Network网卡”IP：192.168.56.1 ,因为VirtualBox的DHCP服务器IP是192.168.56.100，要在同一网段。\n虚拟机：要能与主机互相通信，要能访问互联网（不须要被互联网访问）。\n系统：win2003\n网卡1，网卡2，网卡3 后面说各网卡的配置情况\n各网卡的配置情况\n网卡1： 用NAT方案\nIP:10.0.2.15\n网关：10.0.2.2\nDNS：10.0.2.3\n为什么这样配置？因为VirtualBox的帮助中，有以下一段说明（英译汉）:\n一台虚拟机的多个网卡可以被设定使用 NAT， 第一个网卡连接了到专用网 10.0.2.0，第二个网卡连接到专用网络 10.0.3.0，等等。默认得到的客户端ip（IP Address）是10.0.2.15，网关（Gateway）是10.0.2.2，域名服务器（DNS）是10.0.2.3，可以手动参考这个进行修改。\nNAT方案优缺点：\n笔记本已插网线时： 虚拟机可以访问主机，虚拟机可以访问互联网，在做了端口映射后（最后有说明），主机可以访问虚拟机上的服务（如数据库）。\n笔记本没插网线时： 主机的“本地连接”有红叉的，虚拟机可以访问主机，虚拟机不可以访问互联网，在做了端口映射后，主机可以访问虚拟机上的服务（如数据库）。\n网卡2：用Birdged Network 方案\nIP：一般是DHCP分配的，与主机的“本地连接”的IP 是同一网段的。虚拟机就能与主机互相通信。\n笔记本已插网线时：（若网络中有DHCP服务器）主机与虚拟机会通过DHCP分别得到一个IP，这两个IP在同一网段。 主机与虚拟机可以ping通，虚拟机可以上互联网。\n笔记本没插网线时：主机与虚拟机不能通信。主机的“本地连接”有红叉，就不能手工指定IP。虚拟机也不能通过DHCP得到IP地址，手工指定IP后，也无法与主机通信，因为主机无IP。\n这时主机的VirtualBox Host-Only Network 网卡是有ip的，192.168.56.1。虚拟机就算手工指定了IP 192.168.56.*，也ping不能主机。\n网卡3： 用Host-Only 方案\nip: VirtualBox的DHCP服务器会为它分配IP ，一般得到的是192.168.56.101，因为是从101起分的，也可手工指定192.168.56.*。\n笔记本已插网线时：虚拟机可以与主机的VirtualBox Host-Only Network 网卡通信\n笔记本没插网线时：虚拟机可以与主机的VirtualBox Host-Only Network 网卡通信\n这种方案不受主机本地连接（网卡）是否有红叉的影响。\n以上三种方案，可以右击虚拟机窗口最下边 两个小电视 的图标快速切换。满足各种网络环境。\n关于Internal Network 方案，我也没试。\n上面三种方案的总结\n同进启用下面两个方案：\n网卡2：用Birdged Network 方案\n网卡3： 用Host-Only 方案\n虚拟机访问主机 用的是主机的VirtualBox Host-Only Network网卡的IP：192.168.56.1 ，不管主机“本地连接”有无红叉，永远通。\n主机访问虚拟机，用是的虚拟机的网卡3的IP： 192.168.56.101 ，不管主机“本地连接”有无红叉，永远通。\n虚拟机访问互联网，用的是自己的网卡2， 这时主机要能通过“本地连接”有线上网，（无线网卡不行）\nVirtualBox虚拟机网络设置四种模式刚看起来很头晕，不过只要理解四种模式的作用就可以灵活使用了\n","id":45,"section":"posts","summary":"转载 · 原文链接：https://www.douban.com/group/topic/15558388/ 前言 最近在捣鼓VirtualBox，","tags":null,"title":"VirtualBox虚拟机网络模式","uri":"https://bluestaree.github.io/2021/01/virtualbox%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F/","year":"2021"},{"content":"  转载 · 原文链接：https://www.jianshu.com/p/a80b88b7076b，\nhttps://blog.csdn.net/weixin_42284052/article/details/114543215\n 前提介绍 一般的程序应用当使用者访问不同，并且进入相对应的程序页面，则会把用户相关数据传输到后台这里。在传输的时候需要带上标识（租户ID），以便程序将数据进行隔离。当不同的租户使用同一个程序服务，这里就需要考虑一个数据隔离的情况。\n什么是多租户技术  多租户技术或称多重租赁技术，是一种软件架构技术，是实现如何在多用户环境下（此处的多用户一般是面向企业）共用相同的系统或程序组件，并且确保各用户间数据隔离性。 在一台服务器上运行单个应用实例，它为多个租户（客户）提供服务。从定义中我们可以理解：多租户是一种架构，目的是为了让多用户环境下使用同一套程序，且保证用户间数据隔离。多租户的重点就是同程序下实现多用户数据的隔离。  数据隔离有三种方案：  独立数据库：简单来说就是一个租户使用一个数据库，这种数据隔离级别最高，安全性最好，但是提高成本。 共享数据库、隔离数据架构：多租户使用同一个数据裤，但是每个租户对应一个Schema(数据库user)。 共享数据库、共享数据架构：使用同一个数据库，同一个Schema，但是在表中增加了租户ID的字段，这种共享数据程度最高，隔离级别最低。   优点：三种方案比较，第三种方案的维护和购置成本最低，允许每个数据库支持的租户数量最多。 缺点：隔离级别最低，安全性最低，需要在设计开发时加大对安全的开发量； 数据备份和恢复最困难，需要逐表逐条备份和还原。  多租户具体实现 利用MybatisPlus实现 这里我们选用了第三种方案（共享数据库，共享 Schema，共享数据表）来实现，也就意味着，每个数据表都需要有一个租户标识(provider_id)\n现在有数据库表(user)如下：\n   字段名 字段类型 描述     id BIGINT(20) 主键   provider_id BIGINT(20) 服务商ID   name VARCHAR(30) 姓名    将provider_id视为租户ID，用来隔离租户与租户之间的数据，如果要查询当前服务商的用户，SQL大致如下：\nSELECT * FROM user t WHERE t.name LIKE '%Tom%' AND t.provider_id = 1;\r 试想一下，除了一些系统共用的表以外，其他租户相关的表，我们都需要不厌其烦的加上AND t.provider_id = ?查询条件，稍不注意就会导致数据越界，数据安全问题让人担忧。\n好在有了MybatisPlus这个神器，可以极为方便的实现多租户SQL解析器，官方文档如下： http://mp.baomidou.com/guide/\u0026hellip;\n这里终于进入了正题，开始搭建一个极为简单的开发环境吧!\n#schema.sql\rDROP TABLE IF EXISTS user;\rCREATE TABLE user\r(\rid BIGINT(20) NOT NULL COMMENT '主键',\rprovider_id BIGINT(20) NOT NULL COMMENT '服务商ID',\rname VARCHAR(30) NULL DEFAULT NULL COMMENT '姓名',\rPRIMARY KEY (id)\r);\r#data.sql\rINSERT INTO user (id, provider_id, name) VALUES (1, 1, 'Tony老师');\rINSERT INTO user (id, provider_id, name) VALUES (2, 1, 'William老师');\rINSERT INTO user (id, provider_id, name) VALUES (3, 2, '路人甲');\rINSERT INTO user (id, provider_id, name) VALUES (4, 2, '路人乙');\rINSERT INTO user (id, provider_id, name) VALUES (5, 2, '路人丙');\rINSERT INTO user (id, provider_id, name) VALUES (6, 2, '路人丁');\r MybatisPlus Config\n基础环境搭建完成，现在开始配置MybatisPlus多租户相关的实现。\n1) 核心配置：TenantSqlParser\n@Configuration\r@MapperScan(\u0026quot;com.wuwenze.mybatisplusmultitenancy.mapper\u0026quot;)\rpublic class MybatisPlusConfig {\rprivate static final String SYSTEM_TENANT_ID = \u0026quot;provider_id\u0026quot;;\rprivate static final List IGNORE_TENANT_TABLES = Lists.newArrayList(\u0026quot;provider\u0026quot;);\r@Autowired\rprivate ApiContext apiContext;\r@Bean\rpublic PaginationInterceptor paginationInterceptor() {\rPaginationInterceptor paginationInterceptor = new PaginationInterceptor();\r// SQL解析处理拦截：增加租户处理回调。\rTenantSqlParser tenantSqlParser = new TenantSqlParser()\r.setTenantHandler(new TenantHandler() {\r@Override\rpublic Expression getTenantId() {\r// 从当前系统上下文中取出当前请求的服务商ID，通过解析器注入到SQL中。\rLong currentProviderId = apiContext.getCurrentProviderId();\rif (null == currentProviderId) {\rthrow new RuntimeException(\u0026quot;#1129 getCurrentProviderId error.\u0026quot;);\r}\rreturn new LongValue(currentProviderId);\r}\r@Override\rpublic String getTenantIdColumn() {\rreturn SYSTEM_TENANT_ID;\r}\r@Override\rpublic boolean doTableFilter(String tableName) {\r// 忽略掉一些表：如租户表(provider)本身不需要执行这样的处理。\rreturn IGNORE_TENANT_TABLES.stream().anyMatch((e) -\u0026gt; e.equalsIgnoreCase(tableName));\r}\r});\rpaginationInterceptor.setSqlParserList(Lists.newArrayList(tenantSqlParser));\rreturn paginationInterceptor;\r}\r@Bean(name = \u0026quot;performanceInterceptor\u0026quot;)\rpublic PerformanceInterceptor performanceInterceptor() {\rreturn new PerformanceInterceptor();\r}\r}\r 2) 核心配置：ApiContext\n@Component\rpublic class ApiContext {\rprivate static final String KEY_CURRENT_PROVIDER_ID = \u0026quot;KEY_CURRENT_PROVIDER_ID\u0026quot;;\rprivate static final Map\u0026lt;String, Object\u0026gt; mContext = Maps.newConcurrentMap();\rpublic void setCurrentProviderId(Long providerId) {\rmContext.put(KEY_CURRENT_PROVIDER_ID, providerId);\r}\rpublic Long getCurrentProviderId() {\rreturn (Long) mContext.get(KEY_CURRENT_PROVIDER_ID);\r}\r}\r 单元测试\n@Slf4j\r@RunWith(SpringRunner.class)\r@FixMethodOrder(MethodSorters.JVM)\r@SpringBootTest(classes = MybatisPlusMultiTenancyApplication.class)\rpublic class MybatisPlusMultiTenancyApplicationTests {\r@Autowired\rprivate ApiContext apiContext;\r@Autowired\rprivate UserMapper userMapper;\r@Before\rpublic void before() {\r// 在上下文中设置当前服务商的ID\rapiContext.setCurrentProviderId(1L);\r}\r@Test\rpublic void insert() {\rUser user = new User().setName(\u0026quot;新来的Tom老师\u0026quot;);\rAssert.assertTrue(userMapper.insert(user) \u0026gt; 0);\ruser = userMapper.selectById(user.getId());\rlog.info(\u0026quot;#insert user={}\u0026quot;, user);\r// 检查插入的数据是否自动填充了租户ID\rAssert.assertEquals(apiContext.getCurrentProviderId(), user.getProviderId());\r}\r@Test\rpublic void selectList() {\ruserMapper.selectList(null).forEach((e) -\u0026gt; {\rlog.info(\u0026quot;#selectList, e={}\u0026quot;, e);\r// 验证查询的数据是否超出范围\rAssert.assertEquals(apiContext.getCurrentProviderId(), e.getProviderId());\r});\r}\r}\r 运行结果：\n2018-11-29 21:07:14.262 INFO 18688 --- [ main] .MybatisPlusMultiTenancyApplicationTests : Started MybatisPlusMultiTenancyApplicationTests in 2.629 seconds (JVM running for 3.904)\r2018-11-29 21:07:14.554 DEBUG 18688 --- [ main] c.w.m.mapper.UserMapper.insert : ==\u0026gt; Preparing: INSERT INTO user (id, name, provider_id) VALUES (?, ?, 1)\r2018-11-29 21:07:14.577 DEBUG 18688 --- [ main] c.w.m.mapper.UserMapper.insert : ==\u0026gt; Parameters: 1068129257418178562(Long), 新来的Tom老师(String)\r2018-11-29 21:07:14.577 DEBUG 18688 --- [ main] c.w.m.mapper.UserMapper.insert : \u0026lt;== Updates: 1\rTime：0 ms - ID：com.wuwenze.mybatisplusmultitenancy.mapper.UserMapper.insert\rExecute SQL：INSERT INTO user (id, name, provider_id) VALUES (?, ?, 1) {1: 1068129257418178562, 2: STRINGDECODE('\\u65b0\\u6765\\u7684Tom\\u8001\\u5e08')}\r2018-11-29 21:07:14.585 DEBUG 18688 --- [ main] c.w.m.mapper.UserMapper.selectById : ==\u0026gt; Preparing: SELECT id, provider_id, name FROM user WHERE user.provider_id = 1 AND id = ?\r2018-11-29 21:07:14.595 DEBUG 18688 --- [ main] c.w.m.mapper.UserMapper.selectById : ==\u0026gt; Parameters: 1068129257418178562(Long)\r2018-11-29 21:07:14.614 DEBUG 18688 --- [ main] c.w.m.mapper.UserMapper.selectById : \u0026lt;== Total: 1\r2018-11-29 21:07:14.615 INFO 18688 --- [ main] .MybatisPlusMultiTenancyApplicationTests : #insert user=User(id=1068129257418178562, providerId=1, name=新来的Tom老师)\rTime：19 ms - ID：com.wuwenze.mybatisplusmultitenancy.mapper.UserMapper.selectById\rExecute SQL：SELECT id, provider_id, name FROM user WHERE user.provider_id = 1 AND id = ? {1: 1068129257418178562}\r2018-11-29 21:07:14.626 DEBUG 18688 --- [ main] c.w.m.mapper.UserMapper.selectList : ==\u0026gt; Preparing: SELECT id, provider_id, name FROM user WHERE user.provider_id = 1\rTime：0 ms - ID：com.wuwenze.mybatisplusmultitenancy.mapper.UserMapper.selectList\rExecute SQL：SELECT id, provider_id, name FROM user WHERE user.provider_id = 1\r2018-11-29 21:07:14.629 DEBUG 18688 --- [ main] c.w.m.mapper.UserMapper.selectList : ==\u0026gt; Parameters:\r2018-11-29 21:07:14.630 DEBUG 18688 --- [ main] c.w.m.mapper.UserMapper.selectList : \u0026lt;== Total: 3\r2018-11-29 21:07:14.632 INFO 18688 --- [ main] .MybatisPlusMultiTenancyApplicationTests : #selectList, e=User(id=1, providerId=1, name=Tony老师)\r2018-11-29 21:07:14.632 INFO 18688 --- [ main] .MybatisPlusMultiTenancyApplicationTests : #selectList, e=User(id=2, providerId=1, name=William老师)\r2018-11-29 21:07:14.632 INFO 18688 --- [ main] .MybatisPlusMultiTenancyApplicationTests : #selectList, e=User(id=1068129257418178562, providerId=1, name=新来的Tom老师)\r 从打印的日志不难看出，这个方案相当完美，仅需简单的配置，让开发者完全忽略了(provider_id)字段的存在，同时又最大程度的保证了数据的安全性，可谓是一举两得！\n 注：特定SQL过滤，如果在程序中，有部分SQL不需要加上租户ID的表示，需要过滤特定的sql，可以通过如下两种方式：\n 在配置分页插件中加上配置ISqlParserFilter解析器，配置SQL很多，比较麻烦，不建议；\npaginationInterceptor.setSqlParserFilter(new ISqlParserFilter() {\r@Override\rpublic boolean doFilter(MetaObject metaObject) {\rMappedStatement ms = SqlParserHelper.getMappedStatement(metaObject);\r// 对应Mapper、dao中的方法\rif(\u0026quot;com.example.demo.mapper.UserMapper.selectList\u0026quot;.equals(ms.getId())){\rreturn true;\r}\rreturn false;\r}\r});\r 通过租户注解 @SqlParser(filter = true) 的形式，目前只能作用于Mapper的方法上：\npublic interface UserMapper extends BaseMapper\u0026lt;User\u0026gt; {\r/**\r* 自定Wrapper修改\r*\r* @param userWrapper 条件构造器\r* @param user 修改的对象参数\r* @return\r*/\r@SqlParser(filter = true)\rint updateByMyWrapper(@Param(Constants.WRAPPER) Wrapper\u0026lt;User\u0026gt; userWrapper, @Param(\u0026quot;user\u0026quot;) User user);\r}\r ","id":46,"section":"posts","summary":"转载 · 原文链接：https://www.jianshu.com/p/a80b88b7076b， https://blog.csdn.net/weixin_42284052/article/details/114543215 前提介绍 一般的程序应用当使用者访问不同，并且","tags":["mybatis","SaaS"],"title":"Mybatis Plus实现多租户解析的应用","uri":"https://bluestaree.github.io/2021/01/mybatis-plus%E7%A7%9F%E6%88%B7%E8%A7%A3%E6%9E%90%E7%9A%84%E5%BA%94%E7%94%A8/","year":"2021"},{"content":" 因业务需要对手机号进行保密操作，对金额显示加上分隔符\n代码如下：\npublic class StringReplaceUtils {\r/**\r* 对字符加星号处理：根据字符串长度替换\r* @param content 传入的字符串\r* @return 带星号的字符串\r*/\rpublic static String replaceString2Star(String content) {\rint nameLength = content.length();\rif (nameLength \u0026gt;= 2 \u0026amp;\u0026amp; nameLength \u0026lt;= 3) {\rreturn StringReplaceUtils.replaceString2Star(content, 1, 0);\r} else if (nameLength \u0026gt;= 4 \u0026amp;\u0026amp; nameLength \u0026lt;= 6) {\rreturn StringReplaceUtils.replaceString2Star(content, 1, 1);\r} else if (nameLength == 7) {\rreturn StringReplaceUtils.replaceString2Star(content, 1, 2);\r} else if (nameLength == 8) {\rreturn StringReplaceUtils.replaceString2Star(content, 2, 2);\r} else if (nameLength == 9) {\rreturn StringReplaceUtils.replaceString2Star(content, 2, 3);\r} else if (nameLength == 10) {\rreturn StringReplaceUtils.replaceString2Star(content, 3, 3);\r} else if (nameLength \u0026gt;= 11) {\rreturn StringReplaceUtils.replaceString2Star(content, 3, 4);\r}\rreturn content;\r}\r/**\r* 对字符加星号处理：除前面几位和后面几位外，其他的字符以星号代替\r* @param content 传入的字符串\r* @param frontNum 保留前面字符的位数\r* @param endNum 保留后面字符的位数\r* @return 带星号的字符串\r*/\rpublic static String replaceString2Star(String content, int frontNum, int endNum) {\rif (content == null || content.trim().isEmpty()) {\rreturn content;\r}\rint len = content.length();\rif (frontNum \u0026gt;= len || frontNum \u0026lt; 0 || endNum \u0026gt;= len || endNum \u0026lt; 0) {\rreturn content;\r}\rif (frontNum + endNum \u0026gt;= len) {\rreturn content;\r}\rint beginIndex = frontNum;\rint endIndex = len - endNum;\rchar[] cardChar = content.toCharArray();\rfor (int j = beginIndex; j \u0026lt; endIndex; j++) {\rcardChar[j] = '*';\r}\rreturn new String(cardChar);\r}\r/**\r* 手机号加密处理\r* @param phone 手机号\r* @return 带星号的字符串\r*/\rpublic static String encryptPhone(String phone) {\rreturn replaceString2Star(phone, 3, 4);\r}\r/**\r* 判断字符串中是否包含中文\r* @param str 待校验字符串\r* @return 是否为中文\r* @warn 不能校验是否为中文标点符号\r*/\rpublic static boolean isContainChinese(String str) {\rPattern p = Pattern.compile(\u0026quot;[\\u4e00-\\u9fa5]\u0026quot;);\rMatcher m = p.matcher(str);\rif (m.find()) {\rreturn true;\r}\rreturn false;\r}\r/**\r* 将每三个数字（或字符）加上分隔符处理\r* 5000000.00 --\u0026gt; 5,000,000.00\r* 20000000 --\u0026gt; 20,000,000\r* @param str 000000101\r* @param separator 分隔符 \u0026quot;/\u0026quot;\r* @return 000/000/101\r*/\rpublic static String strAddSeparator(String str, String separator) {\rif (str == null || str.trim().isEmpty() || separator == null || separator.trim().isEmpty()) {\rreturn str;\r}\rString addCommaStr = str; // 需要添加分隔符的字符串（整数）\r// 将传进数字反转\rString reverseStr = new StringBuilder(addCommaStr).reverse().toString();\rString strTemp = \u0026quot;\u0026quot;;\rfor (int i = 0; i \u0026lt; reverseStr.length(); i++) {\rif (i * 3 + 3 \u0026gt; reverseStr.length()) {\rstrTemp += reverseStr.substring(i * 3, reverseStr.length());\rbreak;\r}\rstrTemp += reverseStr.substring(i * 3, i * 3 + 3) + separator;\r}\r// 将 \u0026quot;000/000/001/\u0026quot; 中最后一个\u0026quot;/\u0026quot;去除\rif (strTemp.endsWith(separator)) {\rstrTemp = strTemp.substring(0, strTemp.length() - 1);\r}\r// 将数字重新反转\rString resultStr = new StringBuilder(strTemp).reverse().toString();\rreturn resultStr;\r}\r}\r 参考文章：https://blog.csdn.net/wskii/article/details/79612298\n","id":47,"section":"posts","summary":"因业务需要对手机号进行保密操作，对金额显示加上分隔符 代码如下： public class StringReplaceUtils { /** * 对字符加星号处理：根据字符串长度替换 * @param content 传入的字符串 * @return 带星号的","tags":null,"title":"保留首尾字符，中间全部变为星号","uri":"https://bluestaree.github.io/2021/01/%E4%BF%9D%E7%95%99%E9%A6%96%E5%B0%BE%E5%AD%97%E7%AC%A6%E5%85%B6%E4%BD%99%E5%85%A8%E9%83%A8%E5%8F%98%E4%B8%BA%E6%98%9F%E5%8F%B7/","year":"2021"},{"content":"  转载 · 原文链接：https://baijiahao.baidu.com/s?id=1685490934094994913\u0026amp;wfr=spider\u0026amp;for=pc\n 因最近项目业务需求，最近业务场景需要使用到多数据源进行操作，在使用@DS初步尝试后并未发现问题，能够正常切换数据源。后续自测流程时发现多数据源事务控制上存在问题。\n 由于使用了微服务，会有多个数据库的情况，有时业务需要，需要切换数据源，所以使用了Mybatis plus的@DS来切换多数据源\nyml数据库配置如下：\nservice如下，默认是master数据源\nuserService\nbookService\n但是神奇的事发生的，bookService的数据库应该是common，但是却是master的，也就是说@DS切换数据源没有起作用\n于是开始排查\n去除MasterService.upload上面的@Transactional，数据源切换正常，但是事务无效BookService的save上面加@Transactional，数据源没有切换BookService的save上面加@Transactional(propagation = Propagation.REQUIRES_NEW)，数据源切换，且事务有效原因：\n开启事务的同时，会从数据库连接池获取数据库连接；如果内层的service使用@DS切换数据源，只是又做了一层拦截，但是并没有改变整个事务的连接在这个事务内的所有数据库操作，都是在事务连接建立之后，所以会产生数据源没有切换的问题为了使@DS起作用，必须替换数据库连接，也就是改变事务的传播机智，产生新的事务，获取新的数据库连接所以bookService的save方法上除了加@Transactional外，还需要设置propagation = Propagation.REQUIRES_NEW使得代码走以下逻辑：\n在走startTransaction，再走doBegin，重新创建新事务，获取新的数据库连接，从而得到@DS的数据源\n最终代码如下，只需要修改的是bookService\n在方法上增加：@Transactional(propagation = Propagation.REQUIRES_NEW)\n@DS数据源切换生效@Transaction事务生效需要注意：\nmaster：userService\ncommon：bookService\ncommon数据库的操作，需要在master之后，这样当bookService.save失败，会使得userService回滚； 如果common的操作先，那当userService失败，无法使bookService回滚\n会回滚\n@Transactional(rollbackFor = Exception.class)\rpublic void upload(ReqDto respDto){\ruserService.save(respDto);\rbookService.save(respDto);\r}\r 不会回滚\n@Transactional(rollbackFor = Exception.class)\rpublic void upload(ReqDto respDto){\rbookService.save(respDto);\ruserService.save(respDto);\r}\r ","id":48,"section":"posts","summary":"转载 · 原文链接：https://baijiahao.baidu.com/s?id=1685490934094994913\u0026amp;wfr=s","tags":["mybatis"],"title":"Mybatis plus的多数据源@DS事务问题","uri":"https://bluestaree.github.io/2020/12/mybatis-plus%E7%9A%84%E5%A4%9A%E6%95%B0%E6%8D%AE%E6%BA%90ds%E4%BA%8B%E5%8A%A1%E9%97%AE%E9%A2%98/","year":"2020"},{"content":"  本文介绍开源项目：anji-plus-captcha开源项目集成流程\ngithub地址:\thttps://github.com/anji-plus/captcha/\n码云地址:\thttps://gitee.com/xiweicheng/captcha\n 第一步： 加入pom文件依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.anji-plus\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;captcha\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 第二步： 重写redis服务实现\nimport com.anji.captcha.service.CaptchaCacheService;\rpublic class CaptchaCacheServiceRedisImpl implements CaptchaCacheService {\r@Override\rpublic String type() {\rreturn \u0026quot;redis\u0026quot;;\r}\r@Autowired\rprivate StringRedisTemplate stringRedisTemplate;\r@Override\rpublic void set(String key, String value, long expiresInSeconds) {\rstringRedisTemplate.opsForValue().set(key, value, expiresInSeconds, TimeUnit.SECONDS);\r}\r@Override\rpublic boolean exists(String key) {\rreturn stringRedisTemplate.hasKey(key);\r}\r@Override\rpublic void delete(String key) {\rstringRedisTemplate.delete(key);\r}\r@Override\rpublic String get(String key) {\rreturn stringRedisTemplate.opsForValue().get(key);\r}\r@Override\rpublic Long increment(String key, long val) {\rreturn stringRedisTemplate.opsForValue().increment(key,val);\r}\r}\r 第三步： 自定义验证码背景图片，这里我的资源文件路径配置如下：\n目录结构\n resources  images captcha  pic-click slide  original slidingBlock        第四步： 添加配置类\n@Configuration\rpublic class CaptchaConfig {\r@Bean(name = \u0026quot;captchaCacheService\u0026quot;)\rpublic CaptchaCacheService captchaCacheService() {\rCaptchaCacheServiceRedisImpl captchaCacheServiceRedis = new CaptchaCacheServiceRedisImpl();\rCaptchaServiceFactory.cacheService.put(\u0026quot;redis\u0026quot;, captchaCacheServiceRedis);\rreturn captchaCacheServiceRedis;\r}\r@Bean\r@DependsOn(\u0026quot;captchaCacheService\u0026quot;)\rpublic CaptchaService captchaService() {\rProperties config = new Properties();\rconfig.put(Const.CAPTCHA_CACHETYPE, \u0026quot;redis\u0026quot;);\rconfig.put(Const.CAPTCHA_WATER_MARK, \u0026quot;\u0026quot;);\rconfig.put(Const.CAPTCHA_FONT_TYPE, \u0026quot;宋体\u0026quot;);\rconfig.put(Const.CAPTCHA_TYPE, \u0026quot;default\u0026quot;);\rconfig.put(Const.CAPTCHA_INTERFERENCE_OPTIONS, \u0026quot;0\u0026quot;);\rconfig.put(Const.ORIGINAL_PATH_JIGSAW, \u0026quot;classpath:images/captcha/slide\u0026quot;);\rconfig.put(Const.ORIGINAL_PATH_PIC_CLICK, \u0026quot;classpath:images/captcha/pic-click\u0026quot;);\rconfig.put(Const.CAPTCHA_SLIP_OFFSET, \u0026quot;5\u0026quot;);\rconfig.put(Const.CAPTCHA_AES_STATUS, \u0026quot;true\u0026quot;);\rconfig.put(Const.CAPTCHA_WATER_FONT, \u0026quot;宋体\u0026quot;);\rconfig.put(Const.CAPTCHA_CACAHE_MAX_NUMBER, \u0026quot;1000\u0026quot;);\rconfig.put(Const.CAPTCHA_TIMING_CLEAR_SECOND, \u0026quot;180\u0026quot;);\rconfig.put(Const.HISTORY_DATA_CLEAR_ENABLE, \u0026quot;1\u0026quot;);\rconfig.put(Const.REQ_FREQUENCY_LIMIT_ENABLE, \u0026quot;0\u0026quot;);\rconfig.put(Const.REQ_GET_LOCK_LIMIT, \u0026quot;10\u0026quot;);\rconfig.put(Const.REQ_GET_LOCK_SECONDS, \u0026quot;30\u0026quot;);\rconfig.put(Const.REQ_GET_MINUTE_LIMIT, \u0026quot;240\u0026quot;);\rconfig.put(Const.REQ_CHECK_MINUTE_LIMIT, \u0026quot;600\u0026quot;);\rconfig.put(Const.REQ_VALIDATE_MINUTE_LIMIT, \u0026quot;600\u0026quot;);\rconfig.put(Const.CAPTCHA_FONT_SIZE, \u0026quot;25\u0026quot;);\rconfig.put(Const.CAPTCHA_FONT_STYLE, Font.BOLD);\r//更多自定义参数，请参考service/springboot/../resources/application.properties\rif ((StrUtil.isNotBlank(config.getProperty(Const.ORIGINAL_PATH_JIGSAW))\r\u0026amp;\u0026amp; config.getProperty(Const.ORIGINAL_PATH_JIGSAW).startsWith(\u0026quot;classpath:\u0026quot;))\r|| (StrUtil.isNotBlank(config.getProperty(Const.ORIGINAL_PATH_PIC_CLICK))\r\u0026amp;\u0026amp; config.getProperty(Const.ORIGINAL_PATH_PIC_CLICK).startsWith(\u0026quot;classpath:\u0026quot;))) {\r//自定义resources目录下初始化底图\rconfig.put(Const.CAPTCHA_INIT_ORIGINAL, \u0026quot;true\u0026quot;);\rinitializeBaseMap(config.getProperty(Const.ORIGINAL_PATH_JIGSAW),\rconfig.getProperty(Const.ORIGINAL_PATH_PIC_CLICK));\r}\rCaptchaService s = CaptchaServiceFactory.getInstance(config);\rreturn s;\r}\rprivate static void initializeBaseMap(String jigsaw, String picClick) {\rImageUtils.cacheBootImage(getResourcesImagesFile(jigsaw + \u0026quot;/original/*.png\u0026quot;), getResourcesImagesFile(jigsaw + \u0026quot;/slidingBlock/*.png\u0026quot;), getResourcesImagesFile(picClick + \u0026quot;/*.png\u0026quot;));\r}\rpublic static Map\u0026lt;String, String\u0026gt; getResourcesImagesFile(String path) {\rMap\u0026lt;String, String\u0026gt; imgMap = new HashMap();\rPathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver();\rtry {\rResource[] resources = resolver.getResources(path);\rResource[] var4 = resources;\rint var5 = resources.length;\rfor(int var6 = 0; var6 \u0026lt; var5; ++var6) {\rResource resource = var4[var6];\rbyte[] bytes = FileCopyUtils.copyToByteArray(resource.getInputStream());\rString string = Base64Utils.encodeToString(bytes);\rString filename = resource.getFilename();\rimgMap.put(filename, string);\r}\r} catch (Exception var11) {\rvar11.printStackTrace();\r}\rreturn imgMap;\r}\r}\r 第五步： 控制层接口\n@RestController\r@RequestMapping(\u0026quot;/captcha\u0026quot;)\rpublic class CaptchaController {\r@Autowired\rprivate CaptchaService captchaService;\r@PostMapping(\u0026quot;/get\u0026quot;)\rpublic ResponseModel get(@RequestBody CaptchaVO captchaVO) {\rreturn captchaService.get(captchaVO);\r}\r@PostMapping(\u0026quot;/check\u0026quot;)\rpublic ResponseModel check(@RequestBody CaptchaVO captchaVO) {\rreturn captchaService.check(captchaVO);\r}\r@PostMapping(\u0026quot;/verify\u0026quot;)\rpublic ResponseModel verify(@RequestBody CaptchaVO captchaVO) {\rreturn captchaService.verification(captchaVO);\r}\r}\r 第六步： 定义二次校验过滤器\n@Component\rpublic class ValidateCodeFilter extends OncePerRequestFilter {\r@Autowired\rprivate CaptchaService captchaService;\r@Override\rprotected void doFilterInternal(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse,\rFilterChain filterChain) throws ServletException, IOException {\rRequestMatcher matcher = new AntPathRequestMatcher(\u0026quot;/**/userLogin/login\u0026quot;, HttpMethod.POST.toString());\rboolean matches = matcher.matches(httpServletRequest);\rString grantType = httpServletRequest.getParameter(\u0026quot;grantType\u0026quot;);\rif (matches\r\u0026amp;\u0026amp; StringUtils.equalsIgnoreCase(grantType, \u0026quot;password\u0026quot;)) {\rtry {\rvalidateCode(httpServletRequest);\rfilterChain.doFilter(httpServletRequest, httpServletResponse);\r} catch (Exception e) {\rint code = HttpStatus.ERROR;\rString msg = e.getMessage();\rServletUtils.renderString(httpServletResponse, JSON.toJSONString(Result.error(code, msg)));\r}\r} else {\rfilterChain.doFilter(httpServletRequest, httpServletResponse);\r}\r}\rprivate void validateCode(HttpServletRequest httpServletRequest) {\rString captchaVerification = httpServletRequest.getParameter(\u0026quot;captchaVerification\u0026quot;);\rCaptchaVO captchaVO = new CaptchaVO();\rcaptchaVO.setCaptchaVerification(captchaVerification);\rResponseModel response = captchaService.verification(captchaVO);\r// 验证码校验失败，返回信息告诉前端\rif(response.isSuccess() == false){\rString repCode = response.getRepCode();\rString repMsg = response.getRepMsg();\r// repCode 0000 无异常，代表成功\rif(RepCodeEnum.EXCEPTION.getCode().equals(repCode)) {\r// repCode 9999 服务器内部异常\r} else if(RepCodeEnum.BLANK_ERROR.getCode().equals(repCode)) {\r// repCode 0011 参数不能为空\r} else if(RepCodeEnum.API_CAPTCHA_INVALID.getCode().equals(repCode)) {\r// repCode 6110 验证码已失效，请重新获取\r} else if(RepCodeEnum.API_CAPTCHA_COORDINATE_ERROR.getCode().equals(repCode)) {\r// repCode 6111 验证失败\r} else if(RepCodeEnum.API_CAPTCHA_ERROR.getCode().equals(repCode)) {\r// repCode 6112 获取验证码失败,请联系管理员\r} else {\r// 其他异常\r}\r}\r}\r}\r 第七步： 前端代码, 参考官方文档，提供多种项目示例，这里不再扩展\nhttps://captcha.anji-plus.com/#/doc\n第八步： 启动后台服务 、前端页面服务\n接口联调测试:\n注意： 点选验证码乱码问题\n  如果将项目部署到linux服务器中 ，需保证字体库存在，否则将出现乱码问题,\n具体操作流程可参考官方文档\nhttps://captcha.anji-plus.com/#/doc\n及博客\nhttps://blog.csdn.net/weixin_44850882/article/details/121103708\n  限流功能BUG\n 慎用限流功能，存在永久key BUG，问题代码位置 FrequencyLimitHandler 如图位置：  问题出现场景：\n 正常获取 key （①操作） key刚好过期 此时不会执行if中的 set 方法（②操作） 执行 increment 方法就会在redis中插入一条永久key(③操作)  参考\nhttps://github.com/anji-plus/captcha/issues/66\n","id":49,"section":"posts","summary":"本文介绍开源项目：anji-plus-captcha开源项目集成流程 github地址: https://github.com/anji-plus/captcha/ 码云地址: https://gitee.com/xiweicheng/captcha 第一步： 加入pom文件依赖 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.anji-plus\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;captcha\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 第二步","tags":["captcha"],"title":"anji-plus-captcha行为验证码集成","uri":"https://bluestaree.github.io/2020/12/anji-plus-captcha%E8%A1%8C%E4%B8%BA%E9%AA%8C%E8%AF%81%E7%A0%81%E9%9B%86%E6%88%90/","year":"2020"},{"content":" 前言  在项目开发中，经常会遇到这样的场景：对于参数较多的接口，一般是定义参数VO类的方式进行接收，同时根据需要定义返回的VO类。这样做项目结构清晰，不存在多余属性值，缺点是：VO类定义多。另外的做法是，尽量将入参和返回信息都定义在都一个VO类中。缺点是前端会接收到无关的属性信息，影响前端开发。\n本文主要接收fastjson序列化参数之 WRITE_ONLY 与 READ_ONLY 的配置\n此配置也可以解决 使用@JsonIgnore 属性后无法接收前端参数的问题\n 当接口中请求参数Bean的字段被 @JsonProperty(access = Access.WRITE_ONLY) 约束时，能够正常接收参数（反序列化），但不参与序列化\n反之，被 @JsonProperty(access = Access.READ_ONLY) 约束时的属性，不能接收到前端传递的参数，能正常进行序列化，但不参与反序列化\n 测试准备 实体类\n@Data\r@ToString\rpublic class User implements Serializable {\rprivate static final long serialVersionUID = 1L;\r@TableId(value = \u0026quot;id\u0026quot;, type = IdType.AUTO)\rprivate Long id;\r@JsonProperty(access = JsonProperty.Access.READ_ONLY)\rprivate String username;\r@JsonProperty(access = JsonProperty.Access.READ_ONLY)\rprivate String avatar;\r@JsonProperty(access = JsonProperty.Access.WRITE_ONLY)\rprivate String email;\r@JsonProperty(access = JsonProperty.Access.WRITE_ONLY)\rprivate String password;\r}\r 控制层\n@Slf4j\r@RestController\r@RequestMapping(\u0026quot;/test\u0026quot;)\rpublic class JsonController {\r@PostMapping(\u0026quot;/json\u0026quot;)\rpublic User getUser(@RequestBody User user) {\rlog.info(\u0026quot;接收到的参数：{}\u0026quot; ,user);\ruser.setId(1L);\ruser.setUsername(\u0026quot;username1\u0026quot;);\ruser.setAvatar(\u0026quot;avatar1\u0026quot;);\ruser.setEmail(\u0026quot;email1\u0026quot;);\rreturn user;\r}\r}\r postman 发起测试请求，body参数如下\n请求结果\n后台接收参数:\n因此，总结如下：\nWRITE_ONLY:仅做反序列化操作。\nREAD_ONLY：仅做序列化操作。\n","id":50,"section":"posts","summary":"前言 在项目开发中，经常会遇到这样的场景：对于参数较多的接口，一般是定义参数VO类的方式进行接收，同时根据需要定义返回的VO类。这样做项目结构","tags":["json"],"title":"fastjson序列化之WRITE_ONLY 与 READ_ONLY","uri":"https://bluestaree.github.io/2020/10/fastjson%E5%BA%8F%E5%88%97%E5%8C%96%E4%B9%8Bwrite_only-%E4%B8%8E-read_only/","year":"2020"},{"content":" 场景： 最近开发项目中，有这样一个功能:管理人可自定义消息模板， 可在模板中插入动态参数，由后台进行替换，考虑了下，可以采用正则实现，参考文章 ： https://www.cnblogs.com/xied/p/12445036.html ，\ndemo代码实现：\npackage com.test.utils;\rimport org.apache.commons.lang3.StringUtils;\rimport java.util.HashMap;\rimport java.util.Map;\rimport java.util.regex.Matcher;\rimport java.util.regex.Pattern;\r/**\r* 模板内容替换工具\r*/\rpublic class StringTemplateUtils {\rpublic static final String DEF_REGEX=\u0026quot;\\\\$\\\\{([^}]+)}\u0026quot;; //${name}\rpublic static String render(String template, Map\u0026lt;String, String\u0026gt; data) {\rreturn render(template,data,DEF_REGEX);\r}\rpublic static String render(String template, Map\u0026lt;String, String\u0026gt; data,String regex) {\rif(StringUtils.isBlank(template)){\rreturn \u0026quot;\u0026quot;;\r}\rif(StringUtils.isBlank(regex)){\rreturn template;\r}\rif(data == null || data.size() == 0){\rreturn template;\r}\rtry {\rStringBuffer sb = new StringBuffer();\rPattern pattern = Pattern.compile(regex);\rMatcher matcher = pattern.matcher(template);\rwhile (matcher.find()) {\rString name = matcher.group(1);// 键名\rString value = data.get(name);// 键值\rif (value == null) {value = \u0026quot;\u0026quot;;}\rmatcher.appendReplacement(sb, value);\r}\rmatcher.appendTail(sb);\rreturn sb.toString();\r} catch (Exception e) {\re.printStackTrace();\r}\rreturn template;\r}\rpublic static void main(String args[]) {\rString template=\u0026quot;送您一张【${name}】的【${coupon}】优惠券，马上领取吧\u0026quot;;\rMap\u0026lt;String, String\u0026gt; data = new HashMap\u0026lt;String, String\u0026gt;();\rdata.put(\u0026quot;name\u0026quot;, \u0026quot;冬季棉袄\u0026quot;);\rdata.put(\u0026quot;coupon\u0026quot;, \u0026quot;20元\u0026quot;);\rSystem.out.println(render(template,data));\r}\r}\r 最后推荐一个 正则表达式调试工具\n建议收藏\n","id":51,"section":"posts","summary":"场景： 最近开发项目中，有这样一个功能:管理人可自定义消息模板， 可在模板中插入动态参数，由后台进行替换，考虑了下，可以采用正则实现，参考文章 ：","tags":["正则表达式"],"title":"正则表达式实现字符串模板替换","uri":"https://bluestaree.github.io/2020/09/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%AE%9E%E7%8E%B0%E6%A8%A1%E6%9D%BF%E6%9B%BF%E6%8D%A2/","year":"2020"},{"content":"  转载 · 原文链接：https://blog.csdn.net/weixin_43906974/article/details/107515953\n 场景：前端下拉框展示数据，老项目没有数据字典，在尽量不改动的情况下，可以使用以下方法\npackage com.example.demo.Enum;\rimport java.util.ArrayList;\rimport java.util.HashMap;\rimport java.util.List;\rimport java.util.Map;\r/**\r* XXXX枚举\r*/\rpublic enum TimeKeepingEnum {\rFIRST(1,\u0026quot;20钻石/分钟\u0026quot;),\rSECOND(2,\u0026quot;30钻石/分钟\u0026quot;),\rTHIRD(3,\u0026quot;40钻石/分钟\u0026quot;);\rprivate int value;\rprivate String desc;\rprivate TimeKeepingEnum(int value, String desc) {\rthis.value = value;\rthis.desc = desc;\r}\rpublic int getValue() {\rreturn value;\r}\rpublic void setValue(int value) {\rthis.value = value;\r}\rpublic String getDesc() {\rreturn desc;\r}\rpublic void setDesc(String desc) {\rthis.desc = desc;\r}\r/**\r* 请求返回的Enum集合数据\r* @return\r*/\rpublic static List\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; getTimeKeepingEnumList() {\rList\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt; list = new ArrayList\u0026lt;Map\u0026lt;String, Object\u0026gt;\u0026gt;();\rfor (TimeKeepingEnum timeKeepingEnum: TimeKeepingEnum.values()) {\rMap item= new HashMap\u0026lt;String, Object\u0026gt;();\ritem.put(\u0026quot;value\u0026quot;,timeKeepingEnum.value);\ritem.put(\u0026quot;desc\u0026quot;,timeKeepingEnum.desc);\rlist.add(item);\r}\rreturn list;\r}\rpublic static void main(String[] args) {\rSystem.out.println(TimeKeepingEnum.getTimeKeepingEnumList());\r}\r}\r ","id":52,"section":"posts","summary":"转载 · 原文链接：https://blog.csdn.net/weixin_43906974/article/details/10751595","tags":null,"title":"枚举类转为集合数据","uri":"https://bluestaree.github.io/2020/09/%E6%9E%9A%E4%B8%BE%E7%B1%BB%E8%BD%AC%E4%B8%BA%E9%9B%86%E5%90%88%E6%95%B0%E6%8D%AE/","year":"2020"},{"content":" 最近在项目开发中遇到了个bug，排查后发现Long类型主键字段作为参数返回后，前端接收时出现精度丢失问题\n 原因：前端js对Long类型支持的精度不够，导致后端使用的Long传到前端丢失精度，比如现在分布式id生成算法“雪花算法”在使用中就会出现问题。\n 解决方式： 1、后端的Long类型的id转用String存储，不推荐，失去了其Long类型本身的意义。\n2、在Long类型字段上使用注解标明序列化方式，代码量不大的情况可以考虑\n3、实现WebMvcConfigurer接口，重写configureMessageConverters方法\n@Override\rpublic void configureMessageConverters(List\u0026lt;HttpMessageConverter\u0026lt;?\u0026gt;\u0026gt; converters) {\rMappingJackson2HttpMessageConverter jackson2HttpMessageConverter = new MappingJackson2HttpMessageConverter();\rObjectMapper objectMapper = new ObjectMapper();\rSimpleModule simpleModule = new SimpleModule();\rsimpleModule.addSerializer(BigInteger.class, ToStringSerializer.instance);\rsimpleModule.addSerializer(Long.class, ToStringSerializer.instance);\rsimpleModule.addSerializer(Long.TYPE, ToStringSerializer.instance);\robjectMapper.registerModule(simpleModule);\rjackson2HttpMessageConverter.setObjectMapper(objectMapper);\rconverters.add(jackson2HttpMessageConverter);\rconverters.add(new StringHttpMessageConverter(StandardCharsets.UTF_8));\r}\r 但是这种方式需要开启@EnableWebMvc注解。\n开启这个注解意味着springboot的mvc等自动配置失效，所以这个方式实际上也是不可取的。\n类似的还有继承WebMvcConfigurationSupport类，也会导致一些配置失效\n可参考 https://www.cnblogs.com/asker009/p/12752716.html\n类似不可取的还有重写HttpMessageConverters，这会覆盖其他的类型转换。\n@Configuration\rpublic class LongToJsonConfig {\rpublic LongToJsonConfig() {\r}\r@Bean\rpublic HttpMessageConverters customConverters() {\rMappingJackson2HttpMessageConverter jackson2HttpMessageConverter = new MappingJackson2HttpMessageConverter();\rObjectMapper objectMapper = new ObjectMapper();\rSimpleModule simpleModule = new SimpleModule();\rsimpleModule.addSerializer(Long.class, ToStringSerializer.instance);\rsimpleModule.addSerializer(Long.TYPE, ToStringSerializer.instance);\robjectMapper.registerModule(simpleModule);\rjackson2HttpMessageConverter.setObjectMapper(objectMapper);\rreturn new HttpMessageConverters(new HttpMessageConverter[]{jackson2HttpMessageConverter});\r}\r}\r 以上方式基本都不可取。\n4、重新注册ObjectMapper的Long类型序列化方式，推荐使用，暂时没发现问题。\n@Configuration\rpublic class LongClassMessageConverter implements InitializingBean {\r@Resource\rObjectMapper objectMapper;\rprivate SimpleModule getSimpleModule() {\rSimpleModule simpleModule = new SimpleModule();\rsimpleModule.addSerializer(BigInteger.class, ToStringSerializer.instance);\rsimpleModule.addSerializer(Long.class, ToStringSerializer.instance); // 暂时放弃对小long的转换，约定与前端交互数据时，大Long全部转换成字符串 // simpleModule.addSerializer(Long.TYPE, ToStringSerializer.instance);\robjectMapper.registerModule(simpleModule);\rreturn simpleModule;\r}\r@Override\rpublic void afterPropertiesSet() {\rSimpleModule simpleModule = getSimpleModule();\robjectMapper.registerModule(simpleModule);\r}\r}\r 5、重新构建Jackson序列化方式，与第四点类似的解决方式，推荐使用。\n@Configuration\rpublic class JacksonConfig {\r/**\r* Jackson全局转化long类型为String，解决jackson序列化时传入前端Long类型缺失精度问题\r*/\r@Bean\rpublic Jackson2ObjectMapperBuilderCustomizer jackson2ObjectMapperBuilderCustomizer() {\rJackson2ObjectMapperBuilderCustomizer cunstomizer = new Jackson2ObjectMapperBuilderCustomizer() {\r@Override\rpublic void customize(Jackson2ObjectMapperBuilder jacksonObjectMapperBuilder) {\rjacksonObjectMapperBuilder.serializerByType(BigInteger.class, ToStringSerializer.instance);\rjacksonObjectMapperBuilder.serializerByType(Long.class, ToStringSerializer.instance);\r// jacksonObjectMapperBuilder.serializerByType(Long.TYPE, ToStringSerializer.instance); }\r};\rreturn cunstomizer;\r}\r}\r 6、以上方式针对springboot默认的Jackson序列化，fastjson等其他json组件类似处理。\n7、如果前端自身涉及到Long类型的计算，那么需要前端自己实现Long类型支持，参考： https://github.com/dcodeIO/long.js)//github.com/dcodeIO/long.js\n","id":53,"section":"posts","summary":"最近在项目开发中遇到了个bug，排查后发现Long类型主键字段作为参数返回后，前端接收时出现精度丢失问题 原因：前端js对Long类型支持的精","tags":null,"title":"后端Long类型传到前端精度丢失的正确解决方式","uri":"https://bluestaree.github.io/2020/09/long%E7%B1%BB%E5%9E%8B%E7%B2%BE%E5%BA%A6%E4%B8%A2%E5%A4%B1/","year":"2020"},{"content":"  转载:https://www.jianshu.com/p/157279e6efdb\n 1. volatile简介 在上一篇文章中我们深入理解了java关键字synchronized，我们知道在java中还有一大神器就是关键volatile，可以说是和synchronized各领风骚，其中奥妙，我们来共同探讨下。\n通过上一篇的文章我们了解到synchronized是阻塞式同步，在线程竞争激烈的情况下会升级为重量级锁。而volatile就可以说是java虚拟机提供的最轻量级的同步机制。但它同时不容易被正确理解，也至于在并发编程中很多程序员遇到线程安全的问题就会使用synchronized。Java内存模型告诉我们，各个线程会将共享变量从主内存中拷贝到工作内存，然后执行引擎会基于工作内存中的数据进行操作处理。线程在工作内存进行操作后何时会写到主内存中？这个时机对普通变量是没有规定的，而针对volatile修饰的变量给java虚拟机特殊的约定，线程对volatile变量的修改会立刻被其他线程所感知，即不会出现数据脏读的现象，从而保证数据的“可见性”。\n现在我们有了一个大概的印象就是：被volatile修饰的变量能够保证每个线程能够获取该变量的最新值，从而避免出现数据脏读的现象。\n2. volatile实现原理 volatile是怎样实现了？比如一个很简单的Java代码：\n instance = new Instancce() //instance是volatile变量\n 在生成汇编代码时会在volatile修饰的共享变量进行写操作的时候会多出Lock前缀的指令（具体的大家可以使用一些工具去看一下，这里我就只把结果说出来）。我们想这个Lock指令肯定有神奇的地方，那么Lock前缀的指令在多核处理器下会发现什么事情了？主要有这两个方面的影响：\n 将当前处理器缓存行的数据写回系统内存； 这个写回内存的操作会使得其他CPU里缓存了该内存地址的数据无效  为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2或其他）后再进行操作，但操作完不知道何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。因此，经过分析我们可以得出如下结论：\n Lock前缀的指令会引起处理器缓存写回内存； 一个处理器的缓存回写到内存会导致其他处理器的缓存失效； 当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值。  这样针对volatile变量通过这样的机制就使得每个线程都能获得该变量的最新值。\n3. volatile的happens-before关系 经过上面的分析，我们已经知道了volatile变量可以通过缓存一致性协议保证每个线程都能获得最新值，即满足数据的“可见性”。我们继续延续上一篇分析问题的方式（我一直认为思考问题的方式是属于自己，也才是最重要的，也在不断培养这方面的能力），我一直将并发分析的切入点分为两个核心，三大性质。两大核心：JMM内存模型（主内存和工作内存）以及happens-before；三条性质：原子性，可见性，有序性（关于三大性质的总结在以后得文章会和大家共同探讨）。废话不多说，先来看两个核心之一：volatile的happens-before关系。\n在六条happens-before规则中有一条是：**volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。**下面我们结合具体的代码，我们利用这条规则推导下：\npublic class VolatileExample {\rprivate int a = 0;\rprivate volatile boolean flag = false;\rpublic void writer(){\ra = 1; //1\rflag = true; //2\r}\rpublic void reader(){\rif(flag){ //3\rint i = a; //4\r}\r}\r}\r 上面的实例代码对应的happens-before关系如下图所示：\nVolatileExample的happens-before关系推导\n加锁线程A先执行writer方法，然后线程B执行reader方法图中每一个箭头两个节点就代码一个happens-before关系，黑色的代表根据程序顺序规则推导出来，红色的是根据volatile变量的写happens-before 于任意后续对volatile变量的读，而蓝色的就是根据传递性规则推导出来的。这里的2 happen-before 3，同样根据happens-before规则定义：如果A happens-before B,则A的执行结果对B可见，并且A的执行顺序先于B的执行顺序，我们可以知道操作2执行结果对操作3来说是可见的，也就是说当线程A将volatile变量 flag更改为true后线程B就能够迅速感知。\n4. volatile的内存语义 还是按照两个核心的分析方式，分析完happens-before关系后我们现在就来进一步分析volatile的内存语义（按照这种方式去学习，会不会让大家对知识能够把握的更深，而不至于不知所措，如果大家认同我的这种方式，不妨给个赞，小弟在此谢过，对我是个鼓励）。还是以上面的代码为例，假设线程A先执行writer方法，线程B随后执行reader方法，初始时线程的本地内存中flag和a都是初始状态，下图是线程A执行volatile写后的状态图。\n线程A执行volatile写后的内存状态图\n当volatile变量写后，线程中本地内存中共享变量就会置为失效的状态，因此线程B再需要读取从主内存中去读取该变量的最新值。下图就展示了线程B读取同一个volatile变量的内存变化示意图。\n线程B读volatile后的内存状态图\n从横向来看，线程A和线程B之间进行了一次通信，线程A在写volatile变量时，实际上就像是给B发送了一个消息告诉线程B你现在的值都是旧的了，然后线程B读这个volatile变量时就像是接收了线程A刚刚发送的消息。既然是旧的了，那线程B该怎么办了？自然而然就只能去主内存去取啦。\n好的，我们现在两个核心：happens-before以及内存语义现在已经都了解清楚了。是不是还不过瘾，突然发现原来自己会这么爱学习（微笑脸），那我们下面就再来一点干货\u0026mdash;-volatile内存语义的实现。\n4.1 volatile的内存语义实现 我们都知道，为了性能优化，JMM在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序，那如果想阻止重排序要怎么办了？答案是可以添加内存屏障。\n 内存屏障\n JMM内存屏障分为四类见下图，\n内存屏障分类表\njava编译器会在生成指令系列时在适当的位置会插入内存屏障指令来禁止特定类型的处理器重排序。为了实现volatile的内存语义，JMM会限制特定类型的编译器和处理器重排序，JMM会针对编译器制定volatile重排序规则表：\nvolatile重排序规则表\n\u0026ldquo;NO\u0026quot;表示禁止重排序。为了实现volatile内存语义时，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎是不可能的，为此，JMM采取了保守策略：\n 在每个volatile写操作的前面插入一个StoreStore屏障； 在每个volatile写操作的后面插入一个StoreLoad屏障； 在每个volatile读操作的后面插入一个LoadLoad屏障； 在每个volatile读操作的后面插入一个LoadStore屏障。  需要注意的是：volatile写是在前面和后面分别插入内存屏障，而volatile读操作是在后面插入两个内存屏障\nStoreStore屏障：禁止上面的普通写和下面的volatile写重排序；\nStoreLoad屏障：防止上面的volatile写与下面可能有的volatile读/写重排序\nLoadLoad屏障：禁止下面所有的普通读操作和上面的volatile读重排序\nLoadStore屏障：禁止下面所有的普通写操作和上面的volatile读重排序\n下面以两个示意图进行理解，图片摘自相当好的一本书《java并发编程的艺术》。\nvolatile写插入内存屏障示意图\nvolatile读插入内存屏障示意图\n5. 一个示例 我们现在已经理解volatile的精华了，文章开头的那个问题我想现在我们都能给出答案了。更正后的代码为：\npublic class VolatileDemo {\rprivate static volatile boolean isOver = false;\rpublic static void main(String[] args) {\rThread thread = new Thread(new Runnable() {\r@Override\rpublic void run() {\rwhile (!isOver) ;\r}\r});\rthread.start();\rtry {\rThread.sleep(500);\r} catch (InterruptedException e) {\re.printStackTrace();\r}\risOver = true;\r}\r}\r 注意不同点，现在已经将isOver设置成了volatile变量，这样在main线程中将isOver改为了true后，thread的工作内存该变量值就会失效，从而需要再次从主内存中读取该值，现在能够读出isOver最新值为true从而能够结束在thread里的死循环，从而能够顺利停止掉thread线程。现在问题也解决了，知识也学到了：）。\n","id":54,"section":"posts","summary":"转载:https://www.jianshu.com/p/157279e6efdb 1. volatile简介 在上一篇文章中我们深入理解了java","tags":null,"title":"Java中Volatile关键字","uri":"https://bluestaree.github.io/2020/08/java%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8Bvolatile%E5%85%B3%E9%94%AE%E5%AD%97%E8%A7%A3%E6%9E%90/","year":"2020"},{"content":"  简介：Sentinel-哨兵，是Spring Cloud Alibaba 的开源项目，是面向微服务的轻量级流量控制框架，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。\n官方文档\n 服务熔断 A服务调用B服务的某个功能，由于网络不稳定问题，或者B服务卡机，导致功能时间超长。如果这样子的次数太多。我们就可以直接将B断路了(A不再请求B接口)，凡是调用B的直接返回降级数据，不必等待B的超长执行。这样 B的故障问题，就不会级联影响到A。\n服务降级 整个网站处于流量高峰期，服务器压力剧增,根据当前业务情况及流量，对一些服务和页面进行有策略的降级，停止服务，所有的调用直接返回降级数据 (服务器繁忙，请稍后再试) 。以此缓解服务器资源的的压力，以保证核心业务的正常运行，同时也保持了客户和大部分客户的得到正确的相应。\n异同: 相同点:\n 为了保证集群大部分服务的可用性和可靠性，防止崩溃，牺牲小我 用户最终都是体验到某个功能不可用  不同点:\n 熔断是被调用方故障，触发的系统主动规则 降级是基于全局考虑，停止一些正常服务，释放资源  限流 对打入服务的请求流量进行控制，使服务能够承担不超过自己能力的流量压力\nSentinel基本概念 资源 资源是 Sentinel 的关键概念。它可以是Java 应用程序中的任何内容，例如，由应用程序提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。\n只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。\n规则 围绕资源的实时状态设定的规则，可以包括流量控制规则、熔断降级规则以及系统保护规则。所有规则可以动态实时调整。\nSentinel简单使用 1.导入依赖 \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-sentinel\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.0.2.RELEASE\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 2.sentinel 控制台 sentinel 控制台提供了一个可视化界面，通过它我们可以很轻松的对各个规则进行添加、查询和修改，也可以查看到实时监控，机器列表等信息。 github地址\n 注：优先选择对应版本的控制台，版本的不同可能会出现数据无法传输等问题\n 启动控制台\nsentinel 控制台是一个Spring boot 项目打成的jar包 ，我们可以直接在使用命令行启动这个jar包\njava -jar .\\sentinel-dashboard-1.7.1.jar\n 注：如果端口被占用，可以添加启动参数，修改默认运行端口\n默认用户密码：sentinel\n 初始化界面\n3.启动服务 配置文件\napplication.yml\nspring:\rcloud:\rsentinel:\rtransport:\rport: 8719 #本项目与sentinel控制台数据传输端口，\rdashboard: localhost:8080 #控制台端口\r 默认 sentinel 与spring cloud整合，会将所有请求都标识为受保护的资源\n在服务启动后，我们先访问一个测试请求，之后就可以在sentinel的控制台中查看到本次请求情况\n可以看到，在控制台中，我们能很方便的给指定请求设置一些规则\n这里我们尝试先添加一个流量控制规则 ， sentinel 流量规则定义\n这里设置 QPS = 1 (每秒只允许一个请求进行访问)，其他请求会被限制\n 注意：默认所有的规则设置保存在服务内存中，这些配置会在服务重启后失效\n 效果测试\n超过规则限制，sentinel 默认的返回数据\nsentinel 实时监控 Spring Boot Actuator 可以帮助你监控和管理Spring Boot应用，比如健康检查、审计、统计和HTTP追踪等。所有的这些特性可以通过JMX或者HTTP endpoints来获得。\nSentinel 可以通过获取 Actuator 的信息来达到对服务各项数据的实时监控\n集成Actuator 导入依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 配置文件\nmanagement.endpoints.web.exposure.include:*\r 对外暴露Actuator统计的审计端点信息，让Sentinel能够获取到这些信息\n重新启动服务后，\n结合上面 QPS = 1 的流控设置测试，可以直观的看到 Sentinel 控制台中显示的实时监控数据：\n每秒只允许1个请求访问，其它多余请求都被限制了\n自定义统一处理 设置url请求统一处理:WebCallbackManager\n导入依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.csp\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;sentinel-web-servlet\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 配置类\n@Configuration\rpublic class MySentinelConfig {\r@PostConstruct\rpublic void init() {\rWebCallbackManager.setUrlBlockHandler(new UrlBlockHandler() {\r@Override\rpublic void blocked(HttpServletRequest httpServletRequest, HttpServletResponse response, BlockException e) throws IOException {\rresponse.setCharacterEncoding(\u0026quot;utf-8\u0026quot;);\rresponse.setContentType(\u0026quot;application/json\u0026quot;);\rresponse.getWriter().write(\u0026quot;服务器繁忙，亲稍后再试\u0026quot;);\r}\r}\r);\r}\r}\r 也可以单独实现 UrlBlockHandler 接口实现类，根据异常信息执行相对应的业务，之后再注册到 WebCallbackManager 中\n 注：对于一些特殊业务，可以单独进行配置\n 自定义受保护的资源 常用的几种 sentinel 定义资源方式使用\n1.抛出异常 测试方法\npublic String getProductById(Integer id) {\r//自定义搜保护的资源\rtry (Entry entry = SphU.entry(\u0026quot;getproduct\u0026quot;)) {\rreturn \u0026quot;ok, get product : \u0026quot; + id;\r} catch ( BlockException e) {\r//资源访问受限，相应的处理操作\rlog.info(\u0026quot;请求getproduct资源过多，\u0026quot;,e.getMessage());\r//return \u0026quot;亲，你点的太快了~\u0026quot;;\r}\rreturn \u0026quot;error\u0026quot;;\r}\r 对自定义受保护资源添加流控规则，同上设置QPS=1，方便测试\n多次访问该请求，控制台输出内容\n2.基于注解 //定义资源，以及访问受限时调用的方法\r@SentinelResource(value = \u0026quot;getProductById\u0026quot;,blockHandler = \u0026quot;blockHandlerForGetProduct\u0026quot;)\rpublic String getProductById(Integer id) {\rreturn \u0026quot;ok, get product : \u0026quot; + id;\r}\rpublic String blockHandlerForGetProduct(BlockException e) {\rreturn \u0026quot;亲，你点的太快了~\u0026quot;;\r}\r  其他资源定义方式：Sentinel 定义资源\n 使用Sentinel来保护feign远程调用 以往我们在使用feign进行远程服务调用时，如果忘记启动远程服务了，那么肯定会出现服务不可用500异常。Sentinel能够整合feign对远程服务添加默认熔断处理，来处理这种问题\n1.配置文件\n添加 Sentinel 对 Feign 的支持\nfeign:\rsentinel:\renabled: true\r 2.定义Feign远程测试接口\n@FeignClient(name = \u0026quot;test-sentinel-product\u0026quot;,fallback = ProductFeignClientFallback.class)\rpublic interface ProductFeignClient {\r@GetMapping(\u0026quot;/product/get\u0026quot;)\rpublic String getProductById(@RequestParam(\u0026quot;pid\u0026quot;) Integer pid);\r}\r 3.定义sentinel熔断回调方法\n@Component\rpublic class ProductFeignClientFallback implements ProductFeignClient {\r@Override\rpublic String getProductById(Integer pid) {\rreturn \u0026quot;亲，你点的太快了~\u0026quot;;\r}\r}\r 4.关闭远程服务（模拟宕机情况）\n5.请求资源\ncontroller\n@GetMapping(\u0026quot;/relation/product/{pid}\u0026quot;)\rpublic String buildOrder(@PathVariable(\u0026quot;pid\u0026quot;) Integer pid) {\rreturn productFeignClient.getProductById(pid);\r}\r 响应结果\n虽然我们没有启动远程服务，但是由于我们配置了 sentinel 熔断处理，没有出现服务异常，返回了默认数据。\n对feign添加熔断保护，就相当于加了一个保险。如果远程服务宕机，我们还能够响应默认数据给客户端，而不会因为feign远程调用失败，而导致服务不可用。\n 当然，我们也可以对远程服务添加降级规则，当feign请求超过规则限制，同样会触发我们刚刚设置的熔断回调方法\n对远程服务设置降级规则\n远程服务\n这里为了测试效果，我们可以让线程小睡一会\npublic String getProductById(Integer id) {\rtry {\rThread.sleep(300);\r} catch (InterruptedException e) {\rreturn \u0026quot;error\u0026quot;;\r}\rreturn \u0026quot;ok, get product : \u0026quot; + id;\r}\r 正常启动远程服务\n测试时，远程服务启动，访问相同资源是可以得到正常数据的。但如果你刷新的足够快，触发了服务降级，调用方就会执行我们设置的默认方法，将默认数据返回\n","id":55,"section":"posts","summary":"简介：Sentinel-哨兵，是Spring Cloud Alibaba 的开源项目，是面向微服务的轻量级流量控制框架，从流量控制、熔断降级、系统负载保护等多个维度保","tags":["Sentinel"],"title":"高并发下保证服务稳定性-Sentinel","uri":"https://bluestaree.github.io/2020/08/springcloud-alibaba-sentinel/","year":"2020"},{"content":" 概述 接口幂等性\n接口幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的， 不会因为多次点击而产生了副作用;比如说支付场景，用户购买了商品支付扣款成功，但是返回结果的时候网络异常，此时钱已经扣了，用户再次点击按钮，此时会进行第二次扣款，返回结果成功，用户查询余额返发现多扣钱了，流水记录也变成了两条. . .，这就没有保证接口的幂等性。\n哪些情况需要防止  用户多次点击按钮 用户页面回退再次提交 微服务互相调用，由于网络问题，导致请求失败。feign 触发重试机制 其他业务情况  什么情况下需要幂等 以SQL为例，有些操作是天然幂等的。\n SELECT * FROM table WHER id=? , 无论执行多少次都不会改变状态，是天然的幂等。 UPDATE tab1 SET col1=1 WHERE col2=2 ,无论执行成功多少次状态都是一致的，也是幂等操作。 delete from user where userid=1 ,多次操作，结果样，具备幂等性 insert into user(userid,name) values(1,\u0026lsquo;a\u0026rsquo;) 如userid为唯一主键， 即重复操作上面的业务，只会插入一条用户数据，具备幂等性。    UPDATE tab1 SET col1=col1+1 WHERE col2=2 ,每次执行的结果都会发生变化，不是幂等的。 insert into user(userid,name) values(1,\u0026lsquo;a\u0026rsquo;) 如userid.不是主键，可以重复，那上面业务多次操作，数据都会新增多条，不具备幂等性。  幂等解决方案 Token机制   服务端提供了发送token的接口。我们在分析业务的时候，哪些业务是存在幂等问题的，就必须在执行业务前，先去获取token,服务器会把token保存到redis中。\n  然后调用业务接口请求时，把token携带过去，一般放在请求头部。\n  服务器判断token是否存在redis中，存在表示第一次请求，然后删除token,继续执行业务。\n  如果判断token不存在redis中，就表示是重复操作，直接返回重复标记给client,这样就保证了业务代码，不被重复执行。\n  危险性:\n1、先删除token还是后删除token;\n(1)先删除可能导致，业务确实没有执行，重试还带上之前token,由于防重设计导致，请求还是不能执行。\n(2)后删除可能导致，业务处理成功，但是服务闪断，出现超时，没有删除token,别人继续重试，导致业务被执行两遍\n(3)我们最好设计为先删除token,如果业务调用失败，就重新获取token再次请求。\n2、Token获取、比较和删除必须是原子性\n(1) redis.get(token) 、token.equals 、redis.del(token)如果这两个操作不是原子， 可能导致，高并发下，都get到同样的数据，判断都成功，继续业务并发执行\n(2)可以在redis使用lua脚本完成这个操作\nif redis.call('get',KEYS[1]) == ARGV[1] then return redis.cal('del', KEYS[1]) else return 0 end\r 各种锁机制 1、数据库悲观锁\nselect * from xxxx where id= 1 for update;\n悲观锁使用时一般伴随事务一起使用，数据锁定时间可能会很长，需要根据实际情况选用。另外要注意的是，id字段一定是主键或者唯一索引，这样只会锁住索引或者主键对应的行。普通字段加上for update会造成锁表的结果，处理起来会非常麻烦。\n2、数据库乐观锁\n这种方法适合在更新的场景中，\nupdate t_goods set count = count -1, version = version+ 1 where good_ id=2 and version= 1\n根据version版本，也就是在操作库存前先获取当前商品的version版本号，然后操作的时候带上此version号。我们梳理下，我们第一次操作库存时，得到version为1,调用库存服务version变成了2;但返回给订单服务出现了问题，订单服务又一次发起调用库存服务，当订单服务传如的version还是1，再执行上面的s语句时，就不会执行;因为version已经变为2了，where 条件就不成立。这样就保证了不管调用几次，只会真正的处理次。乐观锁主要使用于处理读多写少的问题\n3、业务层分布式锁\n如果多个机器可能在同一时间同时处理相同的数据，比如多台机器定时任务都拿到了相同数据处理，我们就可以加分布式锁，锁定此数据，处理完成后释放锁。获取到锁的必须先判断这个数据是否被处理过。\n各种唯一约束 1、数据库唯一约束\n插入数据，应该按照唯一索引进行插入， 比如订单号，相同的订单就不可能有两条记录插入。我们在数据库层面防止重复。\n这个机制是利用了数据库的主键唯一约束的特性，解决了在insert场景时幂等问题。但主键的要求不是自增的主键，这样就需要业务生成全局唯一的主键。如果是分库分表场景下，路由规则要保证相同请求下，落地在同一个数据库和同一表中，要不然数据库主键约束就不起效果了，因为是不同的数据库和表主键不相关。\n2、redis set防重\n很多数据需要处理，只能被处理一次，比如我们可以计算数据的MD5将其放入redis的set，每次处理数据，先看这个MD5是否已经存在，存在就不处理。\n防重表 使用订单号orderNo做为去重表的唯一索引， 把唯一索引插入去重表， 再进行业务操作，且他们在同一个事务中。这个保证了重复请求时，因为去重表有唯一约束， 导致请求失败，避免了幂等问题。这里要注意的是，去重表和业务表应该在同一库中，这样就保证了在同一个事务，即使业务操作失败了，也会把去重表的数据回滚。这个很好的保证了数据一致性。之前说的redis防重也算\n全局请求唯一id 调用接口时，生成一个唯一id, redis将数据保存到集合中(去重)，存在即处理过。\n可以使用nginx设置每一个请求的唯一id;\nproxy_set_header X-Request-Id $request_id;\n","id":56,"section":"posts","summary":"概述 接口幂等性 接口幂等性就是用户对于同一操作发起的一次请求或者多次请求的结果是一致的， 不会因为多次点击而产生了副作用;比如说支付场景，用户购","tags":null,"title":"接口幂等性问题与解决方案","uri":"https://bluestaree.github.io/2020/08/%E6%8E%A5%E5%8F%A3%E5%B9%82%E7%AD%89%E6%80%A7/","year":"2020"},{"content":"  简介：Seata是一款阿里巴巴开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了AT、TCC、SAGA 和XA事务模式,为用户打造一站式的分布式解决方案。\n 使用Seata AT(Auto Transaction) 模式控制分布式事务 整体机制 两阶段提交协议的演变：\n 一阶段：业务数据和回滚日志记录在同一个本地事务中提交，释放本地锁和连接资源。 二阶段：  提交异步化，非常快速地完成。 回滚通过一阶段的回滚日志进行反向补偿。    案例演示 用户下订单的部分业务逻辑，由2个微服务组成\n订单服务：创建订单\n库存服务：从订单商品信息中，锁定相应库存\n环境搭建 数据库\n订单表\nCREATE TABLE `orders` (\r`order_number` varchar(32) NOT NULL COMMENT '订单号',\r`initial_price` float(8,2) DEFAULT NULL COMMENT '定价',\r`price` float(8,2) DEFAULT NULL COMMENT '交易价',\r`start_time` datetime NOT NULL COMMENT '起始时间',\r`end_time` datetime NOT NULL COMMENT '结束时间',\r`status` varchar(32) DEFAULT NULL COMMENT '交易状态',\r`user_id` varchar(32) DEFAULT NULL COMMENT '用户id',\r`details` varchar(1000) DEFAULT NULL COMMENT '订单明细',\rPRIMARY KEY (`order_number`)\r) ENGINE=InnoDB DEFAULT CHARSET=utf8;\r 库存表\nCREATE TABLE `ware` (\r`id` bigint(20) NOT NULL COMMENT '库存id',\r`sku_id` bigint(20) DEFAULT NULL COMMENT 'sku_id',\r`ware_id` bigint(20) DEFAULT NULL COMMENT '仓库id',\r`stock` int DEFAULT NULL COMMENT '库存数量',\r`sku_name` varchar(255) DEFAULT NULL COMMENT 'sku名称',\r`stock_locked` int DEFAULT NULL COMMENT '锁定库存量',\rPRIMARY KEY (`id`)\r) ENGINE=InnoDB DEFAULT CHARSET=utf8;\r 主要业务逻辑 订单服务\n@Transactional\rpublic void submitOrder() {\r//生成订单\rOrders orders = new Orders();\rorders.setOrderNumber(UUID.randomUUID().toString().replace(\u0026quot;-\u0026quot;, \u0026quot;\u0026quot;));\rorders.setDetails(\u0026quot;测试订单\u0026quot;);\rorders.setStartTime(new Date());\rorders.setEndTime(new Date());\rordersRepository.save(orders);\r//远程减库存\rwareClient.updateWareStockLockedBySkuId(16,10);\r//TODO 其他微服务业务调用\r//模拟异常发生\r//int num = 1/0;\r}\r 测试 无异常情况\n订单表\n库存表\n两个事务动能正常提交，没有问题。\n接下来演示失败情况，手动操作数据库，将订单表的记录和锁定的库存数量重置\n异常情况\n打开异常代码注释\n可以看到，订单表事务正常回滚，而库存表事务却未回滚，因为spring 控制的是本地事务，无法对远程事务进行控制，造成了数据不一致的情况\n引入Seata进行分布式事务控制 1. 为每一个需要控制事务的数据库都创捷一个 UNDO_LOG 表 -- 注意此处0.3.0+ 增加唯一索引 ux_undo_log\rCREATE TABLE `undo_log` (\r`id` bigint(20) NOT NULL AUTO_INCREMENT,\r`branch_id` bigint(20) NOT NULL,\r`xid` varchar(100) NOT NULL,\r`context` varchar(128) NOT NULL,\r`rollback_info` longblob NOT NULL,\r`log_status` int(11) NOT NULL,\r`log_created` datetime NOT NULL,\r`log_modified` datetime NOT NULL,\r`ext` varchar(100) DEFAULT NULL,\rPRIMARY KEY (`id`),\rUNIQUE KEY `ux_undo_log` (`xid`,`branch_id`)\r) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;\r 当事务需要回滚时，Seata 会根据此表的记录，魔改数据库，将改变的数据再次复原\n2.下载Seata-Service软件包，就是全局事务协调器。 https://github.com/seata/seata/releases\n配置Seata-Service\n下载完Seata-Service软件包后，解压次压缩包。配置文件就位于conf文件夹下\n主要修改已下配置文件设置\nregistry.conf\nregistry { # file 、nacos 、eureka、redis、zk、consul、etcd3、sofa type = \u0026quot;eureka\u0026quot; #指定Seata-Service注册中心\r#各个服务器的配置，指定地址\rnacos {\rserverAddr = \u0026quot;localhost\u0026quot;\rnamespace = \u0026quot;public\u0026quot;\rcluster = \u0026quot;default\u0026quot;\r}\reureka {\rserviceUrl = \u0026quot;http://localhost:60101/eureka\u0026quot;\rapplication = \u0026quot;seata-server\u0026quot;\t#应用名称\rweight = \u0026quot;1\u0026quot;\r}\rredis {\rserverAddr = \u0026quot;localhost:6379\u0026quot;\rdb = \u0026quot;0\u0026quot;\r}\rzk {\rcluster = \u0026quot;default\u0026quot;\rserverAddr = \u0026quot;127.0.0.1:2181\u0026quot;\rsession.timeout = 6000\rconnect.timeout = 2000\r}\rconsul {\rcluster = \u0026quot;default\u0026quot;\rserverAddr = \u0026quot;127.0.0.1:8500\u0026quot;\r}\retcd3 {\rcluster = \u0026quot;default\u0026quot;\rserverAddr = \u0026quot;http://localhost:2379\u0026quot;\r}\rsofa {\rserverAddr = \u0026quot;127.0.0.1:9603\u0026quot;\rapplication = \u0026quot;default\u0026quot;\rregion = \u0026quot;DEFAULT_ZONE\u0026quot;\rdatacenter = \u0026quot;DefaultDataCenter\u0026quot;\rcluster = \u0026quot;default\u0026quot;\rgroup = \u0026quot;SEATA_GROUP\u0026quot;\raddressWaitTime = \u0026quot;3000\u0026quot;\r}\rfile {\rname = \u0026quot;file.conf\u0026quot;\r}\r}\rconfig {\r# file、nacos 、apollo、zk、consul、etcd3\rtype = \u0026quot;file\u0026quot; #设置seata配置的存储位置 ,默认为当前目录下的file.conf\rnacos {\rserverAddr = \u0026quot;localhost\u0026quot;\rnamespace = \u0026quot;public\u0026quot;\rcluster = \u0026quot;default\u0026quot;\r}\rconsul {\rserverAddr = \u0026quot;127.0.0.1:8500\u0026quot;\r}\rapollo {\rapp.id = \u0026quot;seata-server\u0026quot;\rapollo.meta = \u0026quot;http://192.168.1.204:8801\u0026quot;\r}\rzk {\rserverAddr = \u0026quot;127.0.0.1:2181\u0026quot;\rsession.timeout = 6000\rconnect.timeout = 2000\r}\retcd3 {\rserverAddr = \u0026quot;http://localhost:2379\u0026quot;\r}\rfile {\rname = \u0026quot;file.conf\u0026quot;\r}\r}\r 在bin目录下，根据操作系统启动Seata-Service\n可以看到在eurek中Seata-Service已经注册成功\n3.导入Seata依赖 \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-cloud-alibaba-seata\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.0.0.RELEASE\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 4.添加@GlobalTransactional 注解 在分布式大事务方法上添加@GlobalTransactional 注解 ，其他远程分支事务保持@Transactional注解即可\n5.使用seata DataSourceProxy代理自己的数据源 所有需要使用seata控制事务的微服务都需要进行配置\n@Configuration\rpublic class MySeataConfig {\r@Autowired\rDataSourceProperties dataSourceProperties;\r@Bean\rpublic DataSource dataSource(DataSourceProperties dataSourceProperties) {\rHikariDataSource dataSource = dataSourceProperties.initializeDataSourceBuilder().type(HikariDataSource.class).build();\rif (StringUtils.hasText(dataSourceProperties.getName())) {\rdataSource.setPoolName(dataSourceProperties.getName());\r}\rreturn new DataSourceProxy(dataSource);\r}\r}\r 6.导入registry.conf和file.conf文件 每一个服务，都必须导入Seata-Service的conf目录下的registry.conf和file.conf\n其中file.conf的service.vgroup_ mapping配置必须和spring. application.name一致。否则会提示no available server to connect错误\n格式\nvgroup_mapping.{application.name}-fescar-service-group = \u0026quot;default\u0026quot;\n7.启动测试 测试之前，为了方便查看结果，记得把数据库中的数据手动重置下\n先看正常情况\n没啥好说得\n异常情况\n按上述步骤， 同样打开异常代码。 在加入Seata控制事务后， 两张表数据 都更新了\n两个事务都能够进行回滚。成功解决了分布式事务控制问题\n 注意：AT模式并不适合超高并发的情况。在控制事务的过程中，会使用各种锁机制来进行事务控制，在高并发情况下，就会变成串行化。\n在高并发下可以采用消息队列 + 最终一致性的方案\n ","id":57,"section":"posts","summary":"简介：Seata是一款阿里巴巴开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了AT、TCC、S","tags":["Seata"],"title":"分布式解决方案-Seata","uri":"https://bluestaree.github.io/2020/08/springcloud-alibaba-seata/","year":"2020"},{"content":" 本地事务 事务的基本性质 数据库事务的几个特性:原子性(Atomicity)、一致性( Consistency )、隔离性或独立性( Isolation )和持久性( Durabilily )，简称就是ACID：\n   ACID 说明     原子性 一系列的操作整体不可拆分，要么同时成功，要么同时失败。   一致性 数据在事务的前后，业务整体一致。例 A:1000; B:1000; 转200 事务成功 -\u0026gt; A:800 B:1200   隔离性 事务之间互相隔离。   持久性 一旦事务成功，数据-定会落盘在数据库。    在以往的单体应用中，我们多个业务操作使用同一条连接操作不同的数据表，一旦有异常，我们可以很容易的整体回滚;\n事务的隔离级别   READ UNCOMMITED (读未提交) 该隔离级别的事务会读到其它未提交事务的数据，此现象也称之为脏读。\n  READ COMMITTED (读已提交)\n一个事务可以读取另一个已提交的事务，多次读取会造成不一样的结果，此现象称为不可重复读问题，Oracle 和SQL Server的默认隔离级别。\n  REPEATABLE READ (可重复读) 该隔离级别是 MySQL 默认的隔离级别，在同一个事务里，select 的结果是事务开始时时间点的状态，因此，同样的 select 操作读到的结果会是一致的， 但是，会有幻读现象。MySQL 的 InnoDB 引擎可以通过 next-key locks 机制来避免幻读。\n  SERIALIZABLE (序列化) 在该隔离级别下事务都是串行顺序执行的，MySQL 数据库的 InnoDB 引擎会给读操作隐式加一把读共享锁，从而避免了脏读、不可重读复读和幻读问题。\n  在spring事务控制中，指定隔离级别\n@Transactional(isolation = Isolation.READ_COMMITTED)\rpublic void submit(Order order) {\r//TODO ....\r}\r 事务的传播行为    传播行为 说明     PROPAGATION_REQUIRED 如果当前没有事务，就创建一个新事务， 如果当前存在事务，就加入该事务，该设置是最常用的设置。   PROPAGATION _SUPPORTS 支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就以非事务执行。   PROPAGATION_MANDATORY 支持当前事务，如果当前存在事务，就加入该事务，如果当前不存在事务，就抛出异常。   PROPAGATION_REQUIRES_NEW 创建新事务，无论当前存不存在事务，都创建新事务   PROPAGATION_NOT_SUPPORTED 以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。   PROPAGATION_NEVER 以非事务方式执行，如果当前存在事务，则抛出异常。   PROPAGATION_NESTED 如果当前存在事务，则在嵌套事务内执行。如果当前没有事务，则执行与PROPAGATION_REQUIRED 类似的操作。    举个栗子： 先看下面的伪代码。\n@Transactional(timeout = 30)\rpublic void a(){\rb();//使用a事务\rc();//新开一个事务,(后续如果出现异常，不回滚)\r//模拟异常情况\rint num = 2/0; }\r//默认为PROPAGATION_REQUIRED\r@Transactional(propagation = Propagation.REQUIRED，timeout = 10) public void b(){\r}\r@Transactional(propagation = Propagation.REQUIRES_NEW)\rpublic void c(){\r}\r  假定存在a、b、c三个事务方法，其中a调用了b、c方法。（可以理解为一个大事务中包含了其他小事务）\nb事务所设置的是默认传播行为，表示需要一个事务即可，这里会与a方法共用一个事务,并且a事务的所有设置都会传播给和他公用一个事务的方法，（上面的情况，b事务的 timeout = 10会失效）\nc事务的传播行为，表示无论是否存在事务，都会创建一个新事务.\n 如果a方法能够顺利执行，中途没有任何异常情况，那么所有事务都会正常提交，无事发生。\n如果b和c方法都顺利执行，但在a方法最后出现了异常，这时只有a和b会进行回滚(同一个事务控制)，而c由于是另外一个事务控制，不会回滚。\n我们可以更改事务的传播行为来控制多事务嵌套的情况\nSpringBoot事务控制的一个坑\n在同一个类里面，编写两个方法，内部调用的时候，会导致事务设置失效。原因是没有用到代理对象的缘故。\n在上面的伪代码中，如果a、b、c三个方法都是在同一个类中定义的，那么在SpringBoot事务控制下，这些事务设置都不会生效\n原因： 事务是使用代理对象来控制的，在同一个对象内进行方法相互调用，就相当于直接将b、c方法中的代码复制到a中，\n解决： 通过aspectJ 获取当前类的代理对象，或者将方法抽取出来。\n 引入aop-starter，主要为了使用aspectj  \u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-aop\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r  使用 @EnableAspectJAutoProxy(exposeProxy = true) 注解;开启aspectj动态代理功能。以后所有的动态代理都是aspectj创建的(即使没有接口也可以创建动态代理)，默认使用的是jdk动态代理,必须要有接口，设置exposeProxy = true，对外暴露代理对象\n  使用 AopContext.currentProxy(); 获取当前对象的代理对象.\n@Transactional\rpublic void a(){\rTsService tsService = (TsService) AopContext.currentProxy() ;\rtsService.b();\rtsService.c();\rint num = 2/0; }\r   分布式事务 分布式系统经常出现的异常机器宕机、网络异常、消息丢失、消息乱序、数据错误、不可靠的TCP、存储数据丢失等问题\u0026hellip;导致服务器之前无法及时感知对方的状态。\n因此要协调多个系统之间来控制整体事务就非常困难。\nCAP定理与BASE理论 CAP定理    CAP定理 说明     一致性 (Consistency) 在分布式系统中的所有数据备份，在同一时刻是否同样的值。(等同于所有节点访问同一份最新的数据副本)   可用性(Availability) 在集群中一部分节点故障后， 集群整体是否还能响应客户端的读写请求。(对数据更新具备高可用性)   分区容错性 (Partition tolerance) 大多数分布式系统都分布在多个子网络。每个子网络就叫做一个区(partition)。分区容错的意思是，区间通信可能失败。比如，一台服务器放在中国，另一台服务器放在美国，这就是两个区，它们之间可能无法通信。    CAP原则指的是，这三个要素最多只能同时实现两点，不可能三者兼顾。\n一般来说，分区容错无法避免，因此可以认为CAP的P总是成立。CAP定理告诉我们，剩下的C和A无法同时做到。\nCA其实就是本地项目（无网络情况），CP就需要通过一些算法raft,paxos等来保证数据一致性\nRaft算法动画演示地址\n核心：领导选取，日志复制。通过这些操作来保证数据的一致性\n 对于多数大型互联网应用的场景，主机众多、部署分散，而且现在的集群规模越来越大，所以节点故障、网络故障是常态，而且要保证服务可用性达到99.9999% (N个9)，即保证p和A,舍弃C。\nBASE理论 是对CAP理论的延伸，思想是即使无法做到强一致性(CAP的一致性就是强一致性)，但可以采用适当的采取弱一致性，即最终一致性。\n   BASE理论 说明     基本可用 (Basically Available) 基本可用是指分布式系统在 出现故障的时候,允许损失部分可用性(例如响应时间、功能上的可用性)，允许损失部分可用性。需要注意的是，基本可用绝不等价于系统不可用。   软状态 (Soft State) 软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据会有多个副本，允许不同副本同步的延时就是软状态的体现。mysql replication的异步复制也是一种体现。   最终一致性 ( Eventual Consistency) 最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。    从客户端角度，多进程并发访问时，更新过的数据在不同进程如何获取的不同策略，决定了不同的一致性。对于关系型数据库，要求更新过的数据能被后续的访问都能看到，这是强一致性。如果能容忍后续的部分或者全部访问不到，则是弱一致性。如果经过一段时间后要求能访问到更新后的数据，则是最终一致性\n分布式事务的几种解决方案 2PC模式 数据库支持的2PC [2 phase commit 二阶提交]，又叫做XA Transactions。 MySQL从5.5版本开始支持，SQL Server 2005开始支持，Oracle7 开始支持。 其中，XA 是一个两阶段提交协议，该协议分为以下两个阶段:\n 第一阶段: 事务协调器要求每个涉及到事务的数据库预提交 (precommit) 此操作，并反映是否可以提交. 第二阶段: 事务协调器要求每个数据库提交数据。  其中，如果有任何一个数据库否决此次提交，那么所有数据库都会被要求回滚它们在此事务中的那部分信息。\n也有3PC,引入了超时机制(无论协调者还是参与者，在向对方发送请求后，若长时间未收到回应则做出相应处理)\n柔性事务 - TCC事务补偿 刚性事务: 遵循ACID原则，强一致性。\n柔性事务: 遵循BASE理论，最终一致性;\n与刚性事务不同，柔性事务允许一定时间内， 不同节点的数据不一致，但要求最终一致。\n一阶段 prepare 行为: 调用自定义的try逻辑。\n二阶段 commit 行为: 调用自定义的commit逻辑。\n三阶段 rollback 行为: 调用自定义的rollback逻辑。\n所谓TCC 模式，是指支持把自定义的分支事务纳入到全局事务的管理中。\n柔性事务 - 最大努力通知型方案 按规律进行通知，不保证数据一定能通知成功， 但会提供可查询操作接口进行核对。这种方案主要用在与第三方系统通讯时，\n比如: 调用微信或支付宝支付后的支付结果通知。这种方案也是结合MQ进行实现，例如: 通过MQ发送http请求，设置最大通知次数。达到通知次数后即不再通知。\n案例: 银行通知、商户通知等(各大交易业务平台间的商户通知: 多次通知、查询校对、对账文件)，支付宝的支付成功异步回调\n柔性事务 - 可靠消息 + 最终一致性方案 (异步确保型) 实现: 业务处理服务在业务事务提交之前，向实时消息服务请求发送消息，实时消息服务只记录消息数据，而不是真正的发送。业务处理服务在业务事务提交之后，向实时消息服务确认发送。只有在得到确认发送指令后，实时消息服务才会真正发送。\n方案问题和解决： 1.保证消息可靠性 - 消息丢失   消息发送出去，由于网络问题没有抵达服务器\n 做好容错方法(try-catch) ，发送消息可能会网络失败，失败后要有重试机制，可记录到数据库，采用定期扫描重发的方式  表结构示例：\nCREATE TABLE 'mq_ message' (\r'message_id' CHAR(32) NOT NULL COMMENT '消息id',\r'content' TEXT COMMENT '消息内容，json数据',\r'to_exchane' VARCHAR(255) COMMENT '目标交换机',\r'routing_key' VARCHAR(255) DEFAULT NULL COMMENT '路由key',\r'class_type' VARCHAR(255) DEFAULT NULL COMMENT '消息类型',\r'message_status' INT(1) DEFAULT '0' COMMENT '状态 0-新建 1-已发送 2-错误抵达 3-已抵达',\r'create_time' DATETIME DEFAULT NULL,\r'update_time' DATETIME DEFAULT NULL,\rPRIMARY KEY ('message_id')\r) ENGINE=INNODB DEFAULT CHARSET=utf8mb4\r  做好日志记录，每个消息状态是否都被服务器收到都应该记录 做好定期重发，如果消息没有发送成功，定期去数据库扫描未成功的消息进行重发    消息抵达Broker, Broker要将消息写入磁盘(持久化)才算成功。此时Broker尚未持久化完成，宕机。\n  publisher也必须加入确认回调机制(returnCallback)，确认消息成功进入目标队列后，修改数据库消息状态。\n  自动ACK的状态下。消费者收到消息，但没来得及消息然后宕机\n 开启手动ACK，消费成功才移除，失败或者没来得及处理就noAck并重新入队    2.保证消息可靠性 - 消息重复   消息消费成功，事务已经提交，ack时，机器宕机。导致没有ack成功，Broker的消息重新由unack变为ready，并发送给其他消费者\n  消息消费失败，由于重试机制，自动又将消息发送出去\n  成功消费，ack时宕机，消息由unack变为ready，Broker又重新发送\n  消费者的业务消费接口应该设计为幂等性的。比如扣库存有工作单的状态标志\n  使用防重表(redis/mysql)，发送消息每一个都有业务的唯一标识，处理过就不用处理，类似上述方法\n  rabbitMQ的每一个消息都有redelivered字段, 可以获取是否是被重新投递过来的，而不是第一次投递过来的\n  Boolean redelivered = message.getMessageProperties().getRedelivered();\n 注意：也可能是因为上一个业务没有处理成功，将消息重新入队，而被标识已接收\n   3.保证消息可靠性 - 消息积压   消费者宕机积压\n  消费者消费能力不足积压\n  发送者发送流量太大\n  上线更多的消费者，进行正常消费\n  上线专门的队列消费服务，将消息先批量取出来，记录数据库，离线慢慢处理\n    ","id":58,"section":"posts","summary":"本地事务 事务的基本性质 数据库事务的几个特性:原子性(Atomicity)、一致性( Consistency )、隔离性或独立性( Isolation )和持久性( Durabilily )，简称就是ACID","tags":null,"title":"本地事务与分布式事务","uri":"https://bluestaree.github.io/2020/08/%E6%9C%AC%E5%9C%B0%E4%BA%8B%E5%8A%A1%E4%B8%8E%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","year":"2020"},{"content":"  概述：在一些应用场景下，服务端也需要返回完整的页面信息给客户端，比如有利于SEO的主页，搜索页面等，都需要服务端渲染。当然使用Nuxt或Next也可以完美解决此问题，本文使用了Spring Session技术，结合Redis来解决原生Session使用中的一些问题。\n HeepSession 原生HeepSession，是在服务器内存中开辟了一个存储空间，底层使用的是Map结构，用于存储此次会话数据，由SessionManager进行统一管理.\n工作原理： 在第一次使用session时，服务器会创建一个带 JSESSIONID 的cookie，默认以当前服务器域名为该cookie的作用域，以后浏览器只要在对应的作用域下进行请求，服务器就能获取cookie中的JSESSIONID对应的Session数据.\n问题：\n 不能跨域名共享，可以看到该cookie中指定了可生效的域名 分布式情况下，多个服务器下，一个用户的session无法共享  解决方法 Session共享问题解决-session复制 多服务器集群之间进行session的复制，无论负载均衡到哪一个服务器都能找到数据\n优点\n web-server (Tomcat) 原生支持，只需要修改配置文件  缺点\n session同步需要数据传输， 占用大量网络带宽，降低了服务器群的业务处理能力 任意一台web-server保存的数据都是所有web-server的session总和，受到内存限制无法水平扩展更多的web-server 大型分布式集群情况下，由于所有web-server都全量保存数据，所以此方案不可取。  Session共享问题解决-客户端存储 将所有信息都通过cookie存储到客户端中\n优点\n 服务器不需存储session, 用户保存自己的session信息到cookie中。节省服务端资源  缺点\n 每次http请求， 携带用户在cookie中的完整信息，浪费网络带宽 session数据放在cookie中，cookie有长度限制4K,不能保存大量信息 session数据放在cookie中，存在泄漏、篡改、窃取等安全隐患  Session共享问题解决-hash一致性 通过负载均衡，保证同一个IP的多次请求，都落在一个服务器上\n优点:\n 只需要改nginx配置，不需要修改应用代码 负载均衡，只要hash属性的值分布是均匀的，多台web-server的负载是均衡的 可以支持web-server水平扩 展(session同步法是不行的，受内存限制)  缺点:\n session还是存在web server中的， 所以web-server重启可能导致部分session丢失，影响业务，如部分用户需要重新登录 如果web-serven水平扩 展，rehash后session重新分布，也会有一部分用户路由不到正确的session 但是以上缺点问题也不是很大，因为session本来都是有有效期的。所以这两种反向代理的方式可以使用  Session共享问题解决-统一存储 不存在服务器内存中，转为由数据库，或Redis等其他中间件进行存储\n优点:\n 没有安全隐患 可以水平扩展， 数据库/缓存水平切分即可 web-server重启或者扩 容都不会有session丢失  缺点:\n 增加了一次网络调用，并且需要修改应用代码;如将所有的getSession方法替换为从Redis查数据的方式。redis获取数据比内存慢很多  Session共享问题解决-不同服务，子域session共享 子域session无法共享问题主要原因是：默认的cookie有效域仅为当前域名。\n我们可以整合Spring Session修改这个作用域，扩大它的作用范围，如jd.com，这样在其他子域名(pro.jd.com)就\n可以携带此cookie ,实现跨域session共享。\n简单接入Spring Session Spring Session提供了一套API，用于完成管理用户Session的功能\nSpring Session与Redis整合 1. pom文件配置\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.session\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-session-data-redis\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 配置文件\n#Redis连接信息\rspring.redis.host=127.0.0.1\rspring.redis.port=6379\rspring.session.store-type=redis #指定session存储类型\rserver.servlet.session.timeout=30m #session超时时间\r 2. Config配置类\n//配置JSON序列化，默认为JDK序列化方式\r@Bean\rpublic RedisSerializer\u0026lt;Object\u0026gt; springSessionDefaultRedisSerializer() {\rreturn new GenericJackson2JsonRedisSerializer();\r}\r//配置自定义cookie信息\r@Bean\rpublic CookieSerializer cookieSerializer() {\rDefaultCookieSerializer serializer = new DefaultCookieSerializer();\rserializer.setCookieName(\u0026quot;JSESSIONID\u0026quot;); serializer.setCookiePath(\u0026quot;/\u0026quot;); serializer.setDomainName(\u0026quot;bookstore.com\u0026quot;); return serializer;\r}\r 3. Controller\n在Session中添加数据\n@GetMapping(\u0026quot;/session\u0026quot;)\rprivate String session(HttpSession session) {\rUserInfo userInfo = new UserInfo();\ruserInfo.setName(\u0026quot;Jack\u0026quot;);\ruserInfo.setAge(25);\rsession.setAttribute(\u0026quot;userInfo\u0026quot;, userInfo);\rreturn \u0026quot;redirect:http://www.bookstore.com\u0026quot;;\r}\r 4. 启动类\n启动类中添加如下注解\n//整合redis作为session存储\r@EnableRedisHttpSession\r@SpringBootApplication\rpublic class WebApplication {\rpublic static void main(String[] args) {\rSpringApplication.run(WebApplication.class, args);\r}\r}  Redis存储结构 页面cookie信息 这样一来，我们就将Session存储的位置转移到了Redis，并且修改了Cookie默认信息，只要携带有效的Cookie访问服务器，Spring Session就能从Redis中获取到对应的Session数据，在页面中进行渲染。\n","id":59,"section":"posts","summary":"概述：在一些应用场景下，服务端也需要返回完整的页面信息给客户端，比如有利于SEO的主页，搜索页面等，都需要服务端渲染。当然使用Nuxt或Ne","tags":null,"title":"Spring Session与Redis整合","uri":"https://bluestaree.github.io/2020/07/spring-session%E4%B8%8Eredis%E6%95%B4%E5%90%88/","year":"2020"},{"content":"  前言：在一些业务复杂的场景中，往往会涉及多个业务之间的相互调用，通过线程池性能稳定，也可以获取执行结果，并捕获异常。但是，在业务复杂情况下，一个异步调用可能会依赖于另一个异步调用的执行结果。为了解决这个问题，我们可以使用JDK1.8版本新引入的类CompletableFuture来实现异步编排，控制多线程的执行顺序。\n 初始化线程的4种方式  继承Thread  Thread01 thread = new Thread01();\rthread.start();//启动线程\r 实现Runnable接口 ，然后交由Thread处理  Runable01 runable01 = new Runable01();\rnew Thread(runable01).start();\r 实现Callable接口+ FutureTask ( 可以拿到返回结果，处理异常)  FutureTask\u0026lt;Integer\u0026gt; futureTask = new FutureTask\u0026lt;\u0026gt;(new Callable01()); new Thread(futureTask).start();\r//等待整个线程执行完成，获取返回结果 (阻塞等待)\rInteger num = futureTask.get();\r 线程池  方式1和方式2：主进程无法获取线程的运算结果。\n方式3：主进程可以获取线程的运算结果，但是不利于控制服务器中的线程资源。可能导致服务器资源耗尽。\n方式4：通过如下两种方式初始化线程池\n//1.使用Executors工具类（底层使用的是ThreadPoolExecutor）\rExecutors.newFiexedThreadPool(3);\r//2.通过ThreadPoolExecutor 创建线程池。\rnew ThreadPoolExecutor(corePoolSize, maximumPoolSize, keepAlieTime, TimeUnit unit,workQueue, threadFactory, handler);\r ThreadPoolExecutor ThreadPoolExecutor 7 个最重要的参数\n corePoolSize ：核心线程数;一直存在除非 设置了(allowCoreThreadTimeOut)参数。线程池创建好以后就准备就绪的线程数量，等待来接受异步任务去执行 maximumPoolSize：最大线程数量，控制资源 keepAliveTime：线程存活时间。如果当前线程数量大于corePoolSize 超过该事件，就会释放空闲的线程（maximumPoolSize - corePoolSize ） unit ：keepAliveTime 参数的时间单位。 workQueue：队列。如果任务很多，就会将多的任务放入队列中，只要有空闲的线程，就会去队列中取出新的任务执行 threadFactory：创建线程Thread的工厂，使用默认即可 handler：如果队列满了，按照所指定的\t拒绝策略，拒绝执行任务  ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(10, 30,\r300, TimeUnit.SECONDS, new ArrayBlockingQueue\u0026lt;Runnable\u0026gt;(100),\rExecutors.defaultThreadFactory(), new ThreadPoolExecutor.CallerRunsPolicy());\r 关于拒绝策略\n可选参数：\n DiscardOldestPolicy : 丢弃队列中最老的任务 CallerRunsPolicy : 直接调用run方法，也就是使用主线程main执行，（同步调用） AbortPolicy : 直接丢弃新的任务，抛异常 DiscardPolicy : 丢弃新的任务，不抛异常  运行流程:\n1、线程池创建，准备好core数量的核心线程，准备接受任务\n2、新的任务进来，用core准备好的空闲线程执行。\n  core满了，就将再进来的任务放入阻塞队列中。空闲的core就会自己去阻塞队列获取任务执行\n  阻塞队列满了，就直接开新线程执行，最大只能开到max指定的数量\n  max都执行好了。Max-core数量空闲的线程会在keepAliveTime指定的时间后自动销毁。最终保持到core大小\n  如果线程数开到了max的数量，还有新任务进来，就会使用reject 指定的拒绝策略进行处理\n  3、所有的线程创建都是由指定的factory创建的。\n 举个栗子:\n一个线程池core=7;max=20,queue=50, 当100并发进来怎么分配的;\n先有7个能直接得到执行，接下来50个进入队列排队，在多开13个继续执行。现在70个被安排上了。剩下30个默认拒绝策略。\n 常见的4种线程池 使用Exectors线程池工具类创建方法\nnewCachedThreadPool\n创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。\nnewFixedThreadPool\n创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。\nnewScheduledThreadPool\n创建一个定长线程池，支持定时及周期性任务执行。\nnewSingleThreadExecutor\n创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，从队列中获取任务，挨个执行\n为什么使用线程池   降低资源的消耗\n通过重复利用已经创建好的线程降低线程的创建和销毁带来的损耗\n  提高响应速度\n因为线程池中的线程数没有超过线程池的最大上限时，有的线程处于等待分配任务的状态，当任务来时无需创建新的线程就能执行\n  提高线程的可管理性\n线程池会根据当前系统特点对池内的线程进行优化处理,减少创建和销毁线程带来的系统开销。无限的创建和销毁线程不仅消耗系统资源，还降低系统的稳定性，使用线程池进行统一分配\n  CompletableFuture 这个completableFuture是JDK1.8版本新引入的类。\n业务场景:\n查询商品详情页的逻辑比较复杂，有些数据还需要远程调用，必然需要花费更多的时间。\n // 1.获取sku的基本信息 0.5s\n// 2.获取sku的图片信息0.5s\n// 3.获取sku的促销信息1s\n// 4.获取spu的所有销售属性 1s\n// 5.获取规格参数组及组下的规格参数1.5s\n// 6. spu详情1s\n 假如商品详情页的每个查询，需要如下标注的时间才能完成\n那么，用户需要5.5s后才能看到商品详情页的内容。很显然是不能接受的。\n如果有多个线程同时完成这6步操作，也许只需要1.5s即可完成响应。\n但是，可以看到上述1，2，3步骤可以异步进行，互不影响，但是4，5，6则需要1的结果才能进行查询，关系还是比较复杂的\n在这种场景下，我们就可以使用CompletableFuture来处理\nCompletableFuture实现了Future接口，Future可以获取到异步结果，可以理解为vue中的promise，\n1. 创建一个异步对象 CompletableFuture提供了四个静态方法来创建一一个异步操作。\npublic static CompletableFuture\u0026lt;Void\u0026gt; runAsync(Runnable runnable)\rpublic static CompletableFuture\u0026lt;Void\u0026gt; runAsync (Runnable runnable, Executor executor )\rpublic static \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; supplyAsync (Supplier\u0026lt;U\u0026gt; supplier)\rpublic static \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; supplyAsync (Supplier\u0026lt;U\u0026gt; supplier, Executor executor)\r 说明：\n runXxxx都是没有返回结果的，supplyXx都是可以获取返回结果的 可以传入自定义的线程池executor ，否则就用默认的线程池;  2.计算完成时的回调方法 public CompletableFuture\u0026lt;T\u0026gt; whenComplete(BiConsumer\u0026lt;? super T,? super Throwable\u0026gt; action);\rpublic CompletableFuture\u0026lt;T\u0026gt; whenCompleteAsync(BiConsumer\u0026lt;? super T,? super Throwable\u0026gt; action);\rpublic CompletableFuture\u0026lt;T\u0026gt; whenCompleteAsync(BiConsumer\u0026lt;? super T,? super Throwable\u0026gt; action,Executor executor);\rpublic CompletableFuture\u0026lt;T\u0026gt; exceptionally(Function\u0026lt;Throwable,? extends T\u0026gt; fn);\r 说明：\n1.whenComplete可以处理正常和异常的计算结果，exceptionally 处理异常情祝。\n2.whenComplete和whenCompleteAsync 的区别:\n whenComplete:是执行当前任务的线程执行继续执行whenComplete的任务。 whenCompleteAsync:是执行把whenCompleteAsync这个任务继续提交给线程池来进行执行。  方法不以Async结尾，意味着Action使用相同的线程执行，而Async可能会使用其他线程执行(如果是使用相同的线程池，也可能会被同一个线程选中执行\npublic static void main(String[] args) throws ExecutionException,InterruptedException {\rCompletableFuture\u0026lt;Integer\u0026gt; future = CompletableFuture.supplyAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;当前线程:\u0026quot;+ Thread.currentThread().getId());\rint i = 10/0;\rSystem.out.println(\u0026quot;运行结果:\u0026quot;+ i);\rreturn i;\r},executor).whenComplete((res, excption)-\u0026gt;{\r//虽然能得到异常信息，但是没法修改返回数据。\rSystem.out.println( \u0026quot;异步任务成功完成了.. .结果是: \u0026quot;+res+\u0026quot; ;异常是:\u0026quot;+excption);\r}).exceptionally(throwable -\u0026gt; {\r//可以感知异常，同时返回默认值\rreturn 10;\r});\r//使用handle,在方法执行完成后可以进行后续处理\r/*CompletableFuture\u0026lt;Integer\u0026gt; future = CompletableFuture.supplyAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;当前线程:”+ Thread.currentThread().getId());\rint i = 10/4;\rSystem.out.println(\u0026quot;运行结果:“+ i);\rreturn i;\r},executor).handle((res,thr)-\u0026gt;{\rif(res!=nu11){\rreturn res*2;\r}\rif(thr!=nu11){\rreturn 0;\r}\rreturn 0;\r});*/\r//阻塞等待，直到任务结束，获取结果值\rInteger integer = future.get();\rSystem.out.println(\u0026quot;main.... end....\u0026quot;+integer);\r}\r}\r 3.handle 方法 public \u0026lt;U\u0026gt; Completionstage\u0026lt;U\u0026gt; handle(BiFunction\u0026lt;? super T,Throwable, ? extends U\u0026gt; fn) ;\rpublic \u0026lt;U\u0026gt; Completionstage\u0026lt;U\u0026gt; handleAsync(BiFunction\u0026lt;? super T,Throwable, ? extends U\u0026gt; fn);\rpublic \u0026lt;U\u0026gt; CompletionStage\u0026lt;U\u0026gt; handleAsync(BiFunction\u0026lt;? super T,Throwable, ? extends U\u0026gt; fn,Executor executor);\r 说明：\n和complete一样，可对结果做最后的处理(可处理异常)，可改变返回值。\n4.线程串行化方法 //获取上一个任务的执行结果，并返回当前执行的结果\rpublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenApply(Function\u0026lt;? super T,? extends U\u0026gt; fn)\rpublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenApplyAsync(Function\u0026lt;? super T,? extends U\u0026gt; fn)\rpublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; thenApplyAsync(Function\u0026lt;? super T,? extends U\u0026gt; fn, Executor executor )\r//可以获取到上一个线程执行结果\rpublic Completionstage\u0026lt;Void\u0026gt; thenAccept (Consumer\u0026lt;? super T\u0026gt; action) :\rpublic CompletionStage\u0026lt;Void\u0026gt; thenAcceptAsync(Consumer\u0026lt;? super T\u0026gt; action);\rpublic CompletionStage\u0026lt;Void\u0026gt; thenAcceptAsync (Consumer\u0026lt;? super T\u0026gt; ; action, Executor executor );\r//获取不到上一个线程执行的结果\rpublic CompletionStage\u0026lt;Void\u0026gt; thenRun(Runnable action);\rpublic CompletionStage\u0026lt;Void\u0026gt; thenRunAsync (Runnable action);\rpublic Completionstage\u0026lt;Void\u0026gt; thenRunAsync (Runnable action, Executor executor);\r 说明：\n thenApply方法:当一个线程依赖另一个线程时，获取上一个任务返回的结果，并返回当前任务的返回值。 thenAccept方法:消费处理结果。接收任务的处理结果，并消费处理，无返回结果。 thenRun方法:只要上面的任务执行完成，就开始执行thenRun,只是处理完任务后，执行thenRun的后续操作 带有Async默认是异步执行的。同之前。  以上都要前置任务成功完成。\n/**\r*线程串行化\r* 1)、thenRun:不能获取到上一步的执行结果，无返回值\r*/\rCompletableFuture\u0026lt;Void\u0026gt; future = CompletableFuture.supplyAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;当前线程:\u0026quot; + Thread.currentThread().getId());\rint i = 10 / 4;\rSystem.out.println(\u0026quot;运行结果:\u0026quot; + i);\rreturn i;\r}, executor).thenRunAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;任务2启动了...\u0026quot;);\r}, executor);\r/**\r* 2)、thenAcceptAsync:能接受上一步结果，但是无返回值\r*/\rCompletableFuture.supplyAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;当前线程:\u0026quot; + Thread.currentThread().getId());\rint i = 10 / 4;\rSystem.out.println(\u0026quot;运行结果:\u0026quot; + i);\rreturn i;\r}, executor).thenAcceptAsync(res -\u0026gt; {\rSystem.out.println(\u0026quot;任务2启动了...\u0026quot; + res);\r}, executor);\r/**\r*3)、thenApplyAsync:能接受上一步结果，有返回值\r*/\rCompletableFuture\u0026lt;String\u0026gt; future = CompletableFuture.supplyAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;当前线程:\u0026quot; + Thread.currentThread().getId());\rint i = 10 / 4;\rSystem.out.println(\u0026quot;运行结果:\u0026quot; + i);\rreturn i;\r}, executor).thenApplyAsync(res -\u0026gt; {\rSystem.out.println(\u0026quot;任务2启动了...\u0026quot; + res);\rreturn \u0026quot;Hello\u0026quot; + res;\r}, executor);\rSystem.out.println(\u0026quot;main....end....\u0026quot; + future.get());\r}\r 5.两任务组合-都要完成 public \u0026lt;U,V\u0026gt; CompletableFuture\u0026lt;V\u0026gt; thenCombine(CompletionStage\u0026lt;? extends U\u0026gt; other,BiFunction\u0026lt;? super T,? super U,? extends V\u0026gt; fn);\rpublic \u0026lt;U,V\u0026gt; CompletableFuture\u0026lt;V\u0026gt; thenCombineAsync(CompletionStage\u0026lt;? extends U\u0026gt; other , BiFunction\u0026lt;? super T,? super U,? extends V\u0026gt; fn);\rpublic \u0026lt;U,V\u0026gt; CompletableFuture\u0026lt;V\u0026gt; thenCombineAsync(Completionstage\u0026lt;? extends U\u0026gt; other, BiFunction\u0026lt;? super T,? super U,? extends V\u0026gt; fn,Executor executor);\rpublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;Void\u0026gt; thenAcceptBoth(Completionstage\u0026lt;? extends U\u0026gt; other,BiConsumer\u0026lt;? super T, ? super U\u0026gt; action);\rpublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;Void\u0026gt; thenacceptBothasync(CompletionStage\u0026lt;? extends U\u0026gt; other,BiConsumer\u0026lt;? super T, ? super U\u0026gt; action); public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;Void\u0026gt; thenAcceptBothAsync(CompletionStage\u0026lt;? extends U\u0026gt; other,BiConsumer\u0026lt;? super T,? super U\u0026gt; action, Executor executor);\rpublic CompletableFuture\u0026lt;Void\u0026gt; runAfterBoth(CompletionStage\u0026lt;?\u0026gt; other ,Runnable action);\rpublic CompletableFuture\u0026lt;Void\u0026gt; runAfterBothAsync(CompletionStage\u0026lt;?\u0026gt; other,Runnable action);\rpublic CompletableFuture\u0026lt;Void\u0026gt; runAfterBothAsync (Completionstage\u0026lt;?\u0026gt; other,Runnable action,Executor executor);\r 说明：\n两个任务必须都完成，触发该任务。\n thenCombine:组合两个future,获取两个future的返回结果，并返回当前任务的返回值。 thenAcceptBoth:组合两个future,获取两个future任务的返回结果，然后处理任务，没有返回值。 runAfterBoth:组合两个future,不需要获取future的结果，只需两个future处理完任务后，处理该任务。  CompletableFuture\u0026lt;Object\u0026gt; future01 = CompletableFuture.supplyAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;任务1线程: \u0026quot; + Thread.currentThread().getId());\rint i = 10 / 4;\rSystem.out.println(\u0026quot;任务1结束:”);\rreturn i;\r}, executor);\rCompletableFuture\u0026lt;Object\u0026gt; future02 = CompletableFuture.supplyAsync(() -\u0026gt; {\rSystem.out.println(\u0026quot;任务2线程:\u0026quot; + Thread.currentThread().getId());\rSystem.out.println(\u0026quot;任务2结束:\u0026quot;);\rreturn \u0026quot;Hello\u0026quot;;\r}, executor);\r/*//在1，2任务执行完后执行3，不能获取之前任务的结果\rfuture01.runAfterBothAsync(future02,()-\u0026gt;{\rSystem.out.println(\u0026quot;任务3开始...\u0026quot;);\r}, executor);*/\r/*//在1，2任务执行完后执行3，可以获取上一次执行的结果\rfuture01.thenAcceptBothAsync(future02,(f1,f2)-\u0026gt;{\rSystem.out.println(\u0026quot;任务3开始...之前的结果: \u0026quot;+f1+\u0026quot;--》 \u0026quot;+f2);\r},executor);*/\r//在1，2任务执行完后执行3，获取上一次处理的结果，并返回当前结果\rCompletableFuture\u0026lt;String\u0026gt; future = future01.thenCombineAsync(future02, (f1, f2) -\u0026gt; {\rreturnf1 + \u0026quot;:\u0026quot; + f2 + \u0026quot;-\u0026gt;Haha\u0026quot;;\r}, executor);\rSystem.out.println(\u0026quot;main... .end....\u0026quot; + future.get());\r 6.两任务组合-一个完成 public \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; applyToEither(CompletionStage\u0026lt;? extends T\u0026gt; other, Function\u0026lt;? super T, U\u0026gt; fn);\rpublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; applyToEitherAsync(CompletionStage\u0026lt;? extends T\u0026gt; other, Function\u0026lt;? super T, U\u0026gt; fn);\rpublic \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; applyToEitherAsync(Complet ionstage\u0026lt;? extends T\u0026gt; other, Function\u0026lt;? super T, U\u0026gt; fn,Executor executor);\rpublic CompletableFuture\u0026lt;Void\u0026gt; acceptEither(CompletionStage\u0026lt;? extends T\u0026gt; other, Consumer\u0026lt;? super T\u0026gt; action);\rpublic CompletableFuture\u0026lt;Void\u0026gt; acceptEitherAsync(CompletionStage\u0026lt;? extends T\u0026gt; other, Consumer\u0026lt;? super T\u0026gt; action) ;\rpublic CompletableFuture\u0026lt;Void\u0026gt; acceptEitherAsync(CompletionStage\u0026lt;? extends T\u0026gt; other, Consumer\u0026lt;? super T\u0026gt; action,Executor executor);\rpublic CompletableFuture\u0026lt;Void\u0026gt; runAfterEither(CompletionStage\u0026lt;?\u0026gt; other ,Runnable action);\rpublic CompletableFuture\u0026lt;Void\u0026gt; runAfterEitherAsync (CompletionStage\u0026lt;?\u0026gt; other ,Runnable action);\rpublic CompletableFuture\u0026lt;Void\u0026gt; runAfterEitherAsync (CompletionStage\u0026lt;?\u0026gt; other ,Runnable action,Executor executor);\r 说明：\n当两个任务中，任意一个future任务完成的时候，执行任务。\n applyToEither : 两个任务有一个执行完成，获取它的返回值，处理任务并有新的返回值。 acceptEither : 两个任务有一个执行完成，获取它的返回值，处理任务，没有新的返回值。 runAfterEither : 两个任务有个执行完成，不需要获取future的结果，处理任务，也没有返回值。  //runAfterEitherAsync ，不获取上一次执行的结果，也没有返回值\rfuture01.runAfterEitherAsync(future02,()-\u0026gt;{\rSystem.out.println(\u0026quot;任务3开始...之前的结果: \u0026quot;);\r},executor);\r//acceptEitherAsync可获取上一次执行的结果，没有返回值\rfuture01.acceptEitherAsync(future02, (res)-\u0026gt;{\rSystem.out.println(\u0026quot;任务3开始...之前的结果: \u0026quot; + res);\r},executor);\r//获取上一次执行的结果，并且有返回值\rCompletableFuture\u0026lt;String\u0026gt; future = future01.applyToEitherAsync(future02, (res)-\u0026gt;{\rSystem.out.println(\u0026quot;任务3开始...之前的结果: \u0026quot; + res);\rreturn res.toString()+\u0026quot;- \u0026gt;哈哈\u0026quot;;\r} ,executor);\rSystem.out.println(\u0026quot;main... .end....\u0026quot;+future.get()) ;\r 7.等待多任务完成 要等待所有异步任务完成，获取前面线程所执行的结果可以使用CompletableFuture.allOf(task1,task2,....)方法\n此方法可以将各个future实例添加到allOf方法中，然后通过future的get()方法获取future的状态。如果allOf里面的所有线程尚未执行完毕，主线程会阻塞，直到allOf里面的所有线程都执行，线程才会被唤醒。\nCompletableFuture.allOf(future01,future02).get()\n","id":60,"section":"posts","summary":"前言：在一些业务复杂的场景中，往往会涉及多个业务之间的相互调用，通过线程池性能稳定，也可以获取执行结果，并捕获异常。但是，在业务复杂情况下，","tags":null,"title":"CompletableFuture-异步编排","uri":"https://bluestaree.github.io/2020/07/completablefuture-%E5%BC%82%E6%AD%A5%E7%BC%96%E6%8E%92/","year":"2020"},{"content":"  转载 · 原文链接：https://www.jianshu.com/p/6db623355e11\n 一、概述 SpringCache本身是一个缓存体系的抽象实现，并没有具体的缓存能力，要使用SpringCache还需要配合具体的缓存实现来完成。\n虽然如此，但是SpringCache是所有Spring支持的缓存结构的基础，而且所有的缓存的使用最后都要归结于SpringCache，那么一来，要想使用SpringCache，还是要仔细研究一下的。\n二、缓存注解 SpringCache缓存功能的实现是依靠下面的这几个注解完成的。\n @EnableCaching：开启缓存功能 @Cacheable：定义缓存，用于触发缓存 @CachePut：定义更新缓存，触发缓存更新 @CacheEvict：定义清除缓存，触发缓存清除 @Caching：组合定义多种缓存功能 @CacheConfig：定义公共设置，位于class之上  2.1 @EnableCaching 该注解主要用于开启基于注解的缓存功能,使用方式为：\n@EnableCaching\r@Configuration\rpublic class CacheConfig {\r@Bean\rpublic CacheManager cacheManager() {\rSimpleCacheManager cacheManager = new SimpleCacheManager();\rcacheManager.setCaches(Arrays.asList(new ConcurrentMapCache(\u0026quot;default\u0026quot;)));\rreturn cacheManager;\r}\r}\r  注意：在SpringBoot中使用SpringCache可以由自动配置功能来完成CacheManager的注册，SpringBoot会自动发现项目中拥有的缓存系统，而注册对应的缓存管理器，当然我们也可以手动指定。\n 使用该注解和如下XML配置具有一样的效果：\n\u0026lt;beans\u0026gt;\r\u0026lt;cache:annotation-driven/\u0026gt;\r\u0026lt;bean id=\u0026quot;cacheManager\u0026quot; class=\u0026quot;org.springframework.cache.support.SimpleCacheManager\u0026gt;\r\u0026lt;property name=\u0026quot;caches\u0026quot;\u0026gt;\r\u0026lt;set\u0026gt;\r\u0026lt;bean class=\u0026quot;org.springframework.cache.concurrent.ConcurrentMapCacheFactoryBean\u0026gt;\r\u0026lt;property name=\u0026quot;name\u0026quot; value=\u0026quot;default\u0026quot;/\u0026gt;\r\u0026lt;/bean\u0026gt;\r\u0026lt;/set\u0026gt;\r\u0026lt;/property\u0026gt;\r\u0026lt;/bean\u0026gt;\r\u0026lt;/beans\u0026gt;\r 下面来看看@EnableCaching的源码：\n@Target(ElementType.TYPE)\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\r@Import(CachingConfigurationSelector.class)\rpublic @interface EnableCaching {\r// 用于设置使用哪种代理方式，默认为基于接口的JDK动态代理（false），\r// 设置为true，则使用基于继承的CGLIB动态代理\rboolean proxyTargetClass() default false;\r// 用于设置切面织入方式(设置面向切面编程的实现方式)，\r// 默认为使用动态代理的方式织入，当然也可以设置为ASPECTJ的方式来实现AOP\rAdviceMode mode() default AdviceMode.PROXY;\r// 用于设置在一个切点存在多个通知的时候各个通知的执行顺序，默认为最低优先级，\r// 其中数字却大优先级越低，这里默认为最低优先级，int LOWEST_PRECEDENCE =\r// Integer.MAX_VALUE;，却是整数的最大值\rint order() default Ordered.LOWEST_PRECEDENCE;\r}\rpublic enum AdviceMode {\rPROXY,\rASPECTJ\r}\rpublic interface Ordered {\rint HIGHEST_PRECEDENCE = Integer.MIN_VALUE;\rint LOWEST_PRECEDENCE = Integer.MAX_VALUE;\rint getOrder();\r}\r 由上面的源码可以看出，缓存功能是依靠AOP来实现的。\n2.2 @Cacheable 该注解用于标注于方法之上用于标识该方法的返回结果需要被缓存起来，标注于类之上标识该类中所有方法均需要将结果缓存起来。\n该注解标注的方法每次被调用前都会触发缓存校验，校验指定参数的缓存是否已存在（已发生过相同参数的调用），若存在，直接返回缓存结果，否则执行方法内容，最后将方法执行结果保存到缓存中。\n2.2.1 使用 @Service\r@Log4j2\rpublic class AnimalService {\r@Autowired\rprivate AnimalRepository animalRepository;\r//...\r// @Cacheable(\u0026quot;animalById\u0026quot;)\r@Cacheable(value = \u0026quot;animalById\u0026quot;, key = \u0026quot;#id\u0026quot;)\rpublic ResponseEntity\u0026lt;Animal\u0026gt; getAnimalById(final int id){\rreturn ResponseEntity.ok(animalRepository.selectById(id));\r}\r//...\r}\r 上面的实例中两个@Cacheable配置效果其实是一样的，其中value指定的缓存的名称，它和另一个方法cacheName效果一样，一般来说这个缓存名称必须要有，因为这个是区别于其他方法的缓存的唯一方法。\n这里我们介绍一下缓存的简单结构，在缓存中，每个这样的缓存名称的名下都会存在着多个缓存条目，这些缓存条目对应在使用不同的参数调用当前方法时生成的缓存，所有一个缓存名称并不是一个缓存，而是一系列缓存。\n另一个key用于指定当前方法的缓存保存时的键的组合方式，默认的情况下使用所有的参数组合而成，这样可以有效区分不同参数的缓存。当然我们也可以手动指定，指定的方法是使用SPEL表达式。\n这里我么来简单看看其源码，了解下其他几个方法的作用：\n@Target({ElementType.METHOD, ElementType.TYPE})\r@Retention(RetentionPolicy.RUNTIME)\r@Inherited\r@Documented\rpublic @interface Cacheable {\r// 用于指定缓存名称，与cacheNames()方法效果一致\r@AliasFor(\u0026quot;cacheNames\u0026quot;)\rString[] value() default {};\r// 用于指定缓存名称，与value()方法效果一致\r@AliasFor(\u0026quot;value\u0026quot;)\rString[] cacheNames() default {};\r// 用于使用SPEL手动指定缓存键的组合方式，默认情况使用所有的参数来组合成键，除非自定义了keyGenerator。\r// 使用SPEL表达式可以根据上下文环境来获取到指定的数据：\r// #root.method：用于获取当前方法的Method实例\r// #root.target：用于获取当前方法的target实例\r// #root.caches：用于获取当前方法关联的缓存\r// #root.methodName：用于获取当前方法的名称\r// #root.targetClass：用于获取目标类类型\r// #root.args[1]：获取当前方法的第二个参数，等同于：#p1和#a1和#argumentName\rString key() default \u0026quot;\u0026quot;;\r// 自定义键生成器，定义了该方法之后，上面的key方法自动失效，这个键生成器是：\r// org.springframework.cache.interceptor.KeyGenerator，这是一个函数式接口，\r// 只有一个generate方法，我们可以通过自定义的逻辑来实现自定义的key生成策略。\rString keyGenerator() default \u0026quot;\u0026quot;;\r// 用于设置自定义的cacheManager(缓存管理器),可以自动生成一个cacheResolver\r// （缓存解析器），这一下面的cacheResolver()方法设置互斥\rString cacheManager() default \u0026quot;\u0026quot;;\r// 用于设置一个自定义的缓存解析器\rString cacheResolver() default \u0026quot;\u0026quot;;\r// 用于设置执行缓存的条件，如果条件不满足，方法返回的结果就不会被缓存，默认无条件全部缓存。\r// 同样使用SPEL来定义条件，可以使用的获取方式同key方法。\rString condition() default \u0026quot;\u0026quot;;\r// 这个用于禁止缓存功能，如果设置的条件满足，就不执行缓存结果，与上面的condition不同之处在于，\r// 该方法执行在当前方法调用结束，结果出来之后，因此，它除了可以使用上面condition所能使用的SPEL\r// 表达式之外，还可以使用#result来获取方法的执行结果，亦即可以根据结果的不同来决定是否缓存。\rString unless() default \u0026quot;\u0026quot;;\r// 设置是否对多个针对同一key执行缓存加载的操作的线程进行同步，默认不同步。这个功能需要明确确定所\r// 使用的缓存工具支持该功能，否则不要滥用。\rboolean sync() default false;\r}\r 如何自定义一个KeyGenerator呢？\npublic class AnimalKeyGenerator implements KeyGenerator {\r@Override\rpublic Object generate(Object target, Method method, Object... params) {\rStringBuilder sb = new StringBuilder(\u0026quot;animal-\u0026quot;);\rsb.append(target.getClass().getSimpleName()).append(\u0026quot;-\u0026quot;).append(method.getName()).append(\u0026quot;-\u0026quot;);\rfor (Object o : params) {\rString s = o.toString();\rsb.append(s).append(\u0026quot;-\u0026quot;);\r}\rreturn sb.deleteCharAt(sb.lastIndexOf(\u0026quot;-\u0026quot;)).toString();\r}\r}\r 2.3 @CachePut 该注解用于更新缓存，无论结果是否已经缓存，都会在方法执行结束插入缓存，相当于更新缓存。一般用于更新方法之上。\n@Service\r@Log4j2\rpublic class AnimalService {\r@Autowired\rprivate AnimalRepository animalRepository;\r//...\r@CachePut(value = \u0026quot;animalById\u0026quot;, key = \u0026quot;#animal.id\u0026quot;)\rpublic ResponseEntity\u0026lt;Animal\u0026gt; updateAnimal(final Animal animal){\rWrapper\u0026lt;Animal\u0026gt; animalWrapper = new UpdateWrapper\u0026lt;\u0026gt;();\r((UpdateWrapper\u0026lt;Animal\u0026gt;) animalWrapper).eq(\u0026quot;id\u0026quot;,animal.getId());\ranimalRepository.update(animal, animalWrapper);\rreturn ResponseEntity.ok(this.getAnimalById(animal.getId()));\r}\r//...\r}\r 这里指定更新缓存，value同样还是缓存名称，这里更新的是上面查询操作的同一缓存，而且key设置为id也与上面的key设置对应。\n如此设置之后，每次执行update方法时都会直接执行方法内容，然后将返回的结果保存到缓存中，如果存在相同的key,直接替换缓存内容执行缓存更新。\n下面来看看源码：\n@Target({ElementType.METHOD, ElementType.TYPE})\r@Retention(RetentionPolicy.RUNTIME)\r@Inherited\r@Documented\rpublic @interface CachePut {\r// 同上\r@AliasFor(\u0026quot;cacheNames\u0026quot;)\rString[] value() default {};\r// 同上\r@AliasFor(\u0026quot;value\u0026quot;)\rString[] cacheNames() default {};\r// 同上\rString key() default \u0026quot;\u0026quot;;\r// 同上\rString keyGenerator() default \u0026quot;\u0026quot;;\r// 同上\rString cacheManager() default \u0026quot;\u0026quot;;\r// 同上\rString cacheResolver() default \u0026quot;\u0026quot;;\r// 同上\rString condition() default \u0026quot;\u0026quot;;\r// 同上\rString unless() default \u0026quot;\u0026quot;;\r}\r 只有一点要注意：这里的设置一定要和执行缓存保存的方法的@Cacheable的设置一致，否则无法准确更新。\n2.4 @CacheEvict 该注解主要用于删除缓存操作。\n@Service\r@Log4j2\rpublic class AnimalService {\r@Autowired\rprivate AnimalRepository animalRepository;\r//...\r@CacheEvict(value = \u0026quot;animalById\u0026quot;, key = \u0026quot;#id\u0026quot;)\rpublic ResponseEntity\u0026lt;Integer\u0026gt; deleteAnimalById(final int id){\rreturn ResponseEntity.ok(animalRepository.deleteById(id));\r}\r//...\r}\r 简单明了，看看源码：\n@Target({ElementType.METHOD, ElementType.TYPE})\r@Retention(RetentionPolicy.RUNTIME)\r@Inherited\r@Documented\rpublic @interface CacheEvict {\r// 同上\r@AliasFor(\u0026quot;cacheNames\u0026quot;)\rString[] value() default {};\r// 同上\r@AliasFor(\u0026quot;value\u0026quot;)\rString[] cacheNames() default {};\r// 同上\rString key() default \u0026quot;\u0026quot;;\r// 同上\rString keyGenerator() default \u0026quot;\u0026quot;;\r// 同上\rString cacheManager() default \u0026quot;\u0026quot;;\r// 同上\rString cacheResolver() default \u0026quot;\u0026quot;;\r// 同上\rString condition() default \u0026quot;\u0026quot;;\r// 这个设置用于指定当前缓存名称名下的所有缓存是否全部删除，默认false。\rboolean allEntries() default false;\r// 这个用于指定删除缓存的操作是否在方法调用之前完成，默认为false，表示先调用方法，在执行缓存删除。\rboolean beforeInvocation() default false;\r}\r 2.5 @Caching 这个注解用于组个多个缓存操作，包括针对不用缓存名称的相同操作等，源码：\n@Target({ElementType.METHOD, ElementType.TYPE})\r@Retention(RetentionPolicy.RUNTIME)\r@Inherited\r@Documented\rpublic @interface Caching {\r// 用于指定多个缓存设置操作\rCacheable[] cacheable() default {};\r// 用于指定多个缓存更新操作\rCachePut[] put() default {};\r// 用于指定多个缓存失效操作\rCacheEvict[] evict() default {};\r}\r 简单用法：\n@Service\r@Log4j2\rpublic class AnimalService {\r@Autowired\rprivate AnimalRepository animalRepository;\r//...\r@Caching(\revict = {\r@CacheEvict(value = \u0026quot;animalById\u0026quot;, key = \u0026quot;#id\u0026quot;),\r@CacheEvict(value = \u0026quot;animals\u0026quot;, allEntries = true, beforeInvocation = true)\r}\r)\rpublic ResponseEntity\u0026lt;Integer\u0026gt; deleteAnimalById(final int id){\rreturn ResponseEntity.ok(animalRepository.deleteById(id));\r}\r@Cacheable(\u0026quot;animals\u0026quot;)\rpublic ResponseEntity\u0026lt;Page\u0026lt;Animal\u0026gt;\u0026gt; getAnimalPage(final Animal animal, final int pageId, final int pageSize){\rPage\u0026lt;Animal\u0026gt; page = new Page\u0026lt;\u0026gt;();\rpage.setCurrent(pageId);\rpage.setSize(pageSize);\rreturn ResponseEntity.ok((Page\u0026lt;Animal\u0026gt;) animalRepository.selectPage(page,packWrapper(animal, WrapperType.QUERY)));\r}\r//...\r}\r 2.6 @CacheConfig 该注解标注于类之上，用于进行一些公共的缓存相关配置。源码为：\n@Target(ElementType.TYPE)\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\rpublic @interface CacheConfig {\r// 设置统一的缓存名，适用于整个类中的方法全部是针对同一缓存名操作的情况\rString[] cacheNames() default {};\r// 设置统一个键生成器，免去了每个缓存设置中单独设置\rString keyGenerator() default \u0026quot;\u0026quot;;\r// 设置统一个自定义缓存管理器\rString cacheManager() default \u0026quot;\u0026quot;;\r// 设置统一个自定义缓存解析器\rString cacheResolver() default \u0026quot;\u0026quot;;\r}\r ","id":61,"section":"posts","summary":"转载 · 原文链接：https://www.jianshu.com/p/6db623355e11 一、概述 SpringCache本身是一个缓存体系","tags":["Spring Cache"],"title":"Spring Cache使用","uri":"https://bluestaree.github.io/2020/07/springcache%E4%BD%BF%E7%94%A8/","year":"2020"},{"content":"  前言：现在互联网高并发的背景下，为了有效的提高服务应用的响应速度，相信大家都会想到采用缓存技术。然而如果你的应用引入了缓存机制，那么有一个问题是必须要考虑的：如何在数据库更新数据时，保证缓存是最新的数据？这也是缓存在写模式下所存在的问题\n 缓存机制介绍  参考文章：https://www.jianshu.com/p/dc1e5091a0d8\n 如今利用缓存机制来提高查询效率已被广泛用在各大生产环境，查询数据的一般流程如下所示\n在没有更新数据的情况下，数据库和缓存的数据是保持一致的，当时当要执行数据库的更新操作时，数据库和缓存就会出现不一致的情况。\n首先需要明确的是，既然系统引入缓存机制，就必须接受系统会出现数据不一致的情况发生，我们不可能完全避免，只能尽量减少不一致的时间，达到最终一致性。\n那么如何将缓存中的数据与数据库保持一致呢，比较常见的两个模式是：\n 双写模式 失效模式  缓存数据一致性-双写模式 思路：首先更改数据库，然后再更新缓存\n可能存在的问题，如图所示，假设存在两个请求，且其执行顺序如下：\n 请求A更新数据-1 请求B更新数据-2 请求B更新缓存-2 请求A更新缓存-1  出现了缓存与数据不一致的情况。\n这是暂时性的脏数据问题，因为在数据稳定，缓存过期以后，又能得到最新的正确数据。\n解决： 添加读写锁，如果有线程需要更新数据，其他线程必须等待其执行完成。\n注：如果业务允许暂时性的数据不一致问题，可以忽略此问题，但要注意设置合适的缓存过期时间。保证最终数据的一致性。\n缓存数据一致性-失效模式 思路：首先更改数据库，然后删除缓存，等待下次一主动查询进行更新\n可能存在的问题，如图所示，假设存在三个请求，且其执行顺序如下:\n 请求A更新数据-1 请求A删除缓存 请求B更新数据-2 请求C获取数据，此时缓存已经被删除 请求C读取数据-1 请求B删除缓存 请求C更新缓存  此问题依旧导致的是脏数据问题，主要在于线程之间写和读的问题，也可以通过加锁的方式进行解决，不过会增加系统负重性，降低效率。\n缓存数据一致性-解决方案 无论是双写模式还是失效模式，都会导致缓存的不一致问题。即多个实例同时更新会出事。怎么办?\n 对于一些实时性要求靠的数据，如：用户数据，订单数据等，缓存数据加上过期时间，每隔一段时间触发读的主动更新即可 如果是菜单，商品介绍等基础数据，也可以去使用canal订阅binlog的方式。 缓存数据+过期时间也足够解决大部分业务对于缓存的要求。 通过加锁保证并发读写，写写的时候按顺序排好队。读读无所谓。所以适合使用读写锁。 (业务不关心脏数据，允许临时脏数据可忽略) ;  总结:  放入缓存的数据本就不应该是实时性、一致性要求超高的。所以缓存数据的时候加上过期时间，保证每天拿到当前最新数据即可。 不应该过度设计，增加系统的复杂性 遇到实时性、一致性要求高的数据，就应该查数据库，即使慢点。  解决方案之Canal简单介绍 Canal是阿里巴巴旗下的一款开源项目。其定位是基于数据库增量日志解析，提供增量数据订阅\u0026amp;消费。\n使用Canal更新缓存\nCanal可以模拟为Mysql的一个从服务器，只要Mysql数据发生更改，Canal就能够同步到变化的内容（binlog）。\n利用这个特性，我们就可以编写逻辑一些业务，在数据库更改的同时修改redis缓存信息。这样一来，在编码期\n间，我们只需要关注修改数据库的逻辑即可\n优点：屏蔽了对缓存的操作，简化代码\n缺点：添加新的中间件，需要额外开发自定义功能\n 使用Canal解决数据异构\nCanal也可以在大数据情况下解决数据异构问题，举个栗子：\n一些电商网站都会根据用户浏览喜好，显示相关的推荐商品，引导客户点击购买。Canal就可以高效的完成并计算\n分析出用户可能感兴趣的商品。\nCanal通过订阅用户浏览记录表，商品信息表，购物车表等数据的更新。结合这些数据，Canal可以智能的分析计算出用户的喜好商品，并生成一张新的表： 用户推荐表，这样我们就无需自己进行大量计算。\n","id":62,"section":"posts","summary":"前言：现在互联网高并发的背景下，为了有效的提高服务应用的响应速度，相信大家都会想到采用缓存技术。然而如果你的应用引入了缓存机制，那么有一个问","tags":["缓存"],"title":"缓存与数据库一致性问题及最佳解决方案","uri":"https://bluestaree.github.io/2020/07/%E7%BC%93%E5%AD%98%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98%E5%8F%8A%E6%9C%80%E4%BD%B3%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","year":"2020"},{"content":"  概述：Redisson是架设在Redis基础上的一个Java驻内存数据网格。简单来说就是Redis分布式锁对于Java语言的实现，其提供的许多分布式服务，本文介绍了如何使用Redisson来实现分布式锁，以及其他几种常用的分布式锁\n 简单实现 1.引入依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.redisson\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;redisson\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;3.12.0\u0026lt;/version\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 2.配置Redisson客户端\n@Configuration\rpublic class MyRedissonConfig {\r@Bean(destroyMethod = \u0026quot;shutdown\u0026quot;)\rpublic RedissonClient redisson() throws IOException {\rConfig config = new Config();\r//config.useClusterServers( )\t//集群配置\r//.addNodeAddress(\u0026quot;127.0.8.1:7004\u0026quot;，\u0026quot;127.0.0.1:6379\u0026quot;);\r//单节点配置 可以用\u0026quot;rediss://\u0026quot;来启用SSL连接\rconfig.useSingleServer().setAddress(\u0026quot;redis://127.0.0.1:6379\u0026quot;);\rreturn Redisson.create(config);\r}\r}\r 3.测试Controller\n@GetMapping(\u0026quot;/hello\u0026quot;)\rpublic String hello(){\r//1、获取一把锁，只要锁的名字一样，就是同一把锁\rRLock lock = redisson.getLock(\u0026quot;my-lock\u0026quot;);\r//2.加锁\rlock.lock(); //阻塞式等待。默认加的锁存活时间为30s。\r//看门狗机制：\r//1)、锁的自动续期，如果业务超长，运行期间会自动给锁续上新的30s。不用担心业务时间长，锁自动过期被删掉\r//2)、加锁的业务只要运行完成，就不会给当前锁续期，即使不手动解锁，锁默认在30s以后自动删除。\rtry {\rSystem.out.println(\u0026quot;加锁成功... \u0026quot; + Thread.currentThread().getId());\rThread.sleep(30000); //模拟执行耗时业务\rreturn \u0026quot;hello\u0026quot;;\r} catch (Exception e) {\r} finally {\r//3、解锁\rSystem.out.println(\u0026quot;释放锁...\u0026quot; + Thread.currentThread().getId());\rlock.unlock();\r}\rreturn \u0026quot;Throw Exception！\u0026quot;;\r}\r 可通过设置虚拟机参数启动多个服务，模拟集群环境下进行测试\n初次访问时，加锁成功，控制台输出内容：\n加锁成功... 60\n等待30s后业务逻辑执行完成，释放锁，控制台输出内容：\n释放锁...60\nRedis中存储的分布式锁信息如下图：\n在浏览器中同时访问多个服务，\n此时控制台输出内容\n加锁成功... 60\n释放锁...60\n加锁成功... 67\n释放锁...67\n这样一个简单的分布式锁就添加成功了，现在每一个进程都需要获取在获取锁后才能进行进一步的业务处理。我们\n就可以根据这一点=有效的预防缓存击穿、接口幂等性等问题。\nRedisson 看门狗机制 在我们进行测试的时候有一个问题，可以明显的发现，在Redis上存储的分布式锁的有效时间为30s，而且当这个\n值减少到19s时，存活时间又重新刷新为30s。\n这就redisson的看门狗机制。\n让我们先来看看redisson里的 Lock 方法源码\npublic void lock() {\rtry {\rthis.lock(-1L, (TimeUnit)null, false);\r} catch (InterruptedException var2) {\rthrow new IllegalStateException();\r}\r}\r 接下来会调用另一个带参数的重载方法，我们可以进去直接看其中尝试获取锁的那段源码\nprivate \u0026lt;T\u0026gt; RFuture\u0026lt;Long\u0026gt; tryAcquireAsync(long leaseTime, TimeUnit unit, long threadId) {\rif (leaseTime != -1L) {\rreturn this.tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG);\r} else {\rRFuture\u0026lt;Long\u0026gt; ttlRemainingFuture = this.tryLockInnerAsync(this.commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);\rttlRemainingFuture.onComplete((ttlRemaining, e) -\u0026gt; {\rif (e == null) {\rif (ttlRemaining == null) {\rthis.scheduleExpirationRenewal(threadId);\r}\r}\r});\rreturn ttlRemainingFuture;\r}\r}\r 可以看到，如果我们没有传入指定锁的存活时间，也就是上面的 leaseTim 变量的值，默认是-1,\n此时走else路线，其中redisson默认将锁的存活时间设置为30s\nthis.lockWatchdogTimeout = 30000L;\r 接下来 ，可以看到一个重要的方法 scheduleExpirationRenewal() ,根据名称有一个大概的理解，就是一个到期续\n订的定时任务。\n继续跟踪源码，可以看到最主要的方法 renewExpiration()，在这里面就创建了一个定时任务task，\n并且延迟10s执行一次，其中又进行递归调用，相当于每隔10s执行一次，直到我们的业务逻辑执行完毕\nprivate void renewExpiration() {\rRedissonLock.ExpirationEntry ee = (RedissonLock.ExpirationEntry)EXPIRATION_RENEWAL_MAP.get(this.getEntryName());\rif (ee != null) {\rTimeout task = this.commandExecutor.getConnectionManager().newTimeout(new TimerTask() {\rpublic void run(Timeout timeout) throws Exception {\rRedissonLock.ExpirationEntry ent = (RedissonLock.ExpirationEntry)RedissonLock.EXPIRATION_RENEWAL_MAP.get(RedissonLock.this.getEntryName());\rif (ent != null) {\rLong threadId = ent.getFirstThreadId();\rif (threadId != null) {\rRFuture\u0026lt;Boolean\u0026gt; future = RedissonLock.this.renewExpirationAsync(threadId);\rfuture.onComplete((res, e) -\u0026gt; {\rif (e != null) {\rRedissonLock.log.error(\u0026quot;Can't update lock \u0026quot; + RedissonLock.this.getName() + \u0026quot; expiration\u0026quot;, e);\r} else {\rif (res) {\rRedissonLock.this.renewExpiration();\r}\r}\r});\r}\r}\r}\r}, this.internalLockLeaseTime / 3L, TimeUnit.MILLISECONDS);\ree.setTimeout(task);\r}\r}\r 当然我们也可以进入renewExpirationAsync()方法中查看刷新锁存活时间所执行的Lua脚本\nif (redis.call('hexists', KEYS[1], ARGV[2]) == 1) then redis.call('pexpire', KEYS[1], ARGV[1]); return 1; end; return 0;\r 最佳实践，使用时，手动指定过期时间，可以省去整个续期操作\n常见的分布式锁 可重入锁 先看看已下伪代码\na() {\rb();\r}\r 在A方法中调用了B方法，此时A方法需要获取C锁，往下执行，B方法也需要获取C锁，如果C锁为不可重入锁，那\n就需要首先等待A方法释放C锁，而A方法又需要等待B方法执行完成才能释放C锁，这就产生了死锁的问题。如果C\n锁为可重入锁，那么A方法与B方法都同时持有C锁，\n常用的方法\nRlock lock = redisson.getLock(\u0026quot;lock\u0026quot;)\r//加锁\rlock.lock();\r//尝试加锁\rlock.tryLock();\r//释放锁\rlock.unlock();\r 公平锁 顾名思义，所有线程在获取锁时需要顺序的获取，就像日常排队一样。Redisisson默认为非公平锁\n常用的方法\nRlock fireLock = redisson.getFairLock(\u0026quot;fireLock\u0026quot;)\rfireLock.lock();\rfireLock.unlock();\r 读写锁 保证一定能读到最新状态，读锁可以在没有写锁的时候被多个线程同时持有（共享锁），写锁是独占的(排他锁/独\n享锁)。 每次只能有一个写线程，但是可以有多个线程并发地读数据。\n分布式可重入读写锁允许同时有多个读锁和一个写锁处于加锁状态。\n常用的方法\nRReadWriteLock rwlock = redisson.getReadWriteLock(\u0026quot;anyRWLock\u0026quot;);\r//加读锁\rrwlock.readLock().lock();\r//加写锁\rrwlock.writeLock().lock();\r 常见情况分析\n 读+读 ：相当于无锁，并发读，只会在redis中记录好，所有当前的读锁。会同时加锁成功 写+读 ：等待写锁释放 写+写 ：阻塞方式，需等待上一个写锁释放 读+写 ：有读锁，写也需要等待。  总结：只要有写的存在，都必须等待\n信号量 可以限制同时访问共享区域的线程数量，即限流。\n信号量总数存储于Redis的一个key(可自定义)中，每次申请都会将该key对应的value值减去1，直到数量为0，不能\n再次申请。反之，当释放许可时，每次操作都会将其值加上1。\n比喻：相当于一个停车场，来一辆车，可用的车库数就减少一，走一辆，可用的车库数就增加一。\n常用的方法\nRSemaphore semaphore = redisson.getSemaphore(\u0026quot;semaphore\u0026quot;);\r//获取23个信号量，如果无法获取，会一直等待，阻塞方法\rsemaphore.acquire(23);\r//尝试获取1个信号量，无法获取时，返回false\rsemaphore.tryAcquire(); //释放信号量\rsemaphore.release();  闭锁 需要等待其他线程闭锁都执行完成后，才可以开始执行闭锁中的逻辑\n常用的方法\nRCountDownLatch latch = redisson.getCountDownLatch(\u0026quot;anyCountDownLatch\u0026quot;);\r//设置闭锁数量\rlatch.trySetCount(1);\r//等待其他闭锁都执行完成\rlatch.await();\r//在其他线程或其他JVM里\rRCountDownLatch latch = redisson.getCountDownLatch(\u0026quot;anyCountDownLatch\u0026quot;);\r//完成，闭锁数减一\rlatch.countDown();\r ","id":63,"section":"posts","summary":"概述：Redisson是架设在Redis基础上的一个Java驻内存数据网格。简单来说就是Redis分布式锁对于Java语言的实现，其提供的许","tags":["缓存","redisson"],"title":"分布式锁实现-Redisson","uri":"https://bluestaree.github.io/2020/07/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E5%AE%9E%E7%8E%B0-redisson/","year":"2020"},{"content":"  概览：在高并发场景下，缓存在读模式下所存在的问题\n 缓存穿透 缓存雪崩 缓存击穿   缓存穿透 指查询一个一定不存在的数据，由于缓存是不命中，将去查询数据库，但是数据库也无此记录，我们没有将这次查\n询的nulI写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义\n风险:\n他人恶意利用不存在的数据进行攻击，数据库瞬时压力增大，最终导致崩溃\n解决:\n 对于查询不到的结果，可以存为null，并加入短暂过期时间 (可能会导致大量无效key) 使用布隆过滤器，过滤无效请求，拒绝访问（存在误判情况）   缓存雪崩 缓存雪崩是指在我们设置缓存时key采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，\n导致DB瞬时压力过重而崩溃。\n解决:\n原有的失效时间基础上增加一个随机值，不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀，这样\n每一个缓存的过期时间的重复率就会降低，很难引发集体失效的事件。\n 缓存击穿 对于一些设置了过期时间的 key，如果这些 key 可能会在某些时间点被超高并发地访问，是一种非常“热点”的数\n据。如果这个 key 在大量请求同时进来前正好失效，那么所有对这个 key 的数据查询就会直接落到 DB\n解决:\n  加锁。大量并发只让一个去查， 其他人等待，查到以后释放锁，其他人获取到锁，先查缓存，就会有数据，不用去db\n 本地锁 :Synchronized,Lock等  问题：因为Spring容器单例的特点，所以能锁住当前进程资源，即使有百万并发，也只有1个线程访问DB。但在分布式下，必须使用分布式锁，因为不同服务器进程不同，锁对象也就不同，会存在多余线程请求DB的情况\n 分布式锁  使用Redis进行分布式锁的创建(SETNX) 原子加锁\n语法： Set [key] [value] [EX设置过期时间，秒)] [NX] (不存在才设置)\n 举个栗子：Set lock uuid EX 300 NX\n spring data-redis : API\nredisTemplate.opsForValue().setIfAbsent(key,value )\r 每个线程采取自旋的形式周期性尝试获取锁\n注意：在执行业务逻辑后，需要使用Lua脚本进行原子解锁\n\u0026quot;if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\u0026quot;;\r 问题： 需要经过中间件，效率比本地锁要低\nRedis分布式锁的实现方案：Redisson\n  设置热点数据永不过期\n  在 redis、db 中间做一个二级缓存\n  ","id":64,"section":"posts","summary":"概览：在高并发场景下，缓存在读模式下所存在的问题 缓存穿透 缓存雪崩 缓存击穿 缓存穿透 指查询一个一定不存在的数据，由于缓存是不命中，将去查询数据库","tags":["缓存"],"title":"高并发下的缓存失效问题及解决方案","uri":"https://bluestaree.github.io/2020/07/%E9%AB%98%E5%B9%B6%E5%8F%91%E4%B8%8B%E7%9A%84%E7%BC%93%E5%AD%98%E5%A4%B1%E6%95%88%E9%97%AE%E9%A2%98/","year":"2020"},{"content":"  由于Spring Cloud Eureka已经宣布停止开源计划，不再继续维护，这怎么行，还能愉快的使用吗。 今天在空闲之余了解了下另外一个功能更加强大的注册中心，那就是SpringCloud Alibaba的Nacos\n SpringCloud Alibaba Spring Cloud Alibaba致力于提供微服务开发的一站式解决方案。此项目包含开发分布式应用微服务的必需组件,方\n便开发者通过 Spring Cloud编程模型轻松使用这些组件来开发分布式应用服务。\n依托 Spring Cloud Alibaba,您只需要添加一些注解和少量配置,就可以将 Spring Cloud应用接入阿里微服务解决方\n案,通过阿里中间件来迅速搭建分布式应用系统。GitHub地址\n本文主要介绍Spring Cloud Alibaba项目下的Nacos组件基本使用。\nNacos初体验 使用Nacos作为注册中心 1.首先引入SpringCloud Alibaba依赖\n 注意：选择合适的版本\n 1.5.x 版本适用于 Spring Boot 1.5.x 2.0.x 版本适用于 Spring Boot 2.0.x 2.1.x 版本适用于 Spring Boot 2.1.x 2.2.x 版本适用于 Spring Boot 2.2.x   pom文件配置：\n\u0026lt;dependencyManagement\u0026gt;\r\u0026lt;dependencies\u0026gt;\r\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-cloud-alibaba-dependencies\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;2.2.0.RELEASE\u0026lt;/version\u0026gt;\r\u0026lt;type\u0026gt;pom\u0026lt;/type\u0026gt;\r\u0026lt;scope\u0026gt;import\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r\u0026lt;/dependencies\u0026gt;\r\u0026lt;/dependencyManagement\u0026gt;\r 2.引入Nacos注册中心依赖\npom文件配置：\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-discovery\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 配置文件的配置\nserver:\rport: 8080\rspring:\rapplication:\rname: Hello-Nacos\rcloud:\tnacos:\t//这里配置nacos注册中心的地址\rdiscovery:\rserver-addr: 127.0.0.1:8848\r 启动类\n@EnableDiscoveryClient\r@SpringBootApplication\rpublic class WebApplication {\rpublic static void main(String[] args) {\rSpringApplication.run(WebApplication.class, args);\r}\r}\r 3.获取Nacos的服务端 : https://github.com/alibaba/nacos/releases\n下载后启动服务端，打开浏览器访问http://127.0.0.1:8848/nacos\n 默认账号密码均为 : nacos\n 4.启动服务\n启动测试服务后，查看nacos服务管理中心，可以看到该服务已经成功注册\n之后就可以结合spring cloud open-feign进行远程服务调用啦，这里不再演示\n使用Nacos作为配置中心 1.首先导入nacos配置中心的依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;com.alibaba.cloud\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-cloud-starter-alibaba-nacos-config\u0026lt;/artifactId\u0026gt;\r\u0026lt;/dependency\u0026gt;\r 2.新增bootstrap.properties配置文件,添加已下配置信息\nspring.application.name=hello-nacos\t#项目名\rspring.cloud.nacos.config.server-addr=127.0.0.1:8848\t#nacos配置中心地址\r 3.在配置中心中新建配置文件,nacos配置中心默认会加载项目名.properties文件\nController相关代码\n@RestController\rpublic class WebController {\r@Value(\u0026quot;${mycustomer.name}\u0026quot;)\rpublic String name;\r@Value(\u0026quot;${mycustomer.age}\u0026quot;)\rpublic int age;\r@GetMapping\rprivate Map test() {\rHashMap hashMap = new HashMap();\rhashMap.put(\u0026quot;name\u0026quot;, name);\rhashMap.put(\u0026quot;age\u0026quot;, age);\rreturn hashMap;\r}\r}\r 测试结果\n成功读取配置中心里配置信息\n这里还可以配合使用 @RefreshScope 注解实现动态配置刷新\n 注意：如果配置中心和当前应用的配置文件中都配置了相同的项，会优先使用配置中心里的配置\n  实现多配置文件加载(如开发，生产，测试等环境\u0026hellip;) nacos配置中心的一些概念\n  命名空间 ,默认：public(保留空间)，默认新增的所有配置都存在public空间,\n要使用特定的命名空间，需要在bootstrap.properties配置文件中指定命名空间ID\nspring.cloud.nacos.config.namespace=23902197-c354-4216-94cf-8e5cb8537e26\r 通过这一点，我们可以为每一个微服务创建一个命名空间，形成基于微服务间的隔离\n  配置集 ：所有配置文件的集合\n  配置集ID ：相当于文件名\n  配置分组 ：默认所有配置集都属于DEFAULT_GROUP，我们可以在创建配置文件时，使用配置分组来区分不同的环境\n在bootstrap.properties配置文件 中指定分组\nspring.cloud.nacos.config.group=dev\t#指定配置分组\r   bootstrap.properties配置文件中指定多配置文件加载\n#多配置文件加载\rspring.cloud.nacos.config.ext-config[0].data-id=datasource.yml\t#配置ID\rspring.cloud.nacos.config.ext-config[0].group=dev\t#配置分组\rspring.cloud.nacos.config.ext-config[0].refresh=true\t#自动刷新\rspring.cloud.nacos.config.ext-config[1].data-id=hello-nacos.properties\rspring.cloud.nacos.config.ext-config[1].group=dev\rspring.cloud.nacos.config.ext-config[1].refresh=true\r ","id":65,"section":"posts","summary":"由于Spring Cloud Eureka已经宣布停止开源计划，不再继续维护，这怎么行，还能愉快的使用吗。 今天在空闲之余了解了下另外一个功能更加强大的注","tags":["Nacos"],"title":"Spring Cloud Alibaba-Nacos 注册与配置中心","uri":"https://bluestaree.github.io/2020/07/springcloud-alibaba-nacos-%E6%B3%A8%E5%86%8C%E4%B8%8E%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/","year":"2020"},{"content":"  前言：TCP是面向连接的，面向流的，提供高可靠性服务。收发两端(客户端和服务器端)都要有一一成对的socket，因此发送端为了将多个发给接收端的包，更有效的发给对方，使用了优化方法(Nagle算法)，将多次间隔较小且数据量小的数据，合并成一个大的数据块，然后进行封包。这样做虽然提高了效率，但是接收端就难于分辨出完整的数据包了，因为面向流的通信是无消息保护边界的。\n 由于TCP无消息保护边界,需要在接收端处理消息边界问题，也就是我们所说的粘句、拆包问题，看一张图\n假设客户端分别发送了两个数据包D1和D2给服务端，由于服务端一次读取到字节数是不确定的，故可能存在以下四种情况:\n  服务端分两次读取到了两个独立的数据包，分别是D1和D2，没有粘包和拆包\n  服务端一次接受到了两个数据包，D1和D2粘合在一起，称之为TCP粘包\n  服务端分两次读取到了数据包，第一次读取到了完整的D1包和D2包的部分内容，第二次读取到了D2包的剩余内容，这称之为TCP拆包\n  服务端分两次读取到了数据包，第一次读取到了D1包的部分内容D1_1，第二次读取到了D1包的剩余部分内容D1_ 2和完整的D2包。\n  解决方案\n  使用自定义协议(一个自定义对象)+编解码器来解决\n  关键就是要解决服务器端每次读取数据长度的问题,这个问题解决，就不会出现服务器多读或少读数据的问题，从而避免的TCP粘包、拆包。\n  举个栗子\n自定义传输协议对象\npublic class MessageProtocol {\rprivate int len;\rprivate byte[] content;\r// set,get方法\r//....\r}\r 编码器\npublic class MyMessageEncoder extends MessageToByteEncoder\u0026lt;MessageProtocol\u0026gt; {\r@Override\rprotected void encode( ChannelHandlerContext ctx, MessageProtocol msg,ByteBuf out) throws Exception {\rout.writeInt(msg.getLen());\rout.writeBytes(msg.getContent());\r}\r}\r 解码器\npublic class MyMessageDecoder extends ReplayingDecoder\u0026lt;Void\u0026gt; {\r@Override\rprotected void decode(ChannelHandlerContext ctx, ByteBuf in, List\u0026lt;object\u0026gt; out) throws Exception {\r//将得到的二进制字节码转换为MessageProtocol 自定义协议包(对象)\rint length = in.readInt();\rbyte[] content = new byte[length] ;\rin.readBytes(content);\r//封装成MessageProtocol对象，放入out,传递给下一个handler处理\rMessageProtocol messageProtocol = new MessageProtocol();\rmessageProtocol.setLen(length);\rmessageProtocol.setContent(content);\rout.add(messageProtocol);\r}\r}\r ","id":66,"section":"posts","summary":"前言：TCP是面向连接的，面向流的，提供高可靠性服务。收发两端(客户端和服务器端)都要有一一成对的socket，因此发送端为了将多个发给接收","tags":null,"title":"TCP粘包和拆包问题","uri":"https://bluestaree.github.io/2020/06/tcp%E7%B2%98%E5%8C%85%E5%92%8C%E6%8B%86%E5%8C%85%E9%97%AE%E9%A2%98/","year":"2020"},{"content":"  参考：Quartz文档\n cron表达式基本语法：秒 分 时 日 月 周 年 (共7位，其中第7位 年 在Spring中不支持)\n特殊字符:\n,：枚举;\n (cron=\u0026quot;7,9,23 * * * * ?\u0026quot;)：任意时刻的7,9, 23 秒启动这个任务;  -：范围;\n (cron=\u0026quot;7-20 * * * * ?\u0026quot;)：任意时刻的7-20秒之间，每秒启动一次  *：任意;\n 指定位置的任意时刻都可以  /：步长;\n  (cron=\u0026quot;7/5 * * * * ?\u0026quot;)：第7秒启动，每5秒一次;\n  (cron=\u0026rdquo;*/5 * * * * ?\u0026quot;)：任意秒启动，每5秒一次;\n  ? ：(出现在日和周几的位置)：为了防止日和周冲突，在周和日上如果要写通配符使用?\n (cron=\u0026rdquo;* * * 1 * ?\u0026quot;)：每月的1号，而且必须是周二然后启动这个任务;  L：(出现在日和周的位置)，表示last：最后一个\n (cron=\u0026rdquo;* * * ? * 3L\u0026rdquo;)：每月的最后一个周二  W：表示Work Day：工作日\n  (cron=\u0026rdquo;* * * W * ?\u0026quot;)：每个月的工作日触发\n  (cron=\u0026rdquo;* * * L W * ?\u0026quot;)：每个月的最后一个工作日触发\n  #：第几个\n (cron=\u0026rdquo;* * * ? * 5#2\u0026rdquo;)：每个月的第2个周4  ","id":67,"section":"posts","summary":"参考：Quartz文档 cron表达式基本语法：秒 分 时 日 月 周 年 (共7位，其中第7位 年 在Spring中不支持) 特殊字符: ,：枚举; (cron=\u0026quot;7,9,23 * * * * ?\u0026","tags":null,"title":"定时器-cron表达式","uri":"https://bluestaree.github.io/2020/06/%E5%AE%9A%E6%97%B6%E5%99%A8-cron%E8%A1%A8%E8%BE%BE%E5%BC%8F/","year":"2020"},{"content":" Netty的编解码器 当Netty发送或者接受一个消息的时候，就将会发生一次数据转换。入站消息会被解码：从字节转换为另一种格式(比如java对象)；如果是出站消息，它会被编码成字节。\nNetty提供一系列实用的编解码器，他们都实现了ChannelInboundHadnler或者ChannelOutboundHandler接口。在这些类中，channelRead方法已经被重写了。以入站为例，对于每个从入站Channel读取的消息，这个方法会被调用。随后，它将调用由解码器所提供的decode()方法进行解码，并将已经解码的字节转发给ChannelPipeline中的下一个ChannellnboundHandler.\n举个栗子\n关于一个ByteToMessageDecoder(入站解码器)实例分析\npublic class ToIntegerDecoder extends ByteToMessageDecoder {\r@Override\rprotected void decode(ChannelHandlerContext ctx, ByteBuf in, List\u0026lt;Object\u0026gt; out) throws Exception{\r//按照每4字节，即一个int类型进行解码，将读取的数据放入out数组中\r//并将其传入下一个Handler处理器\r//该方法将根据消息内容大小被调用多次\rif (in.readableBytes()\u0026gt;=4){ //判断缓存区(ByteBuf)的数据是否足够，防止拆包和粘包问题\rout.add(in.readInt());\r}\r}\r}\r 说明\n decode 解码器会根据接收的数据，被调用多次，直到确定没有新的元素被添加到list，或者是ByteBuf 没有更多的可读字节为止 如果list不为空，就会将list的内容传递给下一个Handler处理，该处理器的方法也会被调用多次，比如一个8字节的数据，经过上述解码器解码，会调用两次decode方法， 并执行两次解码器之后的Handler的业务处理方法，(简单来说就是客户端发送一个8字节数据，服务端将会应答2次) 编写encode编码器时，需要注意指定编码数据的类型，在发送数据时，其底层会判断当前发送的数据类型是否与之匹配，如果不符合，会直接将数据写出，不会进行相关编码操作  结论\n  不论解码器handler还是编码器handler即接收的消息类型必须与待处理的消息类型一致，否则handler不会被执行\n  在解码器进行数据解码时，需要判断缓存区(ByteBuf)的数据是否足够，否则接收到的结果会期望结果可能不一致\n  ReplayingDecoder ReplayingDecoder扩展了ByteToMessageDecoder类，使用这个类，我们不必调用readableBytes()方法。参数S指定了用户状态管理的类型，其中Void代表不需要状态管理\npublic class MyByteToLongDecoder extends ReplayingDecoder\u0026lt;Void\u0026gt; {\r@Override\rprotected void decode(ChannelHandlerContext ctx, ByteBuf in, List\u0026lt;object\u0026gt; out) throws Exception {\r//在ReplayingDecoder不需要判断数据是否足够读取，内部会进行处理判断\rout.add(in.readLong());\r}\r ReplayingDecoder使用方便， 但它也有一些局限性:\n1.并不是所有的ByteBuf操作都被支持如果调用了一个不被支持的方法，将会抛出一个UnsupportedOperationException。\n2.ReplayingDecoder在某些情况下可能稍慢于ByteToMessageDecoder，例如网络缓慢并且消息格式复杂时，消\n息会被拆成了多个碎片，速度变慢\n其它解码器\n LineBasedFrameDecoder: 这个类在Netty内部也有使用，它使用行尾控制字符(\\n或者\\r\\n)作为分隔符来解析  数据。\n DelimiterBasedFrameDecoder: 使用自定义的特殊字符作为消息的分隔符进行解码。\n  HttpObjectDecoder: 一个HTTP数据的解码器\n  LengthFieldBasedFrameDecoder: 通过指定长度来标识整包消息，这样就可以自动的处理黏包和半包消息。\n  其他编码器\n  ObjectEncoder : 简单地说就是把对象序列化后，转为ChannelBuffer并返回\n  Base64Encoder : base64编码器\n  StringEncoder : 消息转成String编码器\n  ZlibEncoder ：压缩数据\n  ","id":68,"section":"posts","summary":"Netty的编解码器 当Netty发送或者接受一个消息的时候，就将会发生一次数据转换。入站消息会被解码：从字节转换为另一种格式(比如java对","tags":["Netty"],"title":"Netty编解码器","uri":"https://bluestaree.github.io/2020/06/netty%E7%9A%84%E7%BC%96%E8%A7%A3%E7%A0%81%E5%99%A8/","year":"2020"},{"content":"  前言：Netty中ChannelHandler 的作用就是处理IO事件或拦截IO事件，并将其处理结果转发给下一个Handler，那么Handler链的调用机制又是怎样的呢\n 出站和入站机制 ChannelHandler充当了处理入站和出站数据的应用程序逻辑的容器。例如，实现ChannelInboundHandler接口(或ChannelInboundHandlerAdapter)，你就可以接收入站事件和数据，这些数据会被业务逻辑处理。当要给客户端发送响应时，也可以从ChannelInboundHandler冲刷数据。业务逻辑通常写在一个或者多个ChannelInboundHandler中。ChannelOutboundHandler原理一 样，只不过它是用来处理出站数据的\n ChannelPipeline提供了ChannelHandler链的容器。出站和入站方向是相对的，以客户端应用程序为例。如果事\n件的运动方向是从客户端到服务端的，那么我们称这些事件为出站的，即客户端发送给服务端的数据会通过\npipeline中的一系列ChannelOutboundHandler，并被这些Handler处理，反之则称为入站的\n官方图解\n一般来说\n出站要编码，入站要解码\n出站对应写，入站对应读\n","id":69,"section":"posts","summary":"前言：Netty中ChannelHandler 的作用就是处理IO事件或拦截IO事件，并将其处理结果转发给下一个Handler，那么Handl","tags":["Netty"],"title":"Netty-Handler链的调用机制","uri":"https://bluestaree.github.io/2020/06/handler%E9%93%BE%E7%9A%84%E8%B0%83%E7%94%A8%E6%9C%BA%E5%88%B6/","year":"2020"},{"content":" 总览   Bootstrap or ServerBootstrap EventLoop or EventLoopGroup ChannelInitializer ChannelHandler ChannelPipeline ChannelHandlerContext Future or ChannelFuture   Bootstrap or ServerBootstrap 都是用来启动一个Netty应用的配置类，它主要作用是配置整个Netty程序，串联起各个组件。\nEventLoop or EventLoopGroup   EventLoopGroup 是一组EventLoop的抽象，Netty 为了更好的利用多核CPU资源，一般会有多个EventLoop同时工作，每个EventLoop维护着一个Selector实例。\n  EventLoopGroup 提供next接口，可以从组里面按照一定规则获取其中一个EventLoop来处理任务。在Netty服务器端编程中，我们一般都需要提供两个EventLoopGroup，例如: BossEventLoopGroup 和WorkerEventLoopGroup。\n  客户端连接处理流程如下图\nChannelInitializer channel的初始化容器，我们就是在这里面设置自定义的处理器\n相关API\nbootstrap.group(bossGroup, workerGroup) .handler(new NettyBossHandler()) // 给bossGroup的EventLoop对应的管道设置处理器\r.childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() {\r//给pipeline设置处理器\r@Override\rprotected void initChannel(SocketChannel ch) throws Exception {\r//获取当前通道对应的管道,在末尾添加一个自定义的处理器\rch.pipeline().addLast(new NettyWorkerHandler()); }\r}); // 给workerGroup的EventLoop对应的管道设置处理器\r ChannelHandler ChannelHandler 的作用就是处理IO事件或拦截IO事件，并将其转发给下一个处理程序ChannelHandler。Handler处理事件是分入站和出站的，两个方向的操作都是不同的，因此，Netty 定义了两个子接口继承ChannelHandler\n ChannelInboundHandler 处理入站事件接口   ChannelOutboundHandler 处理出站事件接口  此外，ChannelDuplexHandler 类能够同时处理出站和入站事件\n每个客户端Channel 都独享自己的 Handle\nChannelPipeline 在Netty中每个Channel都有且仅有一个ChannelPipeline与之对应，pipeline和channel是相互包含关系 即双方都可以获取对方的实例。它们的组成关系如下图所示\n一个Channel包含了一个ChannelPipeline，而ChannelPipeline 中又维护了一个由ChannelHandlerContext组成的双向链表，并且每个ChannelHandlerContext中又关联着一个ChannelHandler\n入站事件和出站事件在一个双向链表中，入站事件会从链表head往后传递到最后一个入站的handler,出站事件会从链表tail往前传递到最前一个出站的handler,两种类型的handler互不干扰\nChannelHandlerContext 多个ChannelHandlerContext组成了一个双向链表，Context是对Handler的封装。\n  保存了Channel相关的所有上下文信息，同时关联一个ChannelHandler 对象\n  即ChannelHandlerContext中包含一个具体的事件处理器ChannelHandler,同时也绑定了对应的pipeline和Channel的信息，方便对ChannelHandler进行调用.\n  常用方法\n   ChanelFuture close(), 关闭通道 ChannelOutboundInvoker flush()，刷新 ChannelFuture writeAndFlush(Object msg)， 将数据写到ChannelPipeline中当前ChannelHandler 的下一个ChannelHandler开始处理(出站)  Future or ChannelFuture Netty的异步模型\n基本介绍\n  异步的概念和同步相对。当一个异步过程调用发出后,调用者不能立刻得到结果。实际处理这个调用的组件在完成后,通过状态、通知和回调来通知调用者。\n  Nett中的I/0操作是异步的,包括Bind、 Write、 Connect等操作会简单的返回一个ChannelFuture。\n  调用者并不能立刻获得结果,而是通过 Future-Listener机制,用户可以方便的主动获取或者通过通知机制获得IO操作结果\n  Netty的异步模型是建立在 future和 callback的之上的。 callback就是回调。重点说Future,它的核心思想是:假设一个方法fun,计算过程可能非常耗时,等待fun返回显然不合适。那么可以在调用fun的时候,立马返回一个 Future,后续可以通过Future去监控方法fun的处理过程(即: Future-Listener机制)\n    注：当 Future对象刚刚创建时,处于非完成状态,调用者可以通过返回的 ChannelFuture来获取操作执行的状态,注册监听函数来执行完成后的操作\n 常见有如下操作\n  通过 isDone 方法来判断当前操作是否完成;\n  通过 isSuccess 方法来判断已完成的当前操作是否成功;\n  通过 getCause 方法来获取已完成的当前操作失败的原因;\n  通过 isCancelled 方法来判断已完成的当前操作是否被取消;\n  通过 addlistener 方法来注册监听器,当操作已完成( isDone方法返回完成),将会通知指定的监听器;如果 Future对象已完成,则通知指定的监听器;\n  举个栗子\n//启动服务器(并绑定端口)\rChannelFuture cf = bootstrap.bind(6668).sync();\r//给cf 注册监听器，监控我们关心的事件\rcf.addListener(new ChannelFutureListener() {\r@Override\rpublic void operationComplete(ChannelFuture future) throws Exception {\rif (cf.isSuccess()) {\rSystem.out.println(\u0026quot;监听端口 6668 成功\u0026quot;);\r} else {\rSystem.out.println(\u0026quot;监听端口 6668 失败\u0026quot;);\r}\r}\r});\r ","id":70,"section":"posts","summary":"总览 Bootstrap or ServerBootstrap EventLoop or EventLoopGroup ChannelInitializer ChannelHandler ChannelPipeline ChannelHandlerContext Future or ChannelFuture Bootstrap or ServerBootstrap 都是用来启动一个Netty应用的配置类，它主要作用是配置整个Netty程序，串联起各个组件。 EventLoop or EventLoopGroup EventLoopGroup 是一","tags":["Netty"],"title":"Netty基础组件","uri":"https://bluestaree.github.io/2020/06/netty%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D/","year":"2020"},{"content":"  前言：通过Netty完成一个简单的多客户端与单服务端交互的demo\n Netty初体验 服务端\npublic class NettyServer {\rpublic static void main(String[] args) throws Exception {\r//1. 创建两个线程组 bossGroup 和 workerGroup\r//2. bossGroup 只是处理连接请求 , 真正的和客户端业务处理，会交给 workerGroup完成\r//3. 两个都是无限循环\r//4. bossGroup 和 workerGroup 含有的子线程(NioEventLoop)的个数可以在参数中指定\r// 默认数量为实际 cpu核数 * 2\rEventLoopGroup bossGroup = new NioEventLoopGroup(1);//通常bossGroup只需要1个\rEventLoopGroup workerGroup = new NioEventLoopGroup(); try {\r//创建服务器端的启动引导类对象，可以配置服务器参数\rServerBootstrap bootstrap = new ServerBootstrap();\r//使用链式编程来进行设置\rbootstrap.group(bossGroup, workerGroup) //设置两个线程组\r//使用NioSocketChannel 作为服务器的通道实现\r.channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 128) // 设置线程队列得到连接个数\r.childOption(ChannelOption.SO_KEEPALIVE, true) //设置保持活动连接状态\r// .handler(null) // 该 handler对应 bossGroup设置 , childHandler 对应 workerGroup\r.childHandler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() {//创建一个通道初始化对象(匿名对象)\r//给pipeline 设置处理器\r@Override\rprotected void initChannel(SocketChannel ch) throws Exception {\r//这里的SocketChannel 是客户端通道实例\r//获取当前通道对应的管道,在末尾添加一个自定义的处理器\rch.pipeline().addLast(new NettyServerHandler()); }\r}); // 给我们的workerGroup 的 EventLoop 对应的管道设置处理器\r//绑定一个端口，同步执行(阻塞当前线程), 返回一个 ChannelFuture 对象(netty的异步模型)，\r//可通过此对象获取方法执行结果\r//启动服务器(并绑定端口)\rChannelFuture cf = bootstrap.bind(6668).sync();\r//服务端管道关闭的监听器,并同步阻塞,直到channel关闭,线程才会往下执行,进入finally关闭通道结束进程\rcf.channel().closeFuture().sync();\r}finally {\r//优r雅的关闭\rbossGroup.shutdownGracefully();\rworkerGroup.shutdownGracefully();\r}\r}\r}\r 自定义服务端Handler\npublic class NettyServerHandler extends SimpleChannelInboundHandler\u0026lt;String\u0026gt; {\r//通道一旦链接，此方法第一个执行\r@Override\rpublic void handlerAdded(ChannelHandlerContext ctx) throws Exception {\r//通过上线文获取通道信息\rChannel channel = ctx.channel();\r//业务处理\r}\r//断开链接\r@Override\rpublic void handlerRemoved(ChannelHandlerContext ctx) throws Exception {\r}\r//通道处于活跃状态\r@Override\rpublic void channelActive(ChannelHandlerContext ctx) throws Exception {\r}\r//非活跃状态\r@Override\rpublic void channelInactive(ChannelHandlerContext ctx) throws Exception {\r}\r//异常处理,一般是需要关闭通道\r@Override\rpublic void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\rctx.close();\r}\r//通道有数据可读，第二个参数是消息内容\r@Override\rprotected void channelRead0(ChannelHandlerContext channelHandlerContext, String s) throws Exception {\r//writeAndFlush 是 write + flush\r//将数据写入到缓存，并刷新\r//一般，我们会对这个发送的数据进行编码\rctx.writeAndFlush(Unpooled.copiedBuffer(\u0026quot;hello, 客户端~\u0026quot;, CharsetUtil.UTF_8));\r}\r}\r 客户端\npublic class NettyClient {\rpublic static void main(String[] args) throws Exception {\r//客户端需要一个事件循环组\rEventLoopGroup group = new NioEventLoopGroup();\rtry {\r//创建客户端启动对象\r//注意客户端使用的不是 ServerBootstrap 而是 Bootstrap\rBootstrap bootstrap = new Bootstrap();\r//设置相关参数\rbootstrap.group(group) //设置线程组\r.channel(NioSocketChannel.class) // 设置客户端通道的实现类\r.handler(new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() {\r@Override\rprotected void initChannel(SocketChannel ch) throws Exception {\r//这里可以加入自己的处理器\rch.pipeline().addLast(new NettyClientHandler()); }\r});\r//启动客户端去连接服务器端\rChannelFuture channelFuture = bootstrap.connect(\u0026quot;127.0.0.1\u0026quot;, 6668).sync();\r//给关闭通道进行监听\rchannelFuture.channel().closeFuture().sync();\r}finally {\rgroup.shutdownGracefully();\r}\r}\r}\r 自定义客户端Handler\npublic class NettyClientHandler extends ChannelInboundHandlerAdapter {\r//当通道就绪就会触发该方法\r@Override\rpublic void channelActive(ChannelHandlerContext ctx) throws Exception {\rSystem.out.println(\u0026quot;client \u0026quot; + ctx);\rctx.writeAndFlush(Unpooled.copiedBuffer(\u0026quot;hello, server\u0026quot;, CharsetUtil.UTF_8));\r}\r//当通道有读取事件时，会触发\r@Override\rpublic void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception {\rByteBuf buf = (ByteBuf) msg;\rSystem.out.println(\u0026quot;服务器回复的消息:\u0026quot; + buf.toString(CharsetUtil.UTF_8));\rSystem.out.println(\u0026quot;服务器的地址： \u0026quot;+ ctx.channel().remoteAddress());\r}\r@Override\rpublic void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {\rcause.printStackTrace();\rctx.close();\r}\r}\r 关于Channel类型设置\n不同协议、不同的阻塞类型的连接都有不同的 Channel类型与之对应,常用的Channel类型:\n NioSocketChannel,异步的客户端 TCP Socket连接 NioServerSocketChannel,异步的服务器端 TCP Socket连接。 NioDatagramChannel,异步的UDP连接。 NioSctpChannel,异步的客户端Sctp连接。 NioSctpServerChannel,异步的Sctp服务器端连接,这些通道涵盖了UDP和TCP网络IO以及文件IO。  关于ChannelOption参数设置\n参数如下\n ChannelOption.SO_BACKLOG  对应TCP/IP协议listen函数中的backlog参数，用来初始化服务器可连接队列大小。服务端处理客户端连接请求是顺序处理的，所以同一时间只能处理一个客户端连接。 多个客户端来的时候，服务端将不能处理的客户端连接请求放在队列中等待处理，backlog 参数指定了队列的大小。\n ChannelOption.SO_KEEPALIVE  一直保持连接活动状态\n相关代码API\nbootstrap.group(bossGroup, workerGroup) .channel(NioServerSocketChannel.class) .option(ChannelOption.SO_BACKLOG, 128) //给bossGroup通道设置参数\r.childOption(ChannelOption.SO_KEEPALIVE, true) //给workerGroup通道设置参数\r ","id":71,"section":"posts","summary":"前言：通过Netty完成一个简单的多客户端与单服务端交互的demo Netty初体验 服务端 public class NettyServer { public static void main(String[] args) throws Exception { //1. 创建两个线程组 bossGroup 和 workerGroup //2. bossGroup 只","tags":["Netty"],"title":"Netty初体验","uri":"https://bluestaree.github.io/2020/06/netty%E5%88%9D%E4%BD%93%E9%AA%8C/","year":"2020"},{"content":"  转载 · 原文链接：https://www.jianshu.com/p/275602182f39\n 前言 零拷贝这三个字，一直是服务器网络编程的关键字，任何性能优化都离不开。在 Java 程序员的世界，常用的零拷贝有 mmap 和 sendFile。那么，他们在 OS 里，到底是怎么样的一个的设计？本文将简单聊聊 mmap 和 sendFile 这两个零拷贝。\n传统数据读写的劣势 初学 Java 时，我们在学习 IO 和 网络编程时，会使用以下代码：\nFile file = new File(\u0026quot;index.html\u0026quot;);\rRandomAccessFile raf = new RandomAccessFile(file, \u0026quot;rw\u0026quot;);\rbyte[] arr = new byte[(int) file.length()];\rraf.read(arr);\rSocket socket = new ServerSocket(8080).accept();\rsocket.getOutputStream().write(arr);\r 我们会调用 read 方法读取 index.html 的内容—— 变成字节数组，然后调用 write 方法，将 index.html 字节流写到 socket 中，那么，我们调用这两个方法，在 OS 底层发生了什么呢？我这里借鉴了一张其他文字的图片，尝试解释这个过程。\n传统 IO 操作\n上图中，上半部分表示用户态和内核态的上下文切换。下半部分表示数据复制操作。下面说说他们的步骤：\n read 调用导致用户态到内核态的一次变化，同时，第一次复制开始：DMA（Direct Memory Access，直接内存存取，即不使用 CPU 拷贝数据到内存，而是 DMA 引擎传输数据到内存，用于解放 CPU） 引擎从磁盘读取 index.html 文件，并将数据放入到内核缓冲区。 发生第二次数据拷贝，即：将内核缓冲区的数据拷贝到用户缓冲区，同时，发生了一次用内核态到用户态的上下文切换。 发生第三次数据拷贝，我们调用 write 方法，系统将用户缓冲区的数据拷贝到 Socket 缓冲区。此时，又发生了一次用户态到内核态的上下文切换。 第四次拷贝，数据异步的从 Socket 缓冲区，使用 DMA 引擎拷贝到网络协议引擎。这一段，不需要进行上下文切换。 write 方法返回，再次从内核态切换到用户态。  如你所见，复制拷贝操作太多了。如何优化这些流程？\nmmap 优化 mmap 通过内存映射，将文件映射到内核缓冲区，同时，用户空间可以共享内核空间的数据。这样，在进行网络传输时，就可以减少内核空间到用户控件的拷贝次数。如下图：\nmmap 流程\n如上图，user buffer 和 kernel buffer 共享 index.html。如果你想把硬盘的 index.html 传输到网络中，再也不用拷贝到用户空间，再从用户空间拷贝到 Socket 缓冲区。\n现在，你只需要从内核缓冲区拷贝到 Socket 缓冲区即可，这将减少一次内存拷贝（从 4 次变成了 3 次），但不减少上下文切换次数。\nsendFile 那么，我们还能继续优化吗？ Linux 2.1 版本 提供了 sendFile 函数，其基本原理如下：数据根本不经过用户态，直接从内核缓冲区进入到 Socket Buffer，同时，由于和用户态完全无关，就减少了一次上下文切换。\nsnedFile 2.1 版本\n如上图，我们进行 sendFile 系统调用时，数据被 DMA 引擎从文件复制到内核缓冲区，然后调用，然后掉一共 write 方法时，从内核缓冲区进入到 Socket，这时，是没有上下文切换的，因为在一个用户空间。\n最后，数据从 Socket 缓冲区进入到协议栈。\n此时，数据经过了 3 次拷贝，3 次上下文切换。\n那么，还能不能再继续优化呢？ 例如直接从内核缓冲区拷贝到网络协议栈？\n实际上，Linux 在 2.4 版本中，做了一些修改，避免了从内核缓冲区拷贝到 Socket buffer 的操作，直接拷贝到协议栈，从而再一次减少了数据拷贝。具体如下图：\nsendFile 在 2.4 版本的再一次优化\n现在，index.html 要从文件进入到网络协议栈，只需 2 次拷贝：第一次使用 DMA 引擎从文件拷贝到内核缓冲区，第二次从内核缓冲区将数据拷贝到网络协议栈；内核缓存区只会拷贝一些 offset 和 length 信息到 SocketBuffer，基本无消耗。\n等一下，不是说零拷贝吗？为什么还是要 2 次拷贝？\n答：首先我们说零拷贝，是从操作系统的角度来说的。因为内核缓冲区之间，没有数据是重复的（只有 kernel buffer 有一份数据，sendFile 2.1 版本实际上有 2 份数据，算不上零拷贝）。例如我们刚开始的例子，内核缓存区和 Socket 缓冲区的数据就是重复的。\n而零拷贝不仅仅带来更少的数据复制，还能带来其他的性能优势，例如更少的上下文切换，更少的 CPU 缓存伪共享以及无 CPU 校验和计算。\n再稍微讲讲 mmap 和 sendFile 的区别。\n mmap 适合小数据量读写，sendFile 适合大文件传输。 mmap 需要 4 次上下文切换，3 次数据拷贝；sendFile 需要 3 次上下文切换，最少 2 次数据拷贝。 sendFile 可以利用 DMA 方式，减少 CPU 拷贝，mmap 则不能（必须从内核拷贝到 Socket 缓冲区）。  在这个选择上：rocketMQ 在消费消息时，使用了 mmap。kafka 使用了 sendFile。\nJava 世界的例子 kafka 在客户端和 broker 进行数据传输时，会使用 transferTo 和 transferFrom 方法，即对应 Linux 的 sendFile。\ntomcat 内部在进行文件拷贝的时候，也会使用 transferto 方法。\ntomcat 在处理一下心跳保活时，也会调用该 sendFile 方法。\n在 pulsar 项目中，下载文件时，也会使用 sendFile。如下图：\n所以，如果你需要优化网络传输的性能，或者文件读写的速度，请尽量使用零拷贝。他不仅能较少复制拷贝次数，还能较少上下文切换，缓存行污染。\n作者：莫那一鲁道 来源：简书\n ","id":72,"section":"posts","summary":"转载 · 原文链接：https://www.jianshu.com/p/275602182f39 前言 零拷贝这三个字，一直是服务器网络编程的关键字","tags":null,"title":"零拷贝","uri":"https://bluestaree.github.io/2020/06/%E9%9B%B6%E6%8B%B7%E8%B4%9D/","year":"2020"},{"content":" 前言  IO模型：就是用什么样的通道进行数据的发送和接收,很大程度上决定了程序通信的性能\n而netty是一款基于NIO(Nonblocking I/O,非阻塞IO)所开发的网络通信框架。\n 下面介绍三种I/O模型。\nBIO，传统同步阻塞 ： 服务器实现模式为一个连接一个线程,即客户端有连接请求时服务器端就需要启动一个线程\n进行处理,如果这个连接不做任何事情会造成不必要的线程开销\nNIO，同步非阻塞：服务器实现模式为一个线程处理多个请求(连接),即客户端发送的连接请求都会注册到多路复用\n器上,多路复用器轮询到连接有IO请求就进行处理\nAIO，异步非阻塞：AIO引入异步通道的概念,采用了 Proactor模式,简化了程序编写,有效的请求才启动线程,它的特\n点是先由操作系统完成后才通知服务端程序启动线程去处理,一般适用于连接数较多且连接时间较长的应用\nBIO、NIO、AIO适用场景分析  BIO方式适用于连接数目比较小且固定的架构,这种方式对服务器资源要求比较高并发局限于应用中,JDK1.4以前  的唯一选择,但程序简单易理解。\n NIO方式适用于连接数目多且连接比较短(轻操作)的架构,比如聊天服务器,弹幕系统,服务器间通讯等。编程比较复杂,JDK1.4开始支持\n  AIO方式使用于连接数目多且连接比较长(重操作)的架构,比如相册服务器,充分调用OS参与并发操作,编程比较复\n  杂,JDK7开始支持\nNIO的三大核心组件 \u0026ndash; Channel , Selector , Buffer 缓冲区( Buffer ) 缓冲区本质上是一个可以读写数据的内存块,可以理解成是一个容器对象(含数组),该对象提供了一组方法,可以更轻\n松地使用内存块，缓冲区对象内置了一些机制,，能够跟踪和记录缓冲区的状态变化情况。 Channel提供从文件、\n网络读取数据的渠道，但是读取或写入的数据都必须经由 Buffer，常用的Buffer缓冲区：ByteBuffer\n除了Boolean，java中的其他原生数据类型都有与之对应的Buffer\nBuffer的分散和聚集 NIO还支持通过多个Buffer(即Buffer数组)完成读写操作，即Scattering和Gathering\n Scattering：将数据写入到buffer时，可以采用buffer数组的形式，依次写入【分散】 Gathering：从buffer读取数据时，可以采用buffer数组，依次读  通道( Channel ) NIO的通道类似于流,但有些区别如下\n 通道可以同时进行读写,而流只能读或者只能写 通道可以实现异步读写数据 通道可以从缓冲读数据,也可以写数据到缓冲:  常用的通道：FileChannel(文件读写)、DatagramChannel(对UDP数据读写)、ServerSocketChannel(TCP数据读写)、SocketChannel(TCP数据读写)\nChannel 可从原生IO中获取\n// 创建一个输出流- \u0026gt;channel\rFileOutputStream fileOutputStream = new FileOutputStream(\u0026quot;d:\\\\file01.txt\u0026quot;);\r//通过fileOutputStream获取对应的FileChannel\r//这个fileChannel真实类型是FileChannelImpl\rFileChannel fileChannel = fileOutputStream.getChannel();\r NIO还提供了 MappedByteBuffer，可以让文件直接在内存(堆外的内存)中进行修改，而如何同步到文件由NIO来完成.\nRandomAccessFile randomAccessFile = new RandomAccessFile(\u0026quot;1.txt\u0026quot;,\u0026quot;rw\u0026quot;);\r//获取对应的通道\rFileChannel channel = randomAccessFile.getChannel();\r/**\r*参数1: FileChannel.MapMode.READ_WRITE使用的读写模式\r*参数2: 0:可以直接修改的起始位置\r*参数3: 5:是映射到内存的大小, 即将1.txt的多少个字节映射到内存\r*可以直接修改的范围就是 0-5\r*/\rMappedByteBuffer mappedByteBuffer = channel.map(FileChannel.MapMode.READ_WRITE, 0, 5);\rmappedByteBuffer.put(0,(byte)'H');\rmappedByteBuffer.put(3,(byte)'9');\r 选择器( Selector )   Java的NIO，用非阻塞的IO方式。可以用一个线程，处理多个的客户端连接，就会使用到 Selector(选择器)\n  Selector能够检测多个注册的通道上是否有事件发生(注意:多个 Channel以事件的方式可以注册到同一个\n  Selector)，如果有事件发生，便获取事件然后针对每个事件进行相应的处理。这样就可以只用一个单线程去管理\n多个通道，也就是管理多个连接和请求。\n 只有在连接真正有读写事件发生时，才会进行读写，就大大地减少了系统开销，并且不必为每个连接都创建一个线程，不用去维护多个线程\n  避免了多线程之间的上下文切换导致的开销\n  NIO初体验 使用NIO实现简单多人聊天功能\n服务端\nimport java.io.IOException;\rimport java.net.InetSocketAddress;\rimport java.nio.ByteBuffer;\rimport java.nio.channels.*;\rimport java.util.Iterator;\rimport java.util.Set;\r//实现简单多人聊天功能\r//服务端\rpublic class NioService {\rpublic ServerSocketChannel serverSocketChannel;\rpublic Selector selector;\rpublic static final int PORT = 8888;\r//初始化参数\rpublic NioService() throws IOException {\r//初始化serverSocketChannel\rserverSocketChannel = ServerSocketChannel.open();\r//初始化selector\rselector = Selector.open();\r//绑定监听端口\rserverSocketChannel.socket().bind(new InetSocketAddress(PORT));\r//设置非阻塞\rserverSocketChannel.configureBlocking(false);\r//注册至selector\rserverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);\rSystem.out.println(\u0026quot;服务器初始化完成 = \u0026quot;);\r}\r//监听\rpublic void listen() {\rtry {\rwhile (true) {\rint i = selector.select();\rif (i \u0026gt; 0) { // 有事件发生\r//获取触发事件的所有SelectionKey\rIterator\u0026lt;SelectionKey\u0026gt; iterator = selector.selectedKeys().iterator();\r//遍历,\rwhile (iterator.hasNext()) {\rSelectionKey key = iterator.next();\r//连接事件\rif (key.isAcceptable()) {\r//获取客户端链接通道\rSocketChannel socketChannel = serverSocketChannel.accept();\r//设置非阻塞\rsocketChannel.configureBlocking(false);\r//注册至selector\rsocketChannel.register(selector, SelectionKey.OP_READ);\r//提示\rSystem.out.println(socketChannel.getRemoteAddress() + \u0026quot; 上线\u0026quot; );\r}\rif (key.isReadable()) {\r//读数据\rreceiverMessage(key);\r}\riterator.remove();\r}\r}\r}\r} catch (IOException e) {\re.printStackTrace();\r}\r}\r//接收数据\rpublic void receiverMessage(SelectionKey key) {\rif (key == null) {\rreturn;\r}\rSocketChannel socketChannel = (SocketChannel) key.channel();\rByteBuffer byteBuffer = ByteBuffer.allocate(1024);\rtry {\rsocketChannel.read(byteBuffer);\r//\rString msg = new String(byteBuffer.array());\rSystem.out.println(\u0026quot;转发 \u0026quot; + socketChannel.getRemoteAddress() + \u0026quot; :的信息\u0026quot; + msg);\r//转发信息\rsendMessage(msg,socketChannel);\r} catch (IOException e) {\re.printStackTrace();\rtry {\rSystem.out.println(socketChannel.getRemoteAddress() + \u0026quot; 离线了\u0026quot;);\rkey.channel();\rsocketChannel.close();\r} catch (IOException ex) {\rex.printStackTrace();\r}\r}\r}\r//转发信息\rpublic void sendMessage(String msg, SocketChannel self) throws IOException {\rSystem.out.println(\u0026quot;服务器转发消息中\u0026quot;);\r//获取所有已注册的通道(除去自己)\rSet\u0026lt;SelectionKey\u0026gt; keys = selector.keys();\rfor (SelectionKey key : keys) {\rChannel channel = key.channel();\rif (channel instanceof SocketChannel \u0026amp;\u0026amp; channel != self) {\rByteBuffer byteBuffer = ByteBuffer.wrap(msg.getBytes());\r((SocketChannel) channel).write(byteBuffer);\r}\r}\r}\rpublic static void main(String[] args) throws IOException {\rNioService nioService = new NioService();\rnioService.listen();\r}\r}\r 客户端\nimport java.io.IOException;\rimport java.net.InetSocketAddress;\rimport java.nio.ByteBuffer;\rimport java.nio.channels.SelectionKey;\rimport java.nio.channels.Selector;\rimport java.nio.channels.SocketChannel;\rimport java.util.Iterator;\rimport java.util.Scanner;\r//客户端\rpublic class NioClient {\rprivate SocketChannel socketChannel;\rprivate Selector selector;\rprivate static final String ADDRESS = \u0026quot;127.0.0.1\u0026quot;;\rprivate static final int PORT = 8888;\rprivate String username;\rpublic NioClient() throws IOException {\rsocketChannel = SocketChannel.open(new InetSocketAddress(ADDRESS, PORT));\rselector = Selector.open();\rsocketChannel.configureBlocking(false);\rsocketChannel.register(selector, SelectionKey.OP_READ);\rusername = socketChannel.getLocalAddress().toString().substring(1);\rSystem.out.println(username + \u0026quot;is ok...\u0026quot; );\r}\rpublic void sendMessage(String msg) throws IOException {\rmsg = username + \u0026quot; 说:\u0026quot; + msg;\rByteBuffer byteBuffer = ByteBuffer.wrap(msg.getBytes());\rsocketChannel.write(byteBuffer);\r}\rpublic void listen() throws IOException {\rint select = selector.select();\rif (select \u0026gt; 0) {\rIterator\u0026lt;SelectionKey\u0026gt; iterator = selector.selectedKeys().iterator();\rwhile (iterator.hasNext()) {\rSelectionKey key = iterator.next();\rif (key.isReadable()) {\rByteBuffer byteBuffer = ByteBuffer.allocate(1024);\rsocketChannel.read(byteBuffer);\rSystem.out.println(new String(byteBuffer.array()));\r}\r}\riterator.remove();\r}\r}\rpublic static void main(String[] args) throws Exception {\rNioClient nioClient = new NioClient();\r//开启一条线程监听消息\rnew Thread(){\r@Override\rpublic void run() {\rwhile(true) {\rtry {\rnioClient.listen();\rThread.currentThread().sleep(3000);\r} catch (Exception e) {\re.printStackTrace();\r}\r}\r}\r}.start();\r//主线程发送消息\rScanner scanner = new Scanner(System.in);\rwhile (scanner.hasNextLine()) {\rnioClient.sendMessage(scanner.next());\r}\r}\r}\r ","id":73,"section":"posts","summary":"前言 IO模型：就是用什么样的通道进行数据的发送和接收,很大程度上决定了程序通信的性能 而netty是一款基于NIO(Nonblocking I/","tags":["Netty"],"title":"Netty的IO模型","uri":"https://bluestaree.github.io/2020/06/io%E6%A8%A1%E5%9E%8B/","year":"2020"},{"content":" 前言  不同的线程模型，对程序的性能有很大的影响，Netty线程模型主要基于主从Reactor多线程模型做了一定的改进\n 目前存在的线程模型有：\n传统I/O服务模型 模型特点\n 1)采用阻塞I0模式获取输入的数据 2)每个连接都需要独立的线程完成数据的输入，业务处理，数据返回等操作  Reactor模式 针对传统阻塞I/0服务模型的2个缺点，解决方案:\n 基于I/O 复用模型:多个连接共用一个阻塞对象，应用程序只需要在一个阻塞对象等待，无需阻塞等待所有连接。当某个连接有新的数据可以处理时，操作系统通知应用程序，线程从阻塞状态返回，开始进行业务处理 基于线程池复用线程资源:不必再为每个连接创建线程，将连接完成后的业务处理任务分配给线程进行处理，一个线程可以处理多个连接的业务。  I/0复用结合线程池，就是Reactor模式基本设计思想，\n根据Reactor的数量和处理资源池线程的数量不同，有3种典型的实现：\n  单Reactor单线程 流程说明\n  Select 是前面I/0复用模型介绍的标准网络编程API， 可以实现应用程序通过一个阻塞对象监听多路连接请求\n  Reactor 对象通过Select监控客户端请求事件，收到事件后通过Dispatch进行分发\n  如果是建立连接请求事件，则由Acceptor通过accept处理连接请求，然后创建一 个Handler对象处理连接完成后的后续业务处理\n  如果不是建立连接事件，则Reactor会分发调用连接对应的Handler来响应\n  Handler 会完成Read \u0026gt;业务处理\u0026gt;Send 的完整业务流程\n  模型分析\n  优点:模型简单，没有多线程、进程通信、竞争的问题，全部都在一个线程中完成\n  缺点:性能问题，只有一个线程，无法完全发挥多核CPU的性能。Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈\n  缺点:可靠性问题，线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障\n    单Reactor多线程 流程说明\n  Reactor 对象通过select监控客户端请求事件，收到事件后，通过dispatch进行分发\n  如果建立连接请求，则右Acceptor通过accept处理连接请求，然后创建一个Handler对象处理完成连接后的各种事件\n  如果不是连接请求，则由reactor分发调用连接对应的handler来处理\n  handler只负责响应事件，不做具体的业务处理，通过read读取数据后，会分发给后面的worker线程池的某个线程处理业务\n  worker线程池会分配独立线程完成真正的业务，并将结果返回给handler\n  handler收到响应后 ，通过send 将结果返回给client\n  模型分析\n  优点:可以充分的利用多核cpu的处理能力。\n  缺点:多线程数据共享和访问比较复杂，reactor 处理所有的事件的监听和响应，在单线程运行，在高并发场景容易出现性能瓶颈。\n    主从Reactor多线程 流程说明\n  Reactor主线程MainReactor对象通过select监听连接事件，收到事件后，通过Acceptor处理连接事件\n  当Acceptor处理连接事件后，MainReactor将连接分配给SubReactor\n  subreactor将连接加入到连接队列进行监听,并创建handler进行各种事件处理\n  当有新事件发生时，subreactor 就会调用对应的handler处理\n  handler通过read读取数据，分发给后面的worker线程处理\n  worker线程池分配独立的worker线程进行业务处理，并返回结果\n  handler收到响应的结果后，再通过send将结果返回给client\n  注：Reactor主线程可以对应多个Reactor子线程，即MainRecator可以关联多个SubReactor\n模型分析\n  优点:父线程与子线程的数据交互简单职责明确，父线程只需要接收新连接，子线程完成后续的业务处理。\n  优点:父线程与子线程的数据交互简单，Reactor 主线程只需要把新连接传给子线程，子线程无需返回数据。\n  缺点:编程复杂度较高\n    Netty线程模式 主要基于主从Reactor多线程模型做了一定的改进，其中主从Reactor多线程模型中有多个Reactor\n流程说明\n  Netty抽象出两组线程池BossGroup专门负责接收客户端的连接，WorkerGroup专门负责网络读写\n  BossGroup和WorkerGroup类型都是NioEventLoopGroup\n  NioEventLoopGroup相当于一个事件循环组，这个组中含有多个事件循环，每一个事件循环是NioEventLoop\n  NioEventLoop 表示一个不断循环的执行处理任务的线程，每个NioEventLoop都有一个selector ,用于监听绑定在其上的socket的网络通讯\n  NioEventLoopGroup 可以有多个线程，即可以含有多个NioEventLoop\n  每个BossNioEventLoop循环执行的步骤有3步\n   ​\t轮询accept事件 ​\t处理accept事件,与client建立连接，生成NioSocketChannel ,并将其注册到某个worker NIOEventLoop上的selector，分配机制是看哪个线程空闲就分配，否则进入等待 ​\t处理任务队列的任务 ，即runAllTasks  每个Worker NIOEventLoop循环执行的步骤   ​\t轮询read, write事件 ​\t处理i/o事件，即read , write事件，在对应NioSocketChannel处理 ​\t处理任务队列的任务，即runAllTasks  处理过程中会使用到pipeline，其中包含了channel ，通过pipeline可以获取到对应通道，且其中维护了很多处理器，可以自定义处理器\n 总结：Boss Group只是处理连按请求,真正的和客户端业务处理,会交给Worker Group完成\nNioEventLoopGroup下包含多个NioEventLoop\n 每个 NioEventLoop中包含有一个 Selector,一个 taskQueue 每个 NioEventLoop的 Selector上可以注册监听多个 NioChannel 每个 Niochannel只会绑定在唯一的 NioEventLoop上 每个 NioChannel都绑定有一个自己的 ChannelPipeline  ","id":74,"section":"posts","summary":"前言 不同的线程模型，对程序的性能有很大的影响，Netty线程模型主要基于主从Reactor多线程模型做了一定的改进 目前存在的线程模型有： 传统","tags":["Netty"],"title":"Netty线程模型","uri":"https://bluestaree.github.io/2020/06/netty%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/","year":"2020"},{"content":" 所谓的正向与反向，都是对于我们自己的电脑来说\n正向代理：帮助客户端访问外部资源的，\n举个例子：如科学上网。如果我们需要访问谷歌，就需要代理服务器帮助我们访问获得数据，再由代理服务器返回\n给客户端，也就是帮助客户端进行访问连接的，这就是正向代理，\n正向代理作用：\n 访问原来无法访问的资源， 隐藏客户端信息  如何隐藏客户端的信息？因为客户端是将请求转发给代理服务器，此时对于谷歌而言，真正访问的是代理服务器，\n所能看到的地址也只是代理服务器的IP地址\n 反向代理：主要负责接收客户端的请求，并将其转发到内网服务器集群中。\n通常一些真正处理请求的服务器都是部署在内网中，并不会对外暴露真正的IP地址，这主要是为了防止网络攻击。\n那么我们要如何访问位于内网中的服务呢。这时候就需要使用反向代理服务器，如Nginx，对外暴露公网IP地址，\n将所接收到的请求转发到内网中，并将获得的结果返回给客户端。\n反向代理的作用：\n 负载均衡 保护内网安全  ","id":75,"section":"posts","summary":"所谓的正向与反向，都是对于我们自己的电脑来说 正向代理：帮助客户端访问外部资源的， 举个例子：如科学上网。如果我们需要访问谷歌，就需要代理服务器","tags":null,"title":"正向代理与方向代理","uri":"https://bluestaree.github.io/2020/06/%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86%E4%B8%8E%E6%96%B9%E5%90%91%E4%BB%A3%E7%90%86/","year":"2020"},{"content":" 1.PO(Persistant Object) 持久对象\nPO就是对应数据库中某个表中的一条记录,多个记录可以用PO的集合。PO中应该不包含任何对数据库的操作。\n 2.DO(Domain object) 领域对象\n就是从现实世界中抽象出来的有形或无形的业务实体\n 3.TO(Transfer Object) 数据传输对象\n不同的应用程序(服务)之间传输的对象\n 4.DTO(Data Transfer Object) 数据传输对象\n这个概念来源于J2EE的设计模式,原来的目的是为了EJB的分布式应用提供粗粒度的数据实体,以减少分布式调用的次\n数,从而提高分布式调用的性能和降低网络负载,但在这里,泛指用于展示层与服务层之间的数据传输对象。\n 5.VO(Value Object) 值对象\n通常用于业务层之间的数据传递,和PO一样也是仅仅包含数据而已。但应是抽象出的业务对象,可以和表对应,也可\n以不,这根据业务的需要。用new关键字创建,由GC回收的。\n也可以理解为 (View Object) 视图对象\n 接收页面传递过来的数据，封装成一个对象 经过业务处理完成后，封装成页面要用的数据   6.BO(Business Object) 业务对象\n从业务模型的角度看,见UML元件领域模型中的领域对象。封装业务逻辑的java对象,通过调用DAO方法，结合\nPO,VO进行业务操作。\nbusiness object:业务对象主要作用是把业务逻辑封装为一个对象。这个对象可以包括一个或多个其它的对象。比\n如一个简历,有教育经历、工作经历、社会关系等等。我们可以把教育经历对应一个PO,工作经历对应一个PO,社会\n关系对应一个PO。建立一个对应简历的Bo对象处理简历,每个BO包含这些PO。这样处理业务逻辑时,我们就可以针\n对BO去处理。\n 7.POJO(Plain Ordinary Java Object) 简单无规则的java对象\n传统意义的java对象。就是说在一些 Object/Relation Mapping工具中,能够做到维护数据库表记录的 persisent\nobject完全是一个符合 Java Bean规范的纯Java对象，没有增加别的属性和方法。\n我的理解就是最基本的 Java Bean,只有属性字段及 setter和 getter方法!\nPOJO是 DO / DTO / BO / VO 的统称。\n 8.DAO(Data Access Object) 数据访问对象\n是一个sun的一个标准j2ee设计模式，这个模式中有个接囗就是DAO，它负持久层的操作。为业务层提供接口。此\n对象用于访问数据库。通常和PO结合使用，DAO中包含了各种数据库的操作方法。通过它的方法，结合PO对数据\n库进行相关的操作。夹在业务逻辑与数据库资源中间。配合VO，提供数据库的CRUD操作。\n","id":76,"section":"posts","summary":"1.PO(Persistant Object) 持久对象 PO就是对应数据库中某个表中的一条记录,多个记录可以用PO的集合。PO中应该不包含任何对数据库的操作。 2.DO(Domain object) 领域对象 就是从现实世界","tags":null,"title":"Object划分","uri":"https://bluestaree.github.io/2020/06/object%E5%88%92%E5%88%86/","year":"2020"},{"content":" 前言  现在的项目大多都是前后端分离的项目，那么对于一些重要数据的校验，单单使用前端控制是不行的，我们可以使用一些http请求工具如 Postman ，就可以轻松的跳过前端验证直接请求后台服务。因此服务端的数据验证也是必不可少，本文介绍了对于JSR303校验标准的简单使用\n 使用步骤 1.对需要校验的Bean对应字段加上校验注解，并定义错误消息提示\n所支持的校验注解类型可以在 javax.validation.constraints 包下查看\n2.开启校验\n使用 @Valid 开启校验\n这样就能够完成校验功能了，是不是很简单，当然也允许使用自定义规则的校验注解，这里不再进行演示。\n异常信息处理 对于校验不通过的异常数据，通常需要我们自己来处理，如果我们没有进行异常处理，默认返回的结果就像这样一\n长串的错误信息，用户体验就不是很好了\n这样的数据肯定不是我们所希望的，\n处理方法 我们可以在校验方法上，添加 BindingResult 方法参数，就可以接收到异常信息，获取到校验的结果，并进行相应的逻辑处理\n当然这样也不是最好的解决方案，如果有很多服务都需要校验异常，那就太麻烦了，我们可以使用SprngMVC所提\n供控制器增强功能，进行全局异常捕获处理，针对MethodArgumentNotValidException异常进行捕获，并统\n一返回自定义的结果\n分组校验 分组校验适合多场景校验的情况，举个栗子，比如对于商品评论ID，规定在新增时不需要携带ID信息，使用自增\n长主键，而在修改时必须要携带ID信息。\n这样一来就需要在Bean中的ID字段添加多个校验注解,这时就需要用到分组校验\n注意，分组的标识必须为接口类型 ，可以自定义一个标记接口\n在校验的时候使用 @Validated 指定校验组即可\n 注意：如果存在没有指定分组的校验注解，在指定分组校验的情况下不会生效\n ","id":77,"section":"posts","summary":"前言 现在的项目大多都是前后端分离的项目，那么对于一些重要数据的校验，单单使用前端控制是不行的，我们可以使用一些http请求工具如 Postman ，就可以轻","tags":null,"title":"使用JSR303规范标准进行数据校验","uri":"https://bluestaree.github.io/2020/05/%E4%BD%BF%E7%94%A8jsr303%E8%A7%84%E8%8C%83%E6%A0%87%E5%87%86%E8%BF%9B%E8%A1%8C%E6%95%B0%E6%8D%AE%E6%A0%A1%E9%AA%8C/","year":"2020"},{"content":"  转载 · 原文链接：https://blog.csdn.net/wu1317581750/java/article/details/81662929\n hibernate运行原理： hibernate里面提供了3个核心接口 Configuration、SessionFactory、Session\nhibernate启动的时候利用Configuration读取xml配置文件\n通过配置文件创建SessionFactory对象，初始化hibernate基本信息\n获取session然后调用CRUD方法进行数据操作，hibernate会把我们的数据进行三种状态的划分，然后根据状态进行管理我们的数据，对应的发送SQL进行数据操作\n关闭session，如果有事务的情况下，需要手动获取事务并开启，然后事务结束后提交事务。\n在提交事务的时候，去验证我们的快照里面的数据和缓存数据是否一致，如果不一致，发送SQL进行修改，\nhibernate的get方法和load方法的区别 get和load都是利用主键策略查询数据，\nget默认不使用懒加载机制，load默认要使用懒加载机制，所谓的懒加载就是我们这个数据如果不使用，hibernate就不发送SQL到数据库查询数据。\n当查询数据库不存在的数据的时候，get方法返回null，load方法抛出空指针异常，\n原因是因为，load方法采用的动态代理的方式实现的，我们使用load方法的时候，hibernate会创建一个该实体的代理对象，该代理只保存了该对象的ID，当我们访问该实体对象其他属性，hibernate就发送SQL查询数据封装到代理对象，然后在利用代理对象返回给我们实际的数据，\nhibernate的数据三种状态 hibernate把他所管理的数据划分为三种状态\n瞬时的（刚new出来的数据–内存有，数据库没有）\n持久的 （从数据查询的，或者刚保存到数据库，session没关闭的， 数据库有，内存也有）\n游离的 、脱管的（数据库有，内存没有）\n实际上hibernate对数据划分三种状态，主要是为了管理我们持久的数据，在事务提交的时候，hibernate去对比处于持久状态的数据是否发生改变，(快照区、一级缓存区)，当我们会话结束前，对持久状态数据进行了修改的话，快照区的数据会跟着改变。当session提交事务的时候，如果发现快照区和一级缓存的数据不一致，就会发送SQL进行修改。\n简述hibernate的缓存机制 hibernate分为2级缓存\n一级缓存又叫session缓存，又叫事务级缓存，生命周期从事务开始到事务结束，一级缓存是hibernate自带的，暴力使用，当我们一创建session就已有这个缓存了。数据库就会自动往缓存存放，\n二级缓存是hibernate提供的一组开放的接口方式实现的，都是通过整合第三方的缓存框架来实现的，二级缓存又叫sessionFactory的缓存，可以跨session访问。常用的EHcache、OScache，这个需要一些配置。\n当我们每次 查询数据的时候，首先是到一级缓存查看是否存在该对象，如果有直接返回，如果没有就去二级缓存进行查看，如果有直接返回，如果没有在发送SQL到数据库查询数据，\n当SQL发送查询回该数据的时候，hibernate会把该对象以主键为标记的形式存储到二级缓存和一级缓存，如果返回的是集合，会把集合打散然后以主键的形式存储到缓存。一级缓存和二级缓存只针对以ID查询的方式生效，get、load方法。\n简述hibernate中getCurrentSession和openSession区别 getCurrentSession和openSession都是通过H的工厂去获取数据库的会话对象，\n1、getCurrentSession会绑定当前线程，而openSession不会，因为我们把hibernate交给我们的spring来管理之后，我们是有事务配置，这个有事务的线程就会绑定当前的工厂里面的每一个session，而openSession是创建一个新session。\n2、getCurrentSession事务是有spring来控制的，而openSession需要我们手动开启和手动提交事务，\n3、getCurrentSession是不需要我们手动关闭的，因为工厂会自己管理，而openSession需要我们手动关闭。\n4、而getCurrentSession需要我们手动设置 绑定事务的机制，有三种设置方式，jdbc本地的Thread、JTA、第三种是spring提供的事务管理机制org.springframework.orm.hibernate4.SpringSessionContext，而且srping默认使用该种事务管理机制，\n————————————————\n","id":78,"section":"posts","summary":"转载 · 原文链接：https://blog.csdn.net/wu1317581750/java/article/details/816629","tags":["hibernate"],"title":"Hibernate常见问题","uri":"https://bluestaree.github.io/2020/05/hibernate%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/","year":"2020"},{"content":" 记录一个坑，我现在所用的MySQL数据库的版本是8.019，在尝试使用Navicat连接数据库时，出现1251错误\n解决方法： 进入docker容器修改MySQL的root用户加密规则\n ALTER USER \u0026lsquo;root\u0026rsquo;@\u0026lsquo;localhost\u0026rsquo; IDENTIFIED WITH mysql_native_password BY \u0026lsquo;password\u0026rsquo;; #修改加密规则 ALTER USER \u0026lsquo;root\u0026rsquo;@\u0026lsquo;localhost\u0026rsquo; IDENTIFIED BY \u0026lsquo;password\u0026rsquo; PASSWORD EXPIRE NEVER; #更新一下用户的密码 FLUSH PRIVILEGES; #刷新权限  \u0026lsquo;root\u0026rsquo; 为你自己定义的用户名\n\u0026lsquo;localhost\u0026rsquo; 指的是用户开放的IP，可以是\u0026rsquo;localhost\u0026rsquo;(仅本机访问，相当于127.0.0.1)，可以是具体的\u0026rsquo;...'(具体某一IP)，也可以是 \u0026lsquo;%\u0026rsquo; (所有IP均可访问)\n\u0026lsquo;password\u0026rsquo; 是你想使用的用户密码\n","id":79,"section":"posts","summary":"记录一个坑，我现在所用的MySQL数据库的版本是8.019，在尝试使用Navicat连接数据库时，出现1251错误 解决方法： 进入docker","tags":null,"title":"Navicat连接MySQL出现1251错误","uri":"https://bluestaree.github.io/2020/05/navicat-1251%E9%94%99%E8%AF%AF/","year":"2020"},{"content":"  转载 · 原文链接：https://blog.csdn.net/CSDN_Ty/article/details/98877883\n 本文的内容主要想解决一下几个问题：\n equals() 和 == 的作用是什么？ equals() 和 == 的区别是什么？ hashCode()的作用是什么？ hashCode()与equals()之间有什么联系？  equals() 和 == 的作用  == 是用来判断两个对象是否为同一个对象，通过判断两个对象的内存地址来区分它们是否相等。 equals() 是用来判断两个对象是否相等，equals()定义在Object类中，所有类都继承了该方法。  从源码可以看出，默认情况下，equals与==没有区别，equals就是调用的==来进行判断。\npublic boolean equals(Object obj) {\rreturn (this == obj);\r}\r 所以，通常我们都会重写equals方法：两对象内容相等，则返回true，否则返回false。举例：\n①没有重写equals()方法时：\npublic class Test {\r@AllArgsConstructor\r@Setter\r@Getter\rpublic static class Student {\rprivate String name;\rprivate int age;\r}\rpublic static void main(String[] args) {\rStudent stu1 = new Student(\u0026quot;ye17186\u0026quot;, 18);\rStudent stu2 = new Student(\u0026quot;ye17186\u0026quot;, 18);\rSystem.out.println(\u0026quot;stu1.equals(stu2): \u0026quot; + stu1.equals(stu2));\r}\r}\r 输出结果：\n\n解析：\n由于stu1、stu2都是直接new出来的对象，它们指向两块不同的内存地址，在未重写equals方法的情况下，调用equals()方法其实就是调用==，比较的是他们的内存地址是否相同，所以这里打印的结果的false。\n②重写equals()方法时：\npublic class Test {\r@AllArgsConstructor\r@Setter\r@Getter\rpublic static class Student {\rprivate String name;\rprivate int age;\r@Override\rpublic boolean equals(Object o) {\rif (this == o) {\rreturn true;\r}\rif (o == null || getClass() != o.getClass()) {\rreturn false;\r}\rStudent student = (Student) o;\rreturn name.equals(student.getName()) \u0026amp;\u0026amp; age == student.age;\r}\r}\rpublic static void main(String[] args) {\rStudent stu1 = new Student(\u0026quot;ye17186\u0026quot;, 18);\rStudent stu2 = new Student(\u0026quot;ye17186\u0026quot;, 18);\rSystem.out.println(\u0026quot;stu1.equals(stu2): \u0026quot; + stu1.equals(stu2));\r}\r}\r 输出结果：\n\n解析：\n重写equals方法后，就会使用equals方法内的逻辑来判断是否相等，例子中直接比较了name和age是否相等，stu1和stu2两个对象，他们的name都是ye17186，age都是18，所以这里输出的结果是true。\nequals()与==的区别 上面已经解析过了，从设计上说==是用来判断是否为同一个对象，equals()用来判断两个对象是否相等。如果我们没有重写equals()方法，那么二者其实是等价的。但一般我们会重写equals()方法，这样会按照我们重写的逻辑来判断两个对象是否相等。\nhashCode的作用  hashCode()的作用是获取哈希码，也成为了散列码，它实际上返回一个int整数。这个哈希码的作用是确定该对象在哈希表中的索引位置。 hashCode()定义在java.lang.Object中，这意味着JAVA中任何类都有这个函数。 虽然每个JAVA类都有hashCode函数，但是仅仅当创建某个“类的散列表”时，该类的hashCode()才有用（作用是确定该类的每一个对象在散列表中的位置），其他情况下（例如：创建类的单个对象，或者创建类的对象数组等），类的hashCode()没有作用。 上面的散列表，指的是JAVA集合中本质是散列表的类，如HashMap、HashTable、HashSet。 也就是说，hashCode()在散列表中有用，在其他情况下没用。在散列表中hashCode()用于获取对象的散列码，从而确定该对象在散列表中的位置。 如果两个对象相等，他们的散列码一定相等；但是如果散列码相等，它们不一定相等  hashCode()与equals之间的联系 在非”本质是散列表的类”中，两者没有任何关系。而在”本质是散列表的类”中，在HashSet中，如果两个对象的hashCode相同，即使equals不等，它们在集合中也只会存储一个。\n","id":80,"section":"posts","summary":"转载 · 原文链接：https://blog.csdn.net/CSDN_Ty/article/details/98877883 本文的内容主要想","tags":["hashCode","equals"],"title":"hashCode和equals的相关问题","uri":"https://bluestaree.github.io/2020/05/hashcode%E5%92%8Cequals%E7%9A%84%E7%9B%B8%E5%85%B3%E9%97%AE%E9%A2%98/","year":"2020"},{"content":" Feign调用流程  构造请求对象，将对象转为json 发送执行请求(执行成功会解码响应得数据) 获取结果  从代码中可以看出，如何请求出现异常，就会执行 retryer.continueOrPropagate(e) 方法进行重试，直到重试次数到指定的值，或者重试成功为止\nfeign get请求传对象 ","id":81,"section":"posts","summary":"Feign调用流程 构造请求对象，将对象转为json 发送执行请求(执行成功会解码响应得数据) 获取结果 从代码中可以看出，如何请求出现异常，就会执","tags":null,"title":"Feign的一些使用问题","uri":"https://bluestaree.github.io/2020/05/feign%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6/","year":"2020"},{"content":" 最近在学习中遇到了新的包管理工具 - Gradle 。\n上网查询了下Gradle 的依赖方式，方便与Maven区分对比 。\n 转载 · 原文链接：https://blog.csdn.net/zyt_524744325/article/details/86535463\n 依赖配置-Gradle 目前Gradle版本支持的依赖配置有：implementation、api、compileOnly、runtimeOnly和annotationProcessor，已经废弃的配置有：compile、provided、apk、providedCompile。此外依赖配置还可以加一些配置项，例如AndroidTestImplementation、debugApi等等。\n implementation  与compile对应，会添加依赖到编译路径，并且会将依赖打包到输出（aar或apk），但是在编译时不会将依赖的实现暴露给其他module，也就是只有在运行时其他module才能访问这个依赖中的实现。使用这个配置，可以显著提升构建时间，因为它可以减少重新编译的module的数量。建议，尽量使用这个依赖配置。\n api  与compile对应，功能完全一样，会添加依赖到编译路径，并且会将依赖打包到输出（aar或apk），与implementation不同，这个依赖可以传递，其他module无论在编译时和运行时都可以访问这个依赖的实现，也就是会泄漏一些不应该不使用的实现。举个例子，A依赖B，B依赖C，如果都是使用api配置的话，A可以直接使用C中的类（编译时和运行时），而如果是使用implementation配置的话，在编译时，A是无法访问C中的类的。\n compileOnly  与provided对应，Gradle把依赖加到编译路径，编译时使用，不会打包到输出（aar或apk）。这可以减少输出的体积，在只在编译时需要，在运行时可选的情况，很有用。\n runtimeOnly  与apk对应，gradle添加依赖只打包到APK，运行时使用，但不会添加到编译路径。这个没有使用过。\n annotationProcessor  与compile对应，用于注解处理器的依赖配置，这个没用过。\n 依赖配置-Maven  compile  默认scope为compile，表示为当前依赖参与项目的编译、测试和运行阶段，属于强依赖。打包之时，会达到包里去。\n test  该依赖仅仅参与测试相关的内容，包括测试用例的编译和执行，比如定性的Junit。\n runtime  依赖仅参与运行周期中的使用。一般这种类库都是接口与实现相分离的类库，比如JDBC类库，在编译之时仅依赖相关的接口，在具体的运行之时，才需要具体的mysql、oracle等等数据的驱动程序。\n此类的驱动都是为runtime的类库。\n provided  该依赖在打包过程中，不需要打进去，这个由运行的环境来提供，比如tomcat或者基础类库等等，事实上，该依赖可以参与编译、测试和运行等周期，与compile等同。区别在于打包阶段进行了exclude操作。\n system  使用上与provided相同，不同之处在于该依赖不从maven仓库中提取，而是从本地文件系统中提取，其会参照systemPath的属性进行提取依赖。\n import  这个是maven2.0.9版本后出的属性，import只能在dependencyManagement的中使用，能解决maven单继承问题，import依赖关系实际上并不参与限制依赖关系的传递性。\n","id":82,"section":"posts","summary":"最近在学习中遇到了新的包管理工具 - Gradle 。 上网查询了下Gradle 的依赖方式，方便与Maven区分对比 。 转载 · 原文链接：https://blog","tags":["Maven","Gradle"],"title":"Maven,Gradle依赖","uri":"https://bluestaree.github.io/2020/05/mavengradle%E4%BE%9D%E8%B5%96/","year":"2020"},{"content":"  转载 · 原文链接：https://blog.csdn.net/qw463800202/article/details/103221651\n 一、动态sql使用 1.1、在项目中涉及多个动态查询条件，一般我们是通过 where 1 = 1，这样可以处理where后面对应条件全空的情况，我们可以使用标签，该标签可以自动处理,主要是当我们的sql查询条件以AND和OR结尾时，会自动去除，如\n\u0026lt;where\u0026gt; \u0026lt;if test=\u0026quot;keyword != null\u0026quot;\u0026gt; and title like concat('%',trim(#{keyword}),'%') \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt;\r\u0026lt;where\u0026gt; \u0026lt;if test=\u0026quot;name != null\u0026quot;\u0026gt; or name=#{name} \u0026lt;/if\u0026gt; \u0026lt;if test=\u0026quot;keyword != null\u0026quot;\u0026gt; or title like concat('%',trim(#{keyword}),'%') \u0026lt;/if\u0026gt; \u0026lt;/where\u0026gt;\r 1.2、在项目中涉及多个动态update条件时，传统的项目需要我们去除最后一个条件的逗号，但是在mybatis中我们可以使用标签，如\nUPDATE user\r\u0026lt;set\u0026gt;\r\u0026lt;if test ='null != name'\u0026gt;name = #{name},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != email'\u0026gt;email = #{email},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != headUrl'\u0026gt;head_url = #{headUrl},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != linkData'\u0026gt;link_data = #{linkData},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != createTime'\u0026gt;create_time = #{createTime},\u0026lt;/if\u0026gt;\r\u0026lt;if test ='null != updateTime'\u0026gt;update_time = #{updateTime}\u0026lt;/if\u0026gt;\r\u0026lt;/set\u0026gt;\r ​ 1.3、动态if else语句，在mybatis中使用choose、when、otherwise来处理，如下代码\nmybatis 中 SQL 写在mapper.xml文件中，而xml解析 \u0026lt; 、\u0026gt;、\u0026lt;=、\u0026gt;= 时会出错，这时应该使用转义写法，如下\n   \u0026lt; \u0026lt;= \u0026gt; \u0026gt;= \u0026amp; ' \u0026quot;     \u0026amp;lt; \u0026amp;lt;= \u0026amp;gt; \u0026amp;gt;= \u0026amp;amp; \u0026amp;apos; \u0026amp;quot;    三、mybatis循环标签 3.1、循环查询in语句，代码如下\n \u0026lt;select id=\u0026quot;findBy\u0026quot; resultMap=\u0026quot;BaseResultMap\u0026quot;\u0026gt;\rselect * from user where user_id in\r\u0026lt;foreach item=\u0026quot;item\u0026quot; index=\u0026quot;index\u0026quot; collection=\u0026quot;list\u0026quot; open=\u0026quot;(\u0026quot; separator=\u0026quot;,\u0026quot; close=\u0026quot;)\u0026quot;\u0026gt;\r#{item}\r\u0026lt;/foreach\u0026gt;\r\u0026lt;/select\u0026gt;\r 3.2、批量插入使用循环,代码如下\n\u0026lt;insert id=\u0026quot;insertList\u0026quot; parameterType=\u0026quot;java.util.List\u0026quot;\u0026gt;\rinsert into user\r( name,sex,email,remark)\rvalues\r\u0026lt;foreach collection=\u0026quot;list\u0026quot; item=\u0026quot;item\u0026quot; index=\u0026quot;index\u0026quot; separator=\u0026quot;,\u0026quot;\u0026gt;\r(\r#{item.name},\r#{item.sex},\r#{item.email},\r#{item.remark}\r)\r\u0026lt;/foreach\u0026gt; \u0026lt;/insert\u0026gt;  四、重复的sql片段整合在一起使用include标签 定义：\r\u0026lt;sql id=\u0026quot;Base_Column_List\u0026quot; \u0026gt; id, name, url, priority, logo, img \u0026lt;/sql\u0026gt; 引用：\r\u0026lt;include refid=\u0026quot;Base_Column_List\u0026quot; /\u0026gt;  ————————————————\n更多详细的标签介绍可以看下这个大佬的文章，很详细了：\nhttps://blog.csdn.net/cwx397562/article/details/100334210\n","id":83,"section":"posts","summary":"转载 · 原文链接：https://blog.csdn.net/qw463800202/article/details/103221651 一、动","tags":["mybatis"],"title":"Mybatis中Mapper标签总结大全","uri":"https://bluestaree.github.io/2020/04/mybatis%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%E6%B1%87%E6%80%BB/","year":"2020"},{"content":"  转载 · 原文链接：https://www.runoob.com/java/java8-new-features.html\n java 8 新特性 Java8 新增了非常多的特性，我们主要讨论以下几个：\n Lambda 表达式 − Lambda 允许把函数作为一个方法的参数（函数作为参数传递到方法中）。 方法引用 − 方法引用提供了非常有用的语法，可以直接引用已有Java类或对象（实例）的方法或构造器。与lambda联合使用，方法引用可以使语言的构造更紧凑简洁，减少冗余代码。 默认方法 − 默认方法就是一个在接口里面有了一个实现的方法。 新工具 − 新的编译工具，如：Nashorn引擎 jjs、 类依赖分析器jdeps。 Stream API −新添加的Stream API（java.util.stream） 把真正的函数式编程风格引入到Java中。 Date Time API − 加强对日期与时间的处理。 Optional 类 − Optional 类已经成为 Java 8 类库的一部分，用来解决空指针异常。 Nashorn, JavaScript 引擎 − Java 8提供了一个新的Nashorn javascript引擎，它允许我们在JVM上运行特定的javascript应用  先来看看排序方式的对比把\n// 使用 java 7 排序\rprivate void sortUsingJava7(List\u0026lt;String\u0026gt; names){ Collections.sort(names, new Comparator\u0026lt;String\u0026gt;() {\r@Override\rpublic int compare(String s1, String s2) {\rreturn s1.compareTo(s2);\r}\r});\r}\r// 使用 java 8 排序\rprivate void sortUsingJava8(List\u0026lt;String\u0026gt; names){\rCollections.sort(names, (s1, s2) -\u0026gt; s1.compareTo(s2));\r}\r 怎么样，是不是感觉代码简化了不少，让我们继续深入学习java8的那些新特性\nLambda 表达式实例 Lambda 表达式的简单例子:\n// 1. 不需要参数,返回值为 5 () -\u0026gt; 5 // 2. 接收一个参数(数字类型),返回其2倍的值 x -\u0026gt; 2 * x // 3. 接受2个参数(数字),并返回他们的差值 (x, y) -\u0026gt; x – y // 4. 接收2个int型整数,返回他们的和 (int x, int y) -\u0026gt; x + y // 5. 接受一个 string 对象,并在控制台打印,不返回任何值(看起来像是返回void) (String s) -\u0026gt; System.out.print(s)\r 使用 Lambda 表达式需要注意以下两点：\n Lambda 表达式主要用来定义行内执行的方法类型接口，例如，一个简单方法接口。在上面例子中，我们使用各种类型的Lambda表达式来定义MathOperation接口的方法。然后我们定义了sayMessage的执行。 Lambda 表达式免去了使用匿名方法的麻烦，并且给予Java简单但是强大的函数化的编程能力。  Java 8 方法引用 方法引用通过方法的名字来指向一个方法。\n方法引用可以使语言的构造更紧凑简洁，减少冗余代码。\n方法引用使用一对冒号 :: 。\n 构造器引用它的语法是Class::new，或者更一般的Class\u0026lt; T \u0026gt;::new实例如下：  final Car car = Car.create( Car::new );\rfinal List\u0026lt; Car \u0026gt; cars = Arrays.asList( car );\r  静态方法引用它的语法是Class::static_method，实例如下：  cars.forEach( Car::collide );\r  特定类的任意对象的方法引用它的语法是Class::method实例如下：  cars.forEach( Car::repair );\r  特定对象的方法引用它的语法是instance::method实例如下：  final Car police = Car.create( Car::new );\rcars.forEach( police::follow );\r Java 8 Stream Java 8 API添加了一个新的抽象称为流Stream，可以让你以一种声明的方式处理数据。\nStream 使用一种类似用 SQL 语句从数据库查询数据的直观方式来提供一种对 Java 集合运算和表达的高阶抽象。\nStream API可以极大提高Java程序员的生产力，让程序员写出高效率、干净、简洁的代码。\n这种风格将要处理的元素集合看作一种流， 流在管道中传输， 并且可以在管道的节点上进行处理， 比如筛选， 排序，聚合等。\n元素流在管道中经过中间操作（intermediate operation）的处理，最后由最终操作(terminal operation)得到前面处理的结果。\n生成流\n在 Java 8 中, 集合接口有两个方法来生成流：\n stream() − 为集合创建串行流。 parallelStream() − 为集合创建并行流。  List\u0026lt;String\u0026gt; strings = Arrays.asList(\u0026quot;abc\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;bc\u0026quot;, \u0026quot;efg\u0026quot;, \u0026quot;abcd\u0026quot;,\u0026quot;\u0026quot;, \u0026quot;jkl\u0026quot;);\rList\u0026lt;String\u0026gt; filtered = strings.stream().filter(string -\u0026gt; !string.isEmpty()).collect(Collectors.toList());\r  forEach\nStream 提供了新的方法 \u0026lsquo;forEach\u0026rsquo; 来迭代流中的每个数据。以下代码片段使用 forEach 输出了10个随机数：\nRandom random = new Random();\rrandom.ints().limit(10).forEach(System.out::println);\r  map\nmap 方法用于映射每个元素到对应的结果，以下代码片段使用 map 输出了元素对应的平方数：\nList\u0026lt;Integer\u0026gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\r// 获取对应的平方数\rList\u0026lt;Integer\u0026gt; squaresList = numbers.stream().map( i -\u0026gt; i*i).distinct().collect(Collectors.toList());\r  filter\nfilter 方法用于通过设置的条件过滤出元素。以下代码片段使用 filter 方法过滤出空字符串：\nList\u0026lt;String\u0026gt;strings = Arrays.asList(\u0026quot;abc\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;bc\u0026quot;, \u0026quot;efg\u0026quot;, \u0026quot;abcd\u0026quot;,\u0026quot;\u0026quot;, \u0026quot;jkl\u0026quot;);\r// 获取空字符串的数量\rlong count = strings.stream().filter(string -\u0026gt; string.isEmpty()).count();\r  limit\nlimit 方法用于获取指定数量的流。 以下代码片段使用 limit 方法打印出 10 条数据：\nRandom random = new Random();\rrandom.ints().limit(10).forEach(System.out::println);\r  sorted\nsorted 方法用于对流进行排序。以下代码片段使用 sorted 方法对输出的 10 个随机数进行排序：\nRandom random = new Random();\rrandom.ints().limit(10).sorted().forEach(System.out::println);\r  并行（parallel）程序\nparallelStream 是流并行处理程序的代替方法。以下实例我们使用 parallelStream 来输出空字符串的数量：\nList\u0026lt;String\u0026gt; strings = Arrays.asList(\u0026quot;abc\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;bc\u0026quot;, \u0026quot;efg\u0026quot;, \u0026quot;abcd\u0026quot;,\u0026quot;\u0026quot;, \u0026quot;jkl\u0026quot;);\r// 获取空字符串的数量\rint count = strings.parallelStream().filter(string -\u0026gt; string.isEmpty()).count();\r 我们可以很容易的在顺序运行和并行直接切换。\n Collectors\nCollectors 类实现了很多归约操作，例如将流转换成集合和聚合元素。Collectors 可用于返回列表或字符串：\nList\u0026lt;String\u0026gt; strings = Arrays.asList(\u0026quot;abc\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;bc\u0026quot;, \u0026quot;efg\u0026quot;, \u0026quot;abcd\u0026quot;,\u0026quot;\u0026quot;, \u0026quot;jkl\u0026quot;);\rList\u0026lt;String\u0026gt; filtered = strings.stream().filter(string -\u0026gt; !string.isEmpty()).collect(Collectors.toList());\rSystem.out.println(\u0026quot;筛选列表: \u0026quot; + filtered);\rString mergedString = strings.stream().filter(string -\u0026gt; !string.isEmpty()).collect(Collectors.joining(\u0026quot;, \u0026quot;));\rSystem.out.println(\u0026quot;合并字符串: \u0026quot; + mergedString);\r  统计\n另外，一些产生统计结果的收集器也非常有用。它们主要用于int、double、long等基本类型上，它们可以用来产生类似如下的统计结果。\nList\u0026lt;Integer\u0026gt; numbers = Arrays.asList(3, 2, 2, 3, 7, 3, 5);\rIntSummaryStatistics stats = numbers.stream().mapToInt((x) -\u0026gt; x).summaryStatistics();\rSystem.out.println(\u0026quot;列表中最大的数 : \u0026quot; + stats.getMax());\rSystem.out.println(\u0026quot;列表中最小的数 : \u0026quot; + stats.getMin());\rSystem.out.println(\u0026quot;所有数之和 : \u0026quot; + stats.getSum());\rSystem.out.println(\u0026quot;平均数 : \u0026quot; + stats.getAverage());\r 默认方法 Java 8 新增了接口的默认方法。\n简单说，默认方法就是接口可以有实现方法，而且不需要实现类去实现其方法。\n我们只需在方法名前面加个 default 关键字即可实现默认方法。\n语法\n默认方法语法格式如下：\npublic interface Vehicle {\rdefault void print(){\rSystem.out.println(\u0026quot;我是一辆车!\u0026quot;);\r}\r}\r Java 8 函数式接口 函数式接口(Functional Interface)就是一个有且仅有一个抽象方法，但是可以有多个非抽象方法的接口。\n函数式接口可以被隐式转换为 lambda 表达式。\nLambda 表达式和方法引用（实际上也可认为是Lambda表达式）上。\n如定义了一个函数式接口如下：\n@FunctionalInterface\rinterface GreetingService {\rvoid sayMessage(String message);\r}\r 那么就可以使用Lambda表达式来表示该接口的一个实现(注：JAVA 8 之前一般是用匿名类实现的)：\nGreetingService greetService1 = message -\u0026gt; System.out.println(\u0026quot;Hello \u0026quot; + message);\r Java 8 Optional 类 Optional 类是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。\nOptional 是个容器：它可以保存类型T的值，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测。\nOptional 类的引入很好的解决空指针异常。\n类方法    序号 方法 \u0026amp; 描述     1 static Optional empty() 返回空的 Optional 实例。   2 boolean equals(Object obj) 判断其他对象是否等于 Optional。   3 Optional filter(Predicate predicate) 如果值存在，并且这个值匹配给定的 predicate，返回一个Optional用以描述这个值，否则返回一个空的Optional。   4 Optional flatMap(Function\u0026gt; mapper) 如果值存在，返回基于Optional包含的映射方法的值，否则返回一个空的Optional   5 T get() 如果在这个Optional中包含这个值，返回值，否则抛出异常：NoSuchElementException   6 int hashCode() 返回存在值的哈希码，如果值不存在 返回 0。   7 void ifPresent(Consumer consumer) 如果值存在则使用该值调用 consumer , 否则不做任何事情。   8 boolean isPresent() 如果值存在则方法会返回true，否则返回 false。   9 Optional map(Function mapper) 如果有值，则对其执行调用映射函数得到返回值。如果返回值不为 null，则创建包含映射返回值的Optional作为map方法返回值，否则返回空Optional。   10 static Optional of(T value) 返回一个指定非null值的Optional。   11 static Optional ofNullable(T value) 如果为非空，返回 Optional 描述的指定值，否则返回空的 Optional。   12 T orElse(T other) 如果存在该值，返回值， 否则返回 other。   13 T orElseGet(Supplier other) 如果存在该值，返回值， 否则触发 other，并返回 other 调用的结果。   14 T orElseThrow(Supplier exceptionSupplier) 如果存在该值，返回包含的值，否则抛出由 Supplier 继承的异常   15 String toString() 返回一个Optional的非空字符串，用来调试    注意： 这些方法是从 java.lang.Object 类继承来的。\nJava 8 日期时间 API Java 8通过发布新的Date-Time API (JSR 310)来进一步加强对日期与时间的处理。\n在旧版的 Java 中，日期时间 API 存在诸多问题，其中有：\n 非线程安全 − java.util.Date 是非线程安全的，所有的日期类都是可变的，这是Java日期类最大的问题之一。 设计很差 − Java的日期/时间类的定义并不一致，在java.util和java.sql的包中都有日期类，此外用于格式化和解析的类在java.text包中定义。java.util.Date同时包含日期和时间，而java.sql.Date仅包含日期，将其纳入java.sql包并不合理。另外这两个类都有相同的名字，这本身就是一个非常糟糕的设计。 时区处理麻烦 − 日期类并不提供国际化，没有时区支持，因此Java引入了java.util.Calendar和java.util.TimeZone类，但他们同样存在上述所有的问题。  Java 8 在 java.time 包下提供了很多新的 API。以下为两个比较重要的 API：\n Local(本地) − 简化了日期时间的处理，没有时区的问题。 Zoned(时区) − 通过制定的时区处理日期时间。  新的java.time包涵盖了所有处理日期，时间，日期/时间，时区，时刻（instants），过程（during）与时钟（clock）的操作。\n本地化日期时间 API\nLocalDate/LocalTime 和 LocalDateTime 类可以在处理时区不是必须的情况。代码如下：\nJava8Tester.java 文件\nimport java.time.LocalDate;\rimport java.time.LocalTime;\rimport java.time.LocalDateTime;\rimport java.time.Month;\rpublic class Java8Tester {\rpublic static void main(String args[]){\rJava8Tester java8tester = new Java8Tester();\rjava8tester.testLocalDateTime();\r}\rpublic void testLocalDateTime(){\r// 获取当前的日期时间\rLocalDateTime currentTime = LocalDateTime.now();\rSystem.out.println(\u0026quot;当前时间: \u0026quot; + currentTime);\rLocalDate date1 = currentTime.toLocalDate();\rSystem.out.println(\u0026quot;date1: \u0026quot; + date1);\rMonth month = currentTime.getMonth();\rint day = currentTime.getDayOfMonth();\rint seconds = currentTime.getSecond();\rSystem.out.println(\u0026quot;月: \u0026quot; + month +\u0026quot;, 日: \u0026quot; + day +\u0026quot;, 秒: \u0026quot; + seconds);\rLocalDateTime date2 = currentTime.withDayOfMonth(10).withYear(2012);\rSystem.out.println(\u0026quot;date2: \u0026quot; + date2);\r// 12 december 2014\rLocalDate date3 = LocalDate.of(2014, Month.DECEMBER, 12);\rSystem.out.println(\u0026quot;date3: \u0026quot; + date3);\r// 22 小时 15 分钟\rLocalTime date4 = LocalTime.of(22, 15);\rSystem.out.println(\u0026quot;date4: \u0026quot; + date4);\r// 解析字符串\rLocalTime date5 = LocalTime.parse(\u0026quot;20:15:30\u0026quot;);\rSystem.out.println(\u0026quot;date5: \u0026quot; + date5);\r}\r}\r 执行以上脚本，输出结果为：\n$ javac Java8Tester.java $ java Java8Tester\r当前时间: 2016-04-15T16:55:48.668\rdate1: 2016-04-15\r月: APRIL, 日: 15, 秒: 48\rdate2: 2012-04-10T16:55:48.668\rdate3: 2014-12-12\rdate4: 22:15\rdate5: 20:15:30\r ","id":84,"section":"posts","summary":"转载 · 原文链接：https://www.runoob.com/java/java8-new-features.html java 8 新特性 Java8 新增了非常","tags":["jdk8"],"title":"JDK 8 的那些新特性","uri":"https://bluestaree.github.io/2020/04/jdk-8%E7%9A%84%E9%82%A3%E4%BA%9B%E6%96%B0%E7%89%B9%E6%80%A7/","year":"2020"},{"content":" 原反补的相互转换 今天在学习算法时遇到了这个问题，然后大脑就突然宕机。什么情况w(ﾟДﾟ)w！\n在此上网查询资料后记录下，\n 转载 · 原文链接：https://blog.csdn.net/chaochaoaiyuer/article/details/82868761\n 原码转反码\n 符号位不变，数值位按位取反  反码转原码\n 符号位不变，数值位按位取反  原码转补码\n  正数：正数的补码就是其本身。\n  负数：在原码的基础上，符号位不变，其余的各个位取反，最后+1.（反码+1）\n  补码转原码\n 符号位不变，数值位按位取反，末位再加１．即补码的补码等于原码，  已知补码，求原码的负数的补码\n 符号位和数值位都按位取反，末位再加１   总结：  计算机在进行减法时，都是在做加法运算。 正数原码、反码、补码是一样。 负数的反码，在原码的基础上，符号位不变，其余的各个位取反（1变0，0变1）。 负数的补码，就是反码+1.   ","id":85,"section":"posts","summary":"原反补的相互转换 今天在学习算法时遇到了这个问题，然后大脑就突然宕机。什么情况w(ﾟДﾟ)w！ 在此上网查询资料后记录下， 转载 · 原文链接：htt","tags":null,"title":"原码、反码和补码","uri":"https://bluestaree.github.io/2020/04/%E5%8E%9F%E7%A0%81%E5%8F%8D%E7%A0%81%E8%A1%A5%E7%A0%81/","year":"2020"},{"content":"  转载 · 原文链接：https://www.codesheep.cn/2018/09/04/springboot-startup-process/\n 结合 SpringBoot 2.0的源码，来看看SpringBoot应用程序的启动流程！\n概述 说到接触 SpringBoot 伊始，给我第一映像最深的是有两个关键元素：\n对照上面的典型代码，这个两个元素分别是：\n @SpringBootApplication SpringApplication 以及 run() 方法  那么本文我们就来看看这个 SpringApplication 以及 run() 方法 到底是个什么鬼，它背后又隐藏了哪些奥秘呢？\n SpringApplication 惊鸿一瞥 SpringApplication 这个类应该算是 SpringBoot 框架 的“创新”产物了，原始的 Spring中并没有这个类，SpringApplication 里面封装了一套 Spring 应用的启动流程，然而这对用户完全透明，因此我们上手 SpringBoot 时感觉简洁、轻量。\n一般来说默认的 SpringApplication 执行流程已经可以满足大部分需求，但是 若用户想干预这个过程，则可以通过 SpringApplication 在流程某些地方开启的 扩展点 来完成对流程的扩展，典型的扩展方案那就是使用 set 方法。\n我们来举一个栗子，把我们天天司空见惯的 SpringBoot 应用的启动类来拆解一下写出来：\n@SpringBootApplication\rpublic class CodeSheepApplication {\rpublic static void main( String[] args ) {\r// SpringApplication.run( CodeSheepApplication.class args ); // 这是传统SpringBoot应用的启动，一行代码搞定，内部默认做了很多事\rSpringApplication app = new SpringApplication( CodeSheepApplication.class );\rapp.setXXX( ... ); // 用户自定的扩展在此 ！！！\rapp.run( args );\r}\r}\r 这样一拆解后我们发现，我们也需要先构造 SpringApplication 类对象，然后调用该对象的 run() 方法。那么接下来就讲讲 SpringApplication 的构造过程 以及其 run() 方法的流程，搞清楚了这个，那么也就搞清楚了SpringBoot应用是如何运行起来的！\n SpringApplication 实例的初始化 我们对照代码来看：\n四个关键的步骤已标注在图中，分别解释如下：\n ① 推断应用的类型：创建的是 REACTIVE应用、SERVLET应用、NONE 三种中的某一种   ② 使用 SpringFactoriesLoader查找并加载 classpath下 META-INF/spring.factories文件中所有可用的 ApplicationContextInitializer   ③ 使用 SpringFactoriesLoader查找并加载 classpath下 META-INF/spring.factories文件中的所有可用的 ApplicationListener   ④ 推断并设置 main方法的定义类    SpringApplication 的run()方法探秘 先看看代码长啥样子：\n各个主要步骤我已经标注在上图之中了，除此之外，我也按照自己的理解画了一个流程图如下所示，可以对照数字标示看一下：\n我们将各步骤总结精炼如下：\n 通过 SpringFactoriesLoader 加载 META-INF/spring.factories 文件，获取并创建 SpringApplicationRunListener 对象 然后由 SpringApplicationRunListener 来发出 starting 消息 创建参数，并配置当前 SpringBoot 应用将要使用的 Environment 完成之后，依然由 SpringApplicationRunListener 来发出 environmentPrepared 消息 创建 ApplicationContext 初始化 ApplicationContext，并设置 Environment，加载相关配置等 由 SpringApplicationRunListener 来发出 contextPrepared 消息，告知SpringBoot 应用使用的 ApplicationContext 已准备OK 将各种 beans 装载入 ApplicationContext，继续由 SpringApplicationRunListener 来发出 contextLoaded 消息，告知 SpringBoot 应用使用的 ApplicationContext 已装填OK refresh ApplicationContext，完成IoC容器可用的最后一步 由 SpringApplicationRunListener 来发出 started 消息 完成最终的程序的启动 由 SpringApplicationRunListener 来发出 running 消息，告知程序已运行起来了至此，全流程结束！  ","id":86,"section":"posts","summary":"转载 · 原文链接：https://www.codesheep.cn/2018/09/04/springboot-startup-process","tags":["Spring Boot"],"title":"SpringBoot应用程序启动过程","uri":"https://bluestaree.github.io/2020/04/springboot%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E5%90%AF%E5%8A%A8%E8%BF%87%E7%A8%8B/","year":"2020"},{"content":"  转载 · 原文链接：https://www.codesheep.cn/2018/07/30/at-SpringBootApplication-zhujie/\n 概 述 我们在开发基于 SpringBoot 的应用时，用到了一些新的注解和类，正式由于其存在，才让JavaEE的开发如鱼得水。这其中我们用的最多的注解之一，当属 SpringBoot 应用启动类上的 @SpringBootApplication 注解了\n本文就来看看它到底是个啥！\n@SpringBootApplication 背后到底是什么？ @SpringBootApplication注解实际上是SpringBoot提供的一个复合注解，我们来看一看其源码：\n@Target(ElementType.TYPE)\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\r@Inherited\r@SpringBootConfiguration\r@EnableAutoConfiguration\r@ComponentScan(excludeFilters = {\r@Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),\r@Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) })\rpublic @interface SpringBootApplication {\r...\r}\r 看得很清楚，其是一个合成体，但其中最重要的三个注解分别是：\n @SpringBootConfiguration @EnableAutoConfiguration @ComponentScan  我们不妨称其为 “ 三体结构 ” 吧！\n如果我们不怕麻烦，在 SpringBoot 应用的启动类上用这个三个注解代替@SpringBootApplication 注解发现也是没问题的：\n@SpringBootConfiguration\r@EnableAutoConfiguration\r@ComponentScan\rpublic class TestSpringBootApplication {\r...\r}\r 下面分别剖析一下这三个注解的功效！\n  @SpringBootConfiguration 看代码吧，代码里是这样写的：\n@Target(ElementType.TYPE)\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\r@Configuration\rpublic @interface SpringBootConfiguration {\r}\r 这说明 @SpringBootConfiguration 也是来源于 @Configuration，二者功能都是将当前类标注为配置类，并将当前类里以 @Bean 注解标记的方法的实例注入到srping容器中，实例名即为方法名。\n至于@Configuration，我想在非SpringBoot时代大家应该不陌生吧，作用是配置Spring容器，也即 JavaConfig 形式的 Spring IoC 容器的配置类所使用。\n到目前来看，好像还没有什么新东西！！！\n  @EnableAutoConfiguration 再继续看代码，代码是这样的：\n@Target(ElementType.TYPE)\r@Retention(RetentionPolicy.RUNTIME)\r@Documented\r@Inherited\r@AutoConfigurationPackage\r@Import(AutoConfigurationImportSelector.class)\rpublic @interface EnableAutoConfiguration {\r...\r}\r @EnableAutoConfiguration 注解启用自动配置，其可以帮助 SpringBoot 应用将所有符合条件的 @Configuration 配置都加载到当前 IoC 容器之中，可以简要用图形示意如下：\n@EnableAutoConfiguration 幕后的组件调用关系\n接下来我们对照源码，来解释一下这个流程：\n @EnableAutoConfiguration 借助 AutoConfigurationImportSelector 的帮助，而后者通过实现 selectImports() 方法来导出 Configuration  selectImports()\n AutoConfigurationImportSelector 类的 selectImports() 方法里面通过调用Spring Core 包里 SpringFactoriesLoader 类的 loadFactoryNames() 方法  SpringFactoriesLoader.loadFactoryNames()\n 最终通过 SpringFactoriesLoader.loadFactoryNames() 读取了 ClassPath 下面的 META-INF/spring.factories 文件来获取所有导出类。  而spring.factories 文件里关于 EnableAutoConfiguration 的配置其实就是一个键值对结构，样子大概长下面这样：\nspring.factories\n说了这么多，如果从稍微宏观一点的角度 概括总结 上述这一过程那就是：\n从 ClassPath下扫描所有的 META-INF/spring.factories 配置文件，并将spring.factories 文件中的 EnableAutoConfiguration 对应的配置项通过反射机制实例化为对应标注了 @Configuration 的形式的IoC容器配置类，然后注入IoC容器。\n@ComponentScan\n@ComponentScan 对应于XML配置形式中的 context:component-scan，用于将一些标注了特定注解的bean定义批量采集注册到Spring的IoC容器之中，这些特定的注解大致包括：\n @Controller @Entity @Component @Service @Repository  等等\n对于该注解，还可以通过 basePackages 属性来更细粒度的控制该注解的自动扫描范围，比如：\n@ComponentScan(basePackages = {\u0026quot;cn.codesheep.controller\u0026quot;,\u0026quot;cn.codesheep.entity\u0026quot;})\r 可见 这个注解也并不是什么新东西！\n","id":87,"section":"posts","summary":"转载 · 原文链接：https://www.codesheep.cn/2018/07/30/at-SpringBootApplication-z","tags":["Spring Boot"],"title":"@SpringBootApplication注解","uri":"https://bluestaree.github.io/2020/04/springbootapplication%E6%B3%A8%E8%A7%A3/","year":"2020"},{"content":" 查看当前所有镜像\ndocker images\n查看所有容器\ndocker ps -a\n根据一个镜像创建一个容器并运行 (windows环境)\ndocker run -d \u0026ndash;name mysql_3308 -e MYSQL_ROOT_HOST=% -e MYSQL_ROOT_PASSWORD=tdt123 -p 3307:3306 -v //f/docker/mysql_3308:/var/lib/mysql mysql:5.5\n \u0026ndash;name mysql_3308 \u0026hellip; mysql:5.5 设置容器名，及选用镜像（如果没有tag即5.5，则会自动下载最新版的mysql） -e MYSQL_ROOT_HOST=% 允许远程登录 -e MYSQL_ROOT_PASSWORD=123456 root登录密码 -p 3308:3306 端口映射至宿主机3308 -d 后台运行容器，并返回容器ID； -v //f/docker/mysql_3308:/var/lib/mysql 绑定镜像位置到宿主机上 \u0026ndash;lower_case_table_names=1 不区分大小写   其他栗子\ndocker run \u0026ndash;name mysql -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -v //e/docker/share/mysql_3306:/var/lib/mysql mysql\ndocker create \u0026ndash;name tracker \u0026ndash;net host -v //e/docker/data/tracker:/var/fdfs delron/fastdfs tracker\ndocker create \u0026ndash;name es -p 9200:9200 -p 9300:9300 -e \u0026ldquo;discovery.type=single-node\u0026rdquo; -v //e/docker/es/data/:/usr/share/elasticsearch/data elasticsearch:6.5.4\ndocker create \u0026ndash;name kibana -p 5601:5601 -v //e/docker/es/kibana/kibana.yml:/usr/share/kibana/config/kibana.yml kibana:6.5.4\ndocker create \u0026ndash;name redis -p 6379:6379 -v //e/docker/redis/data:/data redis:5.0.2\n复制当前目录文件至指定容器位置\ndocker cp elasticsearch-analysis-ik-6.5.4.zip es:/usr/share/elasticsearch/plugins/\n启动容器并显示启动日志\ndocker start rabbitmq \u0026amp;\u0026amp; docker logs -f rabbitmq\n进入容器\ndocker exec -it 775c7c9ee1e1 /bin/bash (进入容器控制台)\n 775c7c9ee1e1 为容器ID  查看容器信息\ndokcer inspect 容器名\n查找文件\nfind / -name tracker.conf\n保存镜像文件\ndocker save\ndocker save -o python_3.tar python:3\n加载镜像文件\ndocker load\ndocker load -i python_3.tar\n-\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\n","id":88,"section":"posts","summary":"查看当前所有镜像 docker images 查看所有容器 docker ps -a 根据一个镜像创建一个容器并运行 (windows环境) docker run -d \u0026ndash;name mysql_3308 -e MYSQL_ROOT_HOST=% -e MYSQL_ROOT_PASSWORD=tdt123 -p 3307:3306 -v //f/docker/mysql_3308:/var/lib/mysql mysql:5.5 \u0026ndash;name mysql_3308 \u0026hellip; mysql:5.5 设置容器名，及","tags":["docker"],"title":"Docker常用命令","uri":"https://bluestaree.github.io/2020/04/docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","year":"2020"},{"content":"  转载 · 原文链接：SpringBoot应用部署于外置Tomcat容器\n 0x01. 概述 SpringBoot平时我们用的爽歪歪，爽到它自己连Tomcat都自集成了，我们可以直接编写SBT启动类，然后一键开启内置的Tomcat容器服务，确实是很好上手。但考虑到实际的情形中，我们的Tomcat服务器一般是另外部署好了的，有专门的维护方式。此时我们需要剥离掉SBT应用内置的Tomcat服务器，进而将应用发布并部署到外置的Tomcat容器之中，本文就实践一下这个。\n0x02. 修改打包方式 修改项目的pom.xml配置，我们修改其打包方式为war方式，如：\n\u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;demo\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt;\r\u0026lt;packaging\u0026gt;war\u0026lt;/packaging\u0026gt;\r  0x03. 移除SBT自带的嵌入式Tomcat 修改pom.xml，从maven的pom中移除springboot自带的的嵌入式tomcat插件\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt;\r\u0026lt;!-- 移除嵌入式tomcat插件 --\u0026gt;\r\u0026lt;exclusions\u0026gt;\r\u0026lt;exclusion\u0026gt;\r\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;spring-boot-starter-tomcat\u0026lt;/artifactId\u0026gt;\r\u0026lt;/exclusion\u0026gt;\r\u0026lt;/exclusions\u0026gt;\r\u0026lt;/dependency\u0026gt;\r  0x04. 添加servlet-api依赖 修改pom.xml，在maven的pom中添加servlet-api的依赖\n\u0026lt;dependency\u0026gt;\r\u0026lt;groupId\u0026gt;javax.servlet\u0026lt;/groupId\u0026gt;\r\u0026lt;artifactId\u0026gt;javax.servlet-api\u0026lt;/artifactId\u0026gt;\r\u0026lt;version\u0026gt;3.1.0\u0026lt;/version\u0026gt;\r\u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt;\r\u0026lt;/dependency\u0026gt;\r  0x05. 修改启动类，并重写初始化方法 在SpringBoot中我们平常用main方法启动的方式，都有一个SpringBootApplication的启动类，类似代码如下：\n@SpringBootApplication\rpublic class Application {\rpublic static void main(String[] args) {\rSpringApplication.run(Application.class, args);\r}\r}\r 而我们现在需要类似于web.xml的配置方式来启动spring应用，为此，我们在Application类的同级添加一个SpringBootStartApplication类，其代码如下:\n// 修改启动类，继承 SpringBootServletInitializer 并重写 configure 方法\rpublic class SpringBootStartApplication extends SpringBootServletInitializer {\r@Override\rprotected SpringApplicationBuilder configure(SpringApplicationBuilder builder) {\r// 注意这里一定要指向原先用main方法执行的Application启动类\rreturn builder.sources(Application.class);\r}\r}\r  0x06. 部署到外部的Tomcat容器并验证  在项目根目录下（即包含pom.xml的目录）记性maven打包操作：  mvn clean package\r 等待打包完成，出现 [INFO] BUILD SUCCESS 即为打包成功\n 然后我们把target目录下生成的war包放到tomcat的webapps目录下，启动tomcat，即可自动解压部署。  最后在浏览器中验证:\nhttp://YOUR_IP:[端口号]/[打包项目名]\r ","id":89,"section":"posts","summary":"转载 · 原文链接：SpringBoot应用部署于外置Tomcat容器 0x01. 概述 SpringBoot平时我们用的爽歪歪，爽到它自己连Tomcat都自","tags":["Spring Boot"],"title":"SpringBoot应用部署于外置Tomcat容器","uri":"https://bluestaree.github.io/2020/04/springboot%E5%BA%94%E7%94%A8%E9%83%A8%E7%BD%B2%E4%BA%8E%E5%A4%96%E7%BD%AEtomcat%E5%AE%B9%E5%99%A8/","year":"2020"}],"tags":[{"title":"captcha","uri":"https://bluestaree.github.io/tags/captcha/"},{"title":"charles","uri":"https://bluestaree.github.io/tags/charles/"},{"title":"docker","uri":"https://bluestaree.github.io/tags/docker/"},{"title":"dubbo","uri":"https://bluestaree.github.io/tags/dubbo/"},{"title":"Elasticsearch","uri":"https://bluestaree.github.io/tags/elasticsearch/"},{"title":"equals","uri":"https://bluestaree.github.io/tags/equals/"},{"title":"Gradle","uri":"https://bluestaree.github.io/tags/gradle/"},{"title":"hashCode","uri":"https://bluestaree.github.io/tags/hashcode/"},{"title":"hibernate","uri":"https://bluestaree.github.io/tags/hibernate/"},{"title":"Idea","uri":"https://bluestaree.github.io/tags/idea/"},{"title":"jdk8","uri":"https://bluestaree.github.io/tags/jdk8/"},{"title":"json","uri":"https://bluestaree.github.io/tags/json/"},{"title":"jvm","uri":"https://bluestaree.github.io/tags/jvm/"},{"title":"Maven","uri":"https://bluestaree.github.io/tags/maven/"},{"title":"milvus","uri":"https://bluestaree.github.io/tags/milvus/"},{"title":"mybatis","uri":"https://bluestaree.github.io/tags/mybatis/"},{"title":"Nacos","uri":"https://bluestaree.github.io/tags/nacos/"},{"title":"Netty","uri":"https://bluestaree.github.io/tags/netty/"},{"title":"nginx","uri":"https://bluestaree.github.io/tags/nginx/"},{"title":"Rabbitmq","uri":"https://bluestaree.github.io/tags/rabbitmq/"},{"title":"redis","uri":"https://bluestaree.github.io/tags/redis/"},{"title":"redisson","uri":"https://bluestaree.github.io/tags/redisson/"},{"title":"SaaS","uri":"https://bluestaree.github.io/tags/saas/"},{"title":"Seata","uri":"https://bluestaree.github.io/tags/seata/"},{"title":"Sentinel","uri":"https://bluestaree.github.io/tags/sentinel/"},{"title":"Spring Boot","uri":"https://bluestaree.github.io/tags/spring-boot/"},{"title":"Spring Cache","uri":"https://bluestaree.github.io/tags/spring-cache/"},{"title":"spring-security","uri":"https://bluestaree.github.io/tags/spring-security/"},{"title":"正则表达式","uri":"https://bluestaree.github.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"title":"缓存","uri":"https://bluestaree.github.io/tags/%E7%BC%93%E5%AD%98/"}]}